[
  {
    "objectID": "templates/multi_language_template.html",
    "href": "templates/multi_language_template.html",
    "title": "(Language) vs (Language): (Method Name)",
    "section": "",
    "text": "This first section should provide a brief background on the methodology with links to associated journal articles, or relevant sources. This should give the reader a high level overview of the method and its implementation. This will be helpful in setting the stage for the examples and discussion that follow.\n\n\nWhen comparing between languages, it is helpful to have a table with links to the pages with deeper dive of each language for a given method method. For example, this table shows summaries for ANCOVA between R and SAS:\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nANCOVA using general linear model and lsmeans\nYes\nYes\nYes\nGLM() function from sasLM with EMEANS=TRUE is the easiest to use and matches SAS\n\n\n\nFurther, this table provides a summary of the examples that will be showcased further down in the document related to Poisson regression in R and SAS:\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nScenario 1: Basic Functionality\nExample: Yes\nExample: Yes\nExample 1: Yes\nExample 2: No\nSpecific settings or packages required for exact match\n\n\nScenario 2: Advanced Feature\nExample: Yes\nExample: Yes\nExample 3: Partial\nSpecial considerations for data structure or assumptions\n\n\n\n\n\n\nThis section should describe what libraries, packages, or additional materials needed for the analysis described.\n\nlibrary(lme4)"
  },
  {
    "objectID": "templates/multi_language_template.html#comparisons-of-languages",
    "href": "templates/multi_language_template.html#comparisons-of-languages",
    "title": "(Language) vs (Language): (Method Name)",
    "section": "",
    "text": "When comparing between languages, it is helpful to have a table with links to the pages with deeper dive of each language for a given method method. For example, this table shows summaries for ANCOVA between R and SAS:\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nANCOVA using general linear model and lsmeans\nYes\nYes\nYes\nGLM() function from sasLM with EMEANS=TRUE is the easiest to use and matches SAS\n\n\n\nFurther, this table provides a summary of the examples that will be showcased further down in the document related to Poisson regression in R and SAS:\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nScenario 1: Basic Functionality\nExample: Yes\nExample: Yes\nExample 1: Yes\nExample 2: No\nSpecific settings or packages required for exact match\n\n\nScenario 2: Advanced Feature\nExample: Yes\nExample: Yes\nExample 3: Partial\nSpecial considerations for data structure or assumptions"
  },
  {
    "objectID": "templates/multi_language_template.html#libraries-or-extensions-needed",
    "href": "templates/multi_language_template.html#libraries-or-extensions-needed",
    "title": "(Language) vs (Language): (Method Name)",
    "section": "",
    "text": "This section should describe what libraries, packages, or additional materials needed for the analysis described.\n\nlibrary(lme4)"
  },
  {
    "objectID": "templates/multi_language_template.html#scenario-1-basic-functionality",
    "href": "templates/multi_language_template.html#scenario-1-basic-functionality",
    "title": "(Language) vs (Language): (Method Name)",
    "section": "Scenario 1: Basic Functionality",
    "text": "Scenario 1: Basic Functionality\nExample: This section compares the implementation of Poisson Regression in R and SAS. Poisson regression is used to model count data and contingency tables. It’s particularly useful for modeling the number of events occurring within a fixed period of time or space.\n\nRSAS\n\n\nFor R packages, it is helpful to prepend package names to functions so new readers can understand where specific functions originate, especially with new packages.\n\n# R code for basic Poisson Regression\nexample_model &lt;- stats::glm(\n  count ~ predictor,\n  family = stpoisson(link = \"log\"),\n  data = example_data\n)\n\n# Summary of the model\nsummary(example_model)\n\n\n\n\n/* SAS code for basic Poisson Regression */\nproc genmod data=example_data;\n    class predictor;\n    model count = predictor / dist=poisson link=log;\nrun;\n\n\n\n\nDescribe key options utilized in the code, along with a screenshot showcasing the output."
  },
  {
    "objectID": "templates/multi_language_template.html#scenario-2-advanced-feature",
    "href": "templates/multi_language_template.html#scenario-2-advanced-feature",
    "title": "(Language) vs (Language): (Method Name)",
    "section": "Scenario 2: Advanced Feature",
    "text": "Scenario 2: Advanced Feature\nProvide a detailed description of the scenario. Example: Address specific advanced features or configurations that may be necessary for more complex analyses.\n\nR CodeSAS\n\n\n\n# R code for handling overdispersion\nalternative_model &lt;- stats::glm(\n  count ~ predictor,\n  family = quasipoisson(link = \"log\"),\n  data = example_data\n)\n\n# Summary of the alternative model\nsummary(alternative_model)\n\n\n\n\n/* SAS code for handling overdispersion */\nproc genmod data=example_data;\n    class predictor;\n    model count = predictor / dist=poisson link=log scale=pearson;\nrun;\n\n\n\n\nDescribe key options utilized in the code, along with a screenshot showcasing the output."
  },
  {
    "objectID": "templates/multi_language_template.html#comparison-of-languages",
    "href": "templates/multi_language_template.html#comparison-of-languages",
    "title": "(Language) vs (Language): (Method Name)",
    "section": "Comparison of Languages",
    "text": "Comparison of Languages\nProvide a detailed comparison of the results obtained from the comparison of the langauges and methods. Highlight any differences/similarities and provide explanations if possible.\n\n\n\n\n\n\n\n\n\n\nStatistic\nR Result\nSAS Result\nMatch\nNotes\n\n\n\n\nDegrees of Freedom\n98\n98\nYes\n\n\n\nCoefficient Estimate for Predictor\n0.1\n0.1\nYes\n\n\n\np-value\n0.05\n0.05\nYes"
  },
  {
    "objectID": "templates/multi_language_template.html#special-considerations",
    "href": "templates/multi_language_template.html#special-considerations",
    "title": "(Language) vs (Language): (Method Name)",
    "section": "Special Considerations",
    "text": "Special Considerations\nAddress any additional features or settings that need to be considered. This might include specific configuration settings, handling of special cases, or performance considerations.\nExample: For handling overdispersion in Poisson Regression, SAS provides the scale option in PROC GENMOD, while in R, one may have to switch to a quasi-Poisson family or use negative binomial regression.\n\nTroubleshooting and Edge Cases\nList potential issues that users may encounter and propose solutions or troubleshooting steps.\nExample:\n\nIssue: Non-convergence in Poisson Regression.\nSolution: Check for multicollinearity among predictors, scale the predictors, or switch to a more appropriate model family."
  },
  {
    "objectID": "templates/multi_language_template.html#conclusion",
    "href": "templates/multi_language_template.html#conclusion",
    "title": "(Language) vs (Language): (Method Name)",
    "section": "Conclusion",
    "text": "Conclusion\nFinally, add a conclusion section to the page. This may take on different forms but should broadly summarize the findings in the comparison of languages, packages, or approaches. In summarizing, be sure to include the advantages/limitations of the packages and approaches so the reader can understand the capabilities of the approaches to the statstical methodology.\nThere may be instances where you recommend specific languages, packages, or functions. Be sure to provide your rationale for these recommendations."
  },
  {
    "objectID": "templates/multi_language_template.html#references",
    "href": "templates/multi_language_template.html#references",
    "title": "(Language) vs (Language): (Method Name)",
    "section": "References",
    "text": "References\nBe sure to include any references or sources used for the analysis here. These could be external links to pages or in-text citations. This will all help the reader find material needed for further evaluation.\nR Documentation:\n\nglm function\n\nSAS Documentation:\n\nPROC GENMOD\n\nAlso, include this Session Info section. Manually add the packages used in your analysis in a vector, like shown below. This captures the environment used, which is important for reproducibility.\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package  * version date (UTC) lib source\n janitor    2.2.0   2023-02-02 [1] CRAN (R 4.4.0)\n readr      2.1.5   2024-01-10 [1] CRAN (R 4.4.0)\n survival   3.7-0   2024-06-05 [1] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n─ External software ──────────────────────────────────────────────────────────\n setting value\n SAS     9.04.01M7P080520\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "Comp/r-sas_correlation.html#codes",
    "href": "Comp/r-sas_correlation.html#codes",
    "title": "",
    "section": "Codes",
    "text": "Codes\nThe following table shows the three different types of correlations considered, their functions in each language and whether the results match\n\n\n\n\n\n\n\n\n\nCorrelation coefficient\nR code\nSAS code\nResults match\n\n\n\n\nPearson\ncor.test(x,y,method=\"pearson\")\nproc corr data pearson;\nvar x y;\nrun;\nYes\n\n\nSpearman\ncor.test(x,y,method=\"spearman\")\nproc corr data spearman;\nvar x y;\nrun;\nYes\n\n\nKendall\ncor.test(x,y,method=\"kendall\")\nproc corr data kendall;\nvar x y;\nrun;\nYes\n\n\n\n‘x’ and ‘y’ are variables in the dataset “data” for which we determine the correlation."
  },
  {
    "objectID": "Comp/r-sas_correlation.html#comparison-results",
    "href": "Comp/r-sas_correlation.html#comparison-results",
    "title": "",
    "section": "Comparison Results",
    "text": "Comparison Results\nExample: Lung Cancer Data\nData source: Loprinzi CL. Laurie JA. Wieand HS. Krook JE. Novotny PJ. Kugler JW. Bartel J. Law M. Bateman M. Klatt NE. et al. Prospective evaluation of prognostic variables from patient-completed questionnaires. North Central Cancer Treatment Group. Journal of Clinical Oncology. 12(3):601-7, 1994.\nSurvival in patients with advanced lung cancer from the North Central Cancer Treatment Group. Performance scores rate how well the patient can perform usual daily activities. Correlation was observed between age and meal.cal variables in the dataset.\n\n\n\n\n\n\n\n\n\n\nCorrelation coefficient\nSample estimates in R\np-value in R\nSample estimate in SAS\np-value in SAS\n\n\n\n\nPearson\n-0.2314107\n0.001722\n-0.23141\n0.0017\n\n\nSpearman\n-0.2073639\n0.005095\n-0.20736\n0.0051\n\n\nKendall\n-0.1443877\n0.00524\n-0.14439\n0.0052\n\n\n\nPlease note that the results in SAS are rounded at 5 decimals for sample estimates and 4 decimals for p-values."
  },
  {
    "objectID": "Comp/r-sas_correlation.html#summary",
    "href": "Comp/r-sas_correlation.html#summary",
    "title": "",
    "section": "Summary",
    "text": "Summary\nComparisons between SAS and R yield identical results for the tested dataset. R outputs test statistic values and p-values, whereas SAS offers descriptive statistics (N, mean, standard deviation, sum, minimum, maximum) for each variable, but does not display the test statistic values."
  },
  {
    "objectID": "Comp/r-sas_correlation.html#references",
    "href": "Comp/r-sas_correlation.html#references",
    "title": "",
    "section": "References",
    "text": "References\nPROC CORR: The CORR Procedure (sas.com)\ncor.test function - RDocumentation"
  },
  {
    "objectID": "Comp/r-sas_tipping_point.html",
    "href": "Comp/r-sas_tipping_point.html",
    "title": "R vs SAS Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "The following table shows the types of reference-based multiple imputation (rbmi) strategies used for a tipping point analysis with delta adjustments, along with each language’s capabilities and whether the results from each rbmi approach and language are consistent. The results only hold for data that are assumed to be normally distributed. In this comparison, we used the rbmi package in R and the so-called five macros in SAS.\nThe following assumptions are made in both languages:\n\nEqual unstructured covariance matrix across treatment groups\nSame covariates formula for the imputation and analysis model\nSimilar number of MCMC tuning parameters (burn-in, thinning) was used in the MCMC\nThe one intermittent missingness case was imputed under MAR assumption\n\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nrbmi delta adjustment - MI MAR\nYes\nYes\nYes\nResults will be (slightly) different given the randomness in multiple imputations\n\n\nrbmi delta adjustment - MI MNAR Copy Reference\nYes\nYes\nYes\nResults will be (slightly) different given the randomness in multiple imputations\n\n\nrbmi delta adjustment - MI MNAR Jump to Reference\nYes\nYes\nYes\nResults will be (slightly) different given the randomness in multiple imputations\n\n\nrbmi delta adjustment - MI MNAR Copy Increments in Reference\nYes\nYes\nYes\nResults will be (slightly) different given the randomness in multiple imputations\n\n\n\n\n\nThe following two figures compare the treatment effect estimates at visit 7 and corresponding p-values (y-axis) for each increasing delta in the intervention group (x-axis), while the delta adjustment in the control group is fixed to zero. The black crosses indicate exact tipping points as determined by linear interpolation. There seems to be a very good correspondence between R and SAS at M = 500, and near perfect correspondence between R and SAS at M = 5000.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe following figure compares the treatment effect estimate at visit 7 (and associated 95% confidence interval) at the “exact” tipping point for M = 500 and M = 5000. The range of the difference between R and SAS results for the treatment effect estimates are [-1.01 to -0.37]%. and [-0.18 to -0.07]% for M = 500 and M = 5000, respectively.\n\n\n\n\n\n\n\n\n\nMAR = Missing at Random; MNAR = Missing not at Random; JR = Jump to Reference; CR = Copy Reference; CIR = Copy Increments in Reference;"
  },
  {
    "objectID": "Comp/r-sas_tipping_point.html#comparison-results",
    "href": "Comp/r-sas_tipping_point.html#comparison-results",
    "title": "R vs SAS Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "The following two figures compare the treatment effect estimates at visit 7 and corresponding p-values (y-axis) for each increasing delta in the intervention group (x-axis), while the delta adjustment in the control group is fixed to zero. The black crosses indicate exact tipping points as determined by linear interpolation. There seems to be a very good correspondence between R and SAS at M = 500, and near perfect correspondence between R and SAS at M = 5000.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe following figure compares the treatment effect estimate at visit 7 (and associated 95% confidence interval) at the “exact” tipping point for M = 500 and M = 5000. The range of the difference between R and SAS results for the treatment effect estimates are [-1.01 to -0.37]%. and [-0.18 to -0.07]% for M = 500 and M = 5000, respectively.\n\n\n\n\n\n\n\n\n\nMAR = Missing at Random; MNAR = Missing not at Random; JR = Jump to Reference; CR = Copy Reference; CIR = Copy Increments in Reference;"
  },
  {
    "objectID": "Comp/r-sas_recurrent_events.html",
    "href": "Comp/r-sas_recurrent_events.html",
    "title": "R vs SAS Recurrent Events",
    "section": "",
    "text": "The following table shows the different recurrent event models, the capabilities of each language, and whether or not the results from each language match. For this comparison, we used the survival::coxph() function in R and the phreg procedure in SAS.\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nOriginal Andersen-Gill model\nYes (using ties = \"breslow\")\nYes (default is ties = breslow)\nYes\nYou may also opt for the default tie handling in R and set ties = efron in SAS to make the results match\n\n\nImproved Andersen-Gill model (LWYY model)\nYes (using ties = \"breslow\")\nYes (default is ties = breslow)\nYes\nYou may also opt for the default tie handling in R and set ties = efron in SAS to make the results match\n\n\nPrentice-Williams-Peterson total time model\nYes (using ties = \"breslow\")\nYes (default is ties = breslow)\nYes\nYou may also opt for the default tie handling in R and set ties = efron in SAS to make the results match\n\n\nPrentice-Williams-Peterson gap time model\nYes (using ties = \"breslow\")\nYes (default is ties = breslow)\nYes\nYou may also opt for the default tie handling in R and set ties = efron in SAS to make the results match\n\n\nWei-Lin-Weissfeld model\nYes (using ties = \"breslow\")\nYes (default is ties = breslow)\nYes\nYou may also opt for the default tie handling in R and set ties = efron in SAS to make the results match\n\n\n\nThe default methods for handling ties in Cox proportional hazards models are different in each language. R uses ties = \"efron\" by default, while SAS uses ties = breslow by default. If this argument remains unchanged in both languages, it can cause differences in outcome.\n\n\nHere is a table of comparison values of the overall hazard ratio for rx (1 = placebo, 2 = thiotepa) between the coxph() function in R and the phreg procedure in SAS. The Andersen-Gill and Prentice-Williams-Peterson models used the bladder2 dataset, while the Wei-Lin-Weissfeld model used the bladder dataset. More information on the bladder data can be found here.\n\n\n\nStatistic\ncoxph()\nphreg\nMatch\n\n\n\n\nOriginal Andersen-Gill\n\n\n\n\n\nHazard ratio\n0.631\n0.631\nYes\n\n\nRobust standard error\n0.229\n0.229\nYes\n\n\nP-value\n0.0447\n0.0447\nYes\n\n\n95% CI\n0.403 to 0.989\n0.403 to 0.989\nYes\n\n\nImproved Andersen-Gill (LWYY)\n\n\n\n\n\nHazard ratio\n0.631\n0.631\nYes\n\n\nRobust standard error\n0.258\n0.258\nYes\n\n\nP-value\n0.0747\n0.0747\nYes\n\n\n95% CI\n0.381 to 1.047\n0.381 to 1.047\nYes\n\n\nPrentice-Williams-Peterson: total time\n\n\n\n\n\nHazard ratio (overall)\n0.716\n0.716\nYes\n\n\nRobust standard error\n0.197\n0.197\nYes\n\n\nP-value\n0.0898\n0.0898\nYes\n\n\n95% CI\n0.487 to 1.053\n0.486 to 1.053\nYes\n\n\nPrentice-Williams-Peterson: gap time\n\n\n\n\n\nHazard ratio (overall)\n0.764\n0.764\nYes\n\n\nRobust standard error\n0.208\n0.208\nYes\n\n\nP-value\n0.1952\n0.1952\nYes\n\n\n95% CI\n0.508 to 1.148\n0.508 to 1.148\nYes\n\n\nWei-Lin-Weissfeld\n\n\n\n\n\nHazard ratio (overall)\n0.560\n0.560\nYes\n\n\nRobust standard error\n0.303\n0.303\nYes\n\n\nP-value\n0.0560\n0.0560\nYes\n\n\n95% CI\n0.309 to 1.015\n0.309 to 1.015\nYes\n\n\n\nThe table below shows the same comparison, but for the event-specific hazard ratios for rx for the Prentice-Williams-Peterson and Wei-Lin-Weissfeld models.\n\n\n\n\n\n\n\n\n\nStatistic\ncoxph()\nphreg\nMatch\n\n\n\n\nPrentice-Williams-Peterson: total time\n\n\n\n\n\nHazard ratios\n0.664, 0.660, 0.867, 1.111\n0.664, 0.659, 0.867, 1.111\nYes\n\n\nRobust standard error\n0.287, 0.424, 0.405, 0.470\n0.287, 0.424, 0.405, 0.470\nYes\n\n\nP-value\n0.1529, 0.3257, 0.7243, 0.8225\n0.1529, 0.3257, 0.7243, 0.8225\nYes\n\n\n95% CI\n0.378 to 1.164,\n0.288 to 1.513,\n0.392 to 1.918,\n0.443 to 2.790\n0.378 to 1.164,\n0.287 to 1.513,\n0.392 to 1.918,\n0.443 to 2.790\nYes\n\n\nPrentice-Williams-Peterson: gap time\n\n\n\n\n\nHazard ratios\n0.646, 0.740, 1.015, 1.062\n0.646, 0.739, 1.015, 1.062\nYes\n\n\nRobust standard error\n0.284, 0.389, 0.498, 0.540\n0.284, 0.389, 0.498, 0.540\nYes\n\n\nP-value\n0.1239, 0.4379, 0.9762, 0.9112\n0.1239, 0.4379, 0.9762, 0.9112\nYes\n\n\n95% CI\n0.371 to 1.127,\n0.345 to 1.585,\n0.382 to 2.696,\n0.369 to 3.059\n0.371 to 1.127,\n0.345 to 1.585,\n0.382 to 2.696,\n0.369 to 3.059\nYes\n\n\nWei-Lin-Weissfeld\n\n\n\n\n\nHazard ratios\n0.620, 0.523, 0.488, 0.570\n0.619, 0.523, 0.488, 0.570\nYes\n\n\nRobust standard error\n0.283, 0.368, 0.421, 0.496\n0.283, 0.368, 0.421, 0.496\nYes\n\n\nP-value\n0.0908, 0.0779, 0.0885, 0.2573\n0.0908, 0.0780, 0.0886, 0.2573\nYes\n\n\n95% CI\n0.356 to 1.079,\n0.254 to 1.075,\n0.214 to 1.114,\n0.216 to 1.507\n0.356 to 1.079,\n0.254 to 1.075,\n0.214 to 1.114,\n0.216 to 1.507\nYes"
  },
  {
    "objectID": "Comp/r-sas_recurrent_events.html#comparison-results",
    "href": "Comp/r-sas_recurrent_events.html#comparison-results",
    "title": "R vs SAS Recurrent Events",
    "section": "",
    "text": "Here is a table of comparison values of the overall hazard ratio for rx (1 = placebo, 2 = thiotepa) between the coxph() function in R and the phreg procedure in SAS. The Andersen-Gill and Prentice-Williams-Peterson models used the bladder2 dataset, while the Wei-Lin-Weissfeld model used the bladder dataset. More information on the bladder data can be found here.\n\n\n\nStatistic\ncoxph()\nphreg\nMatch\n\n\n\n\nOriginal Andersen-Gill\n\n\n\n\n\nHazard ratio\n0.631\n0.631\nYes\n\n\nRobust standard error\n0.229\n0.229\nYes\n\n\nP-value\n0.0447\n0.0447\nYes\n\n\n95% CI\n0.403 to 0.989\n0.403 to 0.989\nYes\n\n\nImproved Andersen-Gill (LWYY)\n\n\n\n\n\nHazard ratio\n0.631\n0.631\nYes\n\n\nRobust standard error\n0.258\n0.258\nYes\n\n\nP-value\n0.0747\n0.0747\nYes\n\n\n95% CI\n0.381 to 1.047\n0.381 to 1.047\nYes\n\n\nPrentice-Williams-Peterson: total time\n\n\n\n\n\nHazard ratio (overall)\n0.716\n0.716\nYes\n\n\nRobust standard error\n0.197\n0.197\nYes\n\n\nP-value\n0.0898\n0.0898\nYes\n\n\n95% CI\n0.487 to 1.053\n0.486 to 1.053\nYes\n\n\nPrentice-Williams-Peterson: gap time\n\n\n\n\n\nHazard ratio (overall)\n0.764\n0.764\nYes\n\n\nRobust standard error\n0.208\n0.208\nYes\n\n\nP-value\n0.1952\n0.1952\nYes\n\n\n95% CI\n0.508 to 1.148\n0.508 to 1.148\nYes\n\n\nWei-Lin-Weissfeld\n\n\n\n\n\nHazard ratio (overall)\n0.560\n0.560\nYes\n\n\nRobust standard error\n0.303\n0.303\nYes\n\n\nP-value\n0.0560\n0.0560\nYes\n\n\n95% CI\n0.309 to 1.015\n0.309 to 1.015\nYes\n\n\n\nThe table below shows the same comparison, but for the event-specific hazard ratios for rx for the Prentice-Williams-Peterson and Wei-Lin-Weissfeld models.\n\n\n\n\n\n\n\n\n\nStatistic\ncoxph()\nphreg\nMatch\n\n\n\n\nPrentice-Williams-Peterson: total time\n\n\n\n\n\nHazard ratios\n0.664, 0.660, 0.867, 1.111\n0.664, 0.659, 0.867, 1.111\nYes\n\n\nRobust standard error\n0.287, 0.424, 0.405, 0.470\n0.287, 0.424, 0.405, 0.470\nYes\n\n\nP-value\n0.1529, 0.3257, 0.7243, 0.8225\n0.1529, 0.3257, 0.7243, 0.8225\nYes\n\n\n95% CI\n0.378 to 1.164,\n0.288 to 1.513,\n0.392 to 1.918,\n0.443 to 2.790\n0.378 to 1.164,\n0.287 to 1.513,\n0.392 to 1.918,\n0.443 to 2.790\nYes\n\n\nPrentice-Williams-Peterson: gap time\n\n\n\n\n\nHazard ratios\n0.646, 0.740, 1.015, 1.062\n0.646, 0.739, 1.015, 1.062\nYes\n\n\nRobust standard error\n0.284, 0.389, 0.498, 0.540\n0.284, 0.389, 0.498, 0.540\nYes\n\n\nP-value\n0.1239, 0.4379, 0.9762, 0.9112\n0.1239, 0.4379, 0.9762, 0.9112\nYes\n\n\n95% CI\n0.371 to 1.127,\n0.345 to 1.585,\n0.382 to 2.696,\n0.369 to 3.059\n0.371 to 1.127,\n0.345 to 1.585,\n0.382 to 2.696,\n0.369 to 3.059\nYes\n\n\nWei-Lin-Weissfeld\n\n\n\n\n\nHazard ratios\n0.620, 0.523, 0.488, 0.570\n0.619, 0.523, 0.488, 0.570\nYes\n\n\nRobust standard error\n0.283, 0.368, 0.421, 0.496\n0.283, 0.368, 0.421, 0.496\nYes\n\n\nP-value\n0.0908, 0.0779, 0.0885, 0.2573\n0.0908, 0.0780, 0.0886, 0.2573\nYes\n\n\n95% CI\n0.356 to 1.079,\n0.254 to 1.075,\n0.214 to 1.114,\n0.216 to 1.507\n0.356 to 1.079,\n0.254 to 1.075,\n0.214 to 1.114,\n0.216 to 1.507\nYes"
  },
  {
    "objectID": "Comp/r-sas_ancova.html",
    "href": "Comp/r-sas_ancova.html",
    "title": "R vs SAS ANCOVA",
    "section": "",
    "text": "The following table shows the types of One Sample t-test analysis, the capabilities of each language, and whether or not the results from each language match.\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nANCOVA using general linear model and lsmeans\nYes\nYes\nYes\nGLM() function from sasLM with EMEANS=TRUE is the easiest to use and matches SAS\n\n\n\n\n\nHere is a table of comparison values between lm() from the stats package, GLM() from the sasLM package, and SAS PROC GLM:\n\n\n\n\n\n\n\n\n\n\n\nStatistic\nlm()\nGLM()\nPROC GLM\nMatch\nNotes\n\n\n\n\nType I, Sum sq, drug\n293.6000\n293.6000\n293.6000\nYes\n\n\n\nType I, Sum sq, pre\n577.897\n577.8974\n577.8974\nYes\n\n\n\nType III, Sum sq, drug\n68.554\n68.55371\n68.55371\nYes\n\n\n\nType III, Sum sq, pre\n577.897\n577.89740\n577.89740\nYes\n\n\n\nLSmean drugA\n6.71\n6.714963\n6.714963\nYes\n\n\n\nLSmean drugD\n6.82\n6.823935\n6.823935\nYes\n\n\n\nLSmean drugF\n10.16\n10.161102\n10.161102\nYes"
  },
  {
    "objectID": "Comp/r-sas_ancova.html#comp",
    "href": "Comp/r-sas_ancova.html#comp",
    "title": "R vs SAS ANCOVA",
    "section": "",
    "text": "Here is a table of comparison values between lm() from the stats package, GLM() from the sasLM package, and SAS PROC GLM:\n\n\n\n\n\n\n\n\n\n\n\nStatistic\nlm()\nGLM()\nPROC GLM\nMatch\nNotes\n\n\n\n\nType I, Sum sq, drug\n293.6000\n293.6000\n293.6000\nYes\n\n\n\nType I, Sum sq, pre\n577.897\n577.8974\n577.8974\nYes\n\n\n\nType III, Sum sq, drug\n68.554\n68.55371\n68.55371\nYes\n\n\n\nType III, Sum sq, pre\n577.897\n577.89740\n577.89740\nYes\n\n\n\nLSmean drugA\n6.71\n6.714963\n6.714963\nYes\n\n\n\nLSmean drugD\n6.82\n6.823935\n6.823935\nYes\n\n\n\nLSmean drugF\n10.16\n10.161102\n10.161102\nYes"
  },
  {
    "objectID": "Comp/r-sas-python_survey-stats-summary.html",
    "href": "Comp/r-sas-python_survey-stats-summary.html",
    "title": "R vs SAS vs Python Survey Summary Statistics",
    "section": "",
    "text": "This document will compare the survey summary statistics functionality in SAS (available through SAS/STAT), R (available from the {survey} package), and Python (available from the samplics package), highlighting differences in methods and results. Only the default Taylor series linearisation method for calculating variances is used in all languages. A more detailed comparison between R and SAS for specific methods and use-cases is available in (“Software for Analysis of YRBS Data” 2017), (So et al. 2020), or (Damico 2009). For a general guide to survey statistics, which has companion guides for both R and SAS, see (Lohr 2022)."
  },
  {
    "objectID": "Comp/r-sas-python_survey-stats-summary.html#r",
    "href": "Comp/r-sas-python_survey-stats-summary.html#r",
    "title": "R vs SAS vs Python Survey Summary Statistics",
    "section": "R",
    "text": "R\n\nlibrary(survey)\n\ndata(\"nhanes\")\n\nnhanes_design &lt;- survey::svydesign(\n  data = nhanes,\n  id = ~SDMVPSU, # Specify the PSU/cluster column\n  strata = ~SDMVSTRA, # The stratification column\n  weights = ~WTMEC2YR, # The weighting column\n  nest = TRUE # Allows for PSUs with the same name nested within different strata\n)\n\n# Mean of HI_CHOL\nhi_chol_mean &lt;- survey::svymean(~HI_CHOL, nhanes_design, na.rm = TRUE)\n\n# Sum of HI_CHOL\nhi_chol_sum &lt;- survey::svytotal(~HI_CHOL, nhanes_design, na.rm = TRUE)\n\n# Ratio of HI_CHOL / RIAGENDR\nhi_chol_ratio &lt;- survey::svyratio(\n  numerator = ~HI_CHOL,\n  denominator = ~RIAGENDR,\n  nhanes_design,\n  na.rm = TRUE,\n  ci = TRUE,\n  se = TRUE,\n  separate = FALSE\n)\n\n# Proportion of different AGECAT values\nagecat_props &lt;- survey::svymean(~agecat, nhanes_design, na.rm = TRUE)\n\n# Quantiles of HI_CHOL\nhi_chol_quart &lt;- survey::svyquantile(\n  ~HI_CHOL,\n  nhanes_design,\n  quantiles = c(0.025, 0.5, 0.975),\n  na.rm = TRUE,\n  ci = TRUE\n)\n\n# Domain analysis of mean of HI_CHOL by race, with design effect\nhi_chol_mean_by_race &lt;- survey::svyby(\n  ~HI_CHOL,\n  ~race,\n  nhanes_design,\n  svymean,\n  na.rm = TRUE,\n  deff = \"replace\"\n)\n\nprint(list(\n  \"Mean of HI_CHOL\" = coef(hi_chol_mean),\n  \"SE of Mean HI_CHOL\" = survey::SE(hi_chol_mean),\n  \"CL of Mean HI_CHOL\" = confint(\n    hi_chol_mean,\n    df = survey::degf(nhanes_design)\n  ),\n  \"Sum of HI_CHOL\" = coef(hi_chol_sum),\n  \"SE of Sum HI_CHOL\" = survey::SE(hi_chol_sum),\n  \"CL of Sum HI_CHOL\" = confint(hi_chol_sum, df = survey::degf(nhanes_design)),\n  \"Ratio of HI_CHOL / RIAGENDR\" = coef(hi_chol_ratio),\n  \"SE of Ratio HI_CHOL / RIAGENDR\" = survey::SE(hi_chol_ratio),\n  \"CL of Ratio HI_CHOL / RIAGENDR\" = confint(\n    hi_chol_ratio,\n    df = survey::degf(nhanes_design)\n  ),\n  \"Proportion of AGECAT\" = coef(agecat_props),\n  \"SE of Proportion AGECAT\" = survey::SE(agecat_props),\n  \"CL of Proportion AGECAT\" = confint(\n    agecat_props,\n    df = survey::degf(nhanes_design)\n  ),\n  \"Quantiles of HI_CHOL\" = coef(hi_chol_quart),\n  \"SE of Quantiles HI_CHOL\" = survey::SE(hi_chol_quart),\n  \"CL of Quantiles HI_CHOL\" = confint(\n    hi_chol_quart,\n    df = survey::degf(nhanes_design)\n  ),\n  \"Mean of HI_CHOL by race\" = coef(hi_chol_mean_by_race),\n  \"SE of HI_CHOL by race\" = survey::SE(hi_chol_mean_by_race),\n  \"CL of HI_CHOL by race\" = confint(\n    hi_chol_mean_by_race,\n    df = survey::degf(nhanes_design)\n  ),\n  \"Design Effect of HI_CHOL by race\" = hi_chol_mean_by_race$DEff.HI_CHOL\n))\n\n$`Mean of HI_CHOL`\n HI_CHOL \n0.112143 \n\n$`SE of Mean HI_CHOL`\n           HI_CHOL\nHI_CHOL 0.00544584\n\n$`CL of Mean HI_CHOL`\n            2.5 %    97.5 %\nHI_CHOL 0.1005983 0.1236876\n\n$`Sum of HI_CHOL`\n HI_CHOL \n28635245 \n\n$`SE of Sum HI_CHOL`\n        HI_CHOL\nHI_CHOL 2020711\n\n$`CL of Sum HI_CHOL`\n           2.5 %   97.5 %\nHI_CHOL 24351530 32918961\n\n$`Ratio of HI_CHOL / RIAGENDR`\nHI_CHOL/RIAGENDR \n      0.07422209 \n\n$`SE of Ratio HI_CHOL / RIAGENDR`\nHI_CHOL/RIAGENDR \n     0.003714728 \n\n$`CL of Ratio HI_CHOL / RIAGENDR`\n                      2.5 %     97.5 %\nHI_CHOL/RIAGENDR 0.06634722 0.08209696\n\n$`Proportion of AGECAT`\n  agecat(0,19]  agecat(19,39]  agecat(39,59] agecat(59,Inf] \n     0.2077495      0.2934079      0.3032896      0.1955530 \n\n$`SE of Proportion AGECAT`\n  agecat(0,19]  agecat(19,39]  agecat(39,59] agecat(59,Inf] \n   0.006129950    0.009560692    0.004519463    0.008092578 \n\n$`CL of Proportion AGECAT`\n                   2.5 %    97.5 %\nagecat(0,19]   0.1947546 0.2207444\nagecat(19,39]  0.2731401 0.3136756\nagecat(39,59]  0.2937088 0.3128704\nagecat(59,Inf] 0.1783975 0.2127085\n\n$`Quantiles of HI_CHOL`\nHI_CHOL.0.025   HI_CHOL.0.5 HI_CHOL.0.975 \n            0             0             1 \n\n$`SE of Quantiles HI_CHOL`\nHI_CHOL.0.025   HI_CHOL.0.5 HI_CHOL.0.975 \n    0.2358596     0.2358596     0.0000000 \n\n$`CL of Quantiles HI_CHOL`\n              l u\nHI_CHOL.0.025 0 1\nHI_CHOL.0.5   0 1\nHI_CHOL.0.975 1 1\n\n$`Mean of HI_CHOL by race`\n         1          2          3          4 \n0.10149167 0.12164921 0.07864006 0.09967861 \n\n$`SE of HI_CHOL by race`\n[1] 0.006245843 0.006604134 0.010384645 0.024666227\n\n$`CL of HI_CHOL by race`\n       2.5 %    97.5 %\n1 0.08825107 0.1147323\n2 0.10764907 0.1356493\n3 0.05662560 0.1006545\n4 0.04738854 0.1519687\n\n$`Design Effect of HI_CHOL by race`\n[1] 1.082734 1.407822 2.091156 3.098290"
  },
  {
    "objectID": "Comp/r-sas-python_survey-stats-summary.html#sas",
    "href": "Comp/r-sas-python_survey-stats-summary.html#sas",
    "title": "R vs SAS vs Python Survey Summary Statistics",
    "section": "SAS",
    "text": "SAS\n\n* Mean, sum quantile of HI_CHOL;\nproc surveymeans data=nhanes mean sum clm quantile=(0.025 0.5 0.975);\n    cluster SDMVPSU;\n    strata SDMVSTRA;\n    weight WTMEC2YR;\n    var HI_CHOL;\nrun;\n\n* Ratio of HI_CHOL / RIAGENDR;\nproc surveymeans data=nhanes;\n    cluster SDMVPSU;\n    strata SDMVSTRA;\n    weight WTMEC2YR;\n    ratio HI_CHOL / RIAGENDR;\nrun;\n\n* Proportions of agecat;\nproc surveyfreq data=nhanes;\n    cluster SDMVPSU;\n    strata SDMVSTRA;\n    weight WTMEC2YR;\n    table agecat / cl;\nrun;\n\n* Mean and DEFF of HI_CHOL by race;\nproc surveymeans data=nhanes mean deff;\n    cluster SDMVPSU;\n    strata SDMVSTRA;\n    weight WTMEC2YR;\n    domain race;\n    var HI_CHOL;\nrun;\n\n\n                                                 The SURVEYMEANS Procedure\n\n                                                        Data Summary\n\n                                            Number of Strata                  15\n                                            Number of Clusters                31\n                                            Number of Observations          8591\n                                            Sum of Weights             276536446\n\n\n                                                         Statistics\n\n                                Std Error                                                Std Error\n Variable            Mean         of Mean       95% CL for Mean                Sum          of Sum        95% CL for Sum\n --------------------------------------------------------------------------------------------------------------------------\n HI_CHOL         0.112143        0.005446    0.10059829 0.12368762        28635245         2020711    24351529.8 32918960.7\n --------------------------------------------------------------------------------------------------------------------------\n\n\n                                                         Quantiles\n\n                                                                          Std\n                     Variable       Percentile       Estimate           Error    95% Confidence Limits\n                     ---------------------------------------------------------------------------------\n                     HI_CHOL          2.5                   0        0.024281    -0.0514730 0.05147298\n                                       50 Median            0        0.024281    -0.0514730 0.05147298\n                                     97.5            0.777070        0.024281     0.7255973 0.82854324\n                     ---------------------------------------------------------------------------------\n\n                                                 The SURVEYMEANS Procedure\n\n                                                        Data Summary\n\n                                            Number of Strata                  15\n                                            Number of Clusters                31\n                                            Number of Observations          8591\n                                            Sum of Weights             276536446\n\n\n                                                        Statistics\n\n                                                                    Std Error\n                     Variable               N            Mean         of Mean       95% CL for Mean\n                     ---------------------------------------------------------------------------------\n                     HI_CHOL             7846        0.112143        0.005446    0.10059829 0.12368762\n                     RIAGENDR            8591        1.512019        0.005302    1.50077977 1.52325807\n                     ---------------------------------------------------------------------------------\n\n\n                                                       Ratio Analysis\n\n                                                                              Std\n               Numerator Denominator            N           Ratio           Error        95% CL for Ratio\n               ----------------------------------------------------------------------------------------------\n               HI_CHOL   RIAGENDR            7846        0.074222        0.003715    0.06634722    0.08209696\n               ----------------------------------------------------------------------------------------------\n\n                                                  The SURVEYFREQ Procedure\n\n                                                        Data Summary\n\n                                            Number of Strata                  15\n                                            Number of Clusters                31\n                                            Number of Observations          8591\n                                            Sum of Weights             276536446\n\n\n                                                      Table of agecat\n\n                                        Weighted    Std Err of                Std Err of    95% Confidence Limits\n          agecat         Frequency     Frequency      Wgt Freq     Percent       Percent         for Percent\n          -------------------------------------------------------------------------------------------------------\n          (0,19]              2532      57450307       3043819     20.7749        0.6130     19.4755      22.0744\n          (19,39]             2033      81137975       3692818     29.3408        0.9561     27.3140      31.3676\n          (39,59]             2021      83870623       4853936     30.3290        0.4519     29.3709      31.2870\n          (59,Inf]            2005      54077541       4284296     19.5553        0.8093     17.8398      21.2709\n\n          Total               8591     276536446      13935730    100.0000                                       \n          -------------------------------------------------------------------------------------------------------\n\n                                                 The SURVEYMEANS Procedure\n\n                                                        Data Summary\n\n                                            Number of Strata                  15\n                                            Number of Clusters                31\n                                            Number of Observations          8591\n                                            Sum of Weights             276536446\n\n\n                                                         Statistics\n\n                                                                 Std Error          Design\n                                  Variable            Mean         of Mean          Effect\n                                  --------------------------------------------------------\n                                  HI_CHOL         0.112143        0.005446        2.336725\n                                  --------------------------------------------------------\n\n                                                 The SURVEYMEANS Procedure\n\n                                                 Statistics for race Domains\n\n                                                                         Std Error          Design\n                                  race    Variable            Mean         of Mean          Effect\n                          ------------------------------------------------------------------------\n                                     1    HI_CHOL         0.101492        0.006246        1.082734\n                                     2    HI_CHOL         0.121649        0.006604        1.407822\n                                     3    HI_CHOL         0.078640        0.010385        2.091156\n                                     4    HI_CHOL         0.099679        0.024666        3.098290\n                          ------------------------------------------------------------------------"
  },
  {
    "objectID": "Comp/r-sas-python_survey-stats-summary.html#python",
    "href": "Comp/r-sas-python_survey-stats-summary.html#python",
    "title": "R vs SAS vs Python Survey Summary Statistics",
    "section": "Python",
    "text": "Python\n\nimport pandas as pd\nfrom samplics import TaylorEstimator\nfrom samplics.utils.types import PopParam\n\nnhanes = pd.read_csv(\"../data/nhanes.csv\")\n\nnhanes_design_kwargs = dict(\n    psu=nhanes[\"SDMVPSU\"],\n    stratum=nhanes[\"SDMVSTRA\"],\n    samp_weight=nhanes[\"WTMEC2YR\"],\n    remove_nan=True,\n)\n\n# Mean of HI_CHOL\nmean_estimator = TaylorEstimator(PopParam.mean)\nmean_estimator.estimate(nhanes[\"HI_CHOL\"], **nhanes_design_kwargs)\nhi_chol_means = mean_estimator.to_dataframe()\n\n# Sum of HI_CHOL\ntotal_estimator = TaylorEstimator(PopParam.total)\ntotal_estimator.estimate(nhanes[\"HI_CHOL\"], **nhanes_design_kwargs)\nhi_chol_totals = total_estimator.to_dataframe()\n\n# Ratio of HI_CHOL / RIAGENDR\nratio_estimator = TaylorEstimator(PopParam.ratio)\nratio_estimator.estimate(\n    y=nhanes[\"HI_CHOL\"], x=nhanes[\"RIAGENDR\"], **nhanes_design_kwargs\n)\nhi_chol_ratio = ratio_estimator.to_dataframe()\n\n# Proportion of different AGECAT values\nprop_estimator = TaylorEstimator(PopParam.prop)\nprop_estimator.estimate(nhanes[\"agecat\"], **nhanes_design_kwargs)\nagecat_prop = prop_estimator.to_dataframe()\n\n# Quantiles of HI_CHOL\n# NA\n\n# Domain analysis of mean of HI_CHOL by race, with design effect\nmean_estimator = TaylorEstimator(PopParam.mean)\nmean_estimator.estimate(\n    nhanes[\"HI_CHOL\"],\n    **nhanes_design_kwargs,\n    domain=nhanes[\"race\"],\n    deff=True,  # Design effect param currently has no effect\n)\nhi_chol_domain_means = mean_estimator.to_dataframe()\n\n\nag_dict = agecat_prop.set_index(\"_level\").to_dict()\nhc_dict = hi_chol_domain_means.set_index(\"_domain\").to_dict()\n\nprint(\n    f\"\"\"\n    Mean of HI_CHOL: {hi_chol_means[\"_estimate\"][0]}\n    SE of Mean HI_CHOL: {hi_chol_means[\"_stderror\"][0]}\n    CL of Mean HI_CHOL: {(hi_chol_means[\"_lci\"][0], hi_chol_means[\"_uci\"][0])}\n    Sum of HI_CHOL: {hi_chol_totals[\"_estimate\"][0]}\n    SE of Sum HI_CHOL: {hi_chol_totals[\"_stderror\"][0]}\n    CL of Sum HI_CHOL: {(hi_chol_totals[\"_lci\"][0], hi_chol_totals[\"_uci\"][0])}\n    Ratio of HI_CHOL / RIAGENDR: {hi_chol_ratio[\"_estimate\"][0]}\n    SE of Ratio HI_CHOL / RIAGENDR: {hi_chol_ratio[\"_stderror\"][0]}\n    CL of Ratio HI_CHOL / RIAGENDR: {(hi_chol_ratio[\"_lci\"][0], hi_chol_ratio[\"_uci\"][0])}\n    Proportion of AGECAT: {ag_dict[\"_estimate\"]}\n    SE of Proportion AGECAT: {ag_dict[\"_stderror\"]}\n    LCL of Proportion AGECAT: {ag_dict[\"_lci\"]}\n    UCL of Proportion AGECAT: {ag_dict[\"_uci\"]}\n    Quantiles of HI_CHOL: Not available\n    Mean of HI_CHOL by race: {hc_dict[\"_estimate\"]}\n    SE of HI_CHL by race: {hc_dict[\"_stderror\"]}\n    LCL of HI_CHOL by race: {hc_dict[\"_lci\"]}\n    UCL of HI_CHOL by race: {hc_dict[\"_uci\"]}\n    Design Effect of HI_CHOL by race: Not available\n    \"\"\"\n)\n\n\n    Mean of HI_CHOL: 0.11214295634969222\n    SE of Mean HI_CHOL: 0.005445839698954557\n    CL of Mean HI_CHOL: (np.float64(0.1005982919131703), np.float64(0.12368762078621415))\n    Sum of HI_CHOL: 28635245.254672\n    SE of Sum HI_CHOL: 2020710.7436996205\n    CL of Sum HI_CHOL: (np.float64(24351529.84091034), np.float64(32918960.668433655))\n    Ratio of HI_CHOL / RIAGENDR: 0.07422209323594066\n    SE of Ratio HI_CHOL / RIAGENDR: 0.0037147278931070065\n    CL of Ratio HI_CHOL / RIAGENDR: (np.float64(0.06634722189017901), np.float64(0.0820969645817023))\n    Proportion of AGECAT: {'(0,19]': 0.2077494937870972, '(19,39]': 0.29340788818591346, '(39,59]': 0.30328958320385285, '(59,Inf]': 0.19555303482313666}\n    SE of Proportion AGECAT: {'(0,19]': 0.006129950336419631, '(19,39]': 0.009560691634608896, '(39,59]': 0.004519462827363183, '(59,Inf]': 0.008092578243976422}\n    LCL of Proportion AGECAT: {'(0,19]': 0.19505410930097866, '(19,39]': 0.27355685874096586, '(39,59]': 0.2937950591158628, '(59,Inf]': 0.1789647230500222}\n    UCL of Proportion AGECAT: {'(0,19]': 0.2210442684297426, '(19,39]': 0.3140766293472951, '(39,59]': 0.31295496708023285, '(59,Inf]': 0.21327950895208636}\n    Quantiles of HI_CHOL: Not available\n    Mean of HI_CHOL by race: {1: 0.10149166545397208, 2: 0.12164920535593333, 3: 0.07864006039908408, 4: 0.09967860947712034}\n    SE of HI_CHL by race: {1: 0.006245843308749599, 2: 0.006604133623532979, 3: 0.010384645000548863, 4: 0.024666226871851268}\n    LCL of HI_CHOL by race: {1: 0.0882510691256497, 2: 0.10764906749064211, 3: 0.056625596431891564, 4: 0.04738854441969514}\n    UCL of HI_CHOL by race: {1: 0.11473226178229445, 2: 0.13564934322122454, 3: 0.1006545243662766, 4: 0.15196867453454554}\n    Design Effect of HI_CHOL by race: Not available"
  },
  {
    "objectID": "Comp/r-sas-python_survey-stats-summary.html#quantiles",
    "href": "Comp/r-sas-python_survey-stats-summary.html#quantiles",
    "title": "R vs SAS vs Python Survey Summary Statistics",
    "section": "Quantiles",
    "text": "Quantiles\nsamplics in Python does not have a method for calculating quantiles, and in R and SAS the available methods lead to different results. To demonstrate the differences in calculating quantiles, we will use the apisrs dataset from the survey package in R (“API Data Files” 2006).\n\nlibrary(survey)\n\ndata(\"api\")\n\nhead(apisrs) |&gt;\n  gt::gt()\n\n\n\n\n\n\n\ncds\nstype\nname\nsname\nsnum\ndname\ndnum\ncname\ncnum\nflag\npcttest\napi00\napi99\ntarget\ngrowth\nsch.wide\ncomp.imp\nboth\nawards\nmeals\nell\nyr.rnd\nmobility\nacs.k3\nacs.46\nacs.core\npct.resp\nnot.hsg\nhsg\nsome.col\ncol.grad\ngrad.sch\navg.ed\nfull\nemer\nenroll\napi.stu\npw\nfpc\n\n\n\n\n15739081534155\nH\nMcFarland High\nMcFarland High\n1039\nMcFarland Unified\n432\nKern\n14\nNA\n98\n462\n448\n18\n14\nNo\nYes\nNo\nNo\n44\n31\nNA\n6\nNA\nNA\n24\n82\n44\n34\n12\n7\n3\n1.91\n71\n35\n477\n429\n30.97\n6194\n\n\n19642126066716\nE\nStowers (Cecil\nStowers (Cecil B.) Elementary\n1124\nABC Unified\n1\nLos Angeles\n18\nNA\n100\n878\n831\nNA\n47\nYes\nYes\nYes\nYes\n8\n25\nNA\n15\n19\n30\nNA\n97\n4\n10\n23\n43\n21\n3.66\n90\n10\n478\n420\n30.97\n6194\n\n\n30664493030640\nH\nBrea-Olinda Hig\nBrea-Olinda High\n2868\nBrea-Olinda Unified\n79\nOrange\n29\nNA\n98\n734\n742\n3\n-8\nNo\nNo\nNo\nNo\n10\n10\nNA\n7\nNA\nNA\n28\n95\n5\n9\n21\n41\n24\n3.71\n83\n18\n1410\n1287\n30.97\n6194\n\n\n19644516012744\nE\nAlameda Element\nAlameda Elementary\n1273\nDowney Unified\n187\nLos Angeles\n18\nNA\n99\n772\n657\n7\n115\nYes\nYes\nYes\nYes\n70\n25\nNA\n23\n23\nNA\nNA\n100\n37\n40\n14\n8\n1\n1.96\n85\n18\n342\n291\n30.97\n6194\n\n\n40688096043293\nE\nSunnyside Eleme\nSunnyside Elementary\n4926\nSan Luis Coastal Unified\n640\nSan Luis Obispo\n39\nNA\n99\n739\n719\n4\n20\nYes\nYes\nYes\nYes\n43\n12\nNA\n12\n20\n29\nNA\n91\n8\n21\n27\n34\n10\n3.17\n100\n0\n217\n189\n30.97\n6194\n\n\n19734456014278\nE\nLos Molinos Ele\nLos Molinos Elementary\n2463\nHacienda la Puente Unif\n284\nLos Angeles\n18\nNA\n93\n835\n822\nNA\n13\nYes\nYes\nYes\nNo\n16\n19\nNA\n13\n19\n29\nNA\n71\n1\n8\n20\n38\n34\n3.96\n75\n20\n258\n211\n30.97\n6194\n\n\n\n\n\n\n\nIn SAS, PROC SURVEYMEANS will calculate quantiles of specific probabilities as you request them, using Woodruff’s method for intervals and a custom quantile method (SAS/STAT® 15.1 User’s Guide 2018, 9834). The quantile method does not match any of the available qrules in R, and although the default interval.types in the R survey::svyquantile function also uses Woodruff’s method, it is a different implementation.\nThe method and results from SAS are as follows:\n\nproc surveymeans data=apisrs total=6194 quantile=(0.025 0.5 0.975);\n    var growth;\nrun;\n\n                             The SURVEYMEANS Procedure\n\n                                    Data Summary\n\n                        Number of Observations           200\n\n\n\n\n                                     Quantiles\n\n                                                      Std\n Variable       Percentile       Estimate           Error    95% Confidence Limits\n ---------------------------------------------------------------------------------\n growth           2.5          -16.500000        1.755916    -19.962591 -13.037409\n                   50 Median    26.500000        1.924351     22.705263  30.294737\n                 97.5           99.000000       16.133827     67.184794 130.815206\n ---------------------------------------------------------------------------------\nIf in R we use the default qrule=\"math\" (equivalent to qrule=\"hf1\" and matches type=1 in the quantile function for unweighted data) along with the default interval.type=\"mean\", we get the following results:\n\nsrs_design &lt;- survey::svydesign(data = apisrs, id = ~1, fpc = ~fpc, )\n\nsurvey::svyquantile(\n  ~growth,\n  srs_design,\n  quantiles = c(0.025, 0.5, 0.975),\n  ci = TRUE,\n  se = TRUE\n)\n\n$growth\n      quantile ci.2.5 ci.97.5        se\n0.025      -16    -21     -12  2.281998\n0.5         27     24      31  1.774887\n0.975      103     93     189 24.341307\n\nattr(,\"hasci\")\n[1] TRUE\nattr(,\"class\")\n[1] \"newsvyquantile\"\n\n\nHere we can see that the quantiles, confidence intervals, and standard errors do not match SAS. From testing, none of the available qrule methods match SAS for the quantile values, so it is recommended to use the default values unless you have need of some of the other properties of different quantile definitions - see vignette(\"qrule\", package=\"survey\") for more detail. If an exact match to SAS is required, then the svyquantile function allows for passing a custom function to the qrule argument to define your own method for calculating quantiles. Below is an example that will match SAS:\n\nsas_qrule &lt;- function(x, w, p) {\n  # Custom qrule to match SAS, based on survey::oldsvyquantile's internal method\n  if (any(is.na(x))) {\n    return(NA * p)\n  }\n  w &lt;- rowsum(w, x, reorder = TRUE)\n  x &lt;- sort(unique(x))\n  cum.w &lt;- cumsum(w) / sum(w)\n  cdf &lt;- approxfun(\n    cum.w,\n    x,\n    method = \"linear\",\n    f = 1,\n    yleft = min(x),\n    yright = max(x),\n    ties = min\n  )\n  cdf(p)\n}\n\n\nsas_quants &lt;- survey::svyquantile(\n  ~growth,\n  srs_design,\n  quantiles = c(0.025, 0.5, 0.975),\n  qrule = sas_qrule,\n  ci = TRUE,\n  se = TRUE\n)\n\nsas_quants\n\n$growth\n      quantile    ci.2.5   ci.97.5        se\n0.025    -16.5 -22.00000 -15.07482  1.755916\n0.5       26.5  23.03563  30.62510  1.924351\n0.975     99.0  83.70616 147.33657 16.133827\n\nattr(,\"hasci\")\n[1] TRUE\nattr(,\"class\")\n[1] \"newsvyquantile\"\n\n\nNote that although the quantiles and standard errors match, the confidence intervals still do not match SAS. For this another custom calculation is required, based on the formula used in SAS:\n\nsas_quantile_confint &lt;- function(newsvyquantile, level = 0.05, df = Inf) {\n  q &lt;- coef(newsvyquantile)\n  se &lt;- survey::SE(newsvyquantile)\n  ci &lt;- cbind(\n    q,\n    q + se * qt(level / 2, df),\n    q - se * qt(1 - level / 2, df),\n    se\n  )\n  colnames(ci) &lt;- c(\n    \"quantile\",\n    paste0(\"ci.\", c(100 * level / 2, 100 * (1 - level / 2))),\n    \"se\"\n  )\n\n  ci\n}\n\nsas_quantile_confint(sas_quants, df = survey::degf(srs_design))\n\n             quantile    ci.2.5   ci.97.5        se\ngrowth.0.025    -16.5 -19.96259 -19.96259  1.755916\ngrowth.0.5       26.5  22.70526  22.70526  1.924351\ngrowth.0.975     99.0  67.18479  67.18479 16.133827"
  },
  {
    "objectID": "Comp/r-sas-python_survey-stats-summary.html#other-considerations",
    "href": "Comp/r-sas-python_survey-stats-summary.html#other-considerations",
    "title": "R vs SAS vs Python Survey Summary Statistics",
    "section": "Other considerations",
    "text": "Other considerations\n\nDegrees of Freedom\nSome of the functions in R require the degrees of freedom to be specified when calculating confidence intervals, otherwise it assumes a normal distribution. This can be done easily by using the survey::degf function, which calculates the degrees of freedom for a survey design object.\n\n\nSingle PSU Strata\nAlthough it was not apparent with the examples used here, if there is only one PSU from a stratum then R will by default error, whereas SAS will remove that stratum from the variance calculation. This can be changed in R by setting the options(survey.lonely.psu=\"certainty\") to match SAS and have it make no contribution to the variance. In samplics, this behaviour can be configured using the single_psu argument to the estimate method, and can be set to to match SAS using SinglePSUEst.certainty. This should be considered carefully however, in R and Python there are additional methods of handling single PSUs that may be more appropriate for your use-case.\n\n\nDocumentation Differences\nOne key consideration when choosing a statistical package is the documentation available. In this case, both the survey package in R and the survey procedures in SAS have a much more comprehensive set of documentation and examples than samplics in Python. This includes both detailed examples, as well as the underlying theory and methods used in the calculations including references to the literature."
  },
  {
    "objectID": "Comp/r-sas_survival_cif.html",
    "href": "Comp/r-sas_survival_cif.html",
    "title": "R vs SAS - Estimating Cumulative Incidence Functions",
    "section": "",
    "text": "Comparison of R and SAS\nThe following table shows the options available in R and SAS for estimating cumulative incidence functions (CIFs) in a competing risk analysis, especially the capabilities and whether the results match.\n\n\n\n\n\n\n\n\n\nAnalysis\nSupported in R package tidycmprsk\nSupported in SAS PROC LIFETEST\nResults Match\n\n\n\n\nCIF estimates\nYes: with function cuminc()\nYes: with eventcode option in TIME statement\nYes\n\n\nGray’s test for equality across groups\nYes: default when the group variable (a factor) is on the right-hand side of the input formula\nYes: default with strata statement\nYes\n\n\nVariance estimates for the CIF estimates using Aalen (1978)\nYes: default\nYes (default)\nYes\n\n\nVariance estimates for the CIF estimates using the delta method\nNo\nYes: with option error=delta in PROC TEST statement\nN/A\n\n\nConfidence intervals for CIF estimates using log-log transformation\nYes: default\nYes: default\nYes\n\n\nConfidence intervals for CIF estimates using other transformations\nNo\nYes: with conftype option in LIFETEST statement\nN/A\n\n\nCIF estimates for specified time points\nYes: with times option when summarizing results, e.g., using tidy()\nYes: with timelist option in LIFETEST statement\nYes\n\n\nCIF plot by groups\nYes: with ggsurvfit::ggcumin()\nYes: with plots=cif option in LIFETEST statement\nN/A\n\n\n\nAdditional details for using tidycmprsk are given here and for SAS PROC LIFETEST here .\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package    * version date (UTC) lib source\n cmprsk       2.2-12  2024-05-19 [1] CRAN (R 4.4.0)\n survival     3.7-0   2024-06-05 [1] CRAN (R 4.4.0)\n tidycmprsk   1.1.0   2024-08-17 [1] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n─ External software ──────────────────────────────────────────────────────────\n setting value\n SAS     9.04.01M7P080520\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\n\n\nReferences\nSAS PROC LIFETEST Documentation on CIF estimates\nR package ‘tidycmprsk’ Documentation"
  },
  {
    "objectID": "Comp/r-sas_ttest_2Sample.html",
    "href": "Comp/r-sas_ttest_2Sample.html",
    "title": "R vs SAS Two Sample T-Test",
    "section": "",
    "text": "The following table shows the types of Two Sample t-test analysis, the capabilities of each language, and whether or not the results from each language match.\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nTwo sample Student’s t-test\nYes\nYes\nYes\nIn Base R, use t.test() function with paired = FALSE and var.equal = TRUE\n\n\nTwo sample Welch’s t-test\nYes\nYes\nYes\nIn Base R, use t.test() function with paired = FALSE and var.equal = FALSE\n\n\n\n\n\n\n\nHere is a table of comparison values between t.test(), proc_ttest(), and SAS PROC TTEST:\n\n\n\n\n\n\n\n\n\n\n\nStatistic\nt.test()\nproc_ttest()\nPROC TTEST\nMatch\nNotes\n\n\n\n\nDegrees of Freedom\n30\n30\n30\nYes\n\n\n\nt value\n-0.6969002\n-0.6969002\n-0.6969002\nYes\n\n\n\np value\n0.4912306\n0.4912306\n0.4912306\nYes\n\n\n\n\n\n\n\nHere is a table of comparison values between t.test(), proc_ttest(), and SAS PROC TTEST:\n\n\n\n\n\n\n\n\n\n\n\nStatistic\nt.test()\nproc_ttest()\nPROC TTEST\nMatch\nNotes\n\n\n\n\nDegrees of Freedom\n29.69359\n29.69359\n29.69359\nYes\n\n\n\nt value\n-0.6969002\n-0.6969002\n-0.6969002\nYes\n\n\n\np value\n0.4912856\n0.4912856\n0.4912856\nYes"
  },
  {
    "objectID": "Comp/r-sas_ttest_2Sample.html#comparison-results",
    "href": "Comp/r-sas_ttest_2Sample.html#comparison-results",
    "title": "R vs SAS Two Sample T-Test",
    "section": "",
    "text": "Here is a table of comparison values between t.test(), proc_ttest(), and SAS PROC TTEST:\n\n\n\n\n\n\n\n\n\n\n\nStatistic\nt.test()\nproc_ttest()\nPROC TTEST\nMatch\nNotes\n\n\n\n\nDegrees of Freedom\n30\n30\n30\nYes\n\n\n\nt value\n-0.6969002\n-0.6969002\n-0.6969002\nYes\n\n\n\np value\n0.4912306\n0.4912306\n0.4912306\nYes\n\n\n\n\n\n\n\nHere is a table of comparison values between t.test(), proc_ttest(), and SAS PROC TTEST:\n\n\n\n\n\n\n\n\n\n\n\nStatistic\nt.test()\nproc_ttest()\nPROC TTEST\nMatch\nNotes\n\n\n\n\nDegrees of Freedom\n29.69359\n29.69359\n29.69359\nYes\n\n\n\nt value\n-0.6969002\n-0.6969002\n-0.6969002\nYes\n\n\n\np value\n0.4912856\n0.4912856\n0.4912856\nYes"
  },
  {
    "objectID": "Comp/r-sas_kruskalwallis.html",
    "href": "Comp/r-sas_kruskalwallis.html",
    "title": "Kruskal Wallis R v SAS",
    "section": "",
    "text": "From the individual R and SAS pages, performing the Kruskal-Wallis test in R using:\n\nstats::kruskal.test(Sepal_Width ~ Species, data = iris_sub)\n\nand in SAS using:\n\nproc npar1way data=iris_sub wilcoxon;\n    class Species;\n    var Sepal_Width;\n    exact;\nrun;\n\nproduced the same results for the test statistic and asymptotic p-value.\nThere is a difference between languages in that SAS provides the EXACT option to easily output the exact p-value, where R does not seem to have an equivalent. A Monte Carlo permutation test may offer an alternative to the exact test on R. The coin package could help in implementing this."
  },
  {
    "objectID": "Comp/r-sas_kruskalwallis.html#kruskal-wallis-r-and-sas",
    "href": "Comp/r-sas_kruskalwallis.html#kruskal-wallis-r-and-sas",
    "title": "Kruskal Wallis R v SAS",
    "section": "",
    "text": "From the individual R and SAS pages, performing the Kruskal-Wallis test in R using:\n\nstats::kruskal.test(Sepal_Width ~ Species, data = iris_sub)\n\nand in SAS using:\n\nproc npar1way data=iris_sub wilcoxon;\n    class Species;\n    var Sepal_Width;\n    exact;\nrun;\n\nproduced the same results for the test statistic and asymptotic p-value.\nThere is a difference between languages in that SAS provides the EXACT option to easily output the exact p-value, where R does not seem to have an equivalent. A Monte Carlo permutation test may offer an alternative to the exact test on R. The coin package could help in implementing this."
  },
  {
    "objectID": "Comp/r-east_gsd_tte.html",
    "href": "Comp/r-east_gsd_tte.html",
    "title": "R vs EAST vs SAS: Group sequential design",
    "section": "",
    "text": "In this vignette, we briefly compare sample size/power calculations for a group sequential design (GSD) for time to event endpoints between EAST and gsDesign, gsDesign2, and rpact. Note that, a comparison between rpact and gsDesign has been previously reported here. Additionally, we present comparative results between SAS PROC EQDESIGN and rpact to provide a comprehensive evaluation framework.\nThere are two main methods that are generally used for GSD sample-size/power calculations for time to event endpoints under proportional hazard assumption:\n\nLachin & Foulkes (LF) Method (1986)\nKim & Tsiatis (KT) Method (1990)\n\nThe main difference between the two methods is that LF method requires specification of accrual duration as well as study duration, while KT method calculates study duration iteratively given accrual rates and accrual duration. In general, these two methods produce similar, but not identical results.\nBoth LF and KT methods are implemented in gsDesign and SAS, while KT method is implemented in EAST and rpact. gsDesign2 uses a modification of the LF method while applying an average hazard ratio (AHR) approach for non-proportional hazards (Schemper, Wakounig, and Heinze, 2009, Yung and Liu 2020). gsDesign2 also enables use of the sample size method of Yung and Liu (2020).\nOne additional computational difference to note for EAST vs gsDesign/gsDesign2 is the usage of different log hazard ratio variance assumptions. By default, EAST uses the variance under the null hypothesis and provides an option for using the variance under the alternative hypothesis. gsDesign, on the other hand, is using both of these variances as suggested by Lachin and Foulkes (1986). gsDesign2 has info_scale argument in gsDesign2::gs_power_ahr(), gsDesign2::gs_design_ahr(), which could be set to variance under the null or alternative hypothesis or to the combination of variances.\nBelow we provide an example of reproducing EAST results from this vignette using gsDesign/gsDesign2/rpact. As shown in the example, gsDesign2 and rpact can reproduce EAST calculations for GSD boundaries, while gsDesign results have minor differences. Similarly, our comparison between SAS PROC SEQDESIGN and rpact shows good agreement in the calculation, with only minimal numerical differences observed. gsDesign has an option under development to support a complete concordance with EAST."
  },
  {
    "objectID": "Comp/r-east_gsd_tte.html#introduction",
    "href": "Comp/r-east_gsd_tte.html#introduction",
    "title": "R vs EAST vs SAS: Group sequential design",
    "section": "",
    "text": "In this vignette, we briefly compare sample size/power calculations for a group sequential design (GSD) for time to event endpoints between EAST and gsDesign, gsDesign2, and rpact. Note that, a comparison between rpact and gsDesign has been previously reported here. Additionally, we present comparative results between SAS PROC EQDESIGN and rpact to provide a comprehensive evaluation framework.\nThere are two main methods that are generally used for GSD sample-size/power calculations for time to event endpoints under proportional hazard assumption:\n\nLachin & Foulkes (LF) Method (1986)\nKim & Tsiatis (KT) Method (1990)\n\nThe main difference between the two methods is that LF method requires specification of accrual duration as well as study duration, while KT method calculates study duration iteratively given accrual rates and accrual duration. In general, these two methods produce similar, but not identical results.\nBoth LF and KT methods are implemented in gsDesign and SAS, while KT method is implemented in EAST and rpact. gsDesign2 uses a modification of the LF method while applying an average hazard ratio (AHR) approach for non-proportional hazards (Schemper, Wakounig, and Heinze, 2009, Yung and Liu 2020). gsDesign2 also enables use of the sample size method of Yung and Liu (2020).\nOne additional computational difference to note for EAST vs gsDesign/gsDesign2 is the usage of different log hazard ratio variance assumptions. By default, EAST uses the variance under the null hypothesis and provides an option for using the variance under the alternative hypothesis. gsDesign, on the other hand, is using both of these variances as suggested by Lachin and Foulkes (1986). gsDesign2 has info_scale argument in gsDesign2::gs_power_ahr(), gsDesign2::gs_design_ahr(), which could be set to variance under the null or alternative hypothesis or to the combination of variances.\nBelow we provide an example of reproducing EAST results from this vignette using gsDesign/gsDesign2/rpact. As shown in the example, gsDesign2 and rpact can reproduce EAST calculations for GSD boundaries, while gsDesign results have minor differences. Similarly, our comparison between SAS PROC SEQDESIGN and rpact shows good agreement in the calculation, with only minimal numerical differences observed. gsDesign has an option under development to support a complete concordance with EAST."
  },
  {
    "objectID": "Comp/r-east_gsd_tte.html#design-example",
    "href": "Comp/r-east_gsd_tte.html#design-example",
    "title": "R vs EAST vs SAS: Group sequential design",
    "section": "Design example",
    "text": "Design example\nWe assume that a GSD is utilized for progression-free survival (PFS) endpoint. It will be tested at one interim analysis (IA) for both efficacy and non-binding futility and then at final analysis (FA). O’Brien-Fleming spending function will be used for efficacy testing and Hwang-Shih-DeCani spending function with \\(\\gamma = -10\\) will be used for futility.\nFurther design assumptions are as follows:\n\n# PFS HR=0.6\nhr1_pfs &lt;- 0.6\n# median PFS of 9.4 months in the control arm\nmed_pfs &lt;- 9.4\n# minimum follow-up of 10 months for PFS\nminfu_pfs &lt;- 10\n# Monthly exponential dropout of 0.019  for PFS\ndo_rate_pfs &lt;- 0.019\n# IA timing for PFS is at approximately 75% information fraction, and is derived\n# using the number of events that was calculated by EAST which sets integer event counts to approximate targeted information\ntiming_pfs_rpact &lt;- c(176 / 235, 1)\ntiming_pfs_gs &lt;- c(0.75, 1)\n\n# power of approximately 95% for PFS, EAST reported power will be used\npower_pfs &lt;- 0.9505021\n\n# Enrollment period of 24 months\nenroll_dur &lt;- 24\n# 1:1 randomization ratio\nrand_ratio &lt;- 1\n# alpha level of 1.25%\nalphal &lt;- 0.0125\n\nWe assume that EAST was initially used to calculate the target number of events and the total sample size, and we will use gsDesign/gsDesign2/rpact to reproduce those.\nNote that, in EAST the number of target events is reported as an integer, however, gsDesign/gsDesign2/rpact by default provide non-integer values which match exactly the specified information fraction. Both gsDesign/gsDesign2 can facilitate computations using integer number of events with gsDesign::toInteger() and gsDesign2::to_integer() as shown below. In order to reproduce EAST results with rpact, we will use the number of events that was calculated in EAST for informationRates argument in rpact::getDesignGroupSequential(): 176 and 235 PFS events for IA and FA respectively (please see the timing_pfs_rpact object in the code above).\nFor ease of comparison the results from EAST are summarized below:\n\n\nAnalysisValueEfficacyFutilityIA1: 75%Z-2.6606-0.7379N=398p (1-sided)0.00390.2303Events: 176HR at bound0.66960.8947Month: 25P(Cross) if HR=10.00390.7697P(Cross) if HR=0.600.76660.0040FAZ-2.2798N=398p (1-sided)0.0113Events: 235HR at bound0.7427Month: 34P(Cross) if HR=10.0125P(Cross) if HR=0.600.9505\n\n\n\nThe comparison between EAST and gsDesign/gsDesign/rpact results is presented below using absolute difference in efficacy/futility boundaries and crossing probabilities up to 4 decimals. Non-zero values are highlighted.\nNote that, in gsDesign/gsDesign Efficacy/Futility bounds refer to upper/lower bounds respectively, while in EAST these refer to the opposite directions, i.e., lower/upper bounds respectively. For the comparison purposes, we will assume that Efficacy/Futility bounds refer to upper/lower bounds respectively."
  },
  {
    "objectID": "Comp/r-east_gsd_tte.html#code-to-reproduce-east-results",
    "href": "Comp/r-east_gsd_tte.html#code-to-reproduce-east-results",
    "title": "R vs EAST vs SAS: Group sequential design",
    "section": "Code to reproduce EAST results",
    "text": "Code to reproduce EAST results\n\ngsDesign code\n\ngsDesign code to reproduce the above EAST results:\n\n\nlibrary(gsDesign)\n\npfs_gsDesign &lt;- gsDesign::gsSurv(\n  k = length(timing_pfs_gs),\n  timing = timing_pfs_gs,\n  R = enroll_dur,\n  eta = do_rate_pfs,\n  minfup = minfu_pfs,\n  T = enroll_dur + minfu_pfs,\n  lambdaC = log(2) / med_pfs,\n  hr = hr1_pfs,\n  beta = 1 - power_pfs,\n  alpha = alphal,\n  sfu = sfLDOF,\n  sfl = sfHSD,\n  sflpar = -10,\n  test.type = 4\n) |&gt;\n  toInteger()\n\n\npfs_gsDesign |&gt;\n  gsDesign::gsBoundSummary()\n\n    Analysis              Value Efficacy Futility\n   IA 1: 75%                  Z   2.6606   0.7422\n      N: 400        p (1-sided)   0.0039   0.2290\n Events: 176       ~HR at bound   0.6696   0.8941\n   Month: 25   P(Cross) if HR=1   0.0039   0.7710\n             P(Cross) if HR=0.6   0.7679   0.0040\n       Final                  Z   2.2798   2.2798\n      N: 400        p (1-sided)   0.0113   0.0113\n Events: 235       ~HR at bound   0.7427   0.7427\n   Month: 34   P(Cross) if HR=1   0.0125   0.9875\n             P(Cross) if HR=0.6   0.9510   0.0490\n\n\n\ngsDesign vs EAST comparison using absolute differences:\n\n\n\nAnalysisValueEfficacyFutilityIA1: 75%Z0.00000.0043N=398p (1-sided)0.00000.0013Events: 176HR at bound0.00000.0006Month: 25P(Cross) if HR=10.00000.0013P(Cross) if HR=0.600.00130.0000FAZ0.0000N=398p (1-sided)0.0000Events: 235HR at bound0.0000Month: 34P(Cross) if HR=10.0000P(Cross) if HR=0.600.0005\n\n\n\n\ngsDesign2 code\n\ngsDesign2 code to reproduce the above EAST results appears below.\nNote that, here gsDesign2::gs_power_ahr() is used given the number of target events for each analysis based on EAST results.\n\n\nlibrary(gsDesign2)\nlibrary(tibble)\n\nenroll_rate &lt;- tibble(\n  stratum = \"All\",\n  duration = enroll_dur,\n  rate = 398 / enroll_dur\n)\nfail_rate_pfs &lt;- tibble(\n  stratum = \"All\",\n  duration = Inf, #could be set to Inf when proportional hazard is assumed\n  fail_rate = log(2) / med_pfs,\n  hr = hr1_pfs,\n  dropout_rate = do_rate_pfs\n)\n\npfs_gsDesign2 &lt;- gs_power_ahr(\n  enroll_rate = enroll_rate,\n  fail_rate = fail_rate_pfs,\n  ratio = rand_ratio,\n  event = c(176, 235),\n  upper = gs_spending_bound,\n  upar = list(\n    sf = gsDesign::sfLDOF,\n    total_spend = alphal\n  ),\n  lower = gs_spending_bound,\n  lpar = list(\n    sf = gsDesign::sfHSD,\n    total_spend = 1 - power_pfs,\n    param = -10\n  ),\n  info_scale = \"h0_info\"\n) |&gt;\n  to_integer()\n\npfs_gsDesign2 |&gt;\n  summary() |&gt;\n  gsDesign2::as_gt()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBound summary for AHR design\n\n\nAHR approximations of ~HR at bound\n\n\nBound\nZ\nNominal p1\n~HR at bound2\n\nCumulative boundary crossing probability\n\n\n\nAlternate hypothesis\nNull hypothesis\n\n\n\n\nAnalysis: 1 Time: 25.4 N: 398 Events: 176 AHR: 0.6 Information fraction: 0.75\n\n\nFutility\n0.74\n0.2303\n0.8947\n0.0040\n0.7697\n\n\nEfficacy\n2.66\n0.0039\n0.6696\n0.7666\n0.0039\n\n\nAnalysis: 2 Time: 34.1 N: 398 Events: 235 AHR: 0.6 Information fraction: 1\n\n\nFutility\n2.28\n0.0113\n0.7427\n0.0495\n0.9875\n\n\nEfficacy\n2.28\n0.0113\n0.7427\n0.9505\n0.0125\n\n\n\n1 One-sided p-value for experimental vs control treatment. Value &lt; 0.5 favors experimental, &gt; 0.5 favors control.\n\n\n2 Approximate hazard ratio to cross bound.\n\n\n\n\n\n\n\n\n\ngsDesign2 vs EAST comparison using absolute differences:\n\n\n\nAnalysisValueEfficacyFutilityIA1: 75%Z0.00000.0000N=398p (1-sided)0.00000.0000Events: 176HR at bound0.00000.0000Month: 25P(Cross) if HR=10.00000.0000P(Cross) if HR=0.600.00000.0000FAZ0.0000N=398p (1-sided)0.0000Events: 235HR at bound0.0000Month: 34P(Cross) if HR=10.0000P(Cross) if HR=0.600.0000\n\n\n\n\nrpact code\n\nrpact code to reproduce the above EAST results appears below.\n\n\nlibrary(rpact)\n\npfs_rpact_gsd &lt;- rpact::getDesignGroupSequential(\n  sided = 1,\n  alpha = alphal,\n  informationRates = timing_pfs_rpact,\n  typeOfDesign = \"asOF\",\n  beta = 1 - power_pfs,\n  typeBetaSpending = \"bsHSD\",\n  gammaB = -10,\n  bindingFutility = FALSE\n)\n\npfs_rpact &lt;- rpact::getSampleSizeSurvival(\n  design = pfs_rpact_gsd,\n  accrualTime = enroll_dur,\n  followUpTime = minfu_pfs,\n  lambda2 = log(2) / med_pfs,\n  hazardRatio = hr1_pfs,\n  dropoutRate1 = 0.2,\n  dropoutRate2 = 0.2,\n  dropoutTime = 12\n)\n\nkable(summary(pfs_rpact))\n\nSample size calculation for a survival endpoint\nSequential analysis with a maximum of 2 looks (group sequential design), one-sided overall significance level 1.25%, power 95.1%. The results were calculated for a two-sample logrank test, H0: hazard ratio = 1, H1: hazard ratio = 0.6, control lambda(2) = 0.074, accrual time = 24, accrual intensity = 16.6, follow-up time = 10, dropout rate(1) = 0.2, dropout rate(2) = 0.2, dropout time = 12.\n\n\n\nStage\n1\n2\n\n\n\n\nPlanned information rate\n74.9%\n100%\n\n\nCumulative alpha spent\n0.0039\n0.0125\n\n\nCumulative beta spent\n0.0040\n0.0495\n\n\nStage levels (one-sided)\n0.0039\n0.0113\n\n\nEfficacy boundary (z-value scale)\n2.661\n2.280\n\n\nFutility boundary (z-value scale)\n0.738\n\n\n\nEfficacy boundary (t)\n0.670\n0.743\n\n\nFutility boundary (t)\n0.895\n\n\n\nCumulative power\n0.7666\n0.9505\n\n\nNumber of subjects\n397.9\n397.9\n\n\nExpected number of subjects under H1\n\n397.9\n\n\nCumulative number of events\n176.0\n235.0\n\n\nExpected number of events under H1\n189.5\n\n\n\nAnalysis time\n25.34\n34.00\n\n\nExpected study duration under H1\n\n27.32\n\n\nOverall exit probability (under H0)\n0.7736\n\n\n\nOverall exit probability (under H1)\n0.7707\n\n\n\nExit probability for efficacy (under H0)\n0.0039\n\n\n\nExit probability for efficacy (under H1)\n0.7666\n\n\n\nExit probability for futility (under H0)\n0.7697\n\n\n\nExit probability for futility (under H1)\n0.0040\n\n\n\n\nLegend:\n\n(t): treatment effect scale\n\n\n\n\nrpact vs EAST comparison using absolute differences:\n\n\n\nAnalysisValueEfficacyFutilityIA1: 75%Z0.00000.0000N=398p (1-sided)0.00000.0000Events: 176HR at bound0.00000.0000Month: 25P(Cross) if HR=10.00000.0000P(Cross) if HR=0.600.00000.0000FAZ0.0000N=398p (1-sided)0.0000Events: 235HR at bound0.0000Month: 34P(Cross) if HR=10.0000P(Cross) if HR=0.600.0000\n\n\n\n\nSAS code\n\nSAS code to reproduce the above rpact results appears below.\n\n\nPROC SEQDESIGN BOUNDARYSCALE=MLE ERRSPEND;\n   DESIGN NSTAGES=2 \n          INFO=CUM(0.748936170212766 1.0) \n          ALT=UPPER \n          ALPHA=0.0125 \n          BETA=0.05\n          METHOD(ALPHA)=ERRFUNCOBF \n          METHOD(BETA)=ERRFUNCGAMMA(GAMMA=-10)  \n          STOP=BOTH(BETABOUNDARY=NONBINDING);\n   SAMPLESIZE MODEL=TWOSAMPLESURVIVAL(\n          NULLMEDSURVTIME=9.4\n          HAZARDRATIO=0.6\n          ACCTIME=24 \n          FOLTIME=10\n          LOSS=EXP(HAZARD=0.018595295942851)\n          WEIGHT=1);\n  ODS OUTPUT Boundary=BMLE SampleSize=SS SampleSizeSummary=SSS;\nRUN;\n\nPlease note that the BOUNDARYSCALE=MLE | SCORE | STDZ | PVALUE options display the boundary values in the MLE, standardize Z, score, and p-value scales, respectively. SAS will provide a boundary information table based on the specified BOUNDARYSCALE. In the information table, Alpha indicates the efficacy boundaries, and Beta indicates futility boundaries.\nSAS doesn’t provide a boundary information with HR, so the HR boundaries is obtained from the MLE boundaries (as MLE \\(=\\hat{\\theta}=-log(\\text{HR})\\), see SAS User’s Guide: Test for Two Survival Distributions with a Log-Rank Test) via the following code.\n\nDATA BHR;\n   SET BMLE;\n   Bound_UA_HR=exp(-Bound_UA);\n   Bound_UB_HR=exp(-Bound_UB);\n   LABEL BOUND_UA_HR=\"Upper Alpha (HR)\" BOUND_UA_HR=\"Upper Beta (HR)\";\nPROC PRINT LABEL;\n   VAR _Stage_ _InfoProp_ Bound_UA Bound_UB Bound_UA_HR Bound_UB_HR;\nRUN;\n\n(The snapshot of HR table will be uploaded later.)\nThe results calculated by SAS are presneted in the table below. Please note that SAS doesn’t report the probablities \\(P(Cross | HR=1)\\) and \\(P(Cross | HR=0.6)\\), resulting in empty cells for these results in the table.\n\n\nAnalysisValueEfficacyFutilityIA1: 75%Z2.66060.7379N=398p (1-sided)0.00390.2303Events: 176HR at bound0.66960.8947Month: 25P(Cross) if HR=1P(Cross) if HR=0.6FAZ2.2798N=398p (1-sided)0.0113Events: 235HR at bound0.7427Month: 34P(Cross) if HR=1P(Cross) if HR=0.6\n\n\n\nSAS vs rapct comparison using absolute differences:\n\n\n\nAnalysisValueEfficacyFutilityIA1: 75%Z0.00000.0000N=398p (1-sided)0.00000.0000Events: 176HR at bound0.00000.0000Month: 25P(Cross) if HR=1P(Cross) if HR=0.6FAZ0.0000N=398p (1-sided)0.0000Events: 235HR at bound0.0000Month: 34P(Cross) if HR=1P(Cross) if HR=0.6\n\n\n\nSAS vs EAST comparison using absolute differences:\n\n\n\nAnalysisValuediff_eff_sasdiff_fut_sasIA1: 75%Z0.00000.0000N=398p (1-sided)0.00000.0000Events: 176HR at bound0.00000.0000Month: 25P(Cross) if HR=1P(Cross) if HR=0.60FAZ0.0000N=398p (1-sided)0.0000Events: 235HR at bound0.0000Month: 34P(Cross) if HR=1P(Cross) if HR=0.60\n\n\n\nsessionInfo()\n\nR version 4.4.2 (2024-10-31)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 24.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n\ntime zone: UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n[1] rpact_4.1.0     tibble_3.2.1    gsDesign2_1.1.3 gsDesign_3.6.5 \n[5] flextable_0.9.7\n\nloaded via a namespace (and not attached):\n [1] gt_0.11.1               sass_0.4.9              utf8_1.2.4             \n [4] generics_0.1.3          tidyr_1.3.1             fontLiberation_0.1.0   \n [7] renv_1.0.10             xml2_1.3.6              r2rtf_1.1.1            \n[10] digest_0.6.37           magrittr_2.0.3          evaluate_1.0.0         \n[13] grid_4.4.2              fastmap_1.2.0           jsonlite_1.8.9         \n[16] zip_2.3.1               purrr_1.1.0             fansi_1.0.6            \n[19] scales_1.3.0            fontBitstreamVera_0.1.1 textshaping_0.4.0      \n[22] cli_3.6.3               rlang_1.1.6             fontquiver_0.2.1       \n[25] munsell_0.5.1           withr_3.0.1             yaml_2.3.10            \n[28] gdtools_0.4.1           tools_4.4.2             officer_0.6.7          \n[31] uuid_1.2-1              dplyr_1.1.4             colorspace_2.1-1       \n[34] ggplot2_3.5.1           vctrs_0.6.5             R6_2.5.1               \n[37] lifecycle_1.0.4         htmlwidgets_1.6.4       ragg_1.3.3             \n[40] pkgconfig_2.0.3         pillar_1.9.0            gtable_0.3.5           \n[43] data.table_1.16.0       glue_1.8.0              Rcpp_1.0.13            \n[46] systemfonts_1.1.0       xfun_0.52               tidyselect_1.2.1       \n[49] knitr_1.50              xtable_1.8-4            htmltools_0.5.8.1      \n[52] rmarkdown_2.28          compiler_4.4.2          askpass_1.2.1          \n[55] openssl_2.2.2"
  },
  {
    "objectID": "Comp/r-east_gsd_tte.html#references",
    "href": "Comp/r-east_gsd_tte.html#references",
    "title": "R vs EAST vs SAS: Group sequential design",
    "section": "References",
    "text": "References\n\nLachin JM and Foulkes M. Evaluation of sample size and power for analyses of survival with allowance for nonuniform patient entry, losses to follow-up, non-compliance, and stratification. Biometrics 1986;42:507-19.\nKim K and Tsiatis AA. Study duration for clinical trials with survival response and early stopping rule. Biometrics 1990(46): 81-92.\nSchemper M, Wakounig S and Heinze G. The estimation of average hazard ratios by weighted cox regression. Statistics in Medicine 2009; 28(19): 2473-2489.\nYung G and Liu Y. Sample size and power for the weighted log-rank test and Kaplan-Meier based tests with allowance for nonproportional hazards. Biometrics 2020;76:939-50."
  },
  {
    "objectID": "Comp/r-sas_chi-sq.html",
    "href": "Comp/r-sas_chi-sq.html",
    "title": "R/SAS Chi-Squared and Fisher’s Exact Comparision",
    "section": "",
    "text": "Chi-Squared Test\nChi-Squared test is a hypothesis test for independent contingency tables, dependent on rows and column totals. The test assumes:\n\nobservations are independent of each other\nall values are 1 or more and at least 80% of the cells are greater than 5.\ndata should be categorical\n\nThe Chi-Squared statistic is found by:\n\\[\n\\chi^2=\\frac{\\sum(O-E)^2}{E}\n\\]\nWhere O is the observed and E is the expected.\nFor an r x c table (where r is the number of rows and c the number of columns), the Chi-squared distribution’s degrees of freedom is (r-1)*(c-1). The resultant statistic with correct degrees of freedom follows this distribution when its expected values are aligned with the assumptions of the test, under the null hypothesis. The resultant p value informs the magnitude of disagreement with the null hypothesis and not the magnitude of association\nFor this example we will use data about cough symptoms and history of bronchitis.\n\nbronch &lt;- matrix(c(26, 247, 44, 1002), ncol = 2)\nrow.names(bronch) &lt;- c(\"cough\", \"no cough\")\ncolnames(bronch) &lt;- c(\"bronchitis\", \"no bronchitis\")\nbronch\n\n         bronchitis no bronchitis\ncough            26            44\nno cough        247          1002\n\n\nTo a chi-squared test in R you will use the following code.\n\nstats::chisq.test(bronch)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  bronch\nX-squared = 11.145, df = 1, p-value = 0.0008424\n\n\nTo run a chi-squared test in SAS you used the following code.\n\nproc freq data=proj1.bronchitis;\ntables Cough*Bronchitis / chisq;\nrun;\n\nThe result in the “Chi-Square” section of the results table in SAS will not match R, in this case it will be 12.1804 with a p-value of 0.0005. This is because by default R does a Yate’s continuity adjustment. To change this set correct to false.\n\nstats::chisq.test(bronch, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  bronch\nX-squared = 12.18, df = 1, p-value = 0.0004829\n\n\nAlternatively, SAS also produces the correct chi-square value by default. It is the “Continuity Adj. Chi-Square” value in the results table.\n\n\nFisher’s Exact Test\nComparison between the Fisher’s Exact Test in both R and SAS shows that the two software match on the p-value and confidence intervals. The odd ratio does not match. The reason the odds ratio does not match is because R uses an “exact” odds ratio based on the hypergeomtric distribution, while SAS uses a standard AD/BC odds ratio. Note that R always uses an “exact” Fisher test. Therefore, when trying to match SAS, you must use the “exact” statement on the PROC FREQ."
  },
  {
    "objectID": "Comp/r-sas_tobit.html",
    "href": "Comp/r-sas_tobit.html",
    "title": "R vs SAS Tobit Regression",
    "section": "",
    "text": "The following table shows the tobit regression analysis, the capabilities of each language, and whether or not the results from each language match.\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nTobit Regression (normal distributed data assumption)\nYes\nYes\nYes\nThe results from censReg::censReg and survival::survreg match the SAS PROC LIFEREG results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere is a table of comparison values between the R functions censReg::censReg, survival::survreg, VGAM::vglm, and SAS PROC LIFEREG for the dataset used. The statistics around the treatment effect (difference between group A and B, B-A) are provided. Further we also present the estimate of \\(\\sigma\\). All numbers are rounded to 4 digits\n\n\n\n\n\n\n\n\n\n\n\n\nStatistic\ncensReg()\nsurvreg()\nvglm()\nLIFEREG\nMatch\nNotes\n\n\n\n\nTreatment effect\n1.8225\n1.8225\n1.8226\n1.8225\nYes\nsee below\n\n\nStandard error\n0.8061\n0.8061\n0.7942\n0.8061\nYes\nsee below\n\n\np-value\n0.0238\n0.0238\n0.0217\n0.0238\nYes\nsee below\n\n\n95% CI (Wald based)\n0.2427 ; 3.4024\n0.2427 ; 3.4024\n0.2661 ; 3.3791\n0.2427 ; 3.4024\nYes\nsee below\n\n\n\\(\\sigma\\)\n1.7316\n1.7316\n1.7317\n1.7316\nYes\nsee below\n\n\n\nNote: The results of VGAM::vglm() are slightly different since an iteratively reweighted least squares (IRLS) algorithm is used for estimation.\n\n\n\nUsing SAS PROC LIFEREG, one-sided p-values can be easily obtained by adding UPPER (in the presented data example this corresponds with \\(H_1: \\mu_B&gt;\\mu_A\\)) or LOWER (this corresponds with \\(H_1: \\mu_B&lt;\\mu_A\\)) in the estimate statement. In the presented data example, the obtained p-values are:\n\nUPPER: \\(p_{one-sided} = 0.0119\\)\nLOWER: \\(p_{one-sided} = 0.9881\\)\n\nUsing R, no option is available with censReg::censReg or survival::survreg to directly obtain the one-sided p-values. However, the one-sided p-values can be easily calculated. For example, for a right one-sided p-value (in the presented data example this corresponds with \\(H_1: \\mu_B&gt;\\mu_A\\)) the following rules need to be followed:\n\nIf the estimate \\(\\mu_B - \\mu_A \\geq 0\\), then \\(p_{one-sided} = p_{two-sided}/2\\)\nIf the estimate \\(\\mu_B - \\mu_A &lt; 0\\), then \\(p_{one-sided} = 1 - (p_{two-sided}/2)\\)\n\nFor a left one-sided p-value this should be done the other way around. Applying this rule to the results obtained in R, gives similar one-sided p-values as SAS for the presented data example."
  },
  {
    "objectID": "Comp/r-sas_tobit.html#comparison-results",
    "href": "Comp/r-sas_tobit.html#comparison-results",
    "title": "R vs SAS Tobit Regression",
    "section": "",
    "text": "Here is a table of comparison values between the R functions censReg::censReg, survival::survreg, VGAM::vglm, and SAS PROC LIFEREG for the dataset used. The statistics around the treatment effect (difference between group A and B, B-A) are provided. Further we also present the estimate of \\(\\sigma\\). All numbers are rounded to 4 digits\n\n\n\n\n\n\n\n\n\n\n\n\nStatistic\ncensReg()\nsurvreg()\nvglm()\nLIFEREG\nMatch\nNotes\n\n\n\n\nTreatment effect\n1.8225\n1.8225\n1.8226\n1.8225\nYes\nsee below\n\n\nStandard error\n0.8061\n0.8061\n0.7942\n0.8061\nYes\nsee below\n\n\np-value\n0.0238\n0.0238\n0.0217\n0.0238\nYes\nsee below\n\n\n95% CI (Wald based)\n0.2427 ; 3.4024\n0.2427 ; 3.4024\n0.2661 ; 3.3791\n0.2427 ; 3.4024\nYes\nsee below\n\n\n\\(\\sigma\\)\n1.7316\n1.7316\n1.7317\n1.7316\nYes\nsee below\n\n\n\nNote: The results of VGAM::vglm() are slightly different since an iteratively reweighted least squares (IRLS) algorithm is used for estimation.\n\n\n\nUsing SAS PROC LIFEREG, one-sided p-values can be easily obtained by adding UPPER (in the presented data example this corresponds with \\(H_1: \\mu_B&gt;\\mu_A\\)) or LOWER (this corresponds with \\(H_1: \\mu_B&lt;\\mu_A\\)) in the estimate statement. In the presented data example, the obtained p-values are:\n\nUPPER: \\(p_{one-sided} = 0.0119\\)\nLOWER: \\(p_{one-sided} = 0.9881\\)\n\nUsing R, no option is available with censReg::censReg or survival::survreg to directly obtain the one-sided p-values. However, the one-sided p-values can be easily calculated. For example, for a right one-sided p-value (in the presented data example this corresponds with \\(H_1: \\mu_B&gt;\\mu_A\\)) the following rules need to be followed:\n\nIf the estimate \\(\\mu_B - \\mu_A \\geq 0\\), then \\(p_{one-sided} = p_{two-sided}/2\\)\nIf the estimate \\(\\mu_B - \\mu_A &lt; 0\\), then \\(p_{one-sided} = 1 - (p_{two-sided}/2)\\)\n\nFor a left one-sided p-value this should be done the other way around. Applying this rule to the results obtained in R, gives similar one-sided p-values as SAS for the presented data example."
  },
  {
    "objectID": "Comp/r-sas_linear-regression.html",
    "href": "Comp/r-sas_linear-regression.html",
    "title": "R vs SAS Linear Regression",
    "section": "",
    "text": "Summary of R vs SAS Comparison for Linear Regression\nTo date the lm function in R and proc reg in sas have been found to 100% agree.\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nLinear regression\nYes\nYes\nYes"
  },
  {
    "objectID": "Comp/r-sas-summary-stats.html",
    "href": "Comp/r-sas-summary-stats.html",
    "title": "Deriving Quantiles or Percentiles in R vs SAS",
    "section": "",
    "text": "Data\nThe following data will be used show the differences between the default percentile definitions used by SAS and R:\n\nc(10, 20, 30, 40, 150, 160, 170, 180, 190, 200)\n\n\n\nSAS Code\nAssuming the data above is stored in the variable aval within the dataset adlb, the 25th and 40th percentiles could be calculated using the following code.\n\nproc univariate data=adlb;\n  var aval;\n  output out=stats pctlpts=25 40 pctlpre=p;\nrun;\n\nThis procedure creates the dataset stats containing the variables p25 and p40.\nThe procedure has the option PCTLDEF which allows for five different percentile definitions to be used. The default is PCTLDEF=5.\n\n\nR code\nThe 25th and 40th percentiles of aval can be calculated using the quantile function.\n\nquantile(adlb$aval, probs = c(0.25, 0.4))\n\nThis gives the following output.\n\n\n  25%   40% \n 32.5 106.0 \n\n\nThe function has the argument type which allows for nine different percentile definitions to be used. The default is type = 7.\n\n\nComparison\nThe default percentile definition used by the UNIVARIATE procedure in SAS finds the 25th and 40th percentiles to be 30 and 95. The default definition used by R finds these percentiles to be 32.5 and 106.\nIt is possible to get the quantile function in R to use the same definition as the default used in SAS, by specifying type=2.\n\nalquantile(adlb$aval, probs = c(0.25, 0.4), type = 2)\n\nThis gives the following output.\n\n\n25% 40% \n 30  95 \n\n\nIt is not possible to get the UNIVARIATE procedure in SAS to use the same definition as the default used in R.\nRick Wicklin provided a blog post showing how SAS has built in support for calculations using 5 of the 9 percentile definitions available in R, and also demonstrated how you can use a SAS/IML function to calculate percentiles using the other 4 definitions.\nMore information about quantile derivation can be found in the SAS blog.\n\n\nKey references:\nCompare the default definitions for sample quantiles in SAS, R, and Python\nSample quantiles: A comparison of 9 definitions\nHyndman, R. J., & Fan, Y. (1996). Sample quantiles in statistical packages. The American Statistician, 50(4), 361-365."
  },
  {
    "objectID": "Comp/r-sas_negbin.html",
    "href": "Comp/r-sas_negbin.html",
    "title": "R vs SAS: Negative Binomial Regression",
    "section": "",
    "text": "Comparison of implementations and results between SAS vs R for negative binomial regression for count data.\n\n\n\n\n\n\n\n\n\n\n\nNoteMethodologies\n\n\n\n\n\n\nNegative binomial regression\n\n\n\n\n\n\n\n\n\n\n\n\nNoteTechnical implementations\n\n\n\n\n\n\nSAS: PROC GENMOD with option: DIST = NB or DIST = NEGBIN\nR: MASS::glm.nb\n\n\n\n\n\n\n\n\n\n\nBelow are summary of findings from a numerical comparison using dummy data, where possible we specify the same algorithm in R and SAS (see section Numerical Comparisons for details).\n\n\n\n\n\n\nNoteNegative binomial regression\n\n\n\n\n\nExact match (at 0.001 level) can be obtained using glm.nb in R vs PROC GENMOD procedure in SAS, for parameter and lsmeans estimates, confidence intervals and p-values after manually adjusting the estimated variance-covariance matrix in R. For the dispersion parameter the MLEs also match, however discrepancies in the confidence intervals are observed.\n\n\n\nIn the following sections the implementations will be compared in tabular fashion followed by a numerical comparison using dummy data."
  },
  {
    "objectID": "Comp/r-sas_negbin.html#goal",
    "href": "Comp/r-sas_negbin.html#goal",
    "title": "R vs SAS: Negative Binomial Regression",
    "section": "",
    "text": "Comparison of implementations and results between SAS vs R for negative binomial regression for count data."
  },
  {
    "objectID": "Comp/r-sas_negbin.html#scope",
    "href": "Comp/r-sas_negbin.html#scope",
    "title": "R vs SAS: Negative Binomial Regression",
    "section": "",
    "text": "NoteMethodologies\n\n\n\n\n\n\nNegative binomial regression\n\n\n\n\n\n\n\n\n\n\n\n\nNoteTechnical implementations\n\n\n\n\n\n\nSAS: PROC GENMOD with option: DIST = NB or DIST = NEGBIN\nR: MASS::glm.nb"
  },
  {
    "objectID": "Comp/r-sas_negbin.html#findings",
    "href": "Comp/r-sas_negbin.html#findings",
    "title": "R vs SAS: Negative Binomial Regression",
    "section": "",
    "text": "Below are summary of findings from a numerical comparison using dummy data, where possible we specify the same algorithm in R and SAS (see section Numerical Comparisons for details).\n\n\n\n\n\n\nNoteNegative binomial regression\n\n\n\n\n\nExact match (at 0.001 level) can be obtained using glm.nb in R vs PROC GENMOD procedure in SAS, for parameter and lsmeans estimates, confidence intervals and p-values after manually adjusting the estimated variance-covariance matrix in R. For the dispersion parameter the MLEs also match, however discrepancies in the confidence intervals are observed.\n\n\n\nIn the following sections the implementations will be compared in tabular fashion followed by a numerical comparison using dummy data."
  },
  {
    "objectID": "Comp/r-sas_negbin.html#how-to-read-the-tables",
    "href": "Comp/r-sas_negbin.html#how-to-read-the-tables",
    "title": "R vs SAS: Negative Binomial Regression",
    "section": "How to read the tables:",
    "text": "How to read the tables:\nLet’s walk through the conclusions for Table 1:\n\nSAS and R use different parameterizations of the negative binomial\nSAS and R use different likelihood optimization algorithms\nThere are differences in the estimation of the variance-covariance matrix, in particular the covariance between dispersion/scale parameter and model coefficients. It is however possible to obtain the SAS variance-covariance matrix in R.\nConvergence criteria are not generally identical in SAS and R.\nCI estimation methods are by default not identical but by using alternative confint function in R SAS method can be reproduced\n\nMethods for hypothesis testing for model coefficients are equivalent in SAS and R.\nLeast-square or marginal means are not directly available in R but equivalent estimation as in SAS is possible with additional packages\n\n\n\n\nTable 1: Negative binomial regression in SAS vs R\n\n\n\n\n\n\n\n\n\n\n\nAttribute\nSAS  PROC GENMOD\nR MASS::glm.nb\nNote\n\n\n\n\nNegative binomial parameterization\nVariance of the negative binomial is given by \\(\\mu + k\\mu^2\\) and the dispersion parameter k is estimated. Overdispersion increases as k goes to infinity.\nVariance of the negative binomial is given by \\(\\mu + \\frac{\\mu^2}{\\theta}\\) and the scale parameter theta is estimated. Overdispersion increases as theta goes to zero.\n\\(k=\\frac{1}{\\theta}\\)\n\n\nLikelihood optimization algorithm\nRidge-stabilized Newton-Raphson algorithm\nIteratively reweighted least squares (IWLS)\nIt seems SAS performs simultaneous optimization on all parameters (i.e. including dispersion). R uses an alternating process, where glm coefficients are fitted given a fixed theta and then theta is estimated given fixed coefficients until convergence.\n\n\nEstimation of variance-covariance matrix\nObserved (rather than expected) fisher information is used for calculation of standard errors of coefficients, which allows for non-zero covariance between coefficients and dispersion parameter.\nExpected fisher information is used for calculation of standard errors of coefficients, so covariance between coefficients and dispersion parameter is zero (which is asymptotically correct). However identical vcov matrix as in SAS can be obtained “post-hoc”.\nAs shown in the numerical example below in R the variance-covariance matrix corresponding to the PROC GENMOD estimation can be obtained based on the outputs from MASS::glm.nb with the glm.nb.cov function. The “correct” standard errors, confidence intervals and p-values can then be manually calculated based on the new covariance matrix.\n\n\nConvergence criteria\nThe iterations are considered to have converged when the maximum change in the parameter estimates between iteration steps is less than the value specified in CONVERGE option (default: CONVERGENCE = 1E-4)\nBased on relative difference between deviance, specified through epsilon argument in glm.control (default: epsilon = 1e-8).\nPROC GENMOD also checks for relative Hessian convergence and throws a warning if this is larger than the value provided in the CONVH option (default: CONVH = 1E-4 ).\n\n\nConfidence interval (CI) estimation method\nBy default asymptotic Wald CIs are estimated. Profile likelihood CI is estimated if option LRCI is provided.\nconfint function will estimate profile likelihood CIs, Wald CIs can be obtained by using confint.default\nNote that by default confidence intervals can differ even if same method is used if vcov matrix in R is not adjusted as explained above.\n\n\nHypothesis tests for regression coefficients\nAsymptotic Wald test\nAsymptotic Wald test\nPROC GENMOD reports Wald Chi-square statistic, while MASS::glm.nb reports the Z statistic, however the p-values are equivalent. Note that by default test results will differ if vcov matrix in R is not adjusted as explained above.\n\n\nEstimation of least-square/marginal means\nCalculation through lsmeans statement assumes that for classification effects the groups are balanced. OM option can be provided to obtain lsmeans that are using the observed proportions in the data\nNot implemented as part of MASS::glm.nb but can be obtained using emmeans package.\nIn R marginal means can be obtained using the emmeans::emmeans function, setting argument weights = \"equal\" corresponds to the default option in SAS, while weights = \"proportional\" gives the means proportional to observed data"
  },
  {
    "objectID": "Comp/r-sas_negbin.html#prerequisites-r-packages",
    "href": "Comp/r-sas_negbin.html#prerequisites-r-packages",
    "title": "R vs SAS: Negative Binomial Regression",
    "section": "Prerequisites: R packages",
    "text": "Prerequisites: R packages\nIn order to run these analyses we need to load a few packages.\n\nlibrary(MASS)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following object is masked from 'package:MASS':\n\n    select\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(emmeans)\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\n\nWe also define the glm_nb_cov function to obtain the SAS variance-covariance matrix in R from here.\n\n## Helper function to compute the variance from negative binomial regression\n## This matches with variance estimated from SAS\nglm_nb_cov &lt;- function(mod) {\n  # given a model fitted by glm.nb in MASS, this function returns a variance covariance matrix for the\n  # regression coefficients and dispersion parameter, without assuming independence between these\n  # note that the model must have been fitted with x=TRUE argument so that design matrix is available\n\n  # formulae based on p23-p24 of\n  # http://pointer.esalq.usp.br/departamentos/lce/arquivos/aulas/2011/LCE5868/OverdispersionBook.pdf\n  # and http://www.math.mcgill.ca/~dstephens/523/Papers/Lawless-1987-CJS.pdf\n\n  # lintr: off\n  # please rm -- variable not used!\n  # k &lt;- mod$theta\n  # lintr: on\n  # p is number of regression coefficients\n  p &lt;- dim(vcov(mod))[1]\n\n  # construct observed information matrix\n  obsInfo &lt;- array(0, dim = c(p + 1, p + 1))\n\n  # first calculate top left part for regression coefficients\n  for (i in 1:p) {\n    for (j in 1:p) {\n      obsInfo[i, j] &lt;- sum(\n        (1 + mod$y / mod$theta) *\n          mod$fitted.values *\n          mod$x[, i] *\n          mod$x[, j] /\n          (1 + mod$fitted.values / mod$theta)^2\n      )\n    }\n  }\n\n  # information for dispersion parameter\n  obsInfo[(p + 1), (p + 1)] &lt;- -sum(\n    trigamma(mod$theta + mod$y) -\n      trigamma(mod$theta) -\n      1 / (mod$fitted.values + mod$theta) +\n      (mod$theta + mod$y) / (mod$theta + mod$fitted.values)^2 -\n      1 / (mod$fitted.values + mod$theta) +\n      1 / mod$theta\n  )\n\n  # covariance between regression coefficients and dispersion\n  for (i in 1:p) {\n    obsInfo[(p + 1), i] &lt;- -sum(\n      ((mod$y - mod$fitted.values) *\n        mod$fitted.values /\n        ((mod$theta + mod$fitted.values)^2)) *\n        mod$x[, i]\n    )\n    obsInfo[i, (p + 1)] &lt;- obsInfo[(p + 1), i]\n  }\n\n  # return variance covariance matrix\n  solve(obsInfo, tol = 1e-20)\n}"
  },
  {
    "objectID": "Comp/r-sas_negbin.html#dummy-data",
    "href": "Comp/r-sas_negbin.html#dummy-data",
    "title": "R vs SAS: Negative Binomial Regression",
    "section": "Dummy data",
    "text": "Dummy data\nA dummy dataset is simulated, including\n\n100 subjects;\n\\(grp\\): a dummy variable with 1:1 subject assignment to treatment (\\(grp = 1\\)) vs placebo (\\(grp = 0\\)); note, variable \\(grpc\\) is a character version of \\(grp\\), which takes the value of “Trt” or “Plb”.\n\\(x1\\): a continuous variable which follows a normal distribution of mean of 0 and sd of 1;\n\\(x2\\): a categorical variable which take the value of “A” or “B” or “C” with a probability of 0.3, 0.2, 0.5, respectively.\n\\(logtime\\): An offset for the calculation of rates (e.g time in years) on the log-scale\n\\(y\\): a negative binomial outcome giving the event counts;\n\nThe dummy dataset is saved as a csv file, and then the csv file is read into SAS.\n\nN = 100\n\n# set seed for replication\nset.seed(123)\n\n# Treatment Group; 1:1 ratio\ngrp &lt;- rep(c(0, 1), each = N / 2)\n\n# Covariates (one continuous; one categorical)\nx1 &lt;- rnorm(N)\nx2 &lt;- factor(sample(LETTERS[1:3], N, replace = TRUE, prob = c(0.3, 0.2, 0.5)))\n\n# Offset\nlogtime &lt;- log(runif(N, 1, 2))\n\n# Model parameter assumption\nbeta0 = 0.6\nbetaTrt = -0.5\nbeta1 = 0.25\nbeta2 = c(-0.1, 0.2)\ntheta = 1 / 2\n\n\n# Dummy dataset\ndf &lt;- data.frame(grp, x1, x2, logtime) %&gt;%\n  mutate(\n    log_rate = case_when(\n      x2 == \"A\" ~ beta0 + betaTrt * grp + beta1 * x1 + logtime,\n      x2 == \"B\" ~ beta0 + betaTrt * grp + beta1 * x1 + beta2[1] + logtime,\n      x2 == \"C\" ~ beta0 + betaTrt * grp + beta1 * x1 + beta2[2] + logtime\n    ),\n    y = rnegbin(N, mu = exp(log_rate), theta = theta),\n    grpc = factor(case_when(grp == 0 ~ \"Plb\", grp == 1 ~ \"Trt\"))\n  )\n\n# save the dummy dataset to be imported in SAS\n# write.csv(df, file = \"df_dummy_negbin.csv\")"
  },
  {
    "objectID": "Comp/r-sas_negbin.html#negative-binomial-regression-1",
    "href": "Comp/r-sas_negbin.html#negative-binomial-regression-1",
    "title": "R vs SAS: Negative Binomial Regression",
    "section": "Negative binomial regression",
    "text": "Negative binomial regression\n\n\n\n\n\n\nNoteConclusion for negative binomial regression\n\n\n\n\n\nExact match (at 0.001 level) can be obtained using glm.nb in R vs PROC GENMOD procedure in SAS, for parameters and lsmeans estimates, confidence intervals and p-values after manually adjusting the estimated variance-covariance matrix in R. For the dispersion parameter the MLEs also match, however discrepancies in the confidence intervals are observed.\n\n\n\n\nNegative binomial regression in SAS\nAfter importing the dummy dataset we can run the negative binomial regression in SAS using `PROC GENMOD. We estimate the model parameters and lsmeans for the treatment arms using both the default and OM weights.\n\nproc genmod data=df;\n    class GRPC (ref='Plb') X2 (ref='A');\n    model y = GRPC x1 x2 / dist=negbin link=log offset=logtime;\n    lsmeans GRPC /cl;\n    lsmeans GRPC /cl OM;\nrun;\n\nBelow is a screenshot of output tables summarizing coefficient estimates and lsmeans."
  },
  {
    "objectID": "Comp/r-sas_negbin.html#negative-binomial-regression-in-r",
    "href": "Comp/r-sas_negbin.html#negative-binomial-regression-in-r",
    "title": "R vs SAS: Negative Binomial Regression",
    "section": "Negative binomial regression in R",
    "text": "Negative binomial regression in R\nLets now try to reproduce the results in R using MASS::glm.nb.\n\nfit &lt;- glm.nb(y ~ grpc + x1 + x2 + offset(logtime), data = df, x = TRUE)\n\n# model coefficients summary\nsummary(fit)$coefficients\n\n               Estimate Std. Error    z value   Pr(&gt;|z|)\n(Intercept)  0.72652157  0.3507054  2.0716007 0.03830269\ngrpcTrt     -0.61401736  0.3414815 -1.7980982 0.07216145\nx1           0.25663164  0.1890455  1.3575129 0.17461831\nx2B         -0.37406342  0.5069487 -0.7378723 0.46059203\nx2C         -0.04999267  0.3916689 -0.1276401 0.89843376\n\n\nWe can see that while the estimates are exactly matching those in SAS, the standard errors are slightly smaller. This is a result of the difference in covariance estimation mentioned above. To obtain exactly the same results as in SAS we need to re-estimate the covariance matrix using the glm_nb_cov function we defined earlier. Note that to use this function with the fitted results we needed to specify x = TRUE in the glm.nb function so that the design matrix is available.\n\nsigma_hat &lt;- glm_nb_cov(fit)\n\n## recalculate confidence intervals, and p-values\ncoef_est &lt;- coef(fit)\ncoef_se &lt;- sqrt(diag(sigma_hat)[1:5])\n\ncoef_lower &lt;- coef_est - qnorm(0.975) * coef_se\ncoef_upper &lt;- coef_est + qnorm(0.975) * coef_se\n\nzstat &lt;- coef_est / coef_se\npval &lt;- 2 * (1 - pnorm(abs(zstat)))\n\nnew_summary &lt;- cbind(coef_est, coef_se, coef_lower, coef_upper, zstat, pval)\n\ncolnames(new_summary) &lt;- c(\n  \"Estimate\",\n  \"Std. Error\",\n  \"CI_lower\",\n  \"CI_upper\",\n  \"z value\",\n  \"Pr(&gt;|z|)\"\n)\nrownames(new_summary) &lt;- rownames(summary(fit)$coefficients)\nnew_summary\n\n               Estimate Std. Error    CI_lower   CI_upper    z value   Pr(&gt;|z|)\n(Intercept)  0.72652157  0.3517882  0.03702942 1.41601371  2.0652246 0.03890176\ngrpcTrt     -0.61401736  0.3479606 -1.29600763 0.06797291 -1.7646174 0.07762809\nx1           0.25663164  0.2066499 -0.14839474 0.66165803  1.2418667 0.21428575\nx2B         -0.37406342  0.5073695 -1.36848936 0.62036253 -0.7372604 0.46096404\nx2C         -0.04999267  0.4013463 -0.83661692 0.73663158 -0.1245624 0.90086997\n\n\nNow the estimates, standard errors, 95% confidence interval limits and p-values are exactly matching those in SAS up to the 4th digit. We can also provide an estimate and CI for the dispersion parameter:\n\n# estimate and 95%-CI for k = 1/theta\ntheta_est &lt;- fit$theta\ntheta_se &lt;- sqrt(sigma_hat[6, 6])\n\ntheta_est_ci &lt;- c(\n  theta_est,\n  theta_est - qnorm(0.975) * theta_se,\n  theta_est + qnorm(0.975) * theta_se\n)\n1 / theta_est_ci[c(1, 3, 2)]\n\n[1] 2.370525 1.672211 4.070264\n\n\nWe see that while the point estimate is the same as in SAS, the CI for the dispersion does not match, most likely due to the different parameterizations used by SAS and R.\nFinally we can replicate the estimation of lsmeans in SAS via the emmeans package. Note that we need to supply the re-estimated covariance matrix, but only provide the rows and columns for the model coefficients without the dispersion parameter as emmeans does not need the latter.\n\n# lsmeans with weights = equal, equivalent to SAS default\nlsmean1 &lt;- emmeans(\n  fit,\n  ~grpc,\n  data = df,\n  vcov. = sigma_hat[1:5, 1:5],\n  weights = \"equal\",\n  offset = 0\n)\nlsmean1\n\n grpc   emmean    SE  df asymp.LCL asymp.UCL\n Plb   0.60837 0.245 Inf     0.128     1.088\n Trt  -0.00565 0.268 Inf    -0.531     0.519\n\nResults are averaged over the levels of: x2 \nResults are given on the log (not the response) scale. \nConfidence level used: 0.95 \n\n# lsmeans with weights = proportional, equivalent to SAS OM option\nlsmean2 &lt;- emmeans(\n  fit,\n  ~grpc,\n  data = df,\n  vcov. = sigma_hat[1:5, 1:5],\n  weights = \"proportional\",\n  offset = 0\n)\nlsmean2\n\n grpc emmean    SE  df asymp.LCL asymp.UCL\n Plb  0.6527 0.237 Inf     0.188     1.117\n Trt  0.0386 0.250 Inf    -0.451     0.528\n\nResults are averaged over the levels of: x2 \nResults are given on the log (not the response) scale. \nConfidence level used: 0.95 \n\n\nEstimates and CIs are exactly matching those in SAS for both of the options. Finally we can also obtain the z statistic and corresponding p-values:\n\ntest(lsmean1)\n\n grpc   emmean    SE  df z.ratio p.value\n Plb   0.60837 0.245 Inf   2.484  0.0130\n Trt  -0.00565 0.268 Inf  -0.021  0.9832\n\nResults are averaged over the levels of: x2 \nResults are given on the log (not the response) scale. \n\ntest(lsmean2)\n\n grpc emmean    SE  df z.ratio p.value\n Plb  0.6527 0.237 Inf   2.753  0.0059\n Trt  0.0386 0.250 Inf   0.155  0.8770\n\nResults are averaged over the levels of: x2 \nResults are given on the log (not the response) scale. \n\n\nAnd we see that these are also identical to the SAS results."
  },
  {
    "objectID": "Comp/r-sas_negbin.html#discussion",
    "href": "Comp/r-sas_negbin.html#discussion",
    "title": "R vs SAS: Negative Binomial Regression",
    "section": "Discussion",
    "text": "Discussion\nAs shown above it is generally possible to obtain exactly matching results in SAS and R for negative binomial regression. Most important to ensure matching is the manual estimation of the covariance matrix in R, as otherwise standard errors will only asymptotically match those in SAS.\nAs shown above lsmeans-type estimates can also be exactly reproduced using the emmeans package in R if options are correctly specified.\nFor the dispersion parameter an exact match in the MLE is possible, however CIs were not matching in our example. Most likely this is due to the different parameterizations used in SAS and R, since the variance for the dispersion parameters can not be transformed exactly between the two parameterizations. As generally the dispersion parameter should be of lesser interest and the other parameter estimates are not affected by this, this may however not be an issue in most applications.\nEven though results matched in the numerical example we have also highlighted that there are differences in the implementations, in particular when it comes to maximum likelihood optimization methods and convergence criteria. It is possible that this may lead to different estimates for data where the MLE is not easy to find and the methods may disagree on convergence or the optima of the likelihood. In addition, the different parameterizations may lead to different results in scenarios, where there is only very little overdispersion, since in those cases the dispersion parameter will go towards zero in SAS and towards infinity in R.\nAs a final point it should be kept in mind when comparing SAS and R results, that the two apply different rules for rounding. R rounds to the even digit (i.e. both 1.5 and 2.5 round to 2), while SAS uses “conventional” rounding rules (i.e 1.5 is rounded to 2 and 2.5 to 3). This can also occasionally lead to differences in results and may need to be addressed by using a custom rounding function in R, that uses SAS rounding rules. An example of such a function is provided in one of the references given below."
  },
  {
    "objectID": "Comp/r-sas_negbin.html#references",
    "href": "Comp/r-sas_negbin.html#references",
    "title": "R vs SAS: Negative Binomial Regression",
    "section": "References",
    "text": "References\n\nSAS PROC GENMOD documentation.\nR glm.nb documentation.\nCrossValidated discussion on covariance estimation (glm.nb.cov function is provided in the answer by Jonathan Bartlett).\nDiscussion of general differences in SAS and R including rounding"
  },
  {
    "objectID": "Comp/r-sas-wilcoxonsr_HL.html",
    "href": "Comp/r-sas-wilcoxonsr_HL.html",
    "title": "R vs SAS vs StatXact - Wilcoxon signed-rank test",
    "section": "",
    "text": "This section compares the implementation of Wilcoxon signed-rank test in R, SAS and StatXact.\n\n\n\nThe following table provides an overview of the methods support comparability between R, SAS and StatXact for the new analysis point.\n\n\n\n\n\n\n\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nSupported in StatXact\nNotes\n\n\n\n\nWilcoxon signed-rank test with p value only\nYES\nYES\nYES\nAvailable in all, but results match only between R and StatXact. See details on p value on each software page.\n\n\nHodges-Lehmann estimator\nYES\nNO\nYES\nAvailable in R and StatXact only. In SAS needs to be derived manually.\n\n\nExact/non-exact method\nNon-exact method with/without continuity correction\nYES\nYES\nNO\nNO\nYES\nNO\nStats package in R and StatXact support both options. SAS applies a default one depending on N.\nOnly Stats package in R support both options.\n\n\nDataset with “0” differences\nYES\nNO\nYES\nSAS ignores 0s. In R only Coin package supports.\n\n\nDataset with ties\nYES\nYES\nYES\nSupported in SAS and StatXact. In R only in Coin.\n\n\n\n\n\n\nAnalysis will be conducted on the example of anonymized data from 2-period, cross-over study comparing treatments A and B in patients with asthma and acute airway obstruction induced by repeated mannitol challenges.\nFor the purpose of the results comparison we will consider a specific case where the dataset has no ties and N (number of observations) = 240.\nWilcoxon signed rank test was applied to analyse the time to return to baseline FEV1 post-mannitol challenge 2. Median difference, p value and 95% CI were provided using the Hodges-Lehmann estimator.\n\nblood_p &lt;- read.csv(\"../data/WilcoxonSignedRank_TTR.csv\", dec = \".\")\n\n\nhead(blood_p)\n\n  SUBJID   TRT_A   TRT_B\n1      1 143.670 153.316\n2      2 163.082 170.576\n3      3 153.393 168.599\n4      4 153.082 142.358\n5      5 146.720 141.193\n6      6 150.668 147.204\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you need a flexibility of choosing between methods (exact, non-exact etc) in one software, go for R or StatXact.\nIf you need a detailed documentation explaining applied methods, go for StatXact.\nIf you only need p value and don’t mind a default exact or t-Student distribution depending on N, you can choose SAS.\nIf you need 0s to contribute to the analysis, go for Coin package in R or StatXact.\nIf your dataset has ties, go for Coin package in R or StatXact.\n\n\n\n\nDetails of how to implement the methods in the discussed software are available below:\nR:\n\nCheck how to perform this analysis in R here\n\nSAS & StatXact:\n\nCheck how to perform this analysis in SAS & StatXact here"
  },
  {
    "objectID": "Comp/r-sas-wilcoxonsr_HL.html#introduction",
    "href": "Comp/r-sas-wilcoxonsr_HL.html#introduction",
    "title": "R vs SAS vs StatXact - Wilcoxon signed-rank test",
    "section": "",
    "text": "This section compares the implementation of Wilcoxon signed-rank test in R, SAS and StatXact."
  },
  {
    "objectID": "Comp/r-sas-wilcoxonsr_HL.html#general-comparison-table",
    "href": "Comp/r-sas-wilcoxonsr_HL.html#general-comparison-table",
    "title": "R vs SAS vs StatXact - Wilcoxon signed-rank test",
    "section": "",
    "text": "The following table provides an overview of the methods support comparability between R, SAS and StatXact for the new analysis point.\n\n\n\n\n\n\n\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nSupported in StatXact\nNotes\n\n\n\n\nWilcoxon signed-rank test with p value only\nYES\nYES\nYES\nAvailable in all, but results match only between R and StatXact. See details on p value on each software page.\n\n\nHodges-Lehmann estimator\nYES\nNO\nYES\nAvailable in R and StatXact only. In SAS needs to be derived manually.\n\n\nExact/non-exact method\nNon-exact method with/without continuity correction\nYES\nYES\nNO\nNO\nYES\nNO\nStats package in R and StatXact support both options. SAS applies a default one depending on N.\nOnly Stats package in R support both options.\n\n\nDataset with “0” differences\nYES\nNO\nYES\nSAS ignores 0s. In R only Coin package supports.\n\n\nDataset with ties\nYES\nYES\nYES\nSupported in SAS and StatXact. In R only in Coin."
  },
  {
    "objectID": "Comp/r-sas-wilcoxonsr_HL.html#example-data",
    "href": "Comp/r-sas-wilcoxonsr_HL.html#example-data",
    "title": "R vs SAS vs StatXact - Wilcoxon signed-rank test",
    "section": "",
    "text": "Analysis will be conducted on the example of anonymized data from 2-period, cross-over study comparing treatments A and B in patients with asthma and acute airway obstruction induced by repeated mannitol challenges.\nFor the purpose of the results comparison we will consider a specific case where the dataset has no ties and N (number of observations) = 240.\nWilcoxon signed rank test was applied to analyse the time to return to baseline FEV1 post-mannitol challenge 2. Median difference, p value and 95% CI were provided using the Hodges-Lehmann estimator.\n\nblood_p &lt;- read.csv(\"../data/WilcoxonSignedRank_TTR.csv\", dec = \".\")\n\n\nhead(blood_p)\n\n  SUBJID   TRT_A   TRT_B\n1      1 143.670 153.316\n2      2 163.082 170.576\n3      3 153.393 168.599\n4      4 153.082 142.358\n5      5 146.720 141.193\n6      6 150.668 147.204"
  },
  {
    "objectID": "Comp/r-sas-wilcoxonsr_HL.html#summary-and-recommendation",
    "href": "Comp/r-sas-wilcoxonsr_HL.html#summary-and-recommendation",
    "title": "R vs SAS vs StatXact - Wilcoxon signed-rank test",
    "section": "",
    "text": "If you need a flexibility of choosing between methods (exact, non-exact etc) in one software, go for R or StatXact.\nIf you need a detailed documentation explaining applied methods, go for StatXact.\nIf you only need p value and don’t mind a default exact or t-Student distribution depending on N, you can choose SAS.\nIf you need 0s to contribute to the analysis, go for Coin package in R or StatXact.\nIf your dataset has ties, go for Coin package in R or StatXact."
  },
  {
    "objectID": "Comp/r-sas-wilcoxonsr_HL.html#additional-references",
    "href": "Comp/r-sas-wilcoxonsr_HL.html#additional-references",
    "title": "R vs SAS vs StatXact - Wilcoxon signed-rank test",
    "section": "",
    "text": "Details of how to implement the methods in the discussed software are available below:\nR:\n\nCheck how to perform this analysis in R here\n\nSAS & StatXact:\n\nCheck how to perform this analysis in SAS & StatXact here"
  },
  {
    "objectID": "Comp/r-sas_mcnemar.html",
    "href": "Comp/r-sas_mcnemar.html",
    "title": "R v SAS McNemar’s test",
    "section": "",
    "text": "McNemar’s test is a test of marginal homogeneity. That is used with 2x2 contingency tables, when both x and y are binary factors."
  },
  {
    "objectID": "Comp/r-sas_mcnemar.html#introduction",
    "href": "Comp/r-sas_mcnemar.html#introduction",
    "title": "R v SAS McNemar’s test",
    "section": "",
    "text": "McNemar’s test is a test of marginal homogeneity. That is used with 2x2 contingency tables, when both x and y are binary factors."
  },
  {
    "objectID": "Comp/r-sas_mcnemar.html#general-comparison-table",
    "href": "Comp/r-sas_mcnemar.html#general-comparison-table",
    "title": "R v SAS McNemar’s test",
    "section": "General Comparison Table",
    "text": "General Comparison Table\nThe following table provides an overview of the support and results comparability between R and SAS for the new analysis point.\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nMcNemar’s Chi-Squared test\nYes\nYes\n✅\nBy default SAS doesn’t include the continuity correction. In R use {stats} or {coin}\n\n\nCohen’s Kappa CI\nYes\nYes\n✅\nIn R use {vcd}\n\n\n\nIn R,the {stats} or the {coin} package can be used to calculate McNemar. The {coin} package has the same defaults as SAS. But, using either of these packages, the first step is to calculate a frequency table, using the table function.\n\nlibrary(coin)\n\nLoading required package: survival\n\ncolds &lt;- read.csv(\n  file = \"../data/colds.csv\"\n)\nfreq_tbl &lt;- table(\"age12\" = colds$age12, \"age14\" = colds$age14)\nfreq_tbl\n\n     age14\nage12  No Yes\n  No  707 256\n  Yes 144 212\n\ncoin::mh_test(freq_tbl)\n\n\n    Asymptotic Marginal Homogeneity Test\n\ndata:  response by\n     conditions (age12, age14) \n     stratified by block\nchi-squared = 31.36, df = 1, p-value = 2.144e-08\n\n\nIn order to get Cohen’s Kappa an additional package is needed.\n\nlibrary(vcd)\n\nLoading required package: grid\n\ncohen_kappa &lt;- vcd::Kappa(freq_tbl)\ncohen_kappa\n\n            value     ASE     z Pr(&gt;|z|)\nUnweighted 0.2999 0.02733 10.97 5.07e-28\nWeighted   0.2999 0.02733 10.97 5.07e-28\n\nconfint(cohen_kappa, level = 0.95)\n\n            \nKappa              lwr       upr\n  Unweighted 0.2463654 0.3534966\n  Weighted   0.2463654 0.3534966\n\n\nThe FREQ procedure can be used in SAS with the AGREE option to run the McNemar test, with OR, and RISKDIFF options stated for production of odds ratios and risk difference. These options were added as epibasix::mcNemar outputs the odds ratio and risk difference with confidence limits as default. In contrast to R, SAS outputs the Kappa coefficients with confident limits as default.\n\nproc freq data=colds;\n    tables age12*age14 / agree or riskdiff;\nrun;"
  },
  {
    "objectID": "Comp/r-sas_mcnemar.html#summary-and-recommendation",
    "href": "Comp/r-sas_mcnemar.html#summary-and-recommendation",
    "title": "R v SAS McNemar’s test",
    "section": "Summary and Recommendation",
    "text": "Summary and Recommendation\nWhen calculating the odds ratio and risk difference confidence limits, SAS is not treating the data as matched-pairs. There is advice on the SAS blog and SAS support page to amend this, which requires a lot of additional coding.\n{stats} is using Edward’s continuity correction by default, but this can be removed. In contrast, there is no option to include Edward’s continuity correction in SAS, but this can be manually coded to agree with R. However, its use is controversial due to being seen as overly conservative.\nThere is another R package that is sometimes used to calculate McNemar’s, called epibasix. This package is no longer being maintained, and there was no documentation available for certain methods used. Therefore, the use of the epibasix package is advised against and other packages may be more suitable.\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package * version date (UTC) lib source\n P coin    * 1.4-3   2023-09-27 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n─ External software ──────────────────────────────────────────────────────────\n setting value\n SAS     9.04.01M7P080520\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "Comp/r-sas_friedman.html",
    "href": "Comp/r-sas_friedman.html",
    "title": "R vs SAS Non-parametric Analysis - Friedman test",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rstatix)\nlibrary(ggpubr)"
  },
  {
    "objectID": "Comp/r-sas_friedman.html#data-used",
    "href": "Comp/r-sas_friedman.html#data-used",
    "title": "R vs SAS Non-parametric Analysis - Friedman test",
    "section": "Data used",
    "text": "Data used\nFriedman’s test is used when you have one within-subjects independent variable with two or more levels and a dependent variable that is not interval and normally distributed (but at least ordinal). To build such unreplicated blocked data, we’ll create a data frame called  df_bp from random number. In  df_bp : dependent variable bp is randomly generated; Block: subjid ; Group: time_point.\n\nset.seed(123)\n\ndf_bp = data.frame(bp = runif(n = 50, 138, 200)) |&gt;\n  mutate(\n    subjid = as.factor(row_number() %% 5),\n    time_point = as.factor((row_number() - 1) %/% 5 + 1)\n  )\n\nhead(df_bp)\n\n        bp subjid time_point\n1 155.8298      1          1\n2 186.8749      2          1\n3 163.3566      3          1\n4 192.7471      4          1\n5 196.3090      0          1\n6 140.8245      1          2\n\n\nLet’s see distribution of df_bp\n\nggpubr::ggboxplot(df_bp, x = \"time_point\", y = \"bp\", add = \"jitter\")"
  },
  {
    "objectID": "Comp/r-sas_friedman.html#example-code-using-rstatix",
    "href": "Comp/r-sas_friedman.html#example-code-using-rstatix",
    "title": "R vs SAS Non-parametric Analysis - Friedman test",
    "section": "Example Code using {rstatix}",
    "text": "Example Code using {rstatix}\nIn R, friedman_test can be used to compare multiple means of rank in bp grouped by time_point, stratified by subjid.\n\nres.fried &lt;- df_bp |&gt;\n  friedman_test(bp ~ time_point | subjid)\nres.fried\n\n# A tibble: 1 × 6\n  .y.       n statistic    df     p method       \n* &lt;chr&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;        \n1 bp        5      10.9     9 0.284 Friedman test"
  },
  {
    "objectID": "Comp/r-sas_friedman.html#example-code-using-proc-freq",
    "href": "Comp/r-sas_friedman.html#example-code-using-proc-freq",
    "title": "R vs SAS Non-parametric Analysis - Friedman test",
    "section": "Example Code using {PROC FREQ}",
    "text": "Example Code using {PROC FREQ}\nIn SAS, CMH2 option of PROC FREQ is used to perform Friedman’s test.\n\nproc freq data=data_bp;\n  tables patient*dos*bp / \n          cmh2 scores=rank noprint;\nrun;"
  },
  {
    "objectID": "Comp/r-sas_friedman.html#comparison",
    "href": "Comp/r-sas_friedman.html#comparison",
    "title": "R vs SAS Non-parametric Analysis - Friedman test",
    "section": "Comparison",
    "text": "Comparison\nThe Row Mean Scores Differ statistic of SAS result is compared with statistic of R result, together with p-value.\n\n\n\n\n\n\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\n\n\n\n\nFriedman Test\nYes\n\n\n\n\n\nYes\nYes"
  },
  {
    "objectID": "Comp/r-sas_friedman.html#comparison-results-from-more-data",
    "href": "Comp/r-sas_friedman.html#comparison-results-from-more-data",
    "title": "R vs SAS Non-parametric Analysis - Friedman test",
    "section": "Comparison Results from more data",
    "text": "Comparison Results from more data\nFriedman’s chi-suqare approximation varies when the number of blocks or the number of groups in the randomized block design differs. Similar comparison is done when number of block subjid ranges from 4 to 20 and number of group time_point ranges from 2 to 6. All results yield exact match (Comparison criterion is set to the tenth decimal place)."
  },
  {
    "objectID": "minutes/meetings/2023-09-11.html",
    "href": "minutes/meetings/2023-09-11.html",
    "title": "Conference updates & feedback, FDA quartely meeting, CAMIS-ONCO workshop",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n11_sep_2023\n\n\n\n\nAiming Yang\nNo\n\n\nBen Arancibia\nNo\n\n\nBrian Varney\nYes\n\n\nChristina Fillmore\nNo\n\n\nChelsea Dickens\nYes\n\n\nChi Zhang\nNo\n\n\nClara Beck\nNo\n\n\nAditee Dani\nYes\n\n\nDoug Kelkoff\nNo\n\n\nDhvani Patel\nYes\n\n\nFilip Kabaj\nNo\n\n\nHarshal Khanolkar\nYes\n\n\nIris Wu\nNo\n\n\nJayashree Vedanayagam\nNo\n\n\nJoe Rickert\nNo\n\n\nKyle Lee\nNo\n\n\nLeon Shi\nNo\n\n\nLily Hsieh\nYes\n\n\nLyn Taylor\nYes\n\n\nMartin Brown\nYes\n\n\nMia Qi\nNo\n\n\nMichael Kane\nNo\n\n\nMichael Rimler\nNo\n\n\nMike Stackhouse\nNo\n\n\nMin-Hua Jen\nNo\n\n\nMolly MacDiarmid\nYes\n\n\nMona Mehraj\nYes\n\n\nPaula Rowley\nNo\n\n\nSoma Sekhar Sriadibhatla\nYes\n\n\nVandana Yadav\nNo\n\n\nVidya Gopal\nYes\n\n\nVikash Jain\nYes\n\n\nWilmar Igl\nNo\n\n\nOrla Doyle\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda\nPHUSE SDE: Missisauga: June 8th feedback: Jayashreee not available today so see if any feedback at next meeting\nPHUSE FDA CSS Poster acceptance, white paper planning, PHUSE US Connect planning & CAMIS ONCO update: Soma Sekhar / Vikash Jain\nPoster presentation is next week. Harshil will advertise on social media.\nSubmitted a abstract for poster & presentation/workshop for US Connect 2024. White paper ongoing. Python code for CAMIS-ONCO being created. Workshop for PHUSE CSS 2024 will need planning. DVOST subgroup ½ day workshop ACTION Soma/Vikash work on the CSS workshop For 2024 .\nVikash was at the PHUSE SDE Boston last week. Met Michael Rimler and he’s introduced CAMIS to the board so they are aware of it.\nRSS conference feedback - Lyn Suggestions were to get more academics, university representatives involved with the project as it also makes for nice disseration projects for BSc/MScs.\nIBS CEN2023 conference - Feedback from Chi IBS CEN2023 conference (biometric society central Europe network held in Basel), CAMIS was mentioned along with other R working groups in a talk. The talk was about software engineering working group, the one that developed MMRM. Quite encouraging!\nSocial Media update : Harshal\nCall for volunteers.\n\nSoftware Engineering Working Group –\n\nWG goals are:\n\nCollaborate to engineer selected R-packages which will fill in gaps in the open-source statistical software landscape, and to promote software tools designed by the working group through publications, conference presentations, workshops, training courses, and others.\nDevelop best practices for engineering high-quality statistical software, and promote the use of best practices in the broader Biostatistics community via public training materials.\nCommunicate and collaborate with other R software initiatives.\n\n\nWorking group HomePage - https://rconsortium.github.io/asa-biop-swe-wg/\nCo-chairs - Daniel Sabanes Bove and Ya Wang.\n\n\n\n\nStatistical Methods in Oncology Scientific Working Group – WG goals are:\n\nEncourage increased use of systematic oncology assessment approaches and selection of best methods through training and education\n\nGain clear understanding of current regulatory environments in oncology\nPrepare a library of recommended methods including innovative methods\nUnderstand commonly used and innovative methods\nCollect and share experiences on using innovative designs\nPut together points to consider for oncology innovative designs’ implementation\nDevelop new methods if needed\n\nEducate the broader statistical community to understand and contribute to this important area\nIncrease statisticians’ leadership roles in cross-functional collaboration\nCommunicate statistical perspectives to larger clinical trial community\nCo-chairs - qjiang@seagen.com and olga.marchenko@bayer.com\n\n\nAdittee volunteered to join the Stats methods in oncology Scientific working group to represent us. ACTION: Aditee to reach out to co-chairs and ask to join, then feedback at our meetings on if there are opportunities to collaborate.\nAlso looking for volunteers to work on the Software Engineering WG & CAMIS ONCO- white paper, Harshil will work with Vikash & Soma to request that PHUSE share to advertise what we are looking for in a linkedIn post.\nPreparation for PHUSE FDA Quarterly meeting 27th sept: Slides / Survey questions : Lyn / harshil Tomorrow we can get the data back from questionnaire.   ACTION : Lyn/Harshil to meet, summarize survey & prepare slides.   Friday.\nWebsite Christina/ Chi / Jayashree\n\nCurrently, needs fixing pending RENV issue. So will be slight delay on getting content on the website\nContent curation lead items - Chi / Jayashree Made a great start to close discussions & address actions which have questions on them.\nMMRM update - No update ACTION: Lyn to follow up.\ngithub training plan (R/Pharma workshop & PSI training course) - ongoing prep for workshop & course through PSI AIMS team.\nAgnieszka (PAREXEL) and Chi – working on Wilcoxon test content for paired & unpaired data.\n\nUpcoming conference planning\n\nPHUSE SDE New York: Oct 16th : Aiming\nPHUSE US Connect: Soma/Vikash\nR/Pharma – Christina?\nSESUG (South East SAS user group) late october 2023, Brian will present on CAMIS.\nNorth Carolina - SDE if anyone wants to volunteer to attend let us know.\n\nAOB - None."
  },
  {
    "objectID": "minutes/meetings/2023-10-09.html",
    "href": "minutes/meetings/2023-10-09.html",
    "title": "FDA quartely meeting, 1st survey feedback - general updates",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n09_oct_2023\n\n\n\n\nAiming Yang\nNo\n\n\nBen Arancibia\nNo\n\n\nBrian Varney\nYes\n\n\nChristina Fillmore\nNo\n\n\nChelsea Dickens\nYes\n\n\nChi Zhang\nYes\n\n\nClara Beck\nNo\n\n\nAditee Dani\nNo\n\n\nDoug Kelkoff\nNo\n\n\nDhvani Patel\nYes\n\n\nFilip Kabaj\nNo\n\n\nHarshal Khanolkar\nYes\n\n\nIris Wu\nNo\n\n\nJayashree Vedanayagam\nNo\n\n\nJoe Rickert\nNo\n\n\nKyle Lee\nNo\n\n\nLeon Shi\nNo\n\n\nLily Hsieh\nYes\n\n\nLyn Taylor\nYes\n\n\nMartin Brown\nYes\n\n\nMia Qi\nYes\n\n\nMichael Kane\nNo\n\n\nMichael Rimler\nNo\n\n\nMike Stackhouse\nNo\n\n\nMin-Hua Jen\nNo\n\n\nMolly MacDiarmid\nYes\n\n\nMona Mehraj\nNo\n\n\nPaula Rowley\nNo\n\n\nSoma Sekhar Sriadibhatla\nNo\n\n\nVandana Yadav\nYes\n\n\nVidya Gopal\nYes\n\n\nVikash Jain\nNo\n\n\nWilmar Igl\nYes\n\n\nOrla Doyle\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda\nWelcome New Members: Vikrant Vijay FDA, Ismael Rodriguez (Appsilon)\nPHUSE SDE: Missisauga: June 8th feedback: Jayashreee\nCAMIS-ONCO update: Soma Sekhar / Vikash Jain\nPHUSE US Connect 2024 planning (Poster accepted, will find out re: workshop oct 20th)\nWhite paper planning\nFDA meeting update /survey results.: presented to around 15 FDA representatives, but didn’t get any questions/ comments on the call. However, follow the meeting, our slides were passed to others at the FDA and Vikrant Vijay got in touch to join the group. He’s not available today, but will attend in future.\nQuestionnaire only got 16 responses, 9/16 had heard of CAMIS, 13/16 used R for GXP, 4/15 used python for GXP, 1/16 used Julia for GXP. 9/16 had experienced discrepancies whilst trying to replicate analysis between languages.\nACTION: To re-run maybe just before CSS 2024 / or each year to assess progress and use for conference presentations.\nCommon programming challenges\n\nWhilst executing Analysis in R, I come across challenge in Numerical Differences in Statistical results. Would it be great if Industry & regulatory work together to build Standard R package for Statistical Methods & details in CAMIS repository would be highly appreciated.\nEnsuring reproducible environments and having people accept that different results for different implementations of an algorithm should perhaps be interpreted as a hint towards the accuracy, rather than one of the methods being wrong.\nStandard deviation initially did not match between and SAS. Later resolved by using the type option\nChallenges to figure out array of methods to replicate the same results across different software platforms/ Finding why resutls differ / unclear documentation/ discrepancy in values\nLS means contrasts from GLMs or MMRMs between SAS and R (vis lme4/mmrm + emmeans)\nParsing issues, scalability issues and network crash.\nImplementation of median seem to differ between R and SAS…. Sometimes joins in dplyr can also behave differently than i would expect with raw SQL\nDifferent methodologies (e.g for sample size calculation0 and lack of non-standard methods in SAS (e.g sample size for adaptive design).\n\nSocial Media update : Harshal\nNewsletter, (quarterly, or monthly) to advertise progress (ie. content we created) & conferences we are attending. Can we advertize ourself more to EMA, PMDA etc.. Can send to Frank Petavy (methodological working party). ACTION: Harshal/Lyn put togther summary for newsletter & send to Wilmar to reach out to Frank & others. Lyn to email David to see if any wider participation.\nhttps://www.ema.europa.eu/en/committees/working-parties-other-groups/chmp/methodology-working-party\nWebsite Christina/ Chi / Jayashree\n\nAll pull requests accepted & everything up to date\nMMRM update - No update. ACTION: Chi Zhang: will follow up to see if we can get someone to add in MMRM package to our existing content.\ngithub training plan (R/Pharma workshop & PSI training course) - ongoing prep for workshop & course through PSI AIMS team.\nAgnieszka (PAREXEL) and Chi – working on Wilcoxon test content for paired & unpaired data.\nACTION: Chi & Christina to talk about local rendering & renv issue with not having the packages to be able to render… once we know a fix, can write up and put on the website.\n\nUpcoming conference planning\n\nPHUSE SDE New York: Oct 16th : Aiming\nPHUSE US Connect: Soma/Vikash\nR/Pharma – Christina?\nSESUG (South East SAS user group) late october 2023, Brian will present on CAMIS.\nNorth Carolina - SDE if anyone wants to volunteer to attend let us know.\n\nAOB - None."
  },
  {
    "objectID": "minutes/meetings/2024-09-09.html",
    "href": "minutes/meetings/2024-09-09.html",
    "title": "Lessons learnt- Novartis Hackathon, Diversity Alliance, OSTCDA",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n09_Sep_24\n\n\n\n\nChristina Fillmore\nYes\n\n\nLyn Taylor\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBrian Varney\nYes\n\n\nChi Zhang\nNo\n\n\nOrla Doyle\nYes\n\n\nHarshal Khanolkar\nNo\n\n\nLily Hseih\nNo\n\n\nFilip Kabaj\nNo\n\n\nMartin Brown\nYes\n\n\nMin-Hua Jen\nYes\n\n\nSarah Rathwell\nNo\n\n\nKasa Andras\nNo\n\n\nAditee Dani\nNo\n\n\nKeaven Anderson\nYes\n\n\nBenjamin Arancibia\nNo\n\n\nWilmar Igl\nNo\n\n\nVikash Jain\nYes\n\n\nMia Qi\nNo\n\n\nLeon Shi\nNo\n\n\nVandaya Yadav\nNo\n\n\nStephen McCawille\nYes\n\n\nVikrant Vijay\nNo\n\n\nVidya Gopal\nNo\n\n\nDhvani Patel\nNo\n\n\nKyle Lee\nNo\n\n\nChelsea Dickens\nNo\n\n\nDavid Bosak\nNo\n\n\nMichael Kane\nYes\n\n\nLukas Brausch\nNo\n\n\nMichael Walshe\nNo\n\n\nSeemani Abhilipsa\nYes\n\n\nAiming Yang\nNo\n\n\nCuifeng Yin\nNo\n\n\nTodd Coffey\nNo\n\n\nJayashree Vedanayagam\nNo\n\n\nAshwath Gadapa\nNo\n\n\nMiriam Amor\nYes\n\n\nAnwesha Roy\nYes\n\n\nSamrit Pramanik\nYes\n\n\nAgnieszka Tomczyk\nNo\n\n\nPrem Kant Shekhar\nYes\n\n\nSunil\nNo\n\n\nKate Booth\nNo\n\n\nPeilin Zhou\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\n\nNovartis Hackathon\nOrla presented back to the group on Novartis’s Open-Source in Action: Hackathon. Key points were:\n\nAim: to encourage more people to be confident to work in open source and break down barriers in their contributing (such as through git training). To give people exposure to open-source resources that are applicable to their daily work as well as building their network with external experts.\nHow: Novartis open-source enablement team will hold hackathons on a regular basis selecting topics that have the potential to impact day-to-day work. External experts to guide Novartis employees on key initiatives and packages. This time CAMIS was selected with Christina providing support.\nWhen: Prep session 16th July 2024, Intro to git training 17th July, then 2 weeks of hackathon w/c 22nd July and 29th July with support during daily office hours.\nWho: 158 signed up from Advanced quantitative science (AQS), 100+ attended git training, 25+ submitted contributions. 8 SAS, 7 R, 1 Python, 3 SAS vs R and 1 template\nFeedback: Awards for First PR (Quick draw), most closed PRs (Busy bees), Most complex methodology (trailblazing) and Above and beyond (thinking beyond the methods).\nLearnings:\n\nTiming: aligned to ‘summer rejuvenation’ period where Novartis get 2 weeks to catch up with reduced meeting loads\nTraining: git and renv were a steep learning curve for newcomers, but daily office hours and teams channels helped. Little direction was needed to write content in quarto.\nCAMIS: the natural structure of CAMIS minimized prep work as the gaps in the table show what content is missing. It provided a nice culture to work in, focusing on good quality content over perfection. It was inclusive as it’s a multi-language project so could include people who only work in SAS or in R.\nCAMIS repo cloning often hangs if network is busy. Suggestion to reduce size of repo by removing the powerpoint presentations which would improve cloning.\n\n\n\n\nContent update\n\nSuggest to add page on how to run/ conduct a hackathon for CAMIS\nOnly 4 current open pull requests which all require changes by author so we are up to date\nWe still have a lot of open issues, but are making progress. Aim to get issues to 1 page by End of year\n\n\n\nDiversity Alliance Hackathon\nThe R in Pharma diversity alliance aspire to be an inclusive R community for developers who wok in the pharma space. Their goal is to provide a welcoming, equitable and supportive space for people to upskill, share knowledge and build a community of diverse voices.\nThey are holding an upcoming hackathon as part of the R in Pharma conference, where anyone who considers themselves as under-represented in the R in Pharma space, can participate. The event requires volunteers experienced in open source collaboration to lead attendees in small groups helping them to contribute open source collaborations. If you would like more information, to volunteer or attend, please contact Christina @statasaurus\nSee here for more information\n\n\nConferences\nThe conferences tab is up to date, we didn’t get any volunteers to represent us at PHUSE US connect.\n\n\nOSTCDA numeric matching page\nMichael Rimler is putting together a repo containing information about “Open Source Technology in Clinical Data Analysis (OSTCDA) for PHUSE. We now have a ‘numerical matching’ page here.\nPlease review and feel free to suggest changes to the content. Contact Lyn @drlyntaylor for any further information.\nAOB\n\nSarah raised an issue regarding retrieval of the documentation associated with ‘old’ versions of the R ‘stats’ package. For contributed packages, the documentation is present, but she’s struggling to find the same for the ‘stats’ package. ACTION: Christina to help investigate.\nThe issue highlighted that we may have 1 version of a package which mis-matched with SAS, but that later versions would have different functionality, and may match. Keeping the repo up to date will be a challenge, but hopefully if people are using it, issues will be identified and corrected.\nIt’s a reminder to ensure the code runs, from the data wherever possible. An issue for the SASvsR comparison pages is the comparison table is often typed in, such that if numbers change it wont be automatically updated. This is something we could consider in future. Perhaps running the code to populate the comparison table, and putting out a FAIL if conclusion changes from previous run, highlighting we need to update our written text."
  },
  {
    "objectID": "minutes/meetings/2025-05-12.html",
    "href": "minutes/meetings/2025-05-12.html",
    "title": "Blogs, New content, Conferences (2)",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n12_May_25\n\n\n\n\nLyn Taylor\nYes\n\n\nChristina Fillmore\nYes\n\n\nChi Zhang\nNo\n\n\nMolly MacDiarmid\nYes\n\n\nBenjamin Arancibia\nNo\n\n\nMichael Kane\nNo\n\n\nMartin Brown\nNo\n\n\nStephen McCawille\nNo\n\n\nMiriam Amor\nNo\n\n\nPeilin Zhou\nNo\n\n\nSamrit Pramanik\nYes\n\n\nBrian Varney\nYes\n\n\nVikrant Vijay\nNo\n\n\nYannick Vandendijck\nYes\n\n\nVikash Jain\nNo\n\n\nMichael Walshe\nYes\n\n\nAnwesha Roy\nNo\n\n\nMin-Hua Jen\nNo\n\n\nJaskaran Saini\nYes\n\n\nMariusz Zieba\nYes\n\n\nChelsea Dickens\nYes\n\n\nTejas Pandit\nNo\n\n\nAshwath Gadapa\nNo\n\n\nSarah Brosens\nNo\n\n\nKirsten Findlay\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\nBlogs:\n\nVikash blog on PHUSE US\nMolly/Lyn : Meeting with PHUSE admin team tomorrow re: size & frequency of blogs\n\nConferences:\n\nPSI 8th June. Stickers now printed & will be handed out including QR code to repo\nR in medicine: 11th June. Only $40 or so to attend so if anyone at your companies want to learn more it’s a good one to attend.\nPharmaSUG – Brian attending Yannick also applying to attend\nPHUSE EU. R/Pharma Nov 3-7th info TBC. call for abstracts not yet open.\nR in HTA workshop - conference. Stephen attending in June.\nJaskaran is presenting in PHUSE CSS: Synthetic data.\nPSI event in Cambridge England re: moving to R: 3rd July. Yannick attending & can mention CAMIS.\n\nNew content:\n\nBinomial test in SAS – noted comp page missing, so Jaskaran volunteered to do comparison page & Cochran mantel haenzel test in python.\nSample size Cochran Armitage test for trend in R and SAS/StatXact\nAdded to the Friedman Test\nSample size Equivalence R & SAS.\nWorking group on confidence intervals & new package development (GSK Pfizer & roche doing CI’s for proportions). Cardx ones will move into citools (and come out of cardx as that should be manipulation only), and will add other methods such as CI stratified MN. DescTools is a wide ranging package so harder to validate for a GxP validated environment, so taking the CI’s from this package into a separate citools package. One stop place for all CIs for proportions and will have some odds ratios too.\nPoisson / negative binomial regression still needed - Lyn to do in July if poss"
  },
  {
    "objectID": "minutes/meetings/2023-08-21.html",
    "href": "minutes/meetings/2023-08-21.html",
    "title": "FDA quartely meeting, FDA CSS, SDEs, website & conference plans",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n21_aug_2023\n\n\n\n\nAiming Yang\nNo\n\n\nBen Arancibia\nNo\n\n\nBrian Varney\nYes\n\n\nChristina Fillmore\nYes\n\n\nChelsea Dickens\nYes\n\n\nChi Zhang\nYes\n\n\nClara Beck\nNo\n\n\nAditee Dani\nYes\n\n\nDoug Kelkoff\nNo\n\n\nDhvani Patel\nNo\n\n\nFilip Kabaj\nYes\n\n\nHarshal Khanolkar\nYes\n\n\nIris Wu\nNo\n\n\nJayashree Vedanayagam\nYes\n\n\nJoe Rickert\nNo\n\n\nKyle Lee\nNo\n\n\nLeon Shi\nNo\n\n\nLily Hsieh\nYes\n\n\nLyn Taylor\nYes\n\n\nMartin Brown\nYes\n\n\nMia Qi\nYes\n\n\nMichael Kane\nNo\n\n\nMichael Rimler\nNo\n\n\nMike Stackhouse\nNo\n\n\nMin-Hua Jen\nNo\n\n\nMolly MacDiarmid\nYes\n\n\nMona Mehraj\nNo\n\n\nPaula Rowley\nNo\n\n\nSoma Sekhar Sriadibhatla\nYes\n\n\nVandana Yadav\nYes\n\n\nVidya Gopal\nNo\n\n\nVikash Jain\nYes\n\n\nWilmar Igl\nYes\n\n\nOrla Doyle\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda\nPHUSE FDA CSS Poster acceptance & white paper planning: Soma Sekhar\nSocial Media update : Harshal\nPHUSE SDEs: Missisauga: June 8th feedback: Jayashreee\nPreparation for PHUSE FDA Quarterly meeting 13th sept:  Questions/Slides feedback: Lyn\nWebsite Christina/ All\n\nNew Role: “Content curation lead”\n\nWe have been missing some posts when added to issues/discussion pages on website\nThis role will Monitor the  “Discussion” and “Issues” pages of the repo, and help to raise at each meeting where we need volunteers to answer questions/ add to discussion.\nWe will add a Standard agenda item lead by the “Content curation lead” to go through issues, & assign to people / close down issues/ discussions.\nIf you would like to volunteer please let Lyn / Christina know.\n\nHow can we encourage creation of more content?\n\n\n\nWhat areas are key for us to focus on\nMMRM update\ngithub training plan (R/Pharma workshop & PSI training course)\n\nUpcoming conference planning.\n\nRSS 7th Sept: Lyn presentation\n\n\n\nPOSIT Conf: Lyn to reach out to Juliane / Doug to ask to include slide for CAMIS\nPHUSE SDE New York: Oct 16th :  Aiming\n\n\n\nMeeting minutes\nReview of Action log\n\n\n\nAction\nAssigned to\nStatus\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to new members: Chi Zhang & Filip Kabaj\nPHUSE SDEs: Missisauga: June 8th feedback: Jayashreee\nGPT chat & machine learning for oncology presentations, needs for guidelines on how to use next level tools were discussed. Jayashree presented on behalf of CAMIS but on a Shiny App & got good questions including highlighting that for Endpoint /efficacy analysis they may require very specific standards so not easy to be generic/default. Chris Hurley (PHUSE SDE) also mentioned CAMIS which is great exposure for us.\nPreparation for PHUSE FDA Quarterly meeting 27th sept:  Questions/Slides feedback: Lyn/ Harshal\nMeeting was postponed by 4 weeks so we have time to prepare a short survey and send out on social media. Harshal went through the proposed questionnaire. Filip suggested Q2 to refer to frequency more specifically. Harshal to update & distribute\nSocial Media update : Harshal\nHarshal has posted the PSI poster post to social media. Going forward the proposal is to run a series of posts to focus on the content on the website - perhaps a short post just to say have you seen this new content and provide links.\nRE: Workshop - FDA CSS event (5-7 June): could run a comparison of SAS vs R workshop. Could focus on a set of issues & work though them make content & resolve issues. Could turn to linkedIn to ask wider community to vote for the biggest issue outstanding that they’d like to look into and select these for resolving at the workshop. See item below, as can discuss with Soma following this years FDA CSS event.\nWebsite Christina/ All\n\nThank you ALL!! Much content has been recenly pushed to the website.\nNew Role needed for a “Content curation lead”\n\nWe have been missing some posts when added to issues/discussion pages on website\nThis role will Monitor the  “Discussion” and “Issues” pages of the repo, and help to raise at each meeting where we need volunteers to answer questions/ add to discussion.\nWe will add a Standard agenda item lead by the “Content curation lead” to go through issues, & assign to people / close down issues/ discussions.\nJayashree & Chi volunteered to take on the role & to help monitor the repo activity. Lyn & Christina can put together guidance of what’s needed. Currently it’s just the issues & discussion, as pull requests are currently Ok being approved by Lyn & Christina as it’s a bit tricky to make sure it fits in with the repo and doens’t break anything!\nChi suggested that Christina check out projects to see if that would help to monitor whose doing what - may not work if can only be accessed by those already with granted access as we want anyone to be able to assign themselves. ACTION Christina to: Change the readme to say how to assign yourselves to content tasks.\n\nHow can we encourage creation of more content? / What areas are key for us to focus on\n\nGreat increase in content pre-meeting so Ok to grow organically for now.\nMMRM update : Christina to add link to MMRM website to cross reference.\n\ngithub training plan (R/Pharma workshop - free to attend in end October & PSI training course - series of session each week for x weeks, & PSI Conference Amsterdam - workshop 1.5 hrs.)\n\nPHUSE FDA CSS Poster acceptance (sept 20th) & white paper planning/ CAMIS ONCO: Soma Sekhar\nSoma demonstrated the poster which he’ll present with Vikash at CSS. Focused on Solid tumors OS/PFS but could broaden CAMIS ONCO with time to include other cancer.\nLonger term plan to create a white paper and to load survival analysis in python to repo.\nSoma to work with Harshil & others, to plan a sub team to work on CSS workshop for June 2023.\nLyn asked if there is demand for packages to be written that do standard stats analysis? The difficulty with this is how to standardise the programming and what it adds in addition to existing packages. It may not be worthwhile as options need to be considered so can’t automate.\nUpcoming conference planning.\n\nRSS 7th Sept: Lyn presentation\n\n\n\nPOSIT Conf: Lyn to reach out to Juliane / Doug to ask to include slide for CAMIS\nPHUSE SDE New York: Oct 16th :  Aiming\nR/Pharma - Christina submitted presentation\n\nAOQ/AOB - None."
  },
  {
    "objectID": "minutes/meetings/2025-03-10.html",
    "href": "minutes/meetings/2025-03-10.html",
    "title": "GDPR for PHUSE WGs & Latest repo updates",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n10_Mar_25\n\n\n\n\nLyn Taylor\nYes\n\n\nChristina Fillmore\nYes\n\n\nChi Zhang\nNo\n\n\nMolly MacDiarmid\nYes\n\n\nBenjamin Arancibia\nNo\n\n\nMichael Kane\nNo\n\n\nMartin Brown\nNo\n\n\nStephen McCawille\nYes\n\n\nMiriam Amor\nNo\n\n\nPeilin Zhou\nNo\n\n\nSamrit Pramanik\nNo\n\n\nBrian Varney\nYes\n\n\nVikrant Vijay\nNo\n\n\nYannick Vandendijck\nYes\n\n\nVikash Jain\nYes\n\n\nMichael Walshe\nNo\n\n\nAnwesha Roy\nNo\n\n\nMin-Hua Jen\nYes\n\n\nJaskaran Saini\nYes\n\n\nMariusz Zieba\nNo\n\n\nChelsea Dickens\nNo\n\n\nTejas Pandit\nNo\n\n\nAshwath Gadapa\nNo\n\n\nSarah Brosens\nNo\n\n\nKirsten Findlay\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\n\nBlog Update (Molly / Vikash)\n\nYannick’s Tobit regression blog was sent to PSI enews, PHUSE & will be on the CAMIS blog page shortly.\n\nContent updates in the last month ! (Christina / Lyn / Yannick)\n\nCox- PH update for Ties=Exact & Convergence (Nan Xiao & Abi terry)\n\nV 3.2-1.3 of package changed in R, how ties can be handled in survival::coxph function. Now instead of options for Breslow, Efron & discrete, now R can do Exact method & this matches SAS. Also, page had added a description of convergence methods to explain differences caused by convergence.\n\nCIs for Props (Lyn)\n\nNow has a section using desktools:BinomDiffCI for 2 independent samples\n\nLogistic regression (Lyn)\n\nNow complete. (NOTE discussion the call regarding how package authors can write their own\nS3 class R objects which overwrite defaults…. however, something like confint.default() can still be used to revert to the default wald method, incase of the confint() profile likelihood method.\nThis is why it’s dangerous to call variables function.variable as you may overwrite a special class of objects in R.\n\nReference based Multiple imputation joint modelling continuous data (Yannick)\n\nLeads the reader through R, SAS & the comparison. Full description of the LSHTM 5 SAS macros for this, vs R and found to agree!\nNOTE: that for Rbmi, Daniel Sabnane Bove, will be updating the package to include MMRM (at the moment it only does ANOVA).\n\nSample size for Bioequivalence (Andrey Ogurtsov) - TOST sample size added.\n\nRE: the Table of contents, feel free to suggest changes for the required categories vs content.\nNOTE: that we still have some pages, which could be classed as quick wins which are simple to create like SAS page for poisson/negative binomial. If you want to volunteer for anything add and issue or check for existing issues and assign yourself (or add comment that you are working on it.)\nRepo Tech\n\nSome complex methods may slow repo creation down.. Ok for now.\nCould update the running so only re-runs if code changes or only re-run if any of the packages change that the code uses. (if that’s possible).\nIs it useful, to use Riskmetric to assess quality of package? Possibly not, because riskmetric doesn’t handle stats packages very well. something like survival can appear ‘risky’ but it’s just because it was developed so long ago & hasn’t been updated because it doesn’t need to be updated ! Maybe add page on CAMIS talking about risk assessment of stats packages - how to assess trustworthyness.\n\nGDPR for PHUSE WGs - FORM IS BY CLICKING ON WORD FORM IN THE EMAIL.\nThe PHUSE Office has been reviewing our GDPR requirements and the information we hold on Working Group Members. As a result of this review, we have created a Working Group member form to capture the information we need to run effective and impactful Working Groups and project teams. As part of this we need to capture your consent to both hold basic information (name, email & company) and to use this in the context of PHUSE Working Groups.\nConsequently, it is now a mandatory requirement that all members of PHUSE Working Groups complete this *form* to enable your continued participation in project teams and Working Groups. Unfortunately, this means that those who do not respond, will need to be removed from the Working Groups. The deadline for completion of the form is 20 March 2025. Please select all Data Visualisation & Open Source Technology projects from the list that you participate in.\nAdditionally, as part of the form there is an opportunity to provide feedback on your experiences in PHUSE Working Groups. Whilst this is not mandatory, we would appreciate any feedback, particularly around any barriers/challenges you face that limits your participation, or any general feedback, both good and bad.\nIf you have any questions or feedback on the form, please contact the office at workinggroups@phuse.global. Thank you for your attention to this matter and we very much look forward to your continued support in the future.\nAOB"
  },
  {
    "objectID": "minutes/meetings/2025-08-11.html",
    "href": "minutes/meetings/2025-08-11.html",
    "title": "Tipping point, ISBC Poster",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n11_Aug_25\n\n\n\n\nLyn Taylor\nYes\n\n\nChristina Fillmore\nNo\n\n\nChi Zhang\nYes\n\n\nMolly MacDiarmid\nNo\n\n\nBenjamin Arancibia\nNo\n\n\nMichael Kane\nNo\n\n\nMartin Brown\nNo\n\n\nStephen McCawille\nNo\n\n\nMiriam Amor\nYes\n\n\nPeilin Zhou\nNo\n\n\nSamrit Pramanik\nNo\n\n\nBrian Varney\nYes\n\n\nVikrant Vijay\nNo\n\n\nYannick Vandendijck\nYes\n\n\nVikash Jain\nNo\n\n\nMichael Walshe\nNo\n\n\nAnwesha Roy\nNo\n\n\nMin-Hua Jen\nNo\n\n\nJaskaran Saini\nYes\n\n\nMariusz Zieba\nYes\n\n\nChelsea Dickens\nNo\n\n\nTejas Pandit\nNo\n\n\nAshwath Gadapa\nYes\n\n\nSarah Brosens\nNo\n\n\nKirsten Findlay\nYes\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\nNew Content This Month\n\nChristina’s guidance for how to select an appropriate R package to use for your work is now available here. You can also access it from contribution page, under the ‘Asking for help’ section using the short guidance link.\nSarah talked us through her Tipping point analysis R page using {rbmi}. This page now contains a description of what tipping point analysis is, variations you can use and a case study example of how to investigate various delta to find the tipping point. The page demonstrates really helpful plots and easy to write code (so easy compared to SAS)!. Keep watch of the repo table of contents for arrival of the SAS page & Comparison page in the near future. With enough simulations R & SAS were found to match to 3 decimal places.\nLyn raised that Christina and her are still finding interesting issues with even simple analyses such as ANOVA. More information will be added shortly to the ANOVA page with regards to contr.treatment (the default which should not be used due to non-orthogonal contrasts), and the rationale of why we use contr.sum and contr.poly instead !\nMiriam is writing GLMM pages including the methods using Laplace, GHQ & PQL, and will present this work at the PHUSE EU conference in Hamburg in November. Watch the repo for these pages in the near future.\n\n\nConferences.\n\nMiriam & Yannick are both presenting at PHUSE EU, so reach out to them if you are going and would like to meet up.\nYannick showed the team his ISBC CAMIS summary poster which will soon be available on the repo. Remember if you are attending any conferences or need to present a poster there is content you can use on the repo under Conferences."
  },
  {
    "objectID": "minutes/meetings/2022-12-12.html",
    "href": "minutes/meetings/2022-12-12.html",
    "title": "Restart Meeting",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n12_dec_2022\n\n\n\n\nAiming Yang\nNo\n\n\nBen Arancibia\nYes\n\n\nBrian Varney\nNo\n\n\nChristina Fillmore\nNo\n\n\nChelsea Dickens\nNo\n\n\nChi Zhang\nNo\n\n\nClara Beck\nNo\n\n\nAditee Dani\nNo\n\n\nDoug Kelkoff\nNo\n\n\nDhvani Patel\nNo\n\n\nFilip Kabaj\nNo\n\n\nHarshal Khanolkar\nNo\n\n\nIris Wu\nNo\n\n\nJayashree Vedanayagam\nYes\n\n\nJoe Rickert\nYes\n\n\nKyle Lee\nYes\n\n\nLeon Shi\nNo\n\n\nLily Hsieh\nYes\n\n\nLyn Taylor\nYes\n\n\nMartin Brown\nYes\n\n\nMia Qi\nYes\n\n\nMichael Kane\nNo\n\n\nMichael Rimler\nNo\n\n\nMike Stackhouse\nNo\n\n\nMin-Hua Jen\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nMona Mehraj\nNo\n\n\nPaula Rowley\nYes\n\n\nSoma Sekhar Sriadibhatla\nYes\n\n\nVandana Yadav\nNo\n\n\nVidya Gopal\nNo\n\n\nVikash Jain\nYes\n\n\nWilmar Igl\nNo\n\n\nOrla Doyle\nNo\n\n\n\n\n\n\n\n\n\n\nWelcome and brief CAMIS project update: Lyn\nPlease consider which areas of the project you would like to be involved with: * Repository reviewers/framework reviewers * Content creators (Comparing analysis method implementations in software) * Github - content review / approval * Marketing, i.e. blogs and sharing with wider community (PSI, ASA, PHUSE etc) to encourage contributions * Long term plan - Extend reach beyond Europe/USA.\n\n\nRepository roadmap : Lyn\n\nSample website & templates – mid January 2022\nFeedback on website/templates – EOB Feb 2022\nRevisions – March 2022\nLaunch – April 2022\n\n\n\nWhite paper status update: Min-Hua\nNOTE: we would like to put the URL of new website and mention CAMIS in paper if possible?\n\n\nOther stream updates: All\nNeed to identify who were the previous stream leads to check with them we can put content into new template formats. * CMH * Mixed models * Linear models\n\n\nQuestions/ AOB - All\n\nFuture meeting plan – Lyn set up directly so can be quickly adjust/ add more meetings if necessary?\nName change: CAMIS: Comparing analysis method implementations in software\nDo we need our own logo. CAMIS. Volunteers?\nSupported by PHUSE & PSI & ASA. Assign rep (or reps) for each organization.\nExtend membership given many previous members no longer on project\nVolunteer needed – can someone create a comparison using any method (but comparing SAS to Python/Julia or R to Python/Julia) – so we can test up with not just R Vs SAS.\nAOB."
  },
  {
    "objectID": "minutes/meetings/2025-09-08.html",
    "href": "minutes/meetings/2025-09-08.html",
    "title": "Content updates",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n08_Sep_25\n\n\n\n\nLyn Taylor\nYes\n\n\nChristina Fillmore\nNo\n\n\nChi Zhang\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBenjamin Arancibia\nNo\n\n\nMichael Kane\nNo\n\n\nMartin Brown\nNo\n\n\nStephen McCawille\nNo\n\n\nMiriam Amor\nYes\n\n\nPeilin Zhou\nNo\n\n\nSamrit Pramanik\nNo\n\n\nBrian Varney\nYes\n\n\nVikrant Vijay\nNo\n\n\nYannick Vandendijck\nYes\n\n\nVikash Jain\nNo\n\n\nMichael Walshe\nNo\n\n\nAnwesha Roy\nNo\n\n\nMin-Hua Jen\nNo\n\n\nJaskaran Saini\nYes\n\n\nMariusz Zieba\nNo\n\n\nChelsea Dickens\nNo\n\n\nTejas Pandit\nNo\n\n\nAshwath Gadapa\nNo\n\n\nSarah Brosens\nNo\n\n\nKirsten Findlay\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\nNew Content This Month\n\nRecurrent events page: Sarah/Yannick https://psiaims.github.io/CAMIS/Comp/r-sas_recurrent_events.html - R, SAS & R vs SAS recurrent events pages are present.\nWilcoxon rank sum test: Yannick CAMIS - A PHUSE DVOST Working Group - added asht:wmwTest() function available which wasn’t in the other packages that do WRS.\nPropensity score matching R page:  Chi  https://psiaims.github.io/CAMIS/R/causal_ps_matching.html\nANOVA, ANCOVA:  Christina ANOVA\nTidied up Help pages\n\n\nStandards:  use the package::function approach when writing up your pages\nConferences:\n\nBrian presenting at SESUG: September 22-24 2025 on SAS Campus in Cary, NC\nChi asked if we are doing any main session at R/pharma this year. There is the diversity hackathon again - reach out to christina if interested, but so far not aware of any CAMIS main session at R/pharma.\n\nAOB:\nPhil Bowsher: reached out to our group to see if we could investgiate operating system descrepancies, when doing comparisons SAS to R. Eg. the difference is not just in the underlying algorithms, but differences in operating system (R on linux on a server vs SAS on a PC windows or even language engines (SAS vs Altair for example)). Could CAMIS add this sort of comparison to the repo?  \n\nPerhaps have another section in CAMIS in main table (or another page if lots of content).\nWhen submitted to Cran, it is run in different OS (to check it runs), but we dont think any checks are done to check you get the same results. (but we think SAS does do this).\nWould be interesting to see example, and see size of any difference. Are they always tiny and inconsequential?\nCould allocate to students to investigate….?  LT:  project for Sheffield Hallam University ?\nHow would we do this when each person only has 1 operating system ! -  simple table of results & code, then email out & ask everyone to run it & confirm code or new result\nTo discuss further at leadership meeting & then come up with a plan"
  },
  {
    "objectID": "minutes/meetings/2024-07-15.html",
    "href": "minutes/meetings/2024-07-15.html",
    "title": "Repo Content Growth, Conferences 2024",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n15_Jul_24\n\n\n\n\nChristina Fillmore\nYes\n\n\nLyn Taylor\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBrian Varney\nYes\n\n\nChi Zhang\nNo\n\n\nOrla Doyle\nYes\n\n\nHarshal Khanolkar\nYes\n\n\nLily Hseih\nNo\n\n\nFilip Kabaj\nNo\n\n\nMartin Brown\nYes\n\n\nMin-Hua Jen\nYes\n\n\nSarah Rathwell\nYes\n\n\nKasa Andras\nNo\n\n\nAditee Dani\nNo\n\n\nKeaven Anderson\nYes\n\n\nBenjamin Arancibia\nNo\n\n\nWilmar Igl\nNo\n\n\nVikash Jain\nNo\n\n\nMia Qi\nNo\n\n\nLeon Shi\nNo\n\n\nVandaya Yadav\nNo\n\n\nStephen McCawille\nYes\n\n\nVikrant Vijay\nNo\n\n\nVidya Gopal\nNo\n\n\nDhvani Patel\nNo\n\n\nKyle Lee\nNo\n\n\nChelsea Dickens\nNo\n\n\nDavid Bosak\nNo\n\n\nMichael Kane\nYes\n\n\nLukas Brausch\nNo\n\n\nMichael Walshe\nYes\n\n\nSeemani Abhilipsa\nNo\n\n\nAiming Yang\nNo\n\n\nCuifeng Yin\nYes\n\n\nTodd Coffey\nNo\n\n\nJayashree Vedanayagam\nYes\n\n\nAshwath Gadapa\nNo\n\n\nMiriam Amor\nNo\n\n\nAnwesha Roy\nNo\n\n\nSamrit Pramanik\nNo\n\n\nAgnieszka Tomczyk\nNo\n\n\nPrem Kant Shekhar\nNo\n\n\nSunil\nNo\n\n\nKate Booth\nNo\n\n\nPeilin Zhou\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\nMonthly Contributions\n\nNot much content this month, but per the below, lots on the way !\n\nContent updates / assignments\nWe checked the assignments readme (under non-website content)\n\nSurvival – perhaps split into: non parametric, parametric (rather than AFT & non-proportional hazards), Update readme.md table to assign these rows to the survival team.\nTeam will meet again in 2 weeks.\nNegative binomial content has been posted, it’s a comparison, but would now be quick to write the SAS page. ACTION: Orla to ask the Novartis team to add that too.\nKeaven/Yulia – Group sequential designs: pull request internally east vs R – not doing comparison yet, but will do in future.\n\nQUESTIONS: Do we need to use SAS enterprise or SAS studio and should we state the version that gave the output? It’s probably good practice to do this in case something change. For R, we should use renv, any problem ask Christina. The R/Python code runs each time so output will be current per version being used. Only sas is static.\n22nd July – Novartis hackathon 150 signed up. Need to provide Orla with ideas of what we want them to look at. Stats SMEs will also review before doing pull requests. Possible topics could be:\n\nNegative binomial – comparison & SAS code Beecer – covariate adjustment for logistic regression\nLogistic regression page update – improve content & investigate why p value different.\nMANOVA – why R different to SAS\nFriedman test, Jonckheere test, bionomial, R / sas /comp both needed\nCorrelation in SAS\nChristina may need help to review pull request. Both Pfizer, Novartis & merck will have internal reviews prior to pull requests so review can be reduced.\n\nConferences\n\nChi’s UseR slides are now on the repository under\nPHUSE EU Brussels 23rd Sept - Qian Wang (Merck) will attend.\nPOSIT conf, R in pharma…R open now https://github.com/rinpharma/rinpharma-summit-2024?tab=readme-ov-file\nHarshal working with Daniel Sabanes Bove on the organizing committee for R in pharma: Asia pacific track – woudl be good to have a repo from Asia represent us\n25th July: Americas single day event pennylvania anyone going?\nJSM – 1st week august – Keaven Anderson going, lyn to send 1 slide.\n\nQUESTIONS: RE: funding to attend conferences, usually provided by your company, but in special circumstances we could request funding from: R consortium or PHUSE.\nBrainstorming session\nHow can we engage wider to increase content creation?\n\nPSI : enews,\nPHUSE bi-weekly news: Let Alexandra Peace (mailto:workinggroups@phuse.global) know of any events we are attending or new content we worked on and she will share in a weekly summary of progress.\nCould volunteer to host hackathons for conferences. Christina & orla volunteering to host a hackathon for R in pharma this week.\nAdvertise to PSI/PHUSE RE: if you have Findings please add an issue (even if you can’t look into it yourself).\nSpecial media post to Thank you Merck, Pfizer, Novartis for your contributions. Also companies can post what they’ve contributed. New content blogs. -\nBlog of Novartis hackathon.\n\nDissertations –still looking for new ideas for projects & widen engagement with universities."
  },
  {
    "objectID": "minutes/meetings/2024-10-10.html",
    "href": "minutes/meetings/2024-10-10.html",
    "title": "Gen AI for SAS–>R code, Achievements + 2025 objectives",
    "section": "",
    "text": "attendees\n14_oct_24\n\n\n\n\nChristina Fillmore\nYes\n\n\nLyn Taylor\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBrian Varney\nYes\n\n\nChi Zhang\nNo\n\n\nOrla Doyle\nNo\n\n\nHarshal Khanolkar\nYes\n\n\nLily Hseih\nNo\n\n\nFilip Kabaj\nNo\n\n\nMartin Brown\nNo\n\n\nMin-Hua Jen\nYes\n\n\nSarah Rathwell\nNo\n\n\nKasa Andras\nNo\n\n\nAditee Dani\nNo\n\n\nKeaven Anderson\nNo\n\n\nBenjamin Arancibia\nNo\n\n\nWilmar Igl\nNo\n\n\nVikash Jain\nNo\n\n\nMia Qi\nYes\n\n\nLeon Shi\nNo\n\n\nVandaya Yadav\nNo\n\n\nStephen McCawille\nYes\n\n\nVikrant Vijay\nNo\n\n\nVidya Gopal\nNo\n\n\nDhvani Patel\nNo\n\n\nKyle Lee\nNo\n\n\nChelsea Dickens\nNo\n\n\nDavid Bosak\nNo\n\n\nMichael Kane\nYes\n\n\nLukas Brausch\nYes\n\n\nMichael Walshe\nYes\n\n\nSeemani Abhilipsa\nNo\n\n\nAiming Yang\nNo\n\n\nCuifeng Yin\nNo\n\n\nTodd Coffey\nNo\n\n\nJayashree Vedanayagam\nYes\n\n\nAshwath Gadapa\nNo\n\n\nMiriam Amor\nNo\n\n\nAnwesha Roy\nYes\n\n\nSamrit Pramanik\nYes\n\n\nAgnieszka Tomczyk\nNo\n\n\nPrem Kant Shekhar\nYes\n\n\nSunil\nYes\n\n\nKate Booth\nNo\n\n\nPeilin Zhou\nNo"
  },
  {
    "objectID": "minutes/meetings/2024-10-10.html#gen-ai-to-convert-sas-code-to-r-code-brian",
    "href": "minutes/meetings/2024-10-10.html#gen-ai-to-convert-sas-code-to-r-code-brian",
    "title": "Gen AI for SAS–>R code, Achievements + 2025 objectives",
    "section": "Gen AI to convert SAS code to R code (Brian)",
    "text": "Gen AI to convert SAS code to R code (Brian)\nAI (such as chatgpt) can be used to convert SAS code to R or vice-versa. You can even upload a zip file containing multiple programs and it will unzip & convert. It even lists the packages it thinks it needs & can convert SAS macros into an R function (for example).\nIt’s not 100% reliable, and it does need work once translated but huge help if starting from scratch.\nSome caveats:\n\nAll code written is in lower case so you’d have to check that if your variable names are in mixed or upper case (as R case sensitive).\nchatgpt would also store your data, so don’t load anything up that is company sensitive!"
  },
  {
    "objectID": "minutes/meetings/2024-10-10.html#visibility-of-our-blogs-future-blogs-harshal",
    "href": "minutes/meetings/2024-10-10.html#visibility-of-our-blogs-future-blogs-harshal",
    "title": "Gen AI for SAS–>R code, Achievements + 2025 objectives",
    "section": "Visibility of our blogs /Future blogs (Harshal)",
    "text": "Visibility of our blogs /Future blogs (Harshal)\nDiscussed who sees the blogs, only 2 / 17 on the call saw it. Somehow we need to find a way to get more visibility! Any ideas let us know, but plan to do more blogs in future and will help if all share them."
  },
  {
    "objectID": "minutes/meetings/2024-10-10.html#conferences-update-lynall",
    "href": "minutes/meetings/2024-10-10.html#conferences-update-lynall",
    "title": "Gen AI for SAS–>R code, Achievements + 2025 objectives",
    "section": "Conferences update (Lyn/All)",
    "text": "Conferences update (Lyn/All)\n\nPHUSE EU connect meet up ! (Christina to arrange meeting face to face)\nMichael Walshe, Anwesha Roy, Stephen Mccawille, Kate Booth, Agnieska Tomczyk are going\nPHUSE US connect (Cuifeng? ): Lyn to follow up if anyone going.\nObjective 2025: expand our team members that we have in the USA.\nPHUSE FDA CSS will have a event in Utrecht, the netherlands running side by side with the Silver Springs, Maryland\nPSI 2025 deadlines are as follows:\n\nOral abstract submission -22nd November 2024\nNotification - no later than 16th December 2024\nPoster abstract submissions -25th February 2025"
  },
  {
    "objectID": "minutes/meetings/2024-10-10.html#content-updates-chrstina-all",
    "href": "minutes/meetings/2024-10-10.html#content-updates-chrstina-all",
    "title": "Gen AI for SAS–>R code, Achievements + 2025 objectives",
    "section": "Content updates (Chrstina / All)",
    "text": "Content updates (Chrstina / All)\nDiversity alliance hackathon will be addressing/reviewing open issues (especially ‘good first issue’ ones) To help with this event, please raise any Issues - preferably small changes that re needed for the Diversity alliance hackathon to use as example issues to open pull requests to resolve –\nOpen pull request = NONE ! Great work Christina!\nHuge Achievement for 2024: 200 closed pull requests\nSurvival (Christina) Meetings ongoing, if you want to join contact Christina. Objective 2025: Focus is on Accelerated failure time models.\nMMRM (Lyn) Objective 2025: to get updated such that the R, SAS & Comp are consistently written\nIf anyone else is assigned an area to research and needs help or can no longer commit to completing content just let us know and we can get someone to assist you or work to re-assign it."
  },
  {
    "objectID": "minutes/meetings/2024-10-10.html#previous-actions-items-update",
    "href": "minutes/meetings/2024-10-10.html#previous-actions-items-update",
    "title": "Gen AI for SAS–>R code, Achievements + 2025 objectives",
    "section": "Previous Actions Items Update",
    "text": "Previous Actions Items Update\n\nAdd page on how to run/conduct a hackathon: Perhaps drop this action unless someone thinks it’s useful? Please let us know if you want us to add this else we’ll not maintain the page & wind it down\nAdd a hackathon page: Question to ALL – do people want to do hackathons in their company to encourage open source? If we could write the guidance, then could link to it from linkedin. To a webinar or guidance. But if wont be used, wont put this highest on our list of To Do!\nFinding documentation for ‘old’ versions of the base R “stats” package (sarah/ christina) Hard to find this documentation. For this reason, need to use Eval: TRUE, so it runs using latest version and the output will be the latest output. However, in our comparison – often these are typed in, especially as you can’t get live output run from SAS. So if Table is not current… we wont know!\n\nObjective 2025-2026!: Rethink this in 2025. Can we add ‘testthat’ expect equals. So we are notified if something changes? Would have write/save SAS number in dataset to compare electronically with R. For tables with no numbers (listing defaults), we could check default as well. Could also not reproduce entire repo each time… but then run risk of things breaking (only running at snapshots of different versions). Printing of the Versions are now visible on the templates so please use the template so the versions appear In the run content"
  },
  {
    "objectID": "minutes/meetings/2024-10-10.html#goals",
    "href": "minutes/meetings/2024-10-10.html#goals",
    "title": "Gen AI for SAS–>R code, Achievements + 2025 objectives",
    "section": "Goals",
    "text": "Goals\n45 issues closed by end of year (surpassed already as 70 closed now!) NOTE: a lot are open because we opened as examples for the diversity alliance hackathon- will be closed in next few weeks after that event. Would like 1 page by end 2024. 200 pull requests closed out!!\nMMRM content: Stephen Waugh assigned to work on this until June 2025 as his dissertation project\nWebpage for listing dissertation projects? TBC if this is needed or doing OK assigning through volunteers."
  },
  {
    "objectID": "minutes/meetings/2024-10-10.html#new-2025-goals-and-some-carried-forward",
    "href": "minutes/meetings/2024-10-10.html#new-2025-goals-and-some-carried-forward",
    "title": "Gen AI for SAS–>R code, Achievements + 2025 objectives",
    "section": "New 2025 Goals (and some carried forward!)",
    "text": "New 2025 Goals (and some carried forward!)\n\nexpand our influence (particular through representation in USA)\nAdvance our MMRM pages\nAdvance our survival pages\nReconsider our infrastructure with respect to\n\nrenv\nlive running of repo and knowing when a version changes our content\nmaking it easier for people to contribute"
  },
  {
    "objectID": "minutes/meetings/2025-10-13.html",
    "href": "minutes/meetings/2025-10-13.html",
    "title": "SAS Viya, sasquatch, CAMIS End of Year Nominations, US Connect Poster",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n13_Oct_25\n\n\n\n\nLyn Taylor\nYes\n\n\nChristina Fillmore\nYes\n\n\nChi Zhang\nNo\n\n\nMolly MacDiarmid\nNo\n\n\nBenjamin Arancibia\nNo\n\n\nMichael Kane\nNo\n\n\nMartin Brown\nNo\n\n\nStephen McCawille\nYes\n\n\nMiriam Amor\nNo\n\n\nPeilin Zhou\nNo\n\n\nSamrit Pramanik\nNo\n\n\nBrian Varney\nNo\n\n\nVikrant Vijay\nNo\n\n\nYannick Vandendijck\nYes\n\n\nVikash Jain\nNo\n\n\nMichael Walshe\nNo\n\n\nAnwesha Roy\nNo\n\n\nMin-Hua Jen\nNo\n\n\nJaskaran Saini\nNo\n\n\nMariusz Zieba\nYes\n\n\nChelsea Dickens\nNo\n\n\nTejas Pandit\nNo\n\n\nAshwath Gadapa\nNo\n\n\nSarah Brosens\nNo\n\n\nKirsten Findlay\nNo\n\n\nDavid Bosak\nYes\n\n\nAman Bahl\nYes\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\n\nSAS Viya for Learners (SASQUATCH)\n\nIf you have SAS Viya, then you may be able to use sasquatch in R, to run SAS code.  If you can run sasPy, then you can also run sasquatch.\nhttps://github.com/ropensci/sasquatch\nThe advantage here would be being able to compare R vs SAS numerically from code running.\nLogan is going to create a guide & load to repo, then will hopefully present at a future meeting.  Initially, it will be an optional method, or you can continue to use normal SAS & image screen shot.\n\nWithin the repo:issues, anything labelled as ‘Hackathon’ was raised for adding package (session info) to pages -  Volunteers needed to add to current pages missing the session info.\nUse the Discussions channel for technical stats discussions to share issues & progress.\n\nACTION: Christina /Lyn to write something on Contrasts.…  ANCOVA / MMRM etc...  how to output your contrast being made in the design.matrix.\n\nNominations for CAMIS End of Year Awards by 28th Nov.\n\nAnnouncements in the December meeting.\n\nUS Connect Poster - There are a number of poster slots that have become available to Working Groups for US Connect. Time is limited to take advantage of this opportunity.  If you would like to submit a poster for consideration, please reply to this email with:\n\nPoster Title\nPoster Abstract\nPresenter Names\n\nBy This Friday 17 October COB \n\nPlease send poster submission direct to : workinggroups@phuse.global   if you want to apply and say it’s on behalf of CAMIS.\nAOB\n\nAndy Miskell (Eli Lilly)  - Created a list of all their stats methods that they use.  They are going to go through and compare how they do it in SAS and how they do it in R. Will reference CAMIS if we have it available, or research it themselves, (and will hopefully add to CAMIS).  Will also write packages if there are gaps. Open to getting other companies to collaborate across organizations.\nTeaching proposal submitted by Yannick for a masters thesis student Feb/mar until June/July 2026.\nAZ organizing R conference for March 2026, CAMIS could be a presenter (30mins). Mariusz to offer one of us to present.\nACTION Lyn: Reduce calls to 30 mins going forward."
  },
  {
    "objectID": "minutes/meetings/2023-11-20.html",
    "href": "minutes/meetings/2023-11-20.html",
    "title": "End of year summary, plan for 2024",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n20_nov_2023\n\n\n\n\nAiming Yang\nNo\n\n\nBen Arancibia\nNo\n\n\nBrian Varney\nYes\n\n\nChristina Fillmore\nYes\n\n\nChelsea Dickens\nYes\n\n\nChi Zhang\nYes\n\n\nClara Beck\nNo\n\n\nAditee Dani\nNo\n\n\nDoug Kelkoff\nNo\n\n\nDhvani Patel\nYes\n\n\nFilip Kabaj\nYes\n\n\nHarshal Khanolkar\nYes\n\n\nIris Wu\nNo\n\n\nJayashree Vedanayagam\nYes\n\n\nJoe Rickert\nNo\n\n\nKyle Lee\nNo\n\n\nLeon Shi\nNo\n\n\nLily Hsieh\nNo\n\n\nLyn Taylor\nYes\n\n\nMartin Brown\nYes\n\n\nMia Qi\nYes\n\n\nMichael Kane\nNo\n\n\nMichael Rimler\nYes\n\n\nMike Stackhouse\nNo\n\n\nMin-Hua Jen\nNo\n\n\nMolly MacDiarmid\nYes\n\n\nMona Mehraj\nNo\n\n\nPaula Rowley\nNo\n\n\nSoma Sekhar Sriadibhatla\nYes\n\n\nVandana Yadav\nNo\n\n\nVidya Gopal\nNo\n\n\nVikash Jain\nYes\n\n\nWilmar Igl\nYes\n\n\nOrla Doyle\nYes\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\n\nEnd of year summary\nPost & summary diagram of 2023 will go onto linkedIn soon, please like/share\nWe would like to welcome Harshal Khanolkar to become a co-lead of the PHUSE CAMIS Repo. Harshal has been instrumental through 2023 helping Christina and I stay on track and making suggestions for improving the social media and knowledge sharing within the group.\nMMRM now updated & Complete for now.\nGithub training will be on youtube following R/pharma conference soon\n\n2023 : A Year of Progress for PHUSE CAMIS Working Group\nAs we draw towards the end of 2023, the PHUSE CAMIS Working Group reflect on their key progress and successes this year.\nThe CAMIS repository went live in January 2023, drawing on the content from the PHUSE CSRMLW project.  This searchable repo compares analysis method implementations in software (CAMIS) such as SAS, R and python. \nThe White Paper was published in June, which highlighted the importance of clearly specifying your analysis, such that it can be replicated in different software, and isn’t relying on default options which can be different.\nFor more complex analyses, it can still be hard to understand what defaults and algorithms your software is using, so the team focused 2023 on expanding our repo content, comparing SAS vs R methods.  By August, we had covered the following topics in the repo: quartiles, rounding, anova, mmrm, cmh, log-rank, cox-ph, mcnemar’s test, kruskal-wallis test and logistic. October saw the launch of the sub-working group: CAMIS-Oncology, led by Somasekhar Sriadibhatla (AstraZeneca).  This team will focus specifically on oncology endpoints and analyzing them in SAS, R and Python.  The CAMIS team have expanded in membership during 2023 presenting at numerous conferences around the world. In November, we welcomed Harshal Khanolkar (NovoNordisk), to join the leadership team alongside Christina Fillmore (GSK) and Lyn Taylor (PAREXEL).  Our focus for 2024, will be on the creation of additional content for the repo, and sharing awareness of the project across the medical research and wider community.  We’d like to take this opportunity to thank all of our team members and contributors, and encourage everyone to check out the repository and help us to grow our content CAMIS (psiaims.github.io).  If you would like to join the team please get in touch through the repo.\n2023: lessons learnt: What we did well?\n\nAdverts to industry & linkedin posts. To be Continued into 2024 - engage more unis, internship projects, academia, posit conf, r users conf, target key conferences\nGood sharing of conference content through the repo & improving the slides in an ongoing way.\nLeadership & project progress with plans. Transparency of the work. Nice to get Agendas pre-meeting & minutes after meeting in timely manner.\nLarge range of individual contributions helping to grow repo. 1/2 contributors within the phuse group, but 1/2 outside of the group. So spreading the word is really helping us to get external contributions.\nACTION: Christina & Chi: Please can you improve the 2023 conference tab, create a 2024 tab which contains link to presentations within the github repo.\n\n2023: lessons learnt: What we didn’t do so well?\n\nTime to get pull requests approved. Aim for 2024 to reduce the time so it’s a maximum of 2 weeks. The delay was often caused by issues with renv. Christina is working with posit directly to improve renv issues & has already updated contributions guidance to help instruct people on how to contribute such as using Forks rather than needing github username access.\npython - Delayed discussion in how to design the repo to store python content.\nACTION: Vikash/ Soma / Filip - to meet with Lyn / Christina to agree format going forward.\nMore discussion on CAMIS ONCO below.\n\n\n2023: lessons learnt: What is our focus for next year?\n\nMore content\nengage more unis, internship projects, academia, posit conf, r users conf, target key conferences\nCAMIS ONCO white paper, workshop & python/sas/r comparison (See below)\nCSS 2024 workshop, interaction with audience. 3-4 hrs hopefully. TBD at separate meeting, agenda workshop. Vikash, Harshal, Soma. 3-5 June.\nIdea for 2024: Set up a method such that people with no git / github skills can still contribute to the project. Perhaps set up a CAMIS email address. Assign volunteers for someone to email, then the github experts can load it in. Decide best process to non-R, non-github people.\n\nCAMIS-ONCO\nPlan to create cheat sheet for phuse 2024 - can go on CAMIS.\nNeed more volunteers in order to address all the endpoints. Oncology / survival team members needed to join Soma & Team. AZ investing in ChatGPT AZ version, it can create python code from SAS.\nIf AI can convert SAS code to python, we will then need people to test it. Volunteers needed to run in python. Can use the CAMIS repo data to test on hopefully but may need more detailed data? To see what data we currently have in the repo: see “data-info” and “data” folders.\nAction: Chi to have a look at the data folders, and decide better way to control/document data. Chi volunteered to help with Soma’s test to test Python. Harshal may also be able to find volunteers at novonordisk. Starting point for python would be the default options vs R.\n\nACTION: Lyn to Add to members list, who can run which languages & specialist areas (CAMIS-ONCO). ACTION: Soma to put poster into non_website_content/conferences.\nCAMIS: ONCO White paper: Needs to be progressed. invite all members to see if they can contribute. Set up regular meetings in 2024.\nPlan for 2024 : Project board in github: 5 categories\n\nCAMIS : Generic Method Implementation Team: More content\nCAMIS-ONCO: items as above\nUser Experience/Demo Team\nSocial media & Engagement: Advertise/ Universities\n\nbi-monthly post re: new content (newsletter: form to subscribe to newsletter so that when we post out they get informed). ACTION: lyn to check with PHUSE if we can do this, or if we want to ask R consortium to help similar to R validation hub email list.\nAlso would be good to have blog post tab on repository. ACTION: Chi to help Christina with design. Idea would be to have 1 post which goes out on social media, to the emails subscription & on the website.\nmore relationship with ASA OpenStatsware - Orla Doyle.\nopenstatsware (rconsortium.github.io) ACTION: Lyn/Christina/Orla to set up call to discuss collaboration.\n\n\nGeneral Tasks:\n\nPlan to review & accept content within 2 weeks of pull requests.\nPOSIT help with RENV situation\nSearch Engine Optimization: CAMIS full name on website? how do we become top hit ? Any volunteers to help with this let us know.\n\n\nACTION: Lyn to Cancel Dec Meeting 11th Dec. next meeting 8th Jan 2024"
  },
  {
    "objectID": "minutes/meetings/2024-06-10.html",
    "href": "minutes/meetings/2024-06-10.html",
    "title": "Repo Content Growth, Conferences 2024 & Advertising, CAMIS-ONCO & Dissertation project kick off",
    "section": "",
    "text": "attendees\n10_Jun_24\n\n\n\n\nChristina Fillmore\nYes\n\n\nLyn Taylor\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBrian Varney\nNo\n\n\nChi Zhang\nYes\n\n\nOrla Doyle\nNo\n\n\nHarshal Khanolkar\nYes\n\n\nLily Hseih\nNo\n\n\nFilip Kabaj\nNo\n\n\nMartin Brown\nNo\n\n\nMin-Hua Jen\nNo\n\n\nSarah Rathwell\nYes\n\n\nKasa Andras\nYes\n\n\nAditee Dani\nNo\n\n\nKeaven Anderson\nYes\n\n\nBenjamin Arancibia\nYes\n\n\nWilmar Igl\nNo\n\n\nVikash Jain\nNo\n\n\nMia Qi\nNo\n\n\nLeon Shi\nNo\n\n\nVandaya Yadav\nNo\n\n\nStephen McCawille\nYes\n\n\nVikrant Vijay\nNo\n\n\nVidya Gopal\nNo\n\n\nDhvani Patel\nNo\n\n\nKyle Lee\nNo\n\n\nChelsea Dickens\nNo\n\n\nDavid Bosak\nYes\n\n\nMichael Kane\nNo\n\n\nLukas Brausch\nNo\n\n\nMichael Walshe\nYes\n\n\nSeemani Abhilipsa\nYes\n\n\nAiming Yang\nNo\n\n\nCuifeng Yin\nNo\n\n\nTodd Coffey\nYes\n\n\nJayashree Vedanayagam\nYes\n\n\nAshwath Gadapa\nNo\n\n\nMiriam Amor\nNo\n\n\nAnwesha Roy\nNo\n\n\nSamrit Pramanik\nNo\n\n\nAgnieszka Tomczyk\nNo\n\n\nPrem Kant Shekhar\nNo\n\n\nSunil\nNo\n\n\nKate Booth\nNo\n\n\nPeilin Zhou\nNo"
  },
  {
    "objectID": "minutes/meetings/2024-06-10.html#monthly-contributions-update--christina",
    "href": "minutes/meetings/2024-06-10.html#monthly-contributions-update--christina",
    "title": "Repo Content Growth, Conferences 2024 & Advertising, CAMIS-ONCO & Dissertation project kick off",
    "section": "Monthly Contributions update -Christina",
    "text": "Monthly Contributions update -Christina\nThank you to everyone whose contributed this month, Special shout outs to Seemani, Lukas, David & Agnieska and anyone else we’ve missed who completed pull requests this month.\nNOTE that if your work requires a package not yet in the renv.lock file, then you need to install the package and do renv::update() to update the lock file. When you do the pull request, check 2 files change (i.e. the renv.lock file & your file you are submitting).\n\nChristina plans to update the renv control method soon which will hopefully avoid some of the package / renv issues going forward. Remember if you do have problems with the install.packages() & update to renv lock file just let Christina know. ACTION: Christina: To add to the contributions guidance once new method agreed.\nIt was noted by Seemani, that her MANOVA Python content was loaded to the folder, but not visible on the website. ACTION: Christina: to update the TOC to point to the material.\nPlease can people when picking up new pieces to work on update the table of assignments saved in the following readme Or ask Lyn/ Christina to update it for you. This ensures we dont have multiple people working at the same time duplicating effort, when they could be working together."
  },
  {
    "objectID": "minutes/meetings/2024-06-10.html#conferences-update---lyn",
    "href": "minutes/meetings/2024-06-10.html#conferences-update---lyn",
    "title": "Repo Content Growth, Conferences 2024 & Advertising, CAMIS-ONCO & Dissertation project kick off",
    "section": "Conferences update - Lyn",
    "text": "Conferences update - Lyn\nReminder that if you are attending a conference to represent CAMIS to add the detail here.\nWe have updated the page linking to much of the content presented in 2024 and showing we are currently presenting at 7 seminars/ SDEs/ conferences in 2024.\nChristina also presented at the Merck R users group last month. ACTION: Christina: to add to the conferences list to show we did this. If anyone else wants a presentation to their companies please let her know.\nStephen McCawille is also attending PHUSE EU as well as Christine & Agnieska, so the 3 of them can meet up in person.\nAndras Kasa - informed us that there is a PHUSE SDE at UCB in Brussels in september. Details can be found here. Contact UCB biosciences team: Christophe.Praet@ucb.com and marc.derycke@ucb.com if we have someone who could present at this meeting.\nUnfortunately Soma and Vikash were unable to present the workshop at PHUSE CSS last week, however Mike Stackhouse kindly stood in for us, and led a round table discussion about the project. Huge Thank you to Mike for his support and last minute help so we could continue with a session.\nACTION: Volunteer please!! to attend and present at this SDE in person as it would be really good for CAMIS to be presented at this event.\nKeevan asked if we had a single slide to advertise CAMIS. ACTION: Lyn to load single slide to non-website content and add a link to it on conferences tab. Can be found here.\nACTION: Christina : Move Phuse-EU2023 pptx into 2023 folder."
  },
  {
    "objectID": "minutes/meetings/2024-06-10.html#pharma---sug-linkedin-post---chi",
    "href": "minutes/meetings/2024-06-10.html#pharma---sug-linkedin-post---chi",
    "title": "Repo Content Growth, Conferences 2024 & Advertising, CAMIS-ONCO & Dissertation project kick off",
    "section": "Pharma - SUG linkedin Post - Chi",
    "text": "Pharma - SUG linkedin Post - Chi\nChi highlighted the incredible post from Phil Bowsher advertising the CAMIS project. This has been seen by over 400 people with 38 reposts to date ! It has also been commented on by renowned statisticians all enthusiastic about CAMIS, so it’s great to have the awareness of the project growing.\nhttps://www.linkedin.com/posts/philip-bowsher-67151015_rinpharma-rstats-pharmaverse-activity-7202038957512036352-k1AU?utm_source=share&utm_medium=member_desktop\nACTION: Harshil to repost/share in a couple of weeks to maximize the reach of the post.\n##Update from Survival team - Christina\nSoma has officially stepped down as CAMIS-ONCO lead, so Christina will act as this for the time being.\nKick off meeting has occurred last month & the team are now meeting monthly. The first objective is for people to bring together information on the non-proportional hazards models.\nIn future, would be great to have someone take on the lead / co-lead if they feel strongly about leading this, but needs someone dedication to making progress !\n##Dissertation scheme kick off - Chi / Lyn/Christina##\nWe have launched a new page here which will provide ideas for students wanting to look at dissertation projects involved in comparing analysis method differences across software. If you have an idea for a project that you want to research but dont have time to investigate the project yourself, then you could write an abstract and save it to this page, where students looking for projects (or academics looking on behalf of students), could find ideas for projects. Expectation is that most would be MSc level (summer 3 month project), however longer PhD style project could also be offered. Please reach out to us if you are interested in contributing to this area."
  },
  {
    "objectID": "minutes/meetings/2024-06-10.html#goals-reminder",
    "href": "minutes/meetings/2024-06-10.html#goals-reminder",
    "title": "Repo Content Growth, Conferences 2024 & Advertising, CAMIS-ONCO & Dissertation project kick off",
    "section": "2024 Goals Reminder!",
    "text": "2024 Goals Reminder!\n\nIncrease to 45 closed by the end of the year - Currently at 37 closed.\nIn addition, we’d like to improve some of the incomplete content such as MMRM - Stephen Waugh dissertation project launched, if accepted would run sept 24-july25.\nCreate a webpage for listings dissertation projects - Ongoing"
  },
  {
    "objectID": "minutes/meetings/2024-06-10.html#aob",
    "href": "minutes/meetings/2024-06-10.html#aob",
    "title": "Repo Content Growth, Conferences 2024 & Advertising, CAMIS-ONCO & Dissertation project kick off",
    "section": "AOB",
    "text": "AOB\nOur Blog page dosn’t appear in date order or aligned! If anyone can fix let us know ! Saved under News here"
  },
  {
    "objectID": "minutes/meetings/2024-05-13.html",
    "href": "minutes/meetings/2024-05-13.html",
    "title": "2024 Goals",
    "section": "",
    "text": "attendees\n13_May_24\n\n\n\n\nChristina Fillmore\nYes\n\n\nLyn Taylor\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBrian Varney\nNo\n\n\nChi Zhang\nYes\n\n\nOrla Doyle\nNo\n\n\nHarshal Khanolkar\nYes\n\n\nLily Hseih\nNo\n\n\nFilip Kabaj\nNo\n\n\nMartin Brown\nYes\n\n\nMin-Hua Jen\nYes\n\n\nSarah Rathwell\nNo\n\n\nKasa Andras\nNo\n\n\nAditee Dani\nNo\n\n\nKeaven Anderson\nYes\n\n\nBenjamin Arancibia\nYes\n\n\nWilmar Igl\nYes\n\n\nVikash Jain\nNo\n\n\nMia Qi\nYes\n\n\nLeon Shi\nNo\n\n\nVandaya Yadav\nNo\n\n\nStephen McCawille\nYes\n\n\nVikrant Vijay\nNo\n\n\nVidya Gopal\nYes\n\n\nDhvani Patel\nNo\n\n\nKyle Lee\nNo\n\n\nChelsea Dickens\nNo\n\n\nDavid Bosak\nYes\n\n\nMichael Kane\nNo\n\n\nLukas Brausch\nYes\n\n\nMichael Walshe\nYes\n\n\nSeemani Abhilipsa\nNo\n\n\nAiming Yang\nNo\n\n\nCuifeng Yin\nYes\n\n\nTodd Coffey\nYes\n\n\nJayashree Vedanayagam\nNo\n\n\nAshwath Gadapa\nNo\n\n\nMiriam Amor\nNo\n\n\nAnwesha Roy\nNo\n\n\nSamrit Pramanik\nNo\n\n\nAgnieszka Tomczyk\nNo\n\n\nPrem Kant Shekhar\nNo\n\n\nSunil\nNo\n\n\nKate Booth\nNo\n\n\nPeilin Zhou\nNo"
  },
  {
    "objectID": "minutes/meetings/2024-05-13.html#goals",
    "href": "minutes/meetings/2024-05-13.html#goals",
    "title": "2024 Goals",
    "section": "2024 Goals",
    "text": "2024 Goals\n\nOur open issues are here\nCurrently 32 are closed and we would like to increase this to 45 closed by the end of the year\nIn addition, we’d like to improve some of the incomplete content such as MMRM\nCreate a webpage for listings dissertation projects\nHave Soma & Vikash represent us at the CSS workshop."
  },
  {
    "objectID": "minutes/meetings/2024-05-13.html#camis---onco",
    "href": "minutes/meetings/2024-05-13.html#camis---onco",
    "title": "2024 Goals",
    "section": "CAMIS - Onco",
    "text": "CAMIS - Onco\nTo date there has not been much progress. Given the enthusiasm in the meeting to get things kicked off and starting to increase our survival content on the repository, Christina will set up a kick off meeting for those interested. To look at: weighted logrank, MaxCombo, RMST\nThis SAS link may also be useful"
  },
  {
    "objectID": "minutes/meetings/2024-05-13.html#other-content-updates",
    "href": "minutes/meetings/2024-05-13.html#other-content-updates",
    "title": "2024 Goals",
    "section": "Other content updates",
    "text": "Other content updates\nWe now have a new table of assignments saved in the following readme Welcome to edit to update anything you would like to work on, so we keep track of whose working on what. Special shout out to David who has now completed chi-square for SAS and to Lukas for all the python content. Awesome work !\nAs SAS Viya is becoming more used now, we agreed OK to add Viya specific code such as proc freqtab as long as it’s clear that this isn’t a SAS Base procedure."
  },
  {
    "objectID": "minutes/meetings/2024-05-13.html#conference-planning",
    "href": "minutes/meetings/2024-05-13.html#conference-planning",
    "title": "2024 Goals",
    "section": "Conference planning",
    "text": "Conference planning\nReminder that if you are attending a conference to represent CAMIS to add the detail here. We need to ensure we continue to advertise the project to encourage people to use the repo and add content.\n\nPHUSE CSS update (Soma/Vikash)\nR/Pharma – anyone like to present (openstatsware – collab, python): Waiting to be open.\nUSER! – Chi (Accepted)\nStephen phuse EU.\nEU Connect – Agnieska TBC\nR/Medicine 2024- Agnieska accepted for Thurs 13th/14th 11am-6pm EST (20 min talk)"
  },
  {
    "objectID": "minutes/meetings/2024-05-13.html#aob",
    "href": "minutes/meetings/2024-05-13.html#aob",
    "title": "2024 Goals",
    "section": "AOB",
    "text": "AOB\nOur Blog page dosn’t appear in date order or aligned! If anyone can fix let us know ! Saved under News here"
  },
  {
    "objectID": "minutes/meetings/2024-04-08.html",
    "href": "minutes/meetings/2024-04-08.html",
    "title": "General linear models is complete",
    "section": "",
    "text": "attendees\n08_Apr_24\n\n\n\n\nChristina Fillmore\nYes\n\n\nLyn Taylor\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBrian Varney\nYes\n\n\nChi Zhang\nYes\n\n\nOrla Doyle\nNo\n\n\nHarshal Khanolkar\nNo\n\n\nLily Hseih\nNo\n\n\nFilip Kabaj\nNo\n\n\nMartin Brown\nYes\n\n\nMin-Hua Jen\nNo\n\n\nSarah Rathwell\nYes\n\n\nKasa Andras\nNo\n\n\nAditee Dani\nNo\n\n\nKeaven Anderson\nYes\n\n\nBenjamin Arancibia\nYes\n\n\nWilmar Igl\nNo\n\n\nVikash Jain\nYes\n\n\nMia Qi\nNo\n\n\nLeon Shi\nYes\n\n\nVandaya Yadav\nYes\n\n\nStephen McCawille\nYes\n\n\nVikrant Vijay\nNo\n\n\nVidya Gopal\nNo\n\n\nDhvani Patel\nNo\n\n\nKyle Lee\nNo\n\n\nChelsea Dickens\nNo\n\n\nDavid Bosak\nYes\n\n\nMichael Kane\nYes\n\n\nLukas Brausch\nYes\n\n\nMichael Walshe\nYes\n\n\nSeemani Abhilipsa\nYes\n\n\nAiming Yang\nYes\n\n\nCuifeng Yin\nYes\n\n\nTodd Coffey\nNo\n\n\nJayashree Vedanayagam\nNo\n\n\nAshwath Gadapa\nNo\n\n\nMiriam Amor\nNo\n\n\nAnwesha Roy\nNo\n\n\nSamrit Pramanik\nNo\n\n\nAgnieszka Tomczyk\nNo\n\n\nPrem Kant Shekhar\nNo\n\n\nSunil\nNo\n\n\nKate Booth\nNo\n\n\nPeilin Zhou\nNo"
  },
  {
    "objectID": "minutes/meetings/2024-04-08.html#this-months-achievements",
    "href": "minutes/meetings/2024-04-08.html#this-months-achievements",
    "title": "General linear models is complete",
    "section": "This months achievements",
    "text": "This months achievements\nGeneral Linear Models is Complete !\nThanks David & others for great contributions this month.\nWe are seeing more python examples coming through too."
  },
  {
    "objectID": "minutes/meetings/2024-04-08.html#checklist-for-pull-requests",
    "href": "minutes/meetings/2024-04-08.html#checklist-for-pull-requests",
    "title": "General linear models is complete",
    "section": "Checklist for pull requests",
    "text": "Checklist for pull requests\nChristina will add something to help ensure a smooth process"
  },
  {
    "objectID": "minutes/meetings/2024-04-08.html#css-connect-progress-update-soma-vikash",
    "href": "minutes/meetings/2024-04-08.html#css-connect-progress-update-soma-vikash",
    "title": "General linear models is complete",
    "section": "CSS Connect progress update – Soma/ Vikash",
    "text": "CSS Connect progress update – Soma/ Vikash\nVikash to reach out to Soma. Harshil unlikely to be available in person, so we can look for further support to attend & help you if needed."
  },
  {
    "objectID": "minutes/meetings/2024-04-08.html#any-other-conferences-that-people-have-applied-for",
    "href": "minutes/meetings/2024-04-08.html#any-other-conferences-that-people-have-applied-for",
    "title": "General linear models is complete",
    "section": "Any other Conferences that people have applied for?",
    "text": "Any other Conferences that people have applied for?\n\nLukus & Stephen are attending PHUSE EU Connect with other topics, but if others going CAMIS members could meet up in person, TBC nearer the date"
  },
  {
    "objectID": "minutes/meetings/2024-04-08.html#current-assignments",
    "href": "minutes/meetings/2024-04-08.html#current-assignments",
    "title": "General linear models is complete",
    "section": "Current assignments",
    "text": "Current assignments\nLyn to put together Table so we can easily see whose doing what.\n\nSarah Rathwell & Christina volunteered to work on Kolmogorov-Smirnov test\nLukas Brausch to pick up Python one sample t-test, paired & 2 sample t-test\nChi to reach out to open stats ware to see if they can improve MMRM & add any bayesian MMRM\nLeon to look at Reference-based MI (using either SAS macro, or procedures directly).\nKeaven/Martin to look at group sequential design\nCAMIS-ONCO no kick off yet, so Stephen McCawille will start to look at SAS Accelerated failure time models, Volunteer needed to run the same in R.\nTodd/Cuifeng will be looking at Non linear models\nALL - if you are looking for an assignment reach out to Christina & Lyn and we can group you together to collaborate."
  },
  {
    "objectID": "minutes/index.html",
    "href": "minutes/index.html",
    "title": "Meeting Minutes",
    "section": "",
    "text": "SAS Viya, sasquatch, CAMIS End of Year Nominations, US Connect Poster\n\n\n\n2025\n\n\n\n\n\n\n\n\n\nOct 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nContent updates\n\n\n\n2025\n\n\n\n\n\n\n\n\n\nSep 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTipping point, ISBC Poster\n\n\n\n2025\n\n\n\n\n\n\n\n\n\nAug 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPackage selection\n\n\n\n2025\n\n\n\n\n\n\n\n\n\nJul 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBlogs, New content, Conferences (2)\n\n\n\n2025\n\n\n\n\n\n\n\n\n\nMay 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBlogs, New content, Conferences\n\n\n\n2025\n\n\n\n\n\n\n\n\n\nApr 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nGDPR for PHUSE WGs & Latest repo updates\n\n\n\n2025\n\n\n\n\n\n\n\n\n\nMar 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nGeneral meeting updates\n\n\n\n2025\n\n\n\n\n\n\n\n\n\nFeb 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCAMIS Objectives 2025\n\n\n\n2025\n\n\n\n\n\n\n\n\n\nJan 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCAMIS End of Year Thank you\n\n\n\n2024\n\n\n\n\n\n\n\n\n\nDec 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGen AI for SAS–&gt;R code, Achievements + 2025 objectives\n\n\n\n2024\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLessons learnt- Novartis Hackathon, Diversity Alliance, OSTCDA\n\n\n\n2024\n\n\n\n\n\n\n\n\n\nSep 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nNovartis Hackathon & Content growth\n\n\n\n2024\n\n\n\n\n\n\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRepo Content Growth, Conferences 2024\n\n\n\n2024\n\n\n\n\n\n\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRepo Content Growth, Conferences 2024 & Advertising, CAMIS-ONCO & Dissertation project kick off\n\n\n\n2024\n\n\n\n\n\n\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n2024 Goals\n\n\n\n2024\n\n\n\n\n\n\n\n\n\nMay 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGeneral linear models is complete\n\n\n\n2024\n\n\n\n\n\n\n\n\n\nApr 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHow to select packages, Content & Conferences\n\n\n\n2024\n\n\n\n\n\n\n\n\n\nMar 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nWebsite structure update, Team list, Conferences\n\n\n\n2024\n\n\n\n\n\n\n\n\n\nFeb 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCAMIS-ONCO, Conferences, Academic & regulatory input plans\n\n\n\n2024\n\n\n\n\n\n\n\n\n\nJan 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nEnd of year summary, plan for 2024\n\n\n\n2023\n\n\n\n\n\n\n\n\n\nNov 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nFDA quartely meeting, 1st survey feedback - general updates\n\n\n\n2023\n\n\n\n\n\n\n\n\n\nOct 9, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nConference updates & feedback, FDA quartely meeting, CAMIS-ONCO workshop\n\n\n\n2023\n\n\n\n\n\n\n\n\n\nSep 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nFDA quartely meeting, FDA CSS, SDEs, website & conference plans\n\n\n\n2023\n\n\n\n\n\n\n\n\n\nAug 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPlan for Advertising CAMIS progress\n\n\n\n2023\n\n\n\n\n\n\n\n\n\nJul 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWhite Paper Finalization, Advertising CAMIS\n\n\n\n2023\n\n\n\n\n\n\n\n\n\nJun 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWhite Paper, Website, Launch Plan\n\n\n\n2023\n\n\n\n\n\n\n\n\n\nMay 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWhite Paper, Website, Launch Plan\n\n\n\n2023\n\n\n\n\n\n\n\n\n\nApr 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWhite Paper, Website, ONCO, Volunteers, Conferences\n\n\n\n2023\n\n\n\n\n\n\n\n\n\nMar 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWhite Paper and Demo of connecting Rstudio with Github repo\n\n\n\n2023\n\n\n\n\n\n\n\n\n\nFeb 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nNew Website Discussion\n\n\n\n2023\n\n\n\n\n\n\n\n\n\nJan 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRestart Meeting\n\n\n\n2022\n\n\n\n\n\n\n\n\n\nDec 12, 2022\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "R/ci_for_prop.html",
    "href": "R/ci_for_prop.html",
    "title": "Confidence Intervals for Proportions in R",
    "section": "",
    "text": "The methods to use for calculating a confidence interval (CI) for a proportion depend on the type of proportion you have.\n\n1 sample proportion (1 proportion calculated from 1 group of subjects)\n2 sample proportions and you want a CI for the difference in the 2 proportions.\n\nIf the 2 samples come from 2 independent samples (different subjects in each of the 2 groups)\nIf the 2 samples are matched (i.e. the same subject has 2 results, one on each group [paired data]).\n\n\nThe method selected is also dependent on whether your proportion is close to 0 or 1 (or near to the 0.5 midpoint), and your sample size.\nFor more information about these methods, including which performs better in different scenarios see Five Confidence Intervals for Proportions That You Should Know about1.\nNote: information about cicalc package will be added to this page soon."
  },
  {
    "objectID": "R/ci_for_prop.html#introduction",
    "href": "R/ci_for_prop.html#introduction",
    "title": "Confidence Intervals for Proportions in R",
    "section": "",
    "text": "The methods to use for calculating a confidence interval (CI) for a proportion depend on the type of proportion you have.\n\n1 sample proportion (1 proportion calculated from 1 group of subjects)\n2 sample proportions and you want a CI for the difference in the 2 proportions.\n\nIf the 2 samples come from 2 independent samples (different subjects in each of the 2 groups)\nIf the 2 samples are matched (i.e. the same subject has 2 results, one on each group [paired data]).\n\n\nThe method selected is also dependent on whether your proportion is close to 0 or 1 (or near to the 0.5 midpoint), and your sample size.\nFor more information about these methods, including which performs better in different scenarios see Five Confidence Intervals for Proportions That You Should Know about1.\nNote: information about cicalc package will be added to this page soon."
  },
  {
    "objectID": "R/ci_for_prop.html#data-used",
    "href": "R/ci_for_prop.html#data-used",
    "title": "Confidence Intervals for Proportions in R",
    "section": "Data used",
    "text": "Data used\nThe adcibc data stored here was used in this example, creating a binary treatment variable trt taking the values of ACT or PBO and a binary response variable resp taking the values of Yes or No. For this example, a response is defined as a score greater than 4.\nThe below shows that for the Actual Treatment, there are 36 responders out of 154 subjects = 0.234 (23.4% responders).\n\n\n# A tibble: 4 × 3\n# Groups:   trt [2]\n  trt   resp      n\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n1 ACT   No      118\n2 ACT   Yes      36\n3 PBO   No       65\n4 PBO   Yes      12"
  },
  {
    "objectID": "R/ci_for_prop.html#packages",
    "href": "R/ci_for_prop.html#packages",
    "title": "Confidence Intervals for Proportions in R",
    "section": "Packages",
    "text": "Packages\nThe {cardx} package is an extension of the {cards} package, providing additional functions to create Analysis Results Data Objects (ARDs)1. It was developed as part of {NEST} and pharmaverse. This package requires the binary endpoint to be a logical (TRUE/FALSE) vector or a numeric/integer coded as (0, 1) with 1 (TRUE) being the success you want to calculate the confidence interval for.\nSee here for full description of the {cardx} proportions equations.\nIf calculating the CI for a difference in proportions, the package requires both the response and the treatment variable to be numeric/integer coded as (0, 1) (or logical vector).\nInstead of the code presented below, you can use ard_categorical_ci(data, variables=resp, method ='wilson') for example. This invokes the code below but returns an analysis results dataset (ARD) format as the output. Methods included are waldcc, wald, clopper-pearson, wilson, wilsoncc, strat_wilson, strat_wilsoncc, agresti-coull and jeffreys for one-sample proportions and methods for 2 independent samples, however currently does not have a method for 2 matched proportions.\nThe {PropCIs} package produces CIs for methods such as Blaker’s exact method and Midp which aren’t available in {cardx} but are available in SAS. We found results agreed with SAS to the 5th decimal place. The package also calculates CIs for Clopper-Pearson, Wald, Wilson, Agresti-Coull and these align to results obtained in cardx to at least the 7th decimal place. The {PropsCIs} package requires just the number of events (numerator number of successes) & total number of subjects (denominator) as an input dataset. Given Blaker and Midp are rarely used in practice, and {PropsCIs} isn’t a package commonly downloaded from CRAN, further details are not provided here.\nThe {Hmisc} package produces CIs using the Clopper-Pearson method. In this example (x=36 and n=154), the results match the cardx package. Documentation reports that the method uses F distribution to compute exact intervals based on the binomial cdf. However, if the percentage of responders is 100% then the upper limit is set to 1. Similarly if the percentage of responders is 0%, then the lower limit is set to 0. Hence, in extreme cases there may be differences between this package and the standard implementation of Clopper-Pearson method.\nThe {RBesT} package (Prior to Version 1.8-0) produces CIs using the Clopper-Pearson method. In this example (x=36 and n=154), the results match the cardx package. However, as described below, there are 2 cases where the results using RBesT package do not match cardx or Hmisc.\n\nx = 0 (0% responders), in which case the lower limit does not match.\nx = n (100% responders), in which case the upper limit does not match.\n\nBecause of the relationship between the binomial distribution and the beta distribution. This package uses quantiles of the beta distribution to derive exact confidence intervals.\n\\[ B(\\alpha/2;x, n-x+1) &lt; p &lt; B(1-\\alpha/2; x+1, n-x)\\]\nRBesT equations are:\npLow &lt;- qbeta(Low, r + (r == 0), n - r + 1)\npHigh &lt;- qbeta(High, r + 1, n - r + ((n - r) == 0))\nIn Version 1.8-0 onwards the equations were updated as follows, which then match the Hmisc intervals:\npLow &lt;- qbeta(Low, r, n - r + 1)\npHigh &lt;- qbeta(High, r + 1, n - r)\nThe {ExactCIdiff} package produces exact CIs for two dependent proportions (matched pairs).\nThe {DescTools} package has a function BinomDiffCI which produces CIs for two independent proportions (unmatched pairs) including methods for Agresti/Caffo, Wald, Wald with Continuity correction, Newcombe Score, Newcombe score with continuity correction, and more computationally intensive methods such as Miettinen and Nurminen, Mee, Brown Li’s Jeffreys, Hauck-Anderson and Haldane. See here for more detail.\nThe {presize} package has a function prec_prop() which also calculates CIs for 2 independent samples using the Wilson, Agresti-Coull, Exact or Wald approaches. The package is not described in further detail here since in most cases {DescTools} will be able to compute what is needed. However, it’s mentioned due to other functionality it has available such as sample size and precision calculations for AUC, correlations, cronbach’s alpha, intraclass correlation, Cohen’s kappa, likelihood ratios, means, mean differences, odds ratios, rates, rate ratios, risk differences and risk ratios."
  },
  {
    "objectID": "R/ci_for_prop.html#methods-for-calculating-confidence-intervals-for-a-single-proportion-using-cardx",
    "href": "R/ci_for_prop.html#methods-for-calculating-confidence-intervals-for-a-single-proportion-using-cardx",
    "title": "Confidence Intervals for Proportions in R",
    "section": "Methods for Calculating Confidence Intervals for a single proportion using cardx",
    "text": "Methods for Calculating Confidence Intervals for a single proportion using cardx\nFor more technical derivation and reasons for use of each of the methods listed below, see the corresponding SAS page.\nLet’s start by calculating a Confidence interval for the proportion of successes observed in the Active Treatment group (a single sample).\n\nClopper-Pearson (Exact or binomial CI) Method\nClopper-Pearson Exact CI is one of the most popular methods, it is often good for small sample sizes when the proportion is not close to the tails (0,1), but it can be too conservative (too wide an interval compared to the interval containing the true population proportion 95% of the time).\nThe cardx package calculates the Clopper-Pearson score by calling stats::binom.test() function.\n\ncardx::proportion_ci_clopper_pearson(act2, conf.level = 0.95) |&gt;\n  as_tibble()\n\n# A tibble: 1 × 10\n      N conf.level estimate statistic  p.value parameter conf.low conf.high\n  &lt;int&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1   154       0.95    0.234        36 2.21e-11       154    0.169     0.309\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\n\n\nNormal Approximation Method (Also known as the Wald or asymptotic CI Method)\nIn large random samples from independent trials, the sampling distribution of proportions approximately follows the normal distribution. The expectation of a sample proportion is the corresponding population proportion. Therefore, based on a sample of size \\(n\\), a \\((1-\\alpha)\\%\\) confidence interval for population proportion can be calculated using normal approximation as follows:\n\\(p\\approx \\hat p \\pm z_\\alpha \\sqrt{\\hat p(1-\\hat p)}/{n}\\), where \\(\\hat p\\) is the sample proportion, \\(z_\\alpha\\) is the \\(1-\\alpha/2\\) quantile of a standard normal distribution corresponding to level \\(\\alpha\\), and \\(\\sqrt{\\hat p(1-\\hat p)}/{n}\\) is the standard error.\nFor more technical information see the corresponding SAS page.\n\nExample code\nThe following code calculates a confidence interval for a binomial proportion using normal approximation equation manually. This is replicated exactly using the cardx::proportion_ci_wald function which also allows the continuity correction to be applied.\n\n# sample proportion by trt\nsummary &lt;- adcibc |&gt;\n  filter(trt == \"ACT\") |&gt;\n  group_by(resp) |&gt;\n  tally() |&gt;\n  ungroup() |&gt;\n  mutate(\n    total = sum(n),\n    p = n / total\n  )\n\n# Calculate standard error and 95% wald confidence intervals for population proportion\nwaldci &lt;- summary |&gt;\n  filter(resp == \"Yes\") |&gt;\n  mutate(\n    se = sqrt(p * (1 - p) / total),\n    lower_ci = (p - qnorm(1 - 0.05 / 2) * se),\n    upper_ci = (p + qnorm(1 - 0.05 / 2) * se)\n  )\nwaldci\n\n# A tibble: 1 × 7\n  resp      n total     p     se lower_ci upper_ci\n  &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Yes      36   154 0.234 0.0341    0.167    0.301\n\n# cardx package Wald method without continuity correction\ncardx::proportion_ci_wald(act2, conf.level = 0.95, correct = FALSE) |&gt;\n  as_tibble()\n\n# A tibble: 1 × 6\n      N estimate conf.low conf.high conf.level method                           \n  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;glue&gt;                           \n1   154    0.234    0.167     0.301       0.95 Wald Confidence Interval without…\n\n# cardx package Wald method with continuity correction\ncardx::proportion_ci_wald(act2, conf.level = 0.95, correct = TRUE) |&gt;\n  as_tibble()\n\n# A tibble: 1 × 6\n      N estimate conf.low conf.high conf.level method                           \n  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;glue&gt;                           \n1   154    0.234    0.164     0.304       0.95 Wald Confidence Interval with co…\n\n\n\n\n\nWilson Method (Also known as the Score method or the Altman, Newcombe method3 )\nThe cardx package calculates the Wilson (score) method by calling stats::prop.test() function. This method is often used as a compromise between the Clopper-Pearson and the Wald given it was found to be accurate for most parameter values (even those close to 0 and 1), and it does not suffer from being over-conservative. For more technical information see the corresponding SAS page.\nThe package also contains a function for proportion_ci_strat_wilson() which calculates the stratified Wilson CIs for unequal proportions as described on page 47 here.\n\n# cardx package Wilson method without continuity correction\ncardx::proportion_ci_wilson(act2, conf.level = 0.95, correct = FALSE) |&gt;\n  as_tibble()\n\n# A tibble: 1 × 10\n      N conf.level estimate statistic  p.value parameter conf.low conf.high\n  &lt;int&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1   154       0.95    0.234      43.7 3.90e-11         1    0.174     0.307\n# ℹ 2 more variables: method &lt;glue&gt;, alternative &lt;chr&gt;\n\n# cardx package Wilson method with continuity correction\ncardx::proportion_ci_wilson(act2, conf.level = 0.95, correct = TRUE) |&gt;\n  as_tibble()\n\n# A tibble: 1 × 10\n      N conf.level estimate statistic  p.value parameter conf.low conf.high\n  &lt;int&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1   154       0.95    0.234      42.6 6.70e-11         1    0.171     0.310\n# ℹ 2 more variables: method &lt;glue&gt;, alternative &lt;chr&gt;\n\n\n\n\nAgresti-Coull Method\nThe cardx package calculates the Agresti-Coull method using the equation from the published method by Alan Agresti & Brent Coull based on adding 2 successes and 2 failures before computing the wald CI. The CI is truncated, when it overshoots the boundary (&lt;0 or &gt;1).\n\n# cardx package agresti_coull method\ncardx::proportion_ci_agresti_coull(act2, conf.level = 0.95) |&gt;\n  as_tibble()\n\n# A tibble: 1 × 6\n      N estimate conf.low conf.high conf.level method                           \n  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                            \n1   154    0.234    0.174     0.307       0.95 Agresti-Coull Confidence Interval\n\n\n\n\nJeffreys Method\nJeffreys method is a particular type of Bayesian Highest Probability Density (HPD) Method. For proportions, the beta distribution is generally used for the prior, which consists of two parameters alpha and beta. Setting alpha=beta=0.5 is called Jeffrey’s prior. NOTE: if you want to use any other priors, you can use binom.bayes which estimates a credible interval for proportions.\n\n# cardx package jeffreys method\ncardx::proportion_ci_jeffreys(act2, conf.level = 0.95) |&gt;\n  as_tibble()\n\n# A tibble: 1 × 6\n      N estimate conf.low conf.high conf.level method           \n  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;glue&gt;           \n1   154    0.234    0.172     0.305       0.95 Jeffreys Interval"
  },
  {
    "objectID": "R/ci_for_prop.html#methods-for-calculating-confidence-intervals-for-a-matched-pair-proportion-using-exactcidiff",
    "href": "R/ci_for_prop.html#methods-for-calculating-confidence-intervals-for-a-matched-pair-proportion-using-exactcidiff",
    "title": "Confidence Intervals for Proportions in R",
    "section": "Methods for Calculating Confidence Intervals for a matched pair proportion using {ExactCIdiff}",
    "text": "Methods for Calculating Confidence Intervals for a matched pair proportion using {ExactCIdiff}\nFor more information about the detailed methods for calculating confidence intervals for a matched pair proportion see here. When you have 2 measurements on the same subject, the 2 sets of measures are not independent and you have matched pair of responses.\nTo date we have not found an R package which calculates a CI for matched pair proportions using the normal approximation or Wilson methods although they can be done by hand using the equations provided on the SAS page link above.\nThe {ExactCIdiff} package produces exact CIs for two dependent proportions (matched pairs), claiming to be the first package in R to do this method. However, it should only be used when the sample size is not too large as it can be computationally intensive.\nNOTE that the {ExactNumCI} package should not be used for this task. More detail on these two packages can be found here.\nUsing a cross over study as our example, a 2 x 2 table can be formed as follows:\n\nThe proportions of subjects responding on each treatment are:\n\n\n\n\n\n\n\n\n\nPlacebo\nResponse= Yes\nPlacebo\nResponse = No\nTotal\n\n\n\n\nActive Response = Yes\nr\ns\nr+s\n\n\nActive Response = No\nt\nu\nt+u\n\n\nTotal\nr+t\ns+u\nN = r+s+t+u\n\n\n\nActive: \\(\\hat p_1 = (r+s)/n\\) and Placebo: \\(\\hat p_2= (r+t)/n\\)\nDifference between the proportions for each treatment are: \\(D=p1-p2=(s-t)/n\\)\nSuppose :\n\n\n\n\n\n\n\n\n\n\nPlacebo\nResponse= Yes\nPlacebo\nResponse = No\nTotal\n\n\n\n\nActive Response = Yes\nr = 20\ns = 15\nr+s = 35\n\n\nActive Response = No\nt = 6\nu = 5\nt+u = 11\n\n\nTotal\nr+t = 26\ns+u = 20\nN = r+s+t+u = 46\n\n\n\nActive: \\(\\hat p_1 = (r+s)/n\\) =35/46 =0.761 and Placebo: \\(\\hat p_2= (r+t)/n\\) = 26/46 =0.565\nDifference = 0.761-0.565 = 0.196, then PairedCI() function can provide an exact confidence interval as shown below\n-0.00339 to 0.38065\n\n# ExactCIdiff::PairedCI(s, r+u, t, conf.level = 0.95)\n\nCI &lt;- ExactCIdiff::PairedCI(15, 25, 6, conf.level = 0.95)$ExactCI\nCI"
  },
  {
    "objectID": "R/ci_for_prop.html#methods-for-calculating-confidence-intervals-for-2-independent-samples-proportion",
    "href": "R/ci_for_prop.html#methods-for-calculating-confidence-intervals-for-2-independent-samples-proportion",
    "title": "Confidence Intervals for Proportions in R",
    "section": "Methods for Calculating Confidence Intervals for 2 independent samples proportion",
    "text": "Methods for Calculating Confidence Intervals for 2 independent samples proportion\nThis paper4 describes many methods for the calculation of confidence intervals for 2 independent proportions.\n\nNormal Approximation Method (Also known as the Wald or asymptotic CI Method) using {cardx}\nFor more technical information regarding the Wald method see the corresponding SAS page.\n\nExample code\ncardx::ard_stats_prop_test function uses stats::prop.test which also allows a continuity correction to be applied.\nAlthough this website here and this one here both reference Newcombe for the CI that this function uses, replication of the results by hand and compared to SAS show that the results below match the Normal Approximation (Wald method).\nBoth the Treatment variable (ACT,PBO) and the Response variable (Yes,No) have to be numeric (0,1) or Logit (TRUE,FALSE) variables.\nThe prop.test default with 2 groups, is the null hypothesis that the proportions in each group are the same and a 2-sided CI.\n\nindat1 &lt;- adcibc2 |&gt;\n  select(AVAL, TRTP) |&gt;\n  mutate(\n    resp = if_else(AVAL &gt; 4, \"Yes\", \"No\"),\n    respn = if_else(AVAL &gt; 4, 1, 0),\n    trt = if_else(TRTP == \"Placebo\", \"PBO\", \"ACT\"),\n    trtn = if_else(TRTP == \"Placebo\", 1, 0)\n  ) |&gt;\n  select(trt, trtn, resp, respn)\n\n# cardx package required a vector with 0 and 1s for a single proportion CI\n# To get the comparison the correct way around Placebo must be 1, and Active 0\n\nindat &lt;- select(indat1, trtn, respn)\n\ncardx::ard_stats_prop_test(\n  data = indat,\n  by = trtn,\n  variables = respn,\n  conf.level = 0.95,\n  correct = FALSE\n)\n\n{cards} data frame: 13 x 9\n\n\n   group1 variable   context   stat_name stat_label      stat\n1    trtn    respn stats_pr…    estimate  Rate Dif…     0.078\n2    trtn    respn stats_pr…   estimate1  Group 1 …     0.234\n3    trtn    respn stats_pr…   estimate2  Group 2 …     0.156\n4    trtn    respn stats_pr…   statistic  X-square…     1.893\n5    trtn    respn stats_pr…     p.value    p-value     0.169\n6    trtn    respn stats_pr…   parameter  Degrees …         1\n7    trtn    respn stats_pr…    conf.low  CI Lower…    -0.027\n8    trtn    respn stats_pr…   conf.high  CI Upper…     0.183\n9    trtn    respn stats_pr…      method     method 2-sample…\n10   trtn    respn stats_pr… alternative  alternat… two.sided\n11   trtn    respn stats_pr…           p          p          \n12   trtn    respn stats_pr…  conf.level  CI Confi…      0.95\n13   trtn    respn stats_pr…     correct  Yates' c…     FALSE\n\n\nℹ 3 more variables: fmt_fn, warning, error\n\ncardx::ard_stats_prop_test(\n  data = indat,\n  by = trtn,\n  variables = respn,\n  conf.level = 0.95,\n  correct = TRUE\n)\n\n{cards} data frame: 13 x 9\n\n\n   group1 variable   context   stat_name stat_label      stat\n1    trtn    respn stats_pr…    estimate  Rate Dif…     0.078\n2    trtn    respn stats_pr…   estimate1  Group 1 …     0.234\n3    trtn    respn stats_pr…   estimate2  Group 2 …     0.156\n4    trtn    respn stats_pr…   statistic  X-square…      1.45\n5    trtn    respn stats_pr…     p.value    p-value     0.229\n6    trtn    respn stats_pr…   parameter  Degrees …         1\n7    trtn    respn stats_pr…    conf.low  CI Lower…    -0.037\n8    trtn    respn stats_pr…   conf.high  CI Upper…     0.193\n9    trtn    respn stats_pr…      method     method 2-sample…\n10   trtn    respn stats_pr… alternative  alternat… two.sided\n11   trtn    respn stats_pr…           p          p          \n12   trtn    respn stats_pr…  conf.level  CI Confi…      0.95\n13   trtn    respn stats_pr…     correct  Yates' c…      TRUE\n\n\nℹ 3 more variables: fmt_fn, warning, error\n\n\n\n\n\nNormal Approximation (Wald) and Other Methods for 2 independent samples using {DescTools}\nFor more technical information regarding the derivations of these methods see the corresponding SAS page or {DescTools} package documentation here. The {DescTools} package has a function BinomDiffCI which produces CIs for two independent proportions (unmatched pairs) including methods for Agresti/Caffo, Wald, Wald with Continuity correction, Newcombe Score, Newcombe score with continuity correction, and more computationally intensive (less commonly used) methods such as Miettinen and Nurminen, Mee, Brown Li’s Jeffreys, Hauck-Anderson, Haldane and Jeffreys-Perks.\n\nExample code\nWith 2 groups, the null hypothesis that the proportions in each group are the same and a 2-sided CI.\n\ncount_dat &lt;- indat |&gt;\n  count(trtn, respn)\ncount_dat\n\n# A tibble: 4 × 3\n   trtn respn     n\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1     0     0   118\n2     0     1    36\n3     1     0    65\n4     1     1    12\n\n# BinomDiffCI requires\n# x1 = successes in active,  n1 = total subjects in active,\n# x2 = successes in placebo, n2 = total subjects in placebo\n\nDescTools::BinomDiffCI(\n  x1 = 36,\n  n1 = 154,\n  x2 = 12,\n  n2 = 77,\n  conf.level = 0.95,\n  sides = c(\"two.sided\"),\n  method = c(\n    \"wald\",\n    \"waldcc\",\n    \"score\",\n    \"scorecc\",\n    \"ac\",\n    \"mn\",\n    \"mee\",\n    \"blj\",\n    \"ha\",\n    \"hal\",\n    \"jp\"\n  )\n)\n\n               est      lwr.ci    upr.ci\nwald    0.07792208 -0.02710792 0.1829521\nwaldcc  0.07792208 -0.03684818 0.1926923\nscore   0.07792208 -0.03614191 0.1751254\nscorecc 0.07792208 -0.04396244 0.1809901\nac      0.07792208 -0.03292487 0.1781699\nmn      0.07792208 -0.03606525 0.1774952\nmee     0.07792208 -0.03580439 0.1772849\nblj     0.07792208 -0.03062424 0.1810792\nha      0.07792208 -0.03415013 0.1899943\nhal     0.07792208 -0.03143484 0.1769438\njp      0.07792208 -0.03207751 0.1776615"
  },
  {
    "objectID": "R/ci_for_prop.html#references",
    "href": "R/ci_for_prop.html#references",
    "title": "Confidence Intervals for Proportions in R",
    "section": "References",
    "text": "References\n\npharmaverse cardx package\nPropCIs package\nD. Altman, D. Machin, T. Bryant, M. Gardner (eds). Statistics with Confidence: Confidence Intervals and Statistical Guidelines, 2nd edition. John Wiley and Sons 2000.\nhttps://www.lexjansen.com/wuss/2016/127_Final_Paper_PDF.pdf"
  },
  {
    "objectID": "R/PCA_analysis.html",
    "href": "R/PCA_analysis.html",
    "title": "Principle Component Analysis",
    "section": "",
    "text": "Principal Component Analysis (PCA) is a dimensionality reduction technique used to reduce the number of features in a dataset while retaining most of the information.\n\n\n\nWe will load the iris data.\nStandardize the data and then compute PCA.\n\n\nlibrary(factoextra)\n\nLoading required package: ggplot2\n\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\ndata &lt;- iris\npca_result &lt;- stats::prcomp(data[, 1:4], scale = T)\npca_result\n\nStandard deviations (1, .., p=4):\n[1] 1.7083611 0.9560494 0.3830886 0.1439265\n\nRotation (n x k) = (4 x 4):\n                    PC1         PC2        PC3        PC4\nSepal.Length  0.5210659 -0.37741762  0.7195664  0.2612863\nSepal.Width  -0.2693474 -0.92329566 -0.2443818 -0.1235096\nPetal.Length  0.5804131 -0.02449161 -0.1421264 -0.8014492\nPetal.Width   0.5648565 -0.06694199 -0.6342727  0.5235971\n\n\nWe print the summary of the PCA result, which includes the standard deviation of each principal component and the proportion of variance explained.\n\nsummary(pca_result)\n\nImportance of components:\n                          PC1    PC2     PC3     PC4\nStandard deviation     1.7084 0.9560 0.38309 0.14393\nProportion of Variance 0.7296 0.2285 0.03669 0.00518\nCumulative Proportion  0.7296 0.9581 0.99482 1.00000"
  },
  {
    "objectID": "R/PCA_analysis.html#introduction",
    "href": "R/PCA_analysis.html#introduction",
    "title": "Principle Component Analysis",
    "section": "",
    "text": "Principal Component Analysis (PCA) is a dimensionality reduction technique used to reduce the number of features in a dataset while retaining most of the information.\n\n\n\nWe will load the iris data.\nStandardize the data and then compute PCA.\n\n\nlibrary(factoextra)\n\nLoading required package: ggplot2\n\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\ndata &lt;- iris\npca_result &lt;- stats::prcomp(data[, 1:4], scale = T)\npca_result\n\nStandard deviations (1, .., p=4):\n[1] 1.7083611 0.9560494 0.3830886 0.1439265\n\nRotation (n x k) = (4 x 4):\n                    PC1         PC2        PC3        PC4\nSepal.Length  0.5210659 -0.37741762  0.7195664  0.2612863\nSepal.Width  -0.2693474 -0.92329566 -0.2443818 -0.1235096\nPetal.Length  0.5804131 -0.02449161 -0.1421264 -0.8014492\nPetal.Width   0.5648565 -0.06694199 -0.6342727  0.5235971\n\n\nWe print the summary of the PCA result, which includes the standard deviation of each principal component and the proportion of variance explained.\n\nsummary(pca_result)\n\nImportance of components:\n                          PC1    PC2     PC3     PC4\nStandard deviation     1.7084 0.9560 0.38309 0.14393\nProportion of Variance 0.7296 0.2285 0.03669 0.00518\nCumulative Proportion  0.7296 0.9581 0.99482 1.00000"
  },
  {
    "objectID": "R/PCA_analysis.html#visualize-pca-results",
    "href": "R/PCA_analysis.html#visualize-pca-results",
    "title": "Principle Component Analysis",
    "section": "Visualize PCA Results",
    "text": "Visualize PCA Results\n\nScree Plot\nA scree plot shows the proportion of variance explained by each principal component.\n\nfactoextra::fviz_eig(pca_result)\n\n\n\n\n\n\n\n\n\n\nBiplot\nA biplot shows the scores of the samples and the loadings of the variables on the first two principal components.\n\nplt &lt;- factoextra::fviz_pca_biplot(\n  pca_result,\n  geom.ind = \"point\",\n  pointshape = 21,\n  pointsize = 2,\n  fill.ind = iris$Species,\n  col.var = \"black\",\n  repel = TRUE\n)\nplt"
  },
  {
    "objectID": "R/PCA_analysis.html#interpretation",
    "href": "R/PCA_analysis.html#interpretation",
    "title": "Principle Component Analysis",
    "section": "Interpretation",
    "text": "Interpretation\n\nThe Scree Plot suggests to decide the number of principle components to retain by looking an elbow point where the explained variance starts to level off.\nThe biplot visualizes both the samples (points) and the variables (arrows). Points that are close to each other represent samples with similar characteristics, while the direction and length of the arrows indicate the contribution of each variable to the principal components."
  },
  {
    "objectID": "R/PCA_analysis.html#visualization-of-pca-in-3d-scatter-plot",
    "href": "R/PCA_analysis.html#visualization-of-pca-in-3d-scatter-plot",
    "title": "Principle Component Analysis",
    "section": "Visualization of PCA in 3d Scatter Plot",
    "text": "Visualization of PCA in 3d Scatter Plot\nA 3d scatter plot allows us to see the relationships between three principle components simultaneously and also gives us a better understanding of how much variance is explained by these components.\nIt also allows for interactive exploration where we can rotate the plot and view it from a different angles.\nWe will plot this using plotly package.\n\npca_result2 &lt;- stats::prcomp(data[, 1:4], scale = T, rank. = 3)\npca_result2\n\nStandard deviations (1, .., p=4):\n[1] 1.7083611 0.9560494 0.3830886 0.1439265\n\nRotation (n x k) = (4 x 3):\n                    PC1         PC2        PC3\nSepal.Length  0.5210659 -0.37741762  0.7195664\nSepal.Width  -0.2693474 -0.92329566 -0.2443818\nPetal.Length  0.5804131 -0.02449161 -0.1421264\nPetal.Width   0.5648565 -0.06694199 -0.6342727\n\n\nNext, we will create a dataframe of the 3 principle components and negate PC2 and PC3 for visual preference to make the plot look more organised and symmetric in 3d space.\n\ncomponents &lt;- as.data.frame(pca_result2$x)\ncomponents$PC2 &lt;- components$PC2\ncomponents$PC3 &lt;- components$PC3\n\n\nfig &lt;- plotly::plot_ly(\n  components,\n  x = ~PC1,\n  y = ~PC2,\n  z = ~PC3,\n  color = ~ data$Species,\n  colors = c('darkgreen', 'darkblue', 'darkred')\n) |&gt;\n  add_markers(size = 12)\n\nfig &lt;- fig |&gt;\n  layout(title = \"3d Visualization of PCA\", scene = list(bgcolor = \"lightgray\"))\nfig"
  },
  {
    "objectID": "R/logistic_regr.html",
    "href": "R/logistic_regr.html",
    "title": "Logistic Regression in R",
    "section": "",
    "text": "In binary logistic regression, there is a single binary dependent variable, coded by an indicator variable. For example, if we represent a response as 1 and non-response as 0, then the corresponding probability of response, can be between 0 (certainly not a response) and 1 (certainly a response) - hence the labeling !\nThe logistic model models the log-odds of an event as a linear combination of one or more independent variables (explanatory variables). If we observed \\((y_i, x_i),\\) where \\(y_i\\) is a Bernoulli variable and \\(x_i\\) a vector of explanatory variables, the model for \\(\\pi_i = P(y_i=1)\\) is\n\\[\n\\text{logit}(\\pi_i)= \\log\\left\\{ \\frac{\\pi_i}{1-\\pi_i}\\right\\} = \\beta_0 + \\beta x_i, i = 1,\\ldots,n\n\\]\nThe model is especially useful in case-control studies and leads to the effect of risk factors by odds ratios."
  },
  {
    "objectID": "R/logistic_regr.html#modelling-factors-correctly-and-interpretation-of-the-intercept",
    "href": "R/logistic_regr.html#modelling-factors-correctly-and-interpretation-of-the-intercept",
    "title": "Logistic Regression in R",
    "section": "Modelling factors correctly and Interpretation of the Intercept",
    "text": "Modelling factors correctly and Interpretation of the Intercept\nSo far we’ve learnt that it is good practice to always have binary and categorical variables set as factors, and that we should specify what method we want R to use for doing any contrasts (e.g. contr.treatment). You can specify different contrast methods for each variable by including them in a list in the model. It can sometimes be hard to see what contrast method R is using, so best to always specify this in your model (e.g. contrasts = list(trt01pn = \"contr.treatment\", sex=\"contr.sum\"). It is helpful to view what the contrasts look like before you select which to use.\nA factor with 2 levels (2 treatments) using contr.treatment would set the first level to be the reference (0) and contrast the second level to the baseline.\nA factor with 4 levels (4 treatments) using contr.treatment would set the first level to be the reference (0), you would see 3 parameters in the model with 3 estimates corresponding to the increase in log-odds attributable to contrasting the second, third or fourth level to the baseline.\n\ncontr.treatment(2)\n\n  2\n1 0\n2 1\n\ncontr.treatment(4)\n\n  2 3 4\n1 0 0 0\n2 1 0 0\n3 0 1 0\n4 0 0 1\n\n\nBelow we apply contr.treatment to our trt01pn and sex variables. Note: how the variables trt01pn2 and sex2 are now shown in the output, this is indicating that these rows relates to treatment=2 and sex=2. See the next section for how to interpret the estimates and change this contr. option.\n\n# Good practice to have binary variables (eg. treatment) identified as a factor\n# And to specify what contrast option you are using ! more on this below\nlung$trt01pn &lt;- as.factor(lung$trt01pn)\nlung$sex &lt;- as.factor(lung$sex)\n\nm1 &lt;- stats::glm(\n  wt_catn ~ trt01pn + age + sex + ph.ecog + meal.cal,\n  data = lung,\n  family = binomial(link = \"logit\"),\n  contrasts = list(trt01pn = \"contr.treatment\", sex = \"contr.treatment\")\n)\nsummary(m1)\n\n\nCall:\nstats::glm(formula = wt_catn ~ trt01pn + age + sex + ph.ecog + \n    meal.cal, family = binomial(link = \"logit\"), data = lung, \n    contrasts = list(trt01pn = \"contr.treatment\", sex = \"contr.treatment\"))\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept) -2.6415326  1.5140191  -1.745   0.0810 .\ntrt01pn2     0.3887667  0.3781566   1.028   0.3039  \nage          0.0122549  0.0211553   0.579   0.5624  \nsex2         0.8321005  0.3743793   2.223   0.0262 *\nph.ecog     -0.3763592  0.2638322  -1.427   0.1537  \nmeal.cal     0.0008500  0.0004486   1.895   0.0581 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 202.36  on 169  degrees of freedom\nResidual deviance: 190.46  on 164  degrees of freedom\n  (58 observations deleted due to missingness)\nAIC: 202.46\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "R/logistic_regr.html#how-r-parameterizes-your-variables-in-the-model",
    "href": "R/logistic_regr.html#how-r-parameterizes-your-variables-in-the-model",
    "title": "Logistic Regression in R",
    "section": "How R parameterizes your variables in the model",
    "text": "How R parameterizes your variables in the model\n\ncontr.treatment - [default] sets the first level to be the reference and contrasts each other level with the baseline. For example, based on the model shown below. Log-odds for Treatment 2 = -2.64153 + 0.38876 =-2.25277 , Log-odds for Treatment 1=-2.64153\ncontr.sum - sets the last level to be the reference and compares the mean of the dependent variable for a given level to the overall mean of the dependent variable. For treatment 1, the intercept + trt01pn1 estimate. For Treatment 2, the intercept - trt01pn1 estimate.\nLog-odds for Treatment 2 = -2.44715 - - 0.19438 = -2.25277, Log-odds for Treatment 1=-2.44715 - 0.19438 = -2.64153\nuse contr.sum(2) to show the contrast you are using and hence how to interpret your estimates.\nexponential (ratio log-odds) = odds ratio. eg. -2.25277/ -2.64153 = 0.85283 Treatment 2 is 0.85 times as likely (eg. 15% less likely) to have weight gain compared to Treatment 1.\n\n\nma &lt;- stats::glm(\n  wt_catn ~ trt01pn + age + sex + ph.ecog + meal.cal,\n  data = lung,\n  family = binomial(link = \"logit\"),\n  contrasts = list(trt01pn = \"contr.treatment\", sex = \"contr.treatment\")\n)\nsummary(ma)\n\n\nCall:\nstats::glm(formula = wt_catn ~ trt01pn + age + sex + ph.ecog + \n    meal.cal, family = binomial(link = \"logit\"), data = lung, \n    contrasts = list(trt01pn = \"contr.treatment\", sex = \"contr.treatment\"))\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept) -2.6415326  1.5140191  -1.745   0.0810 .\ntrt01pn2     0.3887667  0.3781566   1.028   0.3039  \nage          0.0122549  0.0211553   0.579   0.5624  \nsex2         0.8321005  0.3743793   2.223   0.0262 *\nph.ecog     -0.3763592  0.2638322  -1.427   0.1537  \nmeal.cal     0.0008500  0.0004486   1.895   0.0581 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 202.36  on 169  degrees of freedom\nResidual deviance: 190.46  on 164  degrees of freedom\n  (58 observations deleted due to missingness)\nAIC: 202.46\n\nNumber of Fisher Scoring iterations: 4\n\ncontr.treatment(2)\n\n  2\n1 0\n2 1\n\nmb &lt;- stats::glm(\n  wt_catn ~ trt01pn + age + sex + ph.ecog + meal.cal,\n  data = lung,\n  family = binomial(link = \"logit\"),\n  contrasts = list(trt01pn = \"contr.sum\", sex = \"contr.treatment\")\n)\nsummary(mb)\n\n\nCall:\nstats::glm(formula = wt_catn ~ trt01pn + age + sex + ph.ecog + \n    meal.cal, family = binomial(link = \"logit\"), data = lung, \n    contrasts = list(trt01pn = \"contr.sum\", sex = \"contr.treatment\"))\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept) -2.4471493  1.4929863  -1.639   0.1012  \ntrt01pn1    -0.1943833  0.1890783  -1.028   0.3039  \nage          0.0122549  0.0211553   0.579   0.5624  \nsex2         0.8321005  0.3743793   2.223   0.0262 *\nph.ecog     -0.3763592  0.2638322  -1.427   0.1537  \nmeal.cal     0.0008500  0.0004486   1.895   0.0581 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 202.36  on 169  degrees of freedom\nResidual deviance: 190.46  on 164  degrees of freedom\n  (58 observations deleted due to missingness)\nAIC: 202.46\n\nNumber of Fisher Scoring iterations: 4\n\ncontr.sum(2)\n\n  [,1]\n1    1\n2   -1"
  },
  {
    "objectID": "R/logistic_regr.html#calculation-of-confidence-intervals",
    "href": "R/logistic_regr.html#calculation-of-confidence-intervals",
    "title": "Logistic Regression in R",
    "section": "Calculation of confidence intervals",
    "text": "Calculation of confidence intervals\nUsing the above model, you can output the estimates and confidence intervals using coef() and confint() and exponential back transforming using exp(). NOTE: that there are two types of confidence intervals that you can calculate. Function confint.default gives the Wald confidence limits, which is the default option in SAS PROC LOGISTIC procedure; whereas confint gives the profile-likelihood limits.\n\n# model coefficients summary\nsummary(m1)$coefficients\n\n                 Estimate   Std. Error    z value   Pr(&gt;|z|)\n(Intercept) -2.6415326252 1.5140190574 -1.7447156 0.08103439\ntrt01pn2     0.3887666677 0.3781565596  1.0280574 0.30392281\nage          0.0122549015 0.0211552875  0.5792831 0.56239813\nsex2         0.8321005169 0.3743792762  2.2226137 0.02624186\nph.ecog     -0.3763592487 0.2638321918 -1.4265100 0.15372119\nmeal.cal     0.0008499918 0.0004486401  1.8945961 0.05814593\n\n# Wald confidence limits\ncbind(est = exp(coef(m1)), exp(confint.default(m1)))\n\n                   est       2.5 %   97.5 %\n(Intercept) 0.07125198 0.003664896 1.385263\ntrt01pn2    1.47516031 0.702994248 3.095470\nage         1.01233030 0.971213751 1.055188\nsex2        2.29814096 1.103327506 4.786840\nph.ecog     0.68635572 0.409236994 1.151128\nmeal.cal    1.00085035 0.999970674 1.001731\n\n# profile-likelihood limits\ncbind(est = exp(coef(m1)), exp(confint(m1)))\n\nWaiting for profiling to be done...\n\n\n                   est       2.5 %   97.5 %\n(Intercept) 0.07125198 0.003312288 1.302587\ntrt01pn2    1.47516031 0.696210092 3.085089\nage         1.01233030 0.971670916 1.056194\nsex2        2.29814096 1.107651762 4.836770\nph.ecog     0.68635572 0.405659156 1.147452\nmeal.cal    1.00085035 0.999978126 1.001761"
  },
  {
    "objectID": "R/logistic_regr.html#emmeans",
    "href": "R/logistic_regr.html#emmeans",
    "title": "Logistic Regression in R",
    "section": "{emmeans}",
    "text": "{emmeans}\nHere we will use {emmeans} to output the log-odds of weight gain for treatment 1 and treatment 2.\nNOTE as per the output, these are on the logit scale, you need to exponentiate to get the odds (or use the type=“response” option).\nThe treatment comparison can also be output on the log-odds or back transformed scale as shown below.\n\nm3 &lt;- stats::glm(\n  wt_catn ~ trt01pn + age + sex + ph.ecog + meal.cal,\n  data = lung,\n  family = binomial(link = \"logit\"),\n  contrasts = list(trt01pn = \"contr.treatment\")\n)\nsummary(m3)\n\n\nCall:\nstats::glm(formula = wt_catn ~ trt01pn + age + sex + ph.ecog + \n    meal.cal, family = binomial(link = \"logit\"), data = lung, \n    contrasts = list(trt01pn = \"contr.treatment\"))\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept) -2.6415326  1.5140191  -1.745   0.0810 .\ntrt01pn2     0.3887667  0.3781566   1.028   0.3039  \nage          0.0122549  0.0211553   0.579   0.5624  \nsex2         0.8321005  0.3743793   2.223   0.0262 *\nph.ecog     -0.3763592  0.2638322  -1.427   0.1537  \nmeal.cal     0.0008500  0.0004486   1.895   0.0581 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 202.36  on 169  degrees of freedom\nResidual deviance: 190.46  on 164  degrees of freedom\n  (58 observations deleted due to missingness)\nAIC: 202.46\n\nNumber of Fisher Scoring iterations: 4\n\ncontr.treatment(2)\n\n  2\n1 0\n2 1\n\n# log-odds for each treatment\nlsm &lt;- emmeans::emmeans(m3, \"trt01pn\")\nlsm\n\n trt01pn emmean    SE  df asymp.LCL asymp.UCL\n 1       -1.034 0.225 Inf     -1.47   -0.5935\n 2       -0.645 0.302 Inf     -1.24   -0.0529\n\nResults are averaged over the levels of: sex \nResults are given on the logit (not the response) scale. \nConfidence level used: 0.95 \n\n# log-odds ratios (treatment comparison): This does all pairwise comparisons\n# However as seen below, this is TRT 1 - TRT 2\npairs(lsm)\n\n contrast            estimate    SE  df z.ratio p.value\n trt01pn1 - trt01pn2   -0.389 0.378 Inf  -1.028  0.3039\n\nResults are averaged over the levels of: sex \nResults are given on the log odds ratio (not the response) scale. \n\n# the below creates tests and CI's prior to back transformation (ratios of geometric means)\npairs(lsm, type = \"response\")\n\n contrast            odds.ratio    SE  df null z.ratio p.value\n trt01pn1 / trt01pn2      0.678 0.256 Inf    1  -1.028  0.3039\n\nResults are averaged over the levels of: sex \nTests are performed on the log odds ratio scale \n\n# see coefficients of the linear functions\ncoef(pairs(lsm))\n\n         trt01pn c.1\ntrt01pn1       1   1\ntrt01pn2       2  -1\n\n# Output treatment contrasts 2 vs 1 and 95% CIs, the type=\"response\" option back transforms the results\ntrtdiff &lt;- contrast(lsm, \"poly\")\ntrtdiff\n\n contrast estimate    SE  df z.ratio p.value\n linear      0.389 0.378 Inf   1.028  0.3039\n\nResults are averaged over the levels of: sex \nResults are given on the log odds ratio (not the response) scale. \n\nconfint(trtdiff, type = \"response\")\n\n contrast odds.ratio    SE  df asymp.LCL asymp.UCL\n linear         1.48 0.558 Inf     0.703       3.1\n\nResults are averaged over the levels of: sex \nConfidence level used: 0.95 \nIntervals are back-transformed from the log odds ratio scale \n\n\nIn Summary: Treatment 2 is on average 1.48 times as likely to have weight gain compared to treatment 1, however this is not statistically significant (95% Confidence interval = 0.703-3.100, p-value= 0.3039)."
  },
  {
    "objectID": "R/logistic_regr.html#gmodels",
    "href": "R/logistic_regr.html#gmodels",
    "title": "Logistic Regression in R",
    "section": "{gmodels}",
    "text": "{gmodels}\n{gmodels} is an alternative package to create contrasts instead of &lt;emmeans&gt;, you can use the fit.contrast() function from the gmodels package. The same result is obtained as &lt;emmeans&gt;.\n\nlung2 &lt;- lung |&gt;\n  mutate(dose_id2 = as.factor(lung$dose_id))\n\nm3 &lt;- stats::glm(\n  wt_catn ~ dose_id2 + age + sex + ph.ecog + meal.cal,\n  data = lung2,\n  family = binomial(link = \"logit\"),\n  contrasts = list(dose_id2 = \"contr.treatment\")\n)\n\ngmodels::fit.contrast(m3, 'dose_id2', c(0.5, 0.5, -1), conf.int = 0.95)\n\n                            Estimate Std. Error   z value  Pr(&gt;|z|)  lower CI\ndose_id2 c=( 0.5 0.5 -1 ) -0.4096323  0.3801683 -1.077502 0.2812558 -1.160322\n                           upper CI\ndose_id2 c=( 0.5 0.5 -1 ) 0.3410574"
  },
  {
    "objectID": "R/correlation.html",
    "href": "R/correlation.html",
    "title": "Correlation Analysis Using R",
    "section": "",
    "text": "The most commonly used correlation analysis methods in clinical trials include:\n\nPearson correlation coefficient: product moment coefficient between two continuous variables, measuring linear associations.\n\n\\[\nr = \\frac{\\sum_{i=1}^n (x_i - m_x)(y_i - m_y)}{\\sqrt{\\sum_{i=1}^n (x_i - m_x)^2\\sum_{i=1}^n (y_i - m_y)^2}},\\]\nwhere \\(x\\) and \\(y\\) are observations from two continuous variables of length \\(n\\) and \\(m_x\\) and \\(m_y\\) are their respective means.\nSpearman correlation coefficient: rank correlation defined through the scaled sum of the squared values of the difference between ranks of two continuous variables.\n\\[\n\\rho = \\frac{\\sum_{i=1}^n (x'_i - m_{x'})(y'_i - m_{y'})}{\\sqrt{\\sum_{i=1}^n (x'_i - m_{x'})^2\\sum_{i=1}^n(y'_i - m_{y'})^2}},\n\\]\nwhere \\(x'\\) and \\(y'\\) are the ranks of \\(x\\) and \\(y\\) and \\(m_{x'}\\) and \\(m_{y'}\\) are the mean ranks of \\(x\\) and \\(y\\), respectively.\nKendall’s rank correlation: rank correlation based on the number of inversions in one ranking as compared with another.\n\\[\n\\tau = \\frac{n_c - n_d}{\\frac{1}{2}\\,n\\,(n-1)},\n\\]\nwhere \\(n_c\\) is the total number of concordant pairs, \\(n_d\\) is the total number of disconcordant pairs and \\(n\\) the total size of observations in \\(x\\) and \\(y\\).\n\nOther association measures are available for count data/contingency tables comparing observed frequencies with those expected under the assumption of independence\n\nFisher exact test\nChi-Square statistic\n\n\nExample: Lung Cancer Data\nData source: Loprinzi CL. Laurie JA. Wieand HS. Krook JE. Novotny PJ. Kugler JW. Bartel J. Law M. Bateman M. Klatt NE. et al. Prospective evaluation of prognostic variables from patient-completed questionnaires. North Central Cancer Treatment Group. Journal of Clinical Oncology. 12(3):601-7, 1994.\nSurvival in patients with advanced lung cancer from the North Central Cancer Treatment Group. Performance scores rate how well the patient can perform usual daily activities.\n\nlibrary(survival)\n\nglimpse(lung)\n\nRows: 228\nColumns: 10\n$ inst      &lt;dbl&gt; 3, 3, 3, 5, 1, 12, 7, 11, 1, 7, 6, 16, 11, 21, 12, 1, 22, 16…\n$ time      &lt;dbl&gt; 306, 455, 1010, 210, 883, 1022, 310, 361, 218, 166, 170, 654…\n$ status    &lt;dbl&gt; 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ age       &lt;dbl&gt; 74, 68, 56, 57, 60, 74, 68, 71, 53, 61, 57, 68, 68, 60, 57, …\n$ sex       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, …\n$ ph.ecog   &lt;dbl&gt; 1, 0, 0, 1, 0, 1, 2, 2, 1, 2, 1, 2, 1, NA, 1, 1, 1, 2, 2, 1,…\n$ ph.karno  &lt;dbl&gt; 90, 90, 90, 90, 100, 50, 70, 60, 70, 70, 80, 70, 90, 60, 80,…\n$ pat.karno &lt;dbl&gt; 100, 90, 90, 60, 90, 80, 60, 80, 80, 70, 80, 70, 90, 70, 70,…\n$ meal.cal  &lt;dbl&gt; 1175, 1225, NA, 1150, NA, 513, 384, 538, 825, 271, 1025, NA,…\n$ wt.loss   &lt;dbl&gt; NA, 15, 15, 11, 0, 0, 10, 1, 16, 34, 27, 23, 5, 32, 60, 15, …\n\n\n\n\nOverview\ncor() computes the correlation coefficient between continuous variables x and y, where method chooses which correlation coefficient is to be computed (default: \"pearson\", \"kendall\", or \"spearman\").\ncor.test() calulates the test for association between paired samples, using one of Pearson’s product moment correlation coefficient, Kendall’s \\(\\tau\\) or Spearman’s \\(\\rho\\). Besides the correlation coefficient itself, it provides additional information.\nMissing values are assumed to be missing completely at random (MCAR). Different strategies are available, see ?cor for details.\n\n\nPearson Correlation\n\nstats::cor.test(x = lung$age, y = lung$meal.cal, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  lung$age and lung$meal.cal\nt = -3.1824, df = 179, p-value = 0.001722\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.3649503 -0.0885415\nsample estimates:\n       cor \n-0.2314107 \n\n\n\n\nSpearman Correlation\n\nstats::cor.test(x = lung$age, y = lung$meal.cal, method = \"spearman\")\n\nWarning in cor.test.default(x = lung$age, y = lung$meal.cal, method =\n\"spearman\"): Cannot compute exact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  lung$age and lung$meal.cal\nS = 1193189, p-value = 0.005095\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.2073639 \n\n\nNote: Exact p-values require unanimous ranks.\n\n\nKendall’s rank correlation\n\nstats::cor.test(x = lung$age, y = lung$meal.cal, method = \"kendall\")\n\n\n    Kendall's rank correlation tau\n\ndata:  lung$age and lung$meal.cal\nz = -2.7919, p-value = 0.00524\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n       tau \n-0.1443877 \n\n\n\n\nInterpretation of correlation coefficients\nCorrelation coefficient is comprised between -1 and 1:\n\n\\(-1\\) indicates a strong negative correlation\n\\(0\\) means that there is no association between the two variables\n\\(1\\) indicates a strong positive correlation"
  },
  {
    "objectID": "R/Clustering_Knowhow.html",
    "href": "R/Clustering_Knowhow.html",
    "title": "Clustering Data",
    "section": "",
    "text": "Clustering is a method of segregating unlabeled data or data points into different groups/clusters such that similar data points fall in the same cluster than those which differ from the others. The similarity measures are calculated using distance based metrics like Euclidean distance, Cosine similarity, Manhattan distance, etc.\nFor Example, In the graph given below, we can clearly see that the data points can be grouped into 3 clusters"
  },
  {
    "objectID": "R/Clustering_Knowhow.html#what-is-clustering",
    "href": "R/Clustering_Knowhow.html#what-is-clustering",
    "title": "Clustering Data",
    "section": "",
    "text": "Clustering is a method of segregating unlabeled data or data points into different groups/clusters such that similar data points fall in the same cluster than those which differ from the others. The similarity measures are calculated using distance based metrics like Euclidean distance, Cosine similarity, Manhattan distance, etc.\nFor Example, In the graph given below, we can clearly see that the data points can be grouped into 3 clusters"
  },
  {
    "objectID": "R/Clustering_Knowhow.html#type-of-clustering-algorithm",
    "href": "R/Clustering_Knowhow.html#type-of-clustering-algorithm",
    "title": "Clustering Data",
    "section": "Type of Clustering Algorithm",
    "text": "Type of Clustering Algorithm\nSome of the popular clustering algorithms are:\n\nCentroid-based Clustering (Partitioning methods)\nDensity-based Clustering (Model-based methods)\nConnectivity-based Clustering (Hierarchical clustering)\nDistribution-based Clustering\n\n\n1.Centroid-based Clustering (Partitioning methods)\nPartitioning methods group data points on the basis of their closeness. The similarity measure chosen for these algorithms are Euclidean distance, Manhattan Distance or Minkowski Distance.\nThe primary drawback for these algorithms is we need to pre define the number of clusters before allocating the data points to a group.\nOne of the popular centroid based clustering technique is K means Clustering. \n\nK Means Clustering\nK means is an iterative clustering algorithm that works in these 5 steps:\n\nSpecify the desired number of clusters K: Let us choose k=2 for these 5 data points in 2-D space.\n\nRandomly assign each data point to a cluster: Let’s assign three points in cluster 1, shown using orange color, and two points in cluster 2, shown using grey color.\n\nCompute cluster centroids: Centroids correspond to the arithmetic mean of data points assigned to the cluster. The centroid of data points in the orange cluster is shown using the orange cross, and those in the grey cluster using a grey cross.\n\nAssigns each observation to their closest centroid, based on the Euclidean distance between the object and the centroid\n\nRe-computing the centroids for both clusters.\n\n\nWe will repeat the 4th and 5th steps until no further switching of data points between two clusters for two successive repeats. \n\n\nK-Means Clustering in R\nStep 1: Load packages\nFirst, we’ll load below packages that contain several useful functions regarding k-means clustering in R.\n\nlibrary(cluster) # Contain cluster function\nlibrary(dplyr) # Data manipulation\nlibrary(ggplot2) # Plotting function\nlibrary(readr) # Read and write excel/csv files\nlibrary(factoextra) # Extract and Visualize the Results of Multivariate Data Analyses\n\nStep 2: Load Data\nWe have used the “Mall_Customer” dataset in R for this case study.\n\n# Loading the data\ndf &lt;- read_csv(\"../data/Mall_Customers.csv\")\n\n# Structure of the data\nstr(df)\n\nspc_tbl_ [200 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ CustomerID            : chr [1:200] \"0001\" \"0002\" \"0003\" \"0004\" ...\n $ Genre                 : chr [1:200] \"Male\" \"Male\" \"Female\" \"Female\" ...\n $ Age                   : num [1:200] 19 21 20 23 31 22 35 23 64 30 ...\n $ Annual Income (k$)    : num [1:200] 15 15 16 16 17 17 18 18 19 19 ...\n $ Spending Score (1-100): num [1:200] 39 81 6 77 40 76 6 94 3 72 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   CustomerID = col_character(),\n  ..   Genre = col_character(),\n  ..   Age = col_double(),\n  ..   `Annual Income (k$)` = col_double(),\n  ..   `Spending Score (1-100)` = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\ndataset consists of 200 customers data with their age, annual income and Spending score.\n\n# Rename the columns\ndf &lt;- df |&gt;\n  rename(\n    \"Annual_Income\" = `Annual Income (k$)`,\n    \"Spending_score\" = `Spending Score (1-100)`\n  )\n\n# remove rows with missing values\ndf &lt;- na.omit(df)\n\n# scale each variable to have a mean of 0 and sd of 1\ndf1 &lt;- df |&gt;\n  mutate(across(where(is.numeric), scale))\n\n# view first six rows of dataset\nhead(df1)\n\n# A tibble: 6 × 5\n  CustomerID Genre  Age[,1] Annual_Income[,1] Spending_score[,1]\n  &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt;             &lt;dbl&gt;              &lt;dbl&gt;\n1 0001       Male    -1.42              -1.73             -0.434\n2 0002       Male    -1.28              -1.73              1.19 \n3 0003       Female  -1.35              -1.70             -1.71 \n4 0004       Female  -1.13              -1.70              1.04 \n5 0005       Female  -0.562             -1.66             -0.395\n6 0006       Female  -1.21              -1.66              0.999\n\n\n\nWe have separated the CustomerID and Genre from the dataset. The reason for removing these variables from the cluster dataset as Kmeans can handle only numerical variables.\nTo create cluster with categorical or ordinal variable we can use k-Medoid clustering. \n\ndf1 &lt;- df1[, 4:5]\n\nStep 3: Find the Optimal Number of Clusters\nTo perform k-means clustering in R we can use the built-in kmeans() function, which uses the following syntax:\n kmeans(data, centers, iter.max, nstart)\n where:\n - data: Name of the dataset.\n - centers: The number of clusters, denoted k.\n - iter.max (optional): The maximum number of iterations allowed. Default value is 10.\n - nstart (optional): The number of initial configurations. Default value is 1.\n\nCenters is the k of K Means. centers = 5 would results in 5 clusters being created. We need to predefine the k before the cluster process starts.\n\niter.max is the number of times the algorithm will repeat the cluster assignment and update the centers / centroids. Iteration stops after this many iterations even if the convergence criterion is not satisfied\nnstart is the number of times the initial starting points are re-sampled. It means at the initialization of Clusters you need to specify how many clusters you want and the algorithm will randomly find same number of centroids to initialize. nstart gives you an edge to initialize the centroids through re sampling.\nFor example if total number of cluster is 3 and nstart=25 then it extracts 3 sets of data, 25 times, and for each of these times, the algorithm is run (up to iter.max # of iterations) and the cost function (total sum of the squares) is evaluated and finally 3 centroids with lowest cost function are chosen to start the clustering process.\n\nTo find the best number of clusters/centroids there are two popular methods as shown below.\nA. Elbow Method:\nIt has two parts as explained below-\n\nWSS: The Within Sum of Squares (WSS) is the sum of distance between the centroids and every other data points within a cluster. Small WSS indicates that every data point is close to its nearest centroids.\nElbow rule/method: Here we plot out the WSS score against the number of K. Because with the number of K increasing, the WSS will always decrease; however, the magnitude of decrease between each k will be diminishing, and the plot will be a curve which looks like an arm that curled up. In this way, we can find out which point falls on the elbow.\n\n\nset.seed(1)\nwss &lt;- NULL\n\n# Feeding different centroid/cluster and record WSS\nfor (i in 1:10) {\n  fit = stats::kmeans(df1, centers = i, nstart = 25)\n  wss = c(wss, fit$tot.withinss)\n}\n\n# Visualize the plot\nplot(1:10, wss, type = \"o\", xlab = 'Number of clusters(k)')\n\n\n\n\n\n\n\n\nBased on the above plot at k=5 we can see an “elbow” where the sum of squares begins to “bend” or level off so the ideal number of clusters should be 5.\nThe above process to compute the “Elbow method” has been wrapped up in a single function (fviz_nbclust):\n\nfactoextra::fviz_nbclust(df1, kmeans, method = \"wss\", nstart = 25)\n\n\n\n\n\n\n\n\nB. Silhouette Method:\nThe silhouette coefficient or silhouette score is a measure of how similar a data point is within-cluster (intra-cluster) compared to other clusters (inter-cluster).\nThe Silhouette Coefficient is calculated using the mean intra-cluster distance (a) and the mean nearest-cluster distance (b) for each sample. The Silhouette Coefficient for a sample is (b - a) / max(a, b)\nHere we will plot the silhouette width/coefficient for different number of clusters and will choose the point where the silhouette width is highest.\nPoints to Remember While Calculating Silhouette Coefficient:\nThe value of the silhouette coefﬁcient is between [-1, 1]. A score of 1 denotes the best, meaning that the data points are very compact within the cluster to which it belongs and far away from the other clusters. The worst value is -1. Values near 0 denote overlapping clusters.\nIn this demonstration, we are going to see how silhouette method is used.\n\nsilhouette_score &lt;- function(k) {\n  km &lt;- stats::kmeans(df1, centers = k, nstart = 25)\n  ss &lt;- cluster::silhouette(km$cluster, dist(df1))\n  mean(ss[, 3])\n}\nk &lt;- 2:10\n\navg_sil &lt;- sapply(k, silhouette_score)\nplot(\n  k,\n  type = 'b',\n  avg_sil,\n  xlab = 'Number of clusters',\n  ylab = 'Average Silhouette Scores',\n  frame = FALSE\n)\n\n\n\n\n\n\n\n\nFrom the above method we can see the silhouette width is highest at cluster 5 so the optimal number of cluster should be 5.\nSimilar to the elbow method, this process to compute the “average silhoutte method” has been wrapped up in a single function (fviz_nbclust):\n\nfactoextra::fviz_nbclust(df1, kmeans, method = 'silhouette', nstart = 25)\n\n\n\n\n\n\n\n\nThe optimal number of clusters is 5.\nStep 4: Perform K-Means Clustering with Optimal K\nLastly, we can perform k-means clustering on the dataset using the optimal value for k of 5:\n\n# make this example reproducible\nset.seed(1)\n\n# perform k-means clustering with k = 5 clusters\nfit &lt;- stats::kmeans(df1, 5, nstart = 25)\nfit\n\nK-means clustering with 5 clusters of sizes 35, 39, 22, 23, 81\n\nCluster means:\n  Annual_Income Spending_score\n1     1.0523622    -1.28122394\n2     0.9891010     1.23640011\n3    -1.3262173     1.12934389\n4    -1.3042458    -1.13411939\n5    -0.2004097    -0.02638995\n\nClustering vector:\n  [1] 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4\n [38] 3 4 3 4 3 4 5 4 3 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n [75] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n[112] 5 5 5 5 5 5 5 5 5 5 5 5 2 1 2 5 2 1 2 1 2 5 2 1 2 1 2 1 2 1 2 5 2 1 2 1 2\n[149] 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1\n[186] 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2\n\nWithin cluster sum of squares by cluster:\n[1] 18.304646 19.655252  5.217630  7.577407 14.485632\n (between_SS / total_SS =  83.6 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\nWe can visualize the clusters on a scatterplot that displays the first two principal components on the axes using the fivz_cluster() function:\n\n# plot results of final k-means model\nfactoextra::fviz_cluster(fit, data = df1)\n\n\n\n\n\n\n\n\nStep 5: Exporting the data by adding generated clusters\n\n# Adding the clusters in the main data\ndf_cluster &lt;- df |&gt;\n  mutate(cluster = fit$cluster)\n\n# Creating Summary of created clusters based on existing variables\ndf_summary &lt;- df_cluster |&gt;\n  group_by(cluster) |&gt;\n  summarise(\n    records = n(),\n    avg_age = mean(Age),\n    avg_annual_income = mean(Annual_Income),\n    avg_spending_score = mean(Spending_score)\n  )\n\nprint(df_summary)\n\n# A tibble: 5 × 5\n  cluster records avg_age avg_annual_income avg_spending_score\n    &lt;int&gt;   &lt;int&gt;   &lt;dbl&gt;             &lt;dbl&gt;              &lt;dbl&gt;\n1       1      35    41.1              88.2               17.1\n2       2      39    32.7              86.5               82.1\n3       3      22    25.3              25.7               79.4\n4       4      23    45.2              26.3               20.9\n5       5      81    42.7              55.3               49.5\n\n\nWe can create a group of potential customers to target based on their age, average annual income and average spending score."
  },
  {
    "objectID": "R/mi_mar_predictive_mean_match.html",
    "href": "R/mi_mar_predictive_mean_match.html",
    "title": "Multiple Imputation: Predictive Mean Matching",
    "section": "",
    "text": "Predictive mean matching is a technique for missing value imputation. It calculates the predicted value of the missing variable based on a regression model from complete data, then selects one value (from the observed) that produces the closest prediction. PMM is robust to transformation, less vulnerable to model misspecification. More theoretical details for PMM can be found here.\nAssumption for PMM: distribution of missing is the same aas obsereved data of the candidates that produce the closest values to the predicted value by the missing entry."
  },
  {
    "objectID": "R/mi_mar_predictive_mean_match.html#overview",
    "href": "R/mi_mar_predictive_mean_match.html#overview",
    "title": "Multiple Imputation: Predictive Mean Matching",
    "section": "",
    "text": "Predictive mean matching is a technique for missing value imputation. It calculates the predicted value of the missing variable based on a regression model from complete data, then selects one value (from the observed) that produces the closest prediction. PMM is robust to transformation, less vulnerable to model misspecification. More theoretical details for PMM can be found here.\nAssumption for PMM: distribution of missing is the same aas obsereved data of the candidates that produce the closest values to the predicted value by the missing entry."
  },
  {
    "objectID": "R/mi_mar_predictive_mean_match.html#available-r-package",
    "href": "R/mi_mar_predictive_mean_match.html#available-r-package",
    "title": "Multiple Imputation: Predictive Mean Matching",
    "section": "Available R package",
    "text": "Available R package\nmice is a powerful R package developed by Stef van Buuren, Karin Groothuis-Oudshoorn and other contributors.\nImplementation of PMM in mice:\n\nPredictive mean matching, mice.impute.pmm\nWeighted predictive mean matching, mice.impute.midastouch\nMultivariate predictive mean matching, mice.impute.mpmm"
  },
  {
    "objectID": "R/mi_mar_predictive_mean_match.html#example",
    "href": "R/mi_mar_predictive_mean_match.html#example",
    "title": "Multiple Imputation: Predictive Mean Matching",
    "section": "Example",
    "text": "Example\nWe use the small dataset nhanes included in mice package. It has 25 rows, and three out of four variables have missings.\nThe original NHANES data is a large national level survey, some are publicly available via R package nhanes.\n\nlibrary(mice)\n\n\nAttaching package: 'mice'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following objects are masked from 'package:base':\n\n    cbind, rbind\n\n# load example dataset from mice\nhead(nhanes)\n\n  age  bmi hyp chl\n1   1   NA  NA  NA\n2   2 22.7   1 187\n3   1   NA   1 187\n4   3   NA  NA  NA\n5   1 20.4   1 113\n6   3   NA  NA 184\n\nsummary(nhanes)\n\n      age            bmi             hyp             chl       \n Min.   :1.00   Min.   :20.40   Min.   :1.000   Min.   :113.0  \n 1st Qu.:1.00   1st Qu.:22.65   1st Qu.:1.000   1st Qu.:185.0  \n Median :2.00   Median :26.75   Median :1.000   Median :187.0  \n Mean   :1.76   Mean   :26.56   Mean   :1.235   Mean   :191.4  \n 3rd Qu.:2.00   3rd Qu.:28.93   3rd Qu.:1.000   3rd Qu.:212.0  \n Max.   :3.00   Max.   :35.30   Max.   :2.000   Max.   :284.0  \n                NA's   :9       NA's   :8       NA's   :10     \n\n\n\nImpute with PMM\nTo impute with PMM is straightforward: specify the method, method = pmm.\n\nimp_pmm &lt;- mice::mice(nhanes, method = 'pmm', m = 5, maxit = 10)\n\n\n iter imp variable\n  1   1  bmi  hyp  chl\n  1   2  bmi  hyp  chl\n  1   3  bmi  hyp  chl\n  1   4  bmi  hyp  chl\n  1   5  bmi  hyp  chl\n  2   1  bmi  hyp  chl\n  2   2  bmi  hyp  chl\n  2   3  bmi  hyp  chl\n  2   4  bmi  hyp  chl\n  2   5  bmi  hyp  chl\n  3   1  bmi  hyp  chl\n  3   2  bmi  hyp  chl\n  3   3  bmi  hyp  chl\n  3   4  bmi  hyp  chl\n  3   5  bmi  hyp  chl\n  4   1  bmi  hyp  chl\n  4   2  bmi  hyp  chl\n  4   3  bmi  hyp  chl\n  4   4  bmi  hyp  chl\n  4   5  bmi  hyp  chl\n  5   1  bmi  hyp  chl\n  5   2  bmi  hyp  chl\n  5   3  bmi  hyp  chl\n  5   4  bmi  hyp  chl\n  5   5  bmi  hyp  chl\n  6   1  bmi  hyp  chl\n  6   2  bmi  hyp  chl\n  6   3  bmi  hyp  chl\n  6   4  bmi  hyp  chl\n  6   5  bmi  hyp  chl\n  7   1  bmi  hyp  chl\n  7   2  bmi  hyp  chl\n  7   3  bmi  hyp  chl\n  7   4  bmi  hyp  chl\n  7   5  bmi  hyp  chl\n  8   1  bmi  hyp  chl\n  8   2  bmi  hyp  chl\n  8   3  bmi  hyp  chl\n  8   4  bmi  hyp  chl\n  8   5  bmi  hyp  chl\n  9   1  bmi  hyp  chl\n  9   2  bmi  hyp  chl\n  9   3  bmi  hyp  chl\n  9   4  bmi  hyp  chl\n  9   5  bmi  hyp  chl\n  10   1  bmi  hyp  chl\n  10   2  bmi  hyp  chl\n  10   3  bmi  hyp  chl\n  10   4  bmi  hyp  chl\n  10   5  bmi  hyp  chl\n\nimp_pmm\n\nClass: mids\nNumber of multiple imputations:  5 \nImputation methods:\n  age   bmi   hyp   chl \n   \"\" \"pmm\" \"pmm\" \"pmm\" \nPredictorMatrix:\n    age bmi hyp chl\nage   0   1   1   1\nbmi   1   0   1   1\nhyp   1   1   0   1\nchl   1   1   1   0\n\n# imputations for bmi\nimp_pmm$imp$bmi\n\n      1    2    3    4    5\n1  30.1 27.2 22.0 27.2 22.5\n3  22.0 26.3 26.3 29.6 28.7\n4  24.9 24.9 20.4 21.7 20.4\n6  22.5 22.5 20.4 22.5 22.7\n10 22.7 22.5 22.5 33.2 22.0\n11 27.2 22.0 22.7 33.2 30.1\n12 20.4 20.4 20.4 33.2 24.9\n16 22.0 22.0 26.3 33.2 22.7\n21 27.2 26.3 28.7 30.1 28.7\n\n\nAn alternative to the standard PMM is midastouch.\n\nimp_pmms &lt;- mice::mice(nhanes, method = 'midastouch', m = 5, maxit = 10)\n\n\n iter imp variable\n  1   1  bmi  hyp  chl\n  1   2  bmi  hyp  chl\n  1   3  bmi  hyp  chl\n  1   4  bmi  hyp  chl\n  1   5  bmi  hyp  chl\n  2   1  bmi  hyp  chl\n  2   2  bmi  hyp  chl\n  2   3  bmi  hyp  chl\n  2   4  bmi  hyp  chl\n  2   5  bmi  hyp  chl\n  3   1  bmi  hyp  chl\n  3   2  bmi  hyp  chl\n  3   3  bmi  hyp  chl\n  3   4  bmi  hyp  chl\n  3   5  bmi  hyp  chl\n  4   1  bmi  hyp  chl\n  4   2  bmi  hyp  chl\n  4   3  bmi  hyp  chl\n  4   4  bmi  hyp  chl\n  4   5  bmi  hyp  chl\n  5   1  bmi  hyp  chl\n  5   2  bmi  hyp  chl\n  5   3  bmi  hyp  chl\n  5   4  bmi  hyp  chl\n  5   5  bmi  hyp  chl\n  6   1  bmi  hyp  chl\n  6   2  bmi  hyp  chl\n  6   3  bmi  hyp  chl\n  6   4  bmi  hyp  chl\n  6   5  bmi  hyp  chl\n  7   1  bmi  hyp  chl\n  7   2  bmi  hyp  chl\n  7   3  bmi  hyp  chl\n  7   4  bmi  hyp  chl\n  7   5  bmi  hyp  chl\n  8   1  bmi  hyp  chl\n  8   2  bmi  hyp  chl\n  8   3  bmi  hyp  chl\n  8   4  bmi  hyp  chl\n  8   5  bmi  hyp  chl\n  9   1  bmi  hyp  chl\n  9   2  bmi  hyp  chl\n  9   3  bmi  hyp  chl\n  9   4  bmi  hyp  chl\n  9   5  bmi  hyp  chl\n  10   1  bmi  hyp  chl\n  10   2  bmi  hyp  chl\n  10   3  bmi  hyp  chl\n  10   4  bmi  hyp  chl\n  10   5  bmi  hyp  chl\n\nimp_pmm\n\nClass: mids\nNumber of multiple imputations:  5 \nImputation methods:\n  age   bmi   hyp   chl \n   \"\" \"pmm\" \"pmm\" \"pmm\" \nPredictorMatrix:\n    age bmi hyp chl\nage   0   1   1   1\nbmi   1   0   1   1\nhyp   1   1   0   1\nchl   1   1   1   0\n\nimp_pmms$imp$bmi\n\n      1    2    3    4    5\n1  30.1 22.5 30.1 35.3 33.2\n3  30.1 28.7 30.1 35.3 30.1\n4  25.5 21.7 35.3 27.5 25.5\n6  21.7 21.7 20.4 24.9 25.5\n10 21.7 28.7 27.4 22.5 28.7\n11 30.1 22.5 30.1 20.4 33.2\n12 21.7 26.3 27.4 28.7 30.1\n16 20.4 28.7 30.1 27.5 30.1\n21 20.4 22.5 20.4 27.5 33.2"
  },
  {
    "objectID": "R/linear-regression.html",
    "href": "R/linear-regression.html",
    "title": "Linear Regression",
    "section": "",
    "text": "Simple linear regression is a statistical method used to model the relationship between a continuous dependent variable and continuous independent variable by fitting a linear equation to the observed data. It estimates how changes in the independent variable affect the dependent variable, allowing for predictions and insights about the underlying relationship. The primary goal is to minimize the difference between the observed values and the values predicted by the model.\nThe following assumptions must hold when building a linear regression model.\n\nThe dependent variable must be continuous.\nThe data you are modeling meets the “iid” criterion. That means the error terms, ε, are:\n\nindependent from one another and\nidentically distributed.\n\nThe error term is normally distributed with a mean of zero.\n\nTo demonstrate the use of linear regression we examine a dataset that illustrates the relationship between Height and Weight in a group of 237 teen-aged boys and girls. The dataset is available here and is imported to the workspace.\n\n\nThe first step is to obtain the simple descriptive statistics for the numeric variables of htwt data, and one-way frequencies for categorical variables. This is accomplished by employing summary function. There are 237 participants who are from 13.9 to 25 years old. It is a cross-sectional study, with each participant having one observation. We can use this data set to examine the relationship of participants’ height to their age and sex.\n\nknitr::opts_chunk$set(echo = TRUE)\nhtwt &lt;- read.csv(\"../data/htwt.csv\")\nsummary(htwt)\n\n      ROW          SEX                 AGE            HEIGHT     \n Min.   :  1   Length:237         Min.   :13.90   Min.   :50.50  \n 1st Qu.: 60   Class :character   1st Qu.:14.80   1st Qu.:58.80  \n Median :119   Mode  :character   Median :16.30   Median :61.50  \n Mean   :119                      Mean   :16.44   Mean   :61.36  \n 3rd Qu.:178                      3rd Qu.:17.80   3rd Qu.:64.30  \n Max.   :237                      Max.   :25.00   Max.   :72.00  \n     WEIGHT     \n Min.   : 50.5  \n 1st Qu.: 85.0  \n Median :101.0  \n Mean   :101.3  \n 3rd Qu.:112.0  \n Max.   :171.5  \n\n\nIn order to create a regression model to demonstrate the relationship between age and height for females, we first need to create a flag variable identifying females and an interaction variable between age and female gender flag.\n\nhtwt$female &lt;- ifelse(htwt$SEX == 'f', 1, 0)\nhtwt$fem_age &lt;- htwt$AGE * htwt$female\nhead(htwt)\n\n  ROW SEX  AGE HEIGHT WEIGHT female fem_age\n1   1   f 14.3   56.3   85.0      1    14.3\n2   2   f 15.5   62.3  105.0      1    15.5\n3   3   f 15.3   63.3  108.0      1    15.3\n4   4   f 16.1   59.0   92.0      1    16.1\n5   5   f 19.1   62.5  112.5      1    19.1\n6   6   f 17.1   62.5  112.0      1    17.1\n\n\n\n\n\nNext, we fit a regression model, representing the relationships between gender, age, height and the interaction variable created in the datastep above. We again use a where statement to restrict the analysis to those who are less than or equal to 19 years old. We use the clb option to get a 95% confidence interval for each of the parameters in the model. The model that we are fitting is \\(height = b_0 + b_1\\times female + b_2\\times age + b_3\\times fem\\_age + e\\)\n\nregression &lt;- lm(HEIGHT ~ female + AGE + fem_age, data = htwt, AGE &lt;= 19)\nsummary(regression)\n\n\nCall:\nlm(formula = HEIGHT ~ female + AGE + fem_age, data = htwt, subset = AGE &lt;= \n    19)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.2429 -1.7351  0.0383  1.6518  7.9289 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.8828     2.8734  10.052  &lt; 2e-16 ***\nfemale       13.6123     4.0192   3.387 0.000841 ***\nAGE           2.0313     0.1776  11.435  &lt; 2e-16 ***\nfem_age      -0.9294     0.2478  -3.750 0.000227 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.799 on 215 degrees of freedom\nMultiple R-squared:  0.4595,    Adjusted R-squared:  0.452 \nF-statistic: 60.93 on 3 and 215 DF,  p-value: &lt; 2.2e-16\n\nb0 = round(regression$coefficients[1], 4)\nb1 = round(regression$coefficients[2], 4)\nb2 = round(regression$coefficients[3], 4)\nb3 = round(regression$coefficients[4], 4)\n\nFrom the coefficients table b0,b1,b2,b3 are estimated as b0=28.8828 b1=13.6123 b2=2.0313 b3=-0.9294\nThe resulting regression model for height, age and gender based on the available data is \\(height= 28.8828 + 13.6123\\times female + 2.0313\\times age -0.9294\\times fem\\_age\\)"
  },
  {
    "objectID": "R/linear-regression.html#introduction",
    "href": "R/linear-regression.html#introduction",
    "title": "Linear Regression",
    "section": "",
    "text": "Simple linear regression is a statistical method used to model the relationship between a continuous dependent variable and continuous independent variable by fitting a linear equation to the observed data. It estimates how changes in the independent variable affect the dependent variable, allowing for predictions and insights about the underlying relationship. The primary goal is to minimize the difference between the observed values and the values predicted by the model.\nThe following assumptions must hold when building a linear regression model.\n\nThe dependent variable must be continuous.\nThe data you are modeling meets the “iid” criterion. That means the error terms, ε, are:\n\nindependent from one another and\nidentically distributed.\n\nThe error term is normally distributed with a mean of zero.\n\nTo demonstrate the use of linear regression we examine a dataset that illustrates the relationship between Height and Weight in a group of 237 teen-aged boys and girls. The dataset is available here and is imported to the workspace.\n\n\nThe first step is to obtain the simple descriptive statistics for the numeric variables of htwt data, and one-way frequencies for categorical variables. This is accomplished by employing summary function. There are 237 participants who are from 13.9 to 25 years old. It is a cross-sectional study, with each participant having one observation. We can use this data set to examine the relationship of participants’ height to their age and sex.\n\nknitr::opts_chunk$set(echo = TRUE)\nhtwt &lt;- read.csv(\"../data/htwt.csv\")\nsummary(htwt)\n\n      ROW          SEX                 AGE            HEIGHT     \n Min.   :  1   Length:237         Min.   :13.90   Min.   :50.50  \n 1st Qu.: 60   Class :character   1st Qu.:14.80   1st Qu.:58.80  \n Median :119   Mode  :character   Median :16.30   Median :61.50  \n Mean   :119                      Mean   :16.44   Mean   :61.36  \n 3rd Qu.:178                      3rd Qu.:17.80   3rd Qu.:64.30  \n Max.   :237                      Max.   :25.00   Max.   :72.00  \n     WEIGHT     \n Min.   : 50.5  \n 1st Qu.: 85.0  \n Median :101.0  \n Mean   :101.3  \n 3rd Qu.:112.0  \n Max.   :171.5  \n\n\nIn order to create a regression model to demonstrate the relationship between age and height for females, we first need to create a flag variable identifying females and an interaction variable between age and female gender flag.\n\nhtwt$female &lt;- ifelse(htwt$SEX == 'f', 1, 0)\nhtwt$fem_age &lt;- htwt$AGE * htwt$female\nhead(htwt)\n\n  ROW SEX  AGE HEIGHT WEIGHT female fem_age\n1   1   f 14.3   56.3   85.0      1    14.3\n2   2   f 15.5   62.3  105.0      1    15.5\n3   3   f 15.3   63.3  108.0      1    15.3\n4   4   f 16.1   59.0   92.0      1    16.1\n5   5   f 19.1   62.5  112.5      1    19.1\n6   6   f 17.1   62.5  112.0      1    17.1\n\n\n\n\n\nNext, we fit a regression model, representing the relationships between gender, age, height and the interaction variable created in the datastep above. We again use a where statement to restrict the analysis to those who are less than or equal to 19 years old. We use the clb option to get a 95% confidence interval for each of the parameters in the model. The model that we are fitting is \\(height = b_0 + b_1\\times female + b_2\\times age + b_3\\times fem\\_age + e\\)\n\nregression &lt;- lm(HEIGHT ~ female + AGE + fem_age, data = htwt, AGE &lt;= 19)\nsummary(regression)\n\n\nCall:\nlm(formula = HEIGHT ~ female + AGE + fem_age, data = htwt, subset = AGE &lt;= \n    19)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.2429 -1.7351  0.0383  1.6518  7.9289 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.8828     2.8734  10.052  &lt; 2e-16 ***\nfemale       13.6123     4.0192   3.387 0.000841 ***\nAGE           2.0313     0.1776  11.435  &lt; 2e-16 ***\nfem_age      -0.9294     0.2478  -3.750 0.000227 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.799 on 215 degrees of freedom\nMultiple R-squared:  0.4595,    Adjusted R-squared:  0.452 \nF-statistic: 60.93 on 3 and 215 DF,  p-value: &lt; 2.2e-16\n\nb0 = round(regression$coefficients[1], 4)\nb1 = round(regression$coefficients[2], 4)\nb2 = round(regression$coefficients[3], 4)\nb3 = round(regression$coefficients[4], 4)\n\nFrom the coefficients table b0,b1,b2,b3 are estimated as b0=28.8828 b1=13.6123 b2=2.0313 b3=-0.9294\nThe resulting regression model for height, age and gender based on the available data is \\(height= 28.8828 + 13.6123\\times female + 2.0313\\times age -0.9294\\times fem\\_age\\)"
  },
  {
    "objectID": "R/survey-stats-summary.html",
    "href": "R/survey-stats-summary.html",
    "title": "Survey Summary Statistics using R",
    "section": "",
    "text": "When conducting large-scale trials on samples of the population, it can be necessary to use a more complex sampling design than a simple random sample.\nAll of these designs need to be taken into account when calculating statistics, and when producing models. Only summary statistics are discussed in this document, and variances are calculated using the default Taylor series linearisation methods. For a more detailed introduction to survey statistics in R, see (Lohr 2022) or (Lumley 2004).\nWe will use the {survey} package, which is the standard for survey statistics in R. Note that for those who prefer the tidyverse, the {srvyr} package is a wrapper around {survey} with {dplyr} like syntax."
  },
  {
    "objectID": "R/survey-stats-summary.html#mean",
    "href": "R/survey-stats-summary.html#mean",
    "title": "Survey Summary Statistics using R",
    "section": "Mean",
    "text": "Mean\nIf we want to calculate a mean of a variable in a dataset which has been obtained from a simple random sample such as apisrs, in R we can create a design object using the survey::svydesign function (specifying that there is no PSU using id = ~1 and the finite population correction using fpc=~fpc).\n\nsrs_design &lt;- survey::svydesign(id = ~1, fpc = ~fpc, data = apisrs)\n\nThis design object stores all metadata about the sample alongside the data, and is used by all subsequent functions in the {survey} package. To calculate the mean, standard error, and confidence intervals of the growth variable, we can use the survey::svymean and confint functions:\n\n# Calculate mean and SE of growth. The standard error will be corrected by the finite population correction specified in the design\nsrs_means &lt;- survey::svymean(~growth, srs_design)\n\nsrs_means\n\n       mean     SE\ngrowth 31.9 2.0905\n\n# Use degf() to get the degrees of freedom\nconfint(srs_means, df = survey::degf(srs_design))\n\n          2.5 %   97.5 %\ngrowth 27.77764 36.02236\n\n\nNote that to obtain correct results, we had to specify the degrees of freedom using the design object."
  },
  {
    "objectID": "R/survey-stats-summary.html#total",
    "href": "R/survey-stats-summary.html#total",
    "title": "Survey Summary Statistics using R",
    "section": "Total",
    "text": "Total\nCalculating population totals can be done using the survey::svytotal function in R.\n\nsurvey::svytotal(~growth, srs_design)\n\n        total    SE\ngrowth 197589 12949"
  },
  {
    "objectID": "R/survey-stats-summary.html#ratios",
    "href": "R/survey-stats-summary.html#ratios",
    "title": "Survey Summary Statistics using R",
    "section": "Ratios",
    "text": "Ratios\nTo perform ratio analysis for means or proportions of analysis variables in R, we can survey::svyratio, here requesting that we do not separate the ratio estimation per Strata as this design is not stratified.\n\nsvy_ratio &lt;- survey::svyratio(\n  ~api00,\n  ~api99,\n  srs_design,\n  se = TRUE,\n  df = survey::degf(srs_design),\n  separate = FALSE\n)\n\nsvy_ratio\n\nRatio estimator: svyratio.survey.design2(~api00, ~api99, srs_design, se = TRUE, \n    df = survey::degf(srs_design), separate = FALSE)\nRatios=\n         api99\napi00 1.051066\nSEs=\n            api99\napi00 0.003603991\n\nconfint(svy_ratio, df = survey::degf(srs_design))\n\n               2.5 %   97.5 %\napi00/api99 1.043959 1.058173"
  },
  {
    "objectID": "R/survey-stats-summary.html#proportions",
    "href": "R/survey-stats-summary.html#proportions",
    "title": "Survey Summary Statistics using R",
    "section": "Proportions",
    "text": "Proportions\nTo calculate a proportion in R, we use the svymean function on a factor or character column:\n\nprops &lt;- survey::svymean(~sch.wide, srs_design)\n\nprops\n\n             mean     SE\nsch.wideNo  0.185 0.0271\nsch.wideYes 0.815 0.0271\n\nconfint(props, df = survey::degf(srs_design))\n\n                2.5 %    97.5 %\nsch.wideNo  0.1316041 0.2383959\nsch.wideYes 0.7616041 0.8683959\n\n\nFor proportions close to 0, it can be that survey::svyciprop is more accurate at producing confidence intervals than confint."
  },
  {
    "objectID": "R/survey-stats-summary.html#quantiles",
    "href": "R/survey-stats-summary.html#quantiles",
    "title": "Survey Summary Statistics using R",
    "section": "Quantiles",
    "text": "Quantiles\nTo calculate quantiles in R, we can use the survey::svyquantile function. Note that this function was reworked in version 4.1 of {survey}, and prior to this had different arguments and results. The current version of svyquantile has an qrule which is similar to the type argument in quantile, and can be used to change how the quantiles are calculated. For more information, see vignette(\"qrule\", package=\"survey\").\n\nsurvey::svyquantile(\n  ~growth,\n  srs_design,\n  quantiles = c(0.025, 0.5, 0.975),\n  ci = TRUE,\n  se = TRUE\n)\n\n$growth\n      quantile ci.2.5 ci.97.5        se\n0.025      -16    -21     -12  2.281998\n0.5         27     24      31  1.774887\n0.975      103     93     189 24.341307\n\nattr(,\"hasci\")\n[1] TRUE\nattr(,\"class\")\n[1] \"newsvyquantile\""
  },
  {
    "objectID": "R/binomial_test.html",
    "href": "R/binomial_test.html",
    "title": "Binomial Test",
    "section": "",
    "text": "The statistical test used to determine whether the proportion in a binary outcome experiment is equal to a specific value. It is appropriate when we have a small sample size and want to test the success probability \\(p\\) against a hypothesized value \\(p_0\\)."
  },
  {
    "objectID": "R/binomial_test.html#creating-a-sample-dataset",
    "href": "R/binomial_test.html#creating-a-sample-dataset",
    "title": "Binomial Test",
    "section": "Creating a sample dataset",
    "text": "Creating a sample dataset\n\nWe will generate a dataset where we record the outcomes of 1000 coin flips.\nWe will use the binom.test function to test if the proportion of heads is significantly different from 0.5.\n\n\nset.seed(19)\ncoin_flips &lt;- sample(c(\"H\", \"T\"), size = 1000, replace = T, prob = c(0.5, 0.5))\n\nNow, we will count the heads and tails and summarize the data.\n\n# heads\nheads_count &lt;- sum(coin_flips == \"H\")\nheads_count\n\n[1] 513\n\n# tails\ntails_count &lt;- sum(coin_flips == \"T\")\ntails_count\n\n[1] 487\n\n# total\ntotal_flips &lt;- length(coin_flips)\ntotal_flips\n\n[1] 1000"
  },
  {
    "objectID": "R/binomial_test.html#conducting-binomial-test",
    "href": "R/binomial_test.html#conducting-binomial-test",
    "title": "Binomial Test",
    "section": "Conducting Binomial Test",
    "text": "Conducting Binomial Test\n\nbinom_test_result &lt;- stats::binom.test(heads_count, total_flips, p = 0.5)\nbinom_test_result\n\n\n    Exact binomial test\n\ndata:  heads_count and total_flips\nnumber of successes = 513, number of trials = 1000, p-value = 0.4292\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.4815213 0.5444020\nsample estimates:\nprobability of success \n                 0.513 \n\n\n\nResults:\nThe output has a p-value 0.4292098 \\(&gt; 0.05\\) (chosen level of significance). Hence, we fail to reject the null hypothesis and conclude that the coin is fair."
  },
  {
    "objectID": "R/binomial_test.html#conduct-the-binomial-test",
    "href": "R/binomial_test.html#conduct-the-binomial-test",
    "title": "Binomial Test",
    "section": "Conduct the Binomial Test",
    "text": "Conduct the Binomial Test\nWe will conduct the Binomial test and hypothesize that the proportin of death should be 19%.\n\nbinom_test &lt;- stats::binom.test(num_deaths, total_pat, p = 0.19)\nbinom_test\n\n\n    Exact binomial test\n\ndata:  num_deaths and total_pat\nnumber of successes = 63, number of trials = 228, p-value = 0.001683\nalternative hypothesis: true probability of success is not equal to 0.19\n95 percent confidence interval:\n 0.2193322 0.3392187\nsample estimates:\nprobability of success \n             0.2763158"
  },
  {
    "objectID": "R/binomial_test.html#results-1",
    "href": "R/binomial_test.html#results-1",
    "title": "Binomial Test",
    "section": "Results:",
    "text": "Results:\nThe output has a p-value 0.0016829 \\(&lt; 0.05\\) (chosen level of significance). Hence, we reject the null hypothesis and conclude that the propotion of death is significantly different from 19%."
  },
  {
    "objectID": "R/sample_size_non-inferiority.html",
    "href": "R/sample_size_non-inferiority.html",
    "title": "Sample Size for Non-Inferiority Trials in R",
    "section": "",
    "text": "In R there are lots of packages for sample size calculations. Here we will cover one of the most common {rpact}\n\nlibrary(rpact)\n\n\nTwo Sample Non-inferiority test: Comparing means for parallel design (unpaired)\nThis example is a sample size calculation for the following hypotheses: \\(H_0:\\mu2-\\mu1\\le -\\theta\\) versus \\(H_1: \\mu2-\\mu1\\gt -\\theta\\).\nA client is interested in conducting a clinical trial to compare two cholesterol lowering agents for treatment of hypercholesterolemic patients through a parallel design. The primary efficacy parameter is a low-density lipidprotein cholesterol (LDL-C). We will consider the situation where the intended trial is for testing noninferiority. For establishing it, suppose the true mean difference is 0 and the noninferiority margin is chosen to be -0.05 (-5%). Assuming SD = 0.1, how many patients are required for an 80% power and an overall significance level of 5%?\n\nrpact::getDesignInverseNormal(kMax = 1, alpha = 0.05) |&gt;\n  rpact::getSampleSizeMeans(\n    thetaH0 = -0.05,\n    alternative = 0,\n    stDev = 0.1,\n    allocationRatioPlanned = 1\n  ) |&gt;\n  summary()\n\nSample size calculation for a continuous endpoint\nFixed sample analysis, one-sided significance level 5%, power 80%. The results were calculated for a two-sample t-test, H0: mu(1) - mu(2) = -0.05, H1: effect = 0, standard deviation = 0.1.\n\n\n\nStage\nFixed\n\n\n\n\nStage level (one-sided)\n0.0500\n\n\nEfficacy boundary (z-value scale)\n1.645\n\n\nEfficacy boundary (t)\n-0.017\n\n\nNumber of subjects\n100.3\n\n\n\nLegend:\n\n(t): treatment effect scale\n\n\n\nHere the recommended sample size is 100.3, so we will need to round up to 51 subjects per arm."
  },
  {
    "objectID": "R/anova.html",
    "href": "R/anova.html",
    "title": "ANOVA",
    "section": "",
    "text": "ANOVA (Analysis of Variance) is a statistical method used to compare the means of three or more groups to determine if at least one group mean is significantly different from the others. It helps to test hypotheses about group differences based on sample data.\nThe key assumptions include:\n\nIndependence of observations\nNormality of the data (the distribution should be approximately normal)\nHomogeneity of variances (similar variances across groups)\n\nCommon types include one-way ANOVA (one independent variable) and two-way ANOVA (two independent variables).\nOne-way ANOVA tests the effect of a single independent variable on a dependent variable (the grouping factor).\nTwo-way ANOVA tests the effect of two independent variables on a dependent variable and also examines if there is an interaction between the two independent variables.\n\n\nTo demonstrate the various types of sums of squares, we’ll create a data frame called df_disease taken from the SAS documentation. The corresponding data can be found here.\n\n\n\nFor this example, we’re testing for a significant difference in stem_length using ANOVA. Before getting the sums of squares and associated p-values from the ANOVA, we need to fit a linear model. In R, we’re using lm() to fit the model, and then using broom::glance() and broom::tidy() to view the results in a table format.\n\nlm_model &lt;- lm(y ~ drug + disease + drug * disease, df_disease)\n\nThe glance function gives us a summary of the model diagnostic values.\n\nlm_model |&gt;\n  glance()\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.456         0.326  10.5      3.51 0.00130    11  -212.  450.  477.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nThe tidy function gives a summary of the model results.\n\nlm_model |&gt;\n  tidy()\n\n# A tibble: 12 × 5\n   term           estimate std.error statistic      p.value\n   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1 (Intercept)      29.3        4.29    6.84   0.0000000160\n 2 drug2            -1.33       6.36   -0.210  0.835       \n 3 drug3           -13          7.43   -1.75   0.0869      \n 4 drug4           -15.7        6.36   -2.47   0.0172      \n 5 disease2         -1.08       6.78   -0.160  0.874       \n 6 disease3         -8.93       6.36   -1.40   0.167       \n 7 drug2:disease2    6.58       9.78    0.673  0.504       \n 8 drug3:disease2  -10.8       10.2    -1.06   0.295       \n 9 drug4:disease2    0.317      9.30    0.0340 0.973       \n10 drug2:disease3   -0.900      9.00   -0.100  0.921       \n11 drug3:disease3    1.10      10.2     0.107  0.915       \n12 drug4:disease3    9.53       9.20    1.04   0.306       \n\n\n\n\n\n\n\nType I sums of square, also known as sequential ANOVA, is a method of analysis of variance where model terms are assessed sequentially. In this approach, the contribution of each factor or variable to the model is evaluated in the order they are specified, with each factor being adjusted for the effects of those that precede it. This means that the significance of a factor can depend on the factors that have already been included in the model. Type I ANOVA is useful for hierarchical models, where the sequence of entering factors into the model is meaningful or based on theoretical considerations. While possible to use on unbalanced designs it is often not testing the hypothesis of interest.\nFor a model with two factors, A and B (in that order) the sums of squares will be tested like this: - SS(A) for factor A. - SS(B | A) for factor B. - SS(AB | B, A) for interaction AB.\nThis can be calculated using, the base R {stats} package or the {rstatix} package. Both give the same result.\n\n\n\nstats::anova(lm_model)\n\nAnalysis of Variance Table\n\nResponse: y\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ndrug          3 3133.2 1044.41  9.4558 5.58e-05 ***\ndisease       2  418.8  209.42  1.8960   0.1617    \ndrug:disease  6  707.3  117.88  1.0672   0.3958    \nResiduals    46 5080.8  110.45                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\ndf_disease |&gt;\n  rstatix::anova_test(\n    y ~ drug + disease + drug * disease,\n    type = 1,\n    detailed = TRUE\n  )\n\nWarning: NA detected in rows: 8,10,15,20,25,29,37,38,41,43,51,54,56,72.\nRemoving this rows before the analysis.\n\n\nANOVA Table (type I tests)\n\n        Effect DFn DFd      SSn      SSd     F        p p&lt;.05   ges\n1         drug   3  46 3133.239 5080.817 9.456 5.58e-05     * 0.381\n2      disease   2  46  418.834 5080.817 1.896 1.62e-01       0.076\n3 drug:disease   6  46  707.266 5080.817 1.067 3.96e-01       0.122\n\n\n\n\n\n\nType II sum of squares also known as hierarchical or partially sequential sums of squares. Tests the effect of adding a factor to the model after all other factors have been added. This means that the significance of a factor is assessed while controlling for the effects of all other factors in the model, but not for interactions. Type II ANOVA is particularly useful when there are no interactions in the model or when the focus is on main effects only. It is often used in unbalanced designs, where the number of observations varies across groups.\nFor a model with two factors, A and B (in that order) the sums of squares will be tested like this: - SS(A | B) for factor A. - SS(B | A) for factor B.\nThis can be calculated using the {car} package or the {rstatix} package. Both give the same result.\n\n\n\ncar::Anova(lm_model, type = \"II\")\n\nAnova Table (Type II tests)\n\nResponse: y\n             Sum Sq Df F value    Pr(&gt;F)    \ndrug         3063.4  3  9.2451 6.748e-05 ***\ndisease       418.8  2  1.8960    0.1617    \ndrug:disease  707.3  6  1.0672    0.3958    \nResiduals    5080.8 46                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\ndf_disease |&gt;\n  rstatix::anova_test(\n    y ~ drug + disease + drug * disease,\n    type = 2,\n    detailed = TRUE\n  )\n\nWarning: NA detected in rows: 8,10,15,20,25,29,37,38,41,43,51,54,56,72.\nRemoving this rows before the analysis.\n\n\nANOVA Table (type II tests)\n\n        Effect      SSn      SSd DFn DFd     F        p p&lt;.05   ges\n1         drug 3063.433 5080.817   3  46 9.245 6.75e-05     * 0.376\n2      disease  418.834 5080.817   2  46 1.896 1.62e-01       0.076\n3 drug:disease  707.266 5080.817   6  46 1.067 3.96e-01       0.122\n\n\n\n\n\n\nType III sum of squares is calculated such that every effect is adjusted for all other effect. This means testing for the presence of a main effect after adjusting for other main effects and interactions. For a model with two factors, A and B (in that order) the sums of squares will be tested like this: - SS(A | B, AB) for factor A. - SS(B | A, AB) for factor B.\nThis can be calculated using the base R {stats} package, the {car} package or the {rstatix} package. All give the same result.\nNote: Calculating type III sums of squares in R is a bit tricky, because the multi-way ANOVA model is over-paramerterised. So when running the linear model we need to select a design matrix that sums to zero. In R those options will be either \"contr.sum\" or \"contr.poly\"\n\n# Drug design matrix\ncontr.sum(4) # Using 4 here as we have 4 levels of drug\n\n  [,1] [,2] [,3]\n1    1    0    0\n2    0    1    0\n3    0    0    1\n4   -1   -1   -1\n\n# Disease design matrix\ncontr.sum(3)\n\n  [,1] [,2]\n1    1    0\n2    0    1\n3   -1   -1\n\n\nWhile not relevant for this example as the disease variable isn’t ordinal the polynomial design matrix would look like\n\ncontr.poly(3)\n\n                .L         .Q\n[1,] -7.071068e-01  0.4082483\n[2,] -9.073800e-17 -0.8164966\n[3,]  7.071068e-01  0.4082483\n\n\n\nlm_model &lt;- lm(\n  y ~ drug + disease + drug * disease,\n  df_disease,\n  contrasts = list(drug = \"contr.sum\", disease = \"contr.sum\")\n)\n\n\n\nUsing the base stats package, you can use the drop1() function which drops all possible single terms in a model. The scope term specifies how things can be dropped.\n\nstats::drop1(lm_model, scope = . ~ ., test = \"F\")\n\nSingle term deletions\n\nModel:\ny ~ drug + disease + drug * disease\n             Df Sum of Sq    RSS    AIC F value    Pr(&gt;F)    \n&lt;none&gt;                    5080.8 283.42                      \ndrug          3   2997.47 8078.3 304.32  9.0460 8.086e-05 ***\ndisease       2    415.87 5496.7 283.99  1.8826    0.1637    \ndrug:disease  6    707.27 5788.1 278.98  1.0672    0.3958    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\ncar::Anova(lm_model, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: y\n              Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)  20037.6  1 181.4138 &lt; 2.2e-16 ***\ndrug          2997.5  3   9.0460 8.086e-05 ***\ndisease        415.9  2   1.8826    0.1637    \ndrug:disease   707.3  6   1.0672    0.3958    \nResiduals     5080.8 46                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nThe rstatix package uses the car package to do the anova calculation, but can be nicer to use as it handles the contrasts for you and is more “pipe-able”.\n\ndf_disease |&gt;\n  rstatix::anova_test(\n    y ~ drug + disease + drug * disease,\n    type = 3,\n    detailed = TRUE\n  )\n\nWarning: NA detected in rows: 8,10,15,20,25,29,37,38,41,43,51,54,56,72.\nRemoving this rows before the analysis.\n\n\nANOVA Table (type III tests)\n\n        Effect       SSn      SSd DFn DFd       F        p p&lt;.05   ges\n1  (Intercept) 20037.613 5080.817   1  46 181.414 1.42e-17     * 0.798\n2         drug  2997.472 5080.817   3  46   9.046 8.09e-05     * 0.371\n3      disease   415.873 5080.817   2  46   1.883 1.64e-01       0.076\n4 drug:disease   707.266 5080.817   6  46   1.067 3.96e-01       0.122\n\n\n\n\n\n\nIn R there is no equivalent operation to the Type IV sums of squares calculation in SAS.\n\n\n\n\nThe easiest way to get contrasts in R is by using emmeans. For looking at contrast we are going to fit a different model on new data, that doesn’t include an interaction term as it is easier to calculate contrasts without an interaction term. For this dataset we have three different drugs A, C, and E.\n\ndf_trial &lt;- read.csv(\"../data/drug_trial.csv\")\n\nlm(formula = post ~ pre + drug, data = df_trial) |&gt;\n  emmeans(\"drug\") |&gt;\n  contrast(\n    method = list(\n      \"C vs A\" = c(-1, 1, 0),\n      \"E vs CA\" = c(-1, -1, 2)\n    )\n  )\n\n contrast estimate   SE df t.ratio p.value\n C vs A      0.109 1.80 26   0.061  0.9521\n E vs CA     6.783 3.28 26   2.067  0.0488"
  },
  {
    "objectID": "R/anova.html#introduction",
    "href": "R/anova.html#introduction",
    "title": "ANOVA",
    "section": "",
    "text": "ANOVA (Analysis of Variance) is a statistical method used to compare the means of three or more groups to determine if at least one group mean is significantly different from the others. It helps to test hypotheses about group differences based on sample data.\nThe key assumptions include:\n\nIndependence of observations\nNormality of the data (the distribution should be approximately normal)\nHomogeneity of variances (similar variances across groups)\n\nCommon types include one-way ANOVA (one independent variable) and two-way ANOVA (two independent variables).\nOne-way ANOVA tests the effect of a single independent variable on a dependent variable (the grouping factor).\nTwo-way ANOVA tests the effect of two independent variables on a dependent variable and also examines if there is an interaction between the two independent variables.\n\n\nTo demonstrate the various types of sums of squares, we’ll create a data frame called df_disease taken from the SAS documentation. The corresponding data can be found here.\n\n\n\nFor this example, we’re testing for a significant difference in stem_length using ANOVA. Before getting the sums of squares and associated p-values from the ANOVA, we need to fit a linear model. In R, we’re using lm() to fit the model, and then using broom::glance() and broom::tidy() to view the results in a table format.\n\nlm_model &lt;- lm(y ~ drug + disease + drug * disease, df_disease)\n\nThe glance function gives us a summary of the model diagnostic values.\n\nlm_model |&gt;\n  glance()\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.456         0.326  10.5      3.51 0.00130    11  -212.  450.  477.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nThe tidy function gives a summary of the model results.\n\nlm_model |&gt;\n  tidy()\n\n# A tibble: 12 × 5\n   term           estimate std.error statistic      p.value\n   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1 (Intercept)      29.3        4.29    6.84   0.0000000160\n 2 drug2            -1.33       6.36   -0.210  0.835       \n 3 drug3           -13          7.43   -1.75   0.0869      \n 4 drug4           -15.7        6.36   -2.47   0.0172      \n 5 disease2         -1.08       6.78   -0.160  0.874       \n 6 disease3         -8.93       6.36   -1.40   0.167       \n 7 drug2:disease2    6.58       9.78    0.673  0.504       \n 8 drug3:disease2  -10.8       10.2    -1.06   0.295       \n 9 drug4:disease2    0.317      9.30    0.0340 0.973       \n10 drug2:disease3   -0.900      9.00   -0.100  0.921       \n11 drug3:disease3    1.10      10.2     0.107  0.915       \n12 drug4:disease3    9.53       9.20    1.04   0.306       \n\n\n\n\n\n\n\nType I sums of square, also known as sequential ANOVA, is a method of analysis of variance where model terms are assessed sequentially. In this approach, the contribution of each factor or variable to the model is evaluated in the order they are specified, with each factor being adjusted for the effects of those that precede it. This means that the significance of a factor can depend on the factors that have already been included in the model. Type I ANOVA is useful for hierarchical models, where the sequence of entering factors into the model is meaningful or based on theoretical considerations. While possible to use on unbalanced designs it is often not testing the hypothesis of interest.\nFor a model with two factors, A and B (in that order) the sums of squares will be tested like this: - SS(A) for factor A. - SS(B | A) for factor B. - SS(AB | B, A) for interaction AB.\nThis can be calculated using, the base R {stats} package or the {rstatix} package. Both give the same result.\n\n\n\nstats::anova(lm_model)\n\nAnalysis of Variance Table\n\nResponse: y\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ndrug          3 3133.2 1044.41  9.4558 5.58e-05 ***\ndisease       2  418.8  209.42  1.8960   0.1617    \ndrug:disease  6  707.3  117.88  1.0672   0.3958    \nResiduals    46 5080.8  110.45                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\ndf_disease |&gt;\n  rstatix::anova_test(\n    y ~ drug + disease + drug * disease,\n    type = 1,\n    detailed = TRUE\n  )\n\nWarning: NA detected in rows: 8,10,15,20,25,29,37,38,41,43,51,54,56,72.\nRemoving this rows before the analysis.\n\n\nANOVA Table (type I tests)\n\n        Effect DFn DFd      SSn      SSd     F        p p&lt;.05   ges\n1         drug   3  46 3133.239 5080.817 9.456 5.58e-05     * 0.381\n2      disease   2  46  418.834 5080.817 1.896 1.62e-01       0.076\n3 drug:disease   6  46  707.266 5080.817 1.067 3.96e-01       0.122\n\n\n\n\n\n\nType II sum of squares also known as hierarchical or partially sequential sums of squares. Tests the effect of adding a factor to the model after all other factors have been added. This means that the significance of a factor is assessed while controlling for the effects of all other factors in the model, but not for interactions. Type II ANOVA is particularly useful when there are no interactions in the model or when the focus is on main effects only. It is often used in unbalanced designs, where the number of observations varies across groups.\nFor a model with two factors, A and B (in that order) the sums of squares will be tested like this: - SS(A | B) for factor A. - SS(B | A) for factor B.\nThis can be calculated using the {car} package or the {rstatix} package. Both give the same result.\n\n\n\ncar::Anova(lm_model, type = \"II\")\n\nAnova Table (Type II tests)\n\nResponse: y\n             Sum Sq Df F value    Pr(&gt;F)    \ndrug         3063.4  3  9.2451 6.748e-05 ***\ndisease       418.8  2  1.8960    0.1617    \ndrug:disease  707.3  6  1.0672    0.3958    \nResiduals    5080.8 46                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\ndf_disease |&gt;\n  rstatix::anova_test(\n    y ~ drug + disease + drug * disease,\n    type = 2,\n    detailed = TRUE\n  )\n\nWarning: NA detected in rows: 8,10,15,20,25,29,37,38,41,43,51,54,56,72.\nRemoving this rows before the analysis.\n\n\nANOVA Table (type II tests)\n\n        Effect      SSn      SSd DFn DFd     F        p p&lt;.05   ges\n1         drug 3063.433 5080.817   3  46 9.245 6.75e-05     * 0.376\n2      disease  418.834 5080.817   2  46 1.896 1.62e-01       0.076\n3 drug:disease  707.266 5080.817   6  46 1.067 3.96e-01       0.122\n\n\n\n\n\n\nType III sum of squares is calculated such that every effect is adjusted for all other effect. This means testing for the presence of a main effect after adjusting for other main effects and interactions. For a model with two factors, A and B (in that order) the sums of squares will be tested like this: - SS(A | B, AB) for factor A. - SS(B | A, AB) for factor B.\nThis can be calculated using the base R {stats} package, the {car} package or the {rstatix} package. All give the same result.\nNote: Calculating type III sums of squares in R is a bit tricky, because the multi-way ANOVA model is over-paramerterised. So when running the linear model we need to select a design matrix that sums to zero. In R those options will be either \"contr.sum\" or \"contr.poly\"\n\n# Drug design matrix\ncontr.sum(4) # Using 4 here as we have 4 levels of drug\n\n  [,1] [,2] [,3]\n1    1    0    0\n2    0    1    0\n3    0    0    1\n4   -1   -1   -1\n\n# Disease design matrix\ncontr.sum(3)\n\n  [,1] [,2]\n1    1    0\n2    0    1\n3   -1   -1\n\n\nWhile not relevant for this example as the disease variable isn’t ordinal the polynomial design matrix would look like\n\ncontr.poly(3)\n\n                .L         .Q\n[1,] -7.071068e-01  0.4082483\n[2,] -9.073800e-17 -0.8164966\n[3,]  7.071068e-01  0.4082483\n\n\n\nlm_model &lt;- lm(\n  y ~ drug + disease + drug * disease,\n  df_disease,\n  contrasts = list(drug = \"contr.sum\", disease = \"contr.sum\")\n)\n\n\n\nUsing the base stats package, you can use the drop1() function which drops all possible single terms in a model. The scope term specifies how things can be dropped.\n\nstats::drop1(lm_model, scope = . ~ ., test = \"F\")\n\nSingle term deletions\n\nModel:\ny ~ drug + disease + drug * disease\n             Df Sum of Sq    RSS    AIC F value    Pr(&gt;F)    \n&lt;none&gt;                    5080.8 283.42                      \ndrug          3   2997.47 8078.3 304.32  9.0460 8.086e-05 ***\ndisease       2    415.87 5496.7 283.99  1.8826    0.1637    \ndrug:disease  6    707.27 5788.1 278.98  1.0672    0.3958    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\ncar::Anova(lm_model, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: y\n              Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)  20037.6  1 181.4138 &lt; 2.2e-16 ***\ndrug          2997.5  3   9.0460 8.086e-05 ***\ndisease        415.9  2   1.8826    0.1637    \ndrug:disease   707.3  6   1.0672    0.3958    \nResiduals     5080.8 46                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nThe rstatix package uses the car package to do the anova calculation, but can be nicer to use as it handles the contrasts for you and is more “pipe-able”.\n\ndf_disease |&gt;\n  rstatix::anova_test(\n    y ~ drug + disease + drug * disease,\n    type = 3,\n    detailed = TRUE\n  )\n\nWarning: NA detected in rows: 8,10,15,20,25,29,37,38,41,43,51,54,56,72.\nRemoving this rows before the analysis.\n\n\nANOVA Table (type III tests)\n\n        Effect       SSn      SSd DFn DFd       F        p p&lt;.05   ges\n1  (Intercept) 20037.613 5080.817   1  46 181.414 1.42e-17     * 0.798\n2         drug  2997.472 5080.817   3  46   9.046 8.09e-05     * 0.371\n3      disease   415.873 5080.817   2  46   1.883 1.64e-01       0.076\n4 drug:disease   707.266 5080.817   6  46   1.067 3.96e-01       0.122\n\n\n\n\n\n\nIn R there is no equivalent operation to the Type IV sums of squares calculation in SAS.\n\n\n\n\nThe easiest way to get contrasts in R is by using emmeans. For looking at contrast we are going to fit a different model on new data, that doesn’t include an interaction term as it is easier to calculate contrasts without an interaction term. For this dataset we have three different drugs A, C, and E.\n\ndf_trial &lt;- read.csv(\"../data/drug_trial.csv\")\n\nlm(formula = post ~ pre + drug, data = df_trial) |&gt;\n  emmeans(\"drug\") |&gt;\n  contrast(\n    method = list(\n      \"C vs A\" = c(-1, 1, 0),\n      \"E vs CA\" = c(-1, -1, 2)\n    )\n  )\n\n contrast estimate   SE df t.ratio p.value\n C vs A      0.109 1.80 26   0.061  0.9521\n E vs CA     6.783 3.28 26   2.067  0.0488"
  },
  {
    "objectID": "R/anova.html#references",
    "href": "R/anova.html#references",
    "title": "ANOVA",
    "section": "References",
    "text": "References\nGöttingen University. (n.d.). Type II and III SS using the car package. Retrieved 19 August 2025, from https://md.psych.bio.uni-goettingen.de/mv/unit/lm_cat/lm_cat_unbal_ss_explained.html#type-ii-and-iii-ss-using-the-car-package"
  },
  {
    "objectID": "R/tobit regression.html",
    "href": "R/tobit regression.html",
    "title": "Tobit Regression",
    "section": "",
    "text": "# General\nlibrary(dplyr)\nlibrary(gt)\nlibrary(broom)\n\n# Methodology specific\nlibrary(emmeans)\nlibrary(censReg)\nlibrary(survival)\nlibrary(VGAM)\n\n\n\nCensoring occurs when data on the dependent variable is only partially known. For example, in virology, sample results could be below the lower limit of detection (eg, 100 copies/mL) and in such a case we only know that the sample result is &lt;100 copies/mL, but we don’t know the exact value.\nLet \\(y^{*}\\) be the the true underlying latent variable, and \\(y\\) the observed variable. We discuss here censoring on the left:\n\\[\ny =\n\\begin{cases}\ny^{*}, & y^{*} &gt; \\tau  \\\\\n\\tau, & y^{*} \\leq \\tau\n\\end{cases}       \n\\] We consider tobit regression with a censored normal distribution. The model equation is \\[\ny_{i}^{*} = X_{i}\\beta + \\epsilon_{i}\n\\] with \\(\\epsilon_{i} \\sim N(0,\\sigma^2)\\). But we only observe \\(y = max(\\tau, y^{*})\\). The tobit model uses maximum likelihood estimation (for details see for example Breen, 1996). It is important to note that \\(\\beta\\) estimates the effect of \\(x\\) on the latent variable \\(y^{*}\\), and not on the observed value \\(y\\).\n\n\n\nWe assume two equally sized groups (n=10 in each group). The data is censored on the left at a value of \\(\\tau=8.0\\). In group A 4/10 records are censored, and 1/10 in group B.\n\ndat_used = tribble(\n  ~ID, ~ARM, ~Y, ~CENS,\n  \"001\", \"A\", 8.0, 1, \n  \"002\", \"A\", 8.0, 1,\n  \"003\", \"A\", 8.0, 1,\n  \"004\", \"A\", 8.0, 1,\n  \"005\", \"A\", 8.9, 0,\n  \"006\", \"A\", 9.5, 0,\n  \"007\", \"A\", 9.9, 0,\n  \"008\", \"A\", 10.3, 0,\n  \"009\", \"A\", 11.0, 0,\n  \"010\", \"A\", 11.2, 0,\n  \"011\", \"B\", 8.0, 1, \n  \"012\", \"B\", 9.2, 0,\n  \"013\", \"B\", 9.9, 0,\n  \"014\", \"B\", 10.0, 0,\n  \"015\", \"B\", 10.6, 0,\n  \"016\", \"B\", 10.6, 0,\n  \"017\", \"B\", 11.3, 0,\n  \"018\", \"B\", 11.8, 0,\n  \"019\", \"B\", 12.9, 0,\n  \"020\", \"B\", 13.0, 0,\n)\n\ngt(dat_used)\n\n\n\n\n\n\n\nID\nARM\nY\nCENS\n\n\n\n\n001\nA\n8.0\n1\n\n\n002\nA\n8.0\n1\n\n\n003\nA\n8.0\n1\n\n\n004\nA\n8.0\n1\n\n\n005\nA\n8.9\n0\n\n\n006\nA\n9.5\n0\n\n\n007\nA\n9.9\n0\n\n\n008\nA\n10.3\n0\n\n\n009\nA\n11.0\n0\n\n\n010\nA\n11.2\n0\n\n\n011\nB\n8.0\n1\n\n\n012\nB\n9.2\n0\n\n\n013\nB\n9.9\n0\n\n\n014\nB\n10.0\n0\n\n\n015\nB\n10.6\n0\n\n\n016\nB\n10.6\n0\n\n\n017\nB\n11.3\n0\n\n\n018\nB\n11.8\n0\n\n\n019\nB\n12.9\n0\n\n\n020\nB\n13.0\n0\n\n\n\n\n\n\n\n\n\n\nThe analysis will be based on a Tobit analysis of variance with \\(Y\\), rounded to 1 decimal places, as dependent variable and study group as a fixed covariate. A normally distributed error term will be used. Values will be left censored at the value 8.0.\nSeveral R functions and packages are presented.\n\n\nThe censReg function from the censReg package performs tobit models for left and right censored. The model is estimated by Maximum Likelihood (ML) assuming a Gaussian (normal) distribution of the error term. The maximization of the likelihood function is done by function maxLik of the maxLik package. The optimization method can be changed.\n\nres_censreg = censReg::censReg(Y ~ ARM, left = 8.0, data = dat_used)\nsummary(res_censreg)\n\n\nCall:\ncensReg::censReg(formula = Y ~ ARM, left = 8, data = dat_used)\n\nObservations:\n         Total  Left-censored     Uncensored Right-censored \n            20              5             15              0 \n\nCoefficients:\n            Estimate Std. error t value Pr(&gt; t)    \n(Intercept)   8.8323     0.5918  14.925 &lt; 2e-16 ***\nARMB          1.8225     0.8061   2.261 0.02376 *  \nlogSigma      0.5491     0.1947   2.819 0.00481 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNewton-Raphson maximisation, 4 iterations\nReturn code 1: gradient close to zero (gradtol)\nLog-likelihood: -34.3154 on 3 Df\n\n# Difference between groups (Wald CIs)\nround(res_censreg$estimate[2], 3)\n\n ARMB \n1.823 \n\nround(stats::confint(res_censreg, level = 0.95)[2, ], 3)\n\n 2.5 % 97.5 % \n 0.243  3.402 \n\n\nThe output provides an estimate of difference between groups A and B (B-A), namely 1.8225 (se=0.8061). The presented p-value is a two-sided p-value based on the Z-test. The output also provides an estimate for \\(log(\\sigma) = 0.5491\\). Wald based confidence intervals can be obtained by the stats::confint function.\n\n\n\nUsing the survreg function from the survival package a tobit model can be fit. For more information, refer to the survival package.\n\nres_survreg = survival::survreg(\n  survival::Surv(Y, 1 - CENS, type = \"left\") ~ ARM,\n  dist = \"gaussian\",\n  data = dat_used\n)\nsummary(res_survreg)\n\n\nCall:\nsurvival::survreg(formula = survival::Surv(Y, 1 - CENS, type = \"left\") ~ \n    ARM, data = dat_used, dist = \"gaussian\")\n            Value Std. Error     z      p\n(Intercept) 8.832      0.592 14.92 &lt;2e-16\nARMB        1.823      0.806  2.26 0.0238\nLog(scale)  0.549      0.195  2.82 0.0048\n\nScale= 1.73 \n\nGaussian distribution\nLoglik(model)= -34.3   Loglik(intercept only)= -36.7\n    Chisq= 4.72 on 1 degrees of freedom, p= 0.03 \nNumber of Newton-Raphson Iterations: 4 \nn= 20 \n\n# Least square means by group\nlsm = emmeans::emmeans(res_survreg, specs = trt.vs.ctrl ~ ARM)\nlsm$emmeans\n\n ARM emmean    SE df lower.CL upper.CL\n A     8.83 0.592 17     7.58     10.1\n B    10.65 0.552 17     9.49     11.8\n\nResults are given on the ::.survival.Surv (not the response) scale. \nConfidence level used: 0.95 \n\n# Difference between groups\nlsm_contrast = broom::tidy(lsm$contrasts, conf.int = TRUE, conf.level = 0.95)\nlsm_contrast |&gt;\n  gt() |&gt;\n  fmt_number(decimals = 3)\n\n\n\n\n\n\n\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nconf.low\nconf.high\nstatistic\np.value\n\n\n\n\nARM\nB - A\n0.000\n1.823\n0.806\n17.000\n0.122\n3.523\n2.261\n0.037\n\n\n\n\n\n\n# Wald-based CIs\nround(stats::confint(res_survreg, level = 0.95)[2, ], 3)\n\n 2.5 % 97.5 % \n 0.243  3.402 \n\n\nThe output provides an estimate of difference between groups A and B (B-A), namely 1.823 (se=0.806). The presented p-value is a two-sided p-value based on the Z-test. The output also provides an estimate for \\(log(\\sigma) = 0.549\\). Using the emmeans package/function least square means and contrast can be easily obtained. The confidence intervals and p-value is based on the t-test using emmeans. Wald based confidence intervals can be obtained by the stats::confint function.\n\n\n\nThe VGAM package provides functions for fitting vector generalized linear and additive models (VGLMs and VGAMs). This package centers on the iteratively reweighted least squares (IRLS) algorithm. The vglm function offers the possibility to fit a tobit model.\n\nres_vglm = VGAM::vglm(Y ~ ARM, tobit(Lower = 8.0), data = dat_used)\nsummary(res_vglm)\n\nCall:\nVGAM::vglm(formula = Y ~ ARM, family = tobit(Lower = 8), data = dat_used)\n\nCoefficients: \n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept):1   8.8323     0.5727  15.422  &lt; 2e-16 ***\n(Intercept):2   0.5491     0.1807   3.039  0.00238 ** \nARMB            1.8226     0.7942   2.295  0.02173 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNames of linear predictors: mu, loglink(sd)\n\nLog-likelihood: -34.3154 on 37 degrees of freedom\n\nNumber of Fisher scoring iterations: 7 \n\nNo Hauck-Donner effect found in any of the estimates\n\n# Difference between groups\nround(res_vglm@coefficients[3], 3)\n\n ARMB \n1.823 \n\nround(VGAM::confintvglm(res_vglm, level = 0.95)[3, ], 3)\n\n 2.5 % 97.5 % \n 0.266  3.379 \n\n\nThe output provides an estimate of difference between groups A and B (B-A), namely 1.823 (se=0.794). The presented p-value is a two-sided p-value based on the Z-test. Note that point estimate for the difference (and associated SE) are slightly different from the results obtained by censReg and tobit due to the difference in estimation procedure used. Wald based confidence intervals can be obtained by the confintvglm function. The \\((Intercept):2\\) in the model output is an estimate for \\(log(\\sigma)\\).\n\n\n\n\nThe results from the censReg::censReg and survival::survreg are similar. The survival::survreg allows for easy incorporation with the emmeans package (note: be aware that the standard approach with emmeans is based on the t-test and not the Z-test).\nThe VGAM::vglm approach provides slightly different results. This difference comes from the fact that a iteratively reweighted least squares (IRLS) algorithm is used for estimation.\n\n\n\nBreen, R. (1996). Regression models. SAGE Publications, Inc., https://doi.org/10.4135/9781412985611\nTobin, James (1958). “Estimation of Relationships for Limited Dependent Variables”. Econometrica. 26 (1): 24-36. doi:10.2307/1907382\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package      * version  date (UTC) lib source\n P backports      1.5.0    2024-05-23 [?] CRAN (R 4.4.0)\n P bdsmatrix      1.3-7    2024-03-02 [?] CRAN (R 4.4.0)\n P BiocManager    1.30.25  2024-08-28 [?] CRAN (R 4.4.1)\n P broom        * 1.0.7    2024-09-26 [?] CRAN (R 4.4.1)\n P censReg      * 0.5-38   2024-05-20 [?] CRAN (R 4.4.0)\n P cli            3.6.3    2024-06-21 [?] CRAN (R 4.4.0)\n P coda           0.19-4.1 2024-01-31 [?] CRAN (R 4.4.0)\n   codetools      0.2-20   2024-03-31 [2] CRAN (R 4.4.2)\n P collapse       2.0.18   2024-11-23 [?] CRAN (R 4.4.1)\n P digest         0.6.37   2024-08-19 [?] CRAN (R 4.4.1)\n P dplyr        * 1.1.4    2023-11-17 [?] CRAN (R 4.4.0)\n P emmeans      * 1.10.4   2024-08-21 [?] CRAN (R 4.4.1)\n P estimability   1.5.1    2024-05-12 [?] CRAN (R 4.4.0)\n P evaluate       1.0.0    2024-09-17 [?] CRAN (R 4.4.1)\n P fansi          1.0.6    2023-12-08 [?] CRAN (R 4.4.0)\n P fastmap        1.2.0    2024-05-15 [?] CRAN (R 4.4.0)\n P Formula        1.2-5    2023-02-24 [?] CRAN (R 4.4.0)\n P generics       0.1.3    2022-07-05 [?] CRAN (R 4.4.0)\n P glmmML         1.1.7    2024-09-20 [?] CRAN (R 4.4.1)\n P glue           1.8.0    2024-09-30 [?] CRAN (R 4.4.1)\n P gt           * 0.11.1   2024-10-04 [?] CRAN (R 4.4.1)\n P htmltools      0.5.8.1  2024-04-04 [?] CRAN (R 4.4.0)\n P htmlwidgets    1.6.4    2023-12-06 [?] CRAN (R 4.4.0)\n P jsonlite       1.8.9    2024-09-20 [?] CRAN (R 4.4.1)\n   knitr          1.50     2025-03-16 [1] RSPM (R 4.4.0)\n   lattice        0.22-6   2024-03-20 [2] CRAN (R 4.4.2)\n P lifecycle      1.0.4    2023-11-07 [?] CRAN (R 4.4.0)\n P lmtest         0.9-40   2022-03-21 [?] CRAN (R 4.4.0)\n P magrittr       2.0.3    2022-03-30 [?] CRAN (R 4.4.0)\n   MASS           7.3-61   2024-06-13 [2] CRAN (R 4.4.2)\n   Matrix         1.7-1    2024-10-18 [2] CRAN (R 4.4.2)\n P maxLik       * 1.5-2.1  2024-03-24 [?] CRAN (R 4.4.0)\n P miscTools    * 0.6-28   2023-05-03 [?] CRAN (R 4.4.0)\n P multcomp       1.4-26   2024-07-18 [?] CRAN (R 4.4.0)\n P mvtnorm        1.3-1    2024-09-03 [?] CRAN (R 4.4.1)\n   nlme           3.1-166  2024-08-14 [2] CRAN (R 4.4.2)\n P pillar         1.9.0    2023-03-22 [?] CRAN (R 4.4.0)\n P pkgconfig      2.0.3    2019-09-22 [?] CRAN (R 4.4.0)\n P plm            2.6-4    2024-04-01 [?] CRAN (R 4.4.0)\n P purrr          1.0.2    2023-08-10 [?] CRAN (R 4.4.0)\n P R6             2.5.1    2021-08-19 [?] CRAN (R 4.4.0)\n P rbibutils      2.3      2024-10-04 [?] CRAN (R 4.4.1)\n P Rcpp           1.0.13   2024-07-17 [?] CRAN (R 4.4.0)\n P Rdpack         2.6.1    2024-08-06 [?] CRAN (R 4.4.0)\n   renv           1.0.10   2024-10-05 [1] CRAN (R 4.4.1)\n P rlang          1.1.4    2024-06-04 [?] CRAN (R 4.4.0)\n P rmarkdown      2.28     2024-08-17 [?] CRAN (R 4.4.0)\n P rstudioapi     0.16.0   2024-03-24 [?] CRAN (R 4.4.0)\n P sandwich       3.1-1    2024-09-15 [?] CRAN (R 4.4.1)\n P sass           0.4.9    2024-03-15 [?] CRAN (R 4.4.0)\n P sessioninfo    1.2.2    2021-12-06 [?] CRAN (R 4.4.0)\n P survival     * 3.7-0    2024-06-05 [?] CRAN (R 4.4.0)\n P TH.data        1.1-2    2023-04-17 [?] CRAN (R 4.4.0)\n P tibble         3.2.1    2023-03-20 [?] CRAN (R 4.4.0)\n P tidyr          1.3.1    2024-01-24 [?] CRAN (R 4.4.0)\n P tidyselect     1.2.1    2024-03-11 [?] CRAN (R 4.4.0)\n P utf8           1.2.4    2023-10-22 [?] CRAN (R 4.4.0)\n P vctrs          0.6.5    2023-12-01 [?] CRAN (R 4.4.0)\n P VGAM         * 1.1-12   2024-09-18 [?] CRAN (R 4.4.1)\n P withr          3.0.1    2024-07-31 [?] CRAN (R 4.4.0)\n   xfun           0.52     2025-04-02 [1] RSPM (R 4.4.0)\n P xml2           1.3.6    2023-12-04 [?] CRAN (R 4.4.0)\n P xtable         1.8-4    2019-04-21 [?] CRAN (R 4.4.0)\n P yaml           2.3.10   2024-07-26 [?] CRAN (R 4.4.0)\n P zoo            1.8-12   2023-04-13 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/tobit regression.html#tobit-model",
    "href": "R/tobit regression.html#tobit-model",
    "title": "Tobit Regression",
    "section": "",
    "text": "Censoring occurs when data on the dependent variable is only partially known. For example, in virology, sample results could be below the lower limit of detection (eg, 100 copies/mL) and in such a case we only know that the sample result is &lt;100 copies/mL, but we don’t know the exact value.\nLet \\(y^{*}\\) be the the true underlying latent variable, and \\(y\\) the observed variable. We discuss here censoring on the left:\n\\[\ny =\n\\begin{cases}\ny^{*}, & y^{*} &gt; \\tau  \\\\\n\\tau, & y^{*} \\leq \\tau\n\\end{cases}       \n\\] We consider tobit regression with a censored normal distribution. The model equation is \\[\ny_{i}^{*} = X_{i}\\beta + \\epsilon_{i}\n\\] with \\(\\epsilon_{i} \\sim N(0,\\sigma^2)\\). But we only observe \\(y = max(\\tau, y^{*})\\). The tobit model uses maximum likelihood estimation (for details see for example Breen, 1996). It is important to note that \\(\\beta\\) estimates the effect of \\(x\\) on the latent variable \\(y^{*}\\), and not on the observed value \\(y\\)."
  },
  {
    "objectID": "R/tobit regression.html#data-used",
    "href": "R/tobit regression.html#data-used",
    "title": "Tobit Regression",
    "section": "",
    "text": "We assume two equally sized groups (n=10 in each group). The data is censored on the left at a value of \\(\\tau=8.0\\). In group A 4/10 records are censored, and 1/10 in group B.\n\ndat_used = tribble(\n  ~ID, ~ARM, ~Y, ~CENS,\n  \"001\", \"A\", 8.0, 1, \n  \"002\", \"A\", 8.0, 1,\n  \"003\", \"A\", 8.0, 1,\n  \"004\", \"A\", 8.0, 1,\n  \"005\", \"A\", 8.9, 0,\n  \"006\", \"A\", 9.5, 0,\n  \"007\", \"A\", 9.9, 0,\n  \"008\", \"A\", 10.3, 0,\n  \"009\", \"A\", 11.0, 0,\n  \"010\", \"A\", 11.2, 0,\n  \"011\", \"B\", 8.0, 1, \n  \"012\", \"B\", 9.2, 0,\n  \"013\", \"B\", 9.9, 0,\n  \"014\", \"B\", 10.0, 0,\n  \"015\", \"B\", 10.6, 0,\n  \"016\", \"B\", 10.6, 0,\n  \"017\", \"B\", 11.3, 0,\n  \"018\", \"B\", 11.8, 0,\n  \"019\", \"B\", 12.9, 0,\n  \"020\", \"B\", 13.0, 0,\n)\n\ngt(dat_used)\n\n\n\n\n\n\n\nID\nARM\nY\nCENS\n\n\n\n\n001\nA\n8.0\n1\n\n\n002\nA\n8.0\n1\n\n\n003\nA\n8.0\n1\n\n\n004\nA\n8.0\n1\n\n\n005\nA\n8.9\n0\n\n\n006\nA\n9.5\n0\n\n\n007\nA\n9.9\n0\n\n\n008\nA\n10.3\n0\n\n\n009\nA\n11.0\n0\n\n\n010\nA\n11.2\n0\n\n\n011\nB\n8.0\n1\n\n\n012\nB\n9.2\n0\n\n\n013\nB\n9.9\n0\n\n\n014\nB\n10.0\n0\n\n\n015\nB\n10.6\n0\n\n\n016\nB\n10.6\n0\n\n\n017\nB\n11.3\n0\n\n\n018\nB\n11.8\n0\n\n\n019\nB\n12.9\n0\n\n\n020\nB\n13.0\n0"
  },
  {
    "objectID": "R/tobit regression.html#example-code-using-r",
    "href": "R/tobit regression.html#example-code-using-r",
    "title": "Tobit Regression",
    "section": "",
    "text": "The analysis will be based on a Tobit analysis of variance with \\(Y\\), rounded to 1 decimal places, as dependent variable and study group as a fixed covariate. A normally distributed error term will be used. Values will be left censored at the value 8.0.\nSeveral R functions and packages are presented.\n\n\nThe censReg function from the censReg package performs tobit models for left and right censored. The model is estimated by Maximum Likelihood (ML) assuming a Gaussian (normal) distribution of the error term. The maximization of the likelihood function is done by function maxLik of the maxLik package. The optimization method can be changed.\n\nres_censreg = censReg::censReg(Y ~ ARM, left = 8.0, data = dat_used)\nsummary(res_censreg)\n\n\nCall:\ncensReg::censReg(formula = Y ~ ARM, left = 8, data = dat_used)\n\nObservations:\n         Total  Left-censored     Uncensored Right-censored \n            20              5             15              0 \n\nCoefficients:\n            Estimate Std. error t value Pr(&gt; t)    \n(Intercept)   8.8323     0.5918  14.925 &lt; 2e-16 ***\nARMB          1.8225     0.8061   2.261 0.02376 *  \nlogSigma      0.5491     0.1947   2.819 0.00481 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNewton-Raphson maximisation, 4 iterations\nReturn code 1: gradient close to zero (gradtol)\nLog-likelihood: -34.3154 on 3 Df\n\n# Difference between groups (Wald CIs)\nround(res_censreg$estimate[2], 3)\n\n ARMB \n1.823 \n\nround(stats::confint(res_censreg, level = 0.95)[2, ], 3)\n\n 2.5 % 97.5 % \n 0.243  3.402 \n\n\nThe output provides an estimate of difference between groups A and B (B-A), namely 1.8225 (se=0.8061). The presented p-value is a two-sided p-value based on the Z-test. The output also provides an estimate for \\(log(\\sigma) = 0.5491\\). Wald based confidence intervals can be obtained by the stats::confint function.\n\n\n\nUsing the survreg function from the survival package a tobit model can be fit. For more information, refer to the survival package.\n\nres_survreg = survival::survreg(\n  survival::Surv(Y, 1 - CENS, type = \"left\") ~ ARM,\n  dist = \"gaussian\",\n  data = dat_used\n)\nsummary(res_survreg)\n\n\nCall:\nsurvival::survreg(formula = survival::Surv(Y, 1 - CENS, type = \"left\") ~ \n    ARM, data = dat_used, dist = \"gaussian\")\n            Value Std. Error     z      p\n(Intercept) 8.832      0.592 14.92 &lt;2e-16\nARMB        1.823      0.806  2.26 0.0238\nLog(scale)  0.549      0.195  2.82 0.0048\n\nScale= 1.73 \n\nGaussian distribution\nLoglik(model)= -34.3   Loglik(intercept only)= -36.7\n    Chisq= 4.72 on 1 degrees of freedom, p= 0.03 \nNumber of Newton-Raphson Iterations: 4 \nn= 20 \n\n# Least square means by group\nlsm = emmeans::emmeans(res_survreg, specs = trt.vs.ctrl ~ ARM)\nlsm$emmeans\n\n ARM emmean    SE df lower.CL upper.CL\n A     8.83 0.592 17     7.58     10.1\n B    10.65 0.552 17     9.49     11.8\n\nResults are given on the ::.survival.Surv (not the response) scale. \nConfidence level used: 0.95 \n\n# Difference between groups\nlsm_contrast = broom::tidy(lsm$contrasts, conf.int = TRUE, conf.level = 0.95)\nlsm_contrast |&gt;\n  gt() |&gt;\n  fmt_number(decimals = 3)\n\n\n\n\n\n\n\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nconf.low\nconf.high\nstatistic\np.value\n\n\n\n\nARM\nB - A\n0.000\n1.823\n0.806\n17.000\n0.122\n3.523\n2.261\n0.037\n\n\n\n\n\n\n# Wald-based CIs\nround(stats::confint(res_survreg, level = 0.95)[2, ], 3)\n\n 2.5 % 97.5 % \n 0.243  3.402 \n\n\nThe output provides an estimate of difference between groups A and B (B-A), namely 1.823 (se=0.806). The presented p-value is a two-sided p-value based on the Z-test. The output also provides an estimate for \\(log(\\sigma) = 0.549\\). Using the emmeans package/function least square means and contrast can be easily obtained. The confidence intervals and p-value is based on the t-test using emmeans. Wald based confidence intervals can be obtained by the stats::confint function.\n\n\n\nThe VGAM package provides functions for fitting vector generalized linear and additive models (VGLMs and VGAMs). This package centers on the iteratively reweighted least squares (IRLS) algorithm. The vglm function offers the possibility to fit a tobit model.\n\nres_vglm = VGAM::vglm(Y ~ ARM, tobit(Lower = 8.0), data = dat_used)\nsummary(res_vglm)\n\nCall:\nVGAM::vglm(formula = Y ~ ARM, family = tobit(Lower = 8), data = dat_used)\n\nCoefficients: \n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept):1   8.8323     0.5727  15.422  &lt; 2e-16 ***\n(Intercept):2   0.5491     0.1807   3.039  0.00238 ** \nARMB            1.8226     0.7942   2.295  0.02173 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNames of linear predictors: mu, loglink(sd)\n\nLog-likelihood: -34.3154 on 37 degrees of freedom\n\nNumber of Fisher scoring iterations: 7 \n\nNo Hauck-Donner effect found in any of the estimates\n\n# Difference between groups\nround(res_vglm@coefficients[3], 3)\n\n ARMB \n1.823 \n\nround(VGAM::confintvglm(res_vglm, level = 0.95)[3, ], 3)\n\n 2.5 % 97.5 % \n 0.266  3.379 \n\n\nThe output provides an estimate of difference between groups A and B (B-A), namely 1.823 (se=0.794). The presented p-value is a two-sided p-value based on the Z-test. Note that point estimate for the difference (and associated SE) are slightly different from the results obtained by censReg and tobit due to the difference in estimation procedure used. Wald based confidence intervals can be obtained by the confintvglm function. The \\((Intercept):2\\) in the model output is an estimate for \\(log(\\sigma)\\)."
  },
  {
    "objectID": "R/tobit regression.html#discussion",
    "href": "R/tobit regression.html#discussion",
    "title": "Tobit Regression",
    "section": "",
    "text": "The results from the censReg::censReg and survival::survreg are similar. The survival::survreg allows for easy incorporation with the emmeans package (note: be aware that the standard approach with emmeans is based on the t-test and not the Z-test).\nThe VGAM::vglm approach provides slightly different results. This difference comes from the fact that a iteratively reweighted least squares (IRLS) algorithm is used for estimation."
  },
  {
    "objectID": "R/tobit regression.html#reference",
    "href": "R/tobit regression.html#reference",
    "title": "Tobit Regression",
    "section": "",
    "text": "Breen, R. (1996). Regression models. SAGE Publications, Inc., https://doi.org/10.4135/9781412985611\nTobin, James (1958). “Estimation of Relationships for Limited Dependent Variables”. Econometrica. 26 (1): 24-36. doi:10.2307/1907382\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package      * version  date (UTC) lib source\n P backports      1.5.0    2024-05-23 [?] CRAN (R 4.4.0)\n P bdsmatrix      1.3-7    2024-03-02 [?] CRAN (R 4.4.0)\n P BiocManager    1.30.25  2024-08-28 [?] CRAN (R 4.4.1)\n P broom        * 1.0.7    2024-09-26 [?] CRAN (R 4.4.1)\n P censReg      * 0.5-38   2024-05-20 [?] CRAN (R 4.4.0)\n P cli            3.6.3    2024-06-21 [?] CRAN (R 4.4.0)\n P coda           0.19-4.1 2024-01-31 [?] CRAN (R 4.4.0)\n   codetools      0.2-20   2024-03-31 [2] CRAN (R 4.4.2)\n P collapse       2.0.18   2024-11-23 [?] CRAN (R 4.4.1)\n P digest         0.6.37   2024-08-19 [?] CRAN (R 4.4.1)\n P dplyr        * 1.1.4    2023-11-17 [?] CRAN (R 4.4.0)\n P emmeans      * 1.10.4   2024-08-21 [?] CRAN (R 4.4.1)\n P estimability   1.5.1    2024-05-12 [?] CRAN (R 4.4.0)\n P evaluate       1.0.0    2024-09-17 [?] CRAN (R 4.4.1)\n P fansi          1.0.6    2023-12-08 [?] CRAN (R 4.4.0)\n P fastmap        1.2.0    2024-05-15 [?] CRAN (R 4.4.0)\n P Formula        1.2-5    2023-02-24 [?] CRAN (R 4.4.0)\n P generics       0.1.3    2022-07-05 [?] CRAN (R 4.4.0)\n P glmmML         1.1.7    2024-09-20 [?] CRAN (R 4.4.1)\n P glue           1.8.0    2024-09-30 [?] CRAN (R 4.4.1)\n P gt           * 0.11.1   2024-10-04 [?] CRAN (R 4.4.1)\n P htmltools      0.5.8.1  2024-04-04 [?] CRAN (R 4.4.0)\n P htmlwidgets    1.6.4    2023-12-06 [?] CRAN (R 4.4.0)\n P jsonlite       1.8.9    2024-09-20 [?] CRAN (R 4.4.1)\n   knitr          1.50     2025-03-16 [1] RSPM (R 4.4.0)\n   lattice        0.22-6   2024-03-20 [2] CRAN (R 4.4.2)\n P lifecycle      1.0.4    2023-11-07 [?] CRAN (R 4.4.0)\n P lmtest         0.9-40   2022-03-21 [?] CRAN (R 4.4.0)\n P magrittr       2.0.3    2022-03-30 [?] CRAN (R 4.4.0)\n   MASS           7.3-61   2024-06-13 [2] CRAN (R 4.4.2)\n   Matrix         1.7-1    2024-10-18 [2] CRAN (R 4.4.2)\n P maxLik       * 1.5-2.1  2024-03-24 [?] CRAN (R 4.4.0)\n P miscTools    * 0.6-28   2023-05-03 [?] CRAN (R 4.4.0)\n P multcomp       1.4-26   2024-07-18 [?] CRAN (R 4.4.0)\n P mvtnorm        1.3-1    2024-09-03 [?] CRAN (R 4.4.1)\n   nlme           3.1-166  2024-08-14 [2] CRAN (R 4.4.2)\n P pillar         1.9.0    2023-03-22 [?] CRAN (R 4.4.0)\n P pkgconfig      2.0.3    2019-09-22 [?] CRAN (R 4.4.0)\n P plm            2.6-4    2024-04-01 [?] CRAN (R 4.4.0)\n P purrr          1.0.2    2023-08-10 [?] CRAN (R 4.4.0)\n P R6             2.5.1    2021-08-19 [?] CRAN (R 4.4.0)\n P rbibutils      2.3      2024-10-04 [?] CRAN (R 4.4.1)\n P Rcpp           1.0.13   2024-07-17 [?] CRAN (R 4.4.0)\n P Rdpack         2.6.1    2024-08-06 [?] CRAN (R 4.4.0)\n   renv           1.0.10   2024-10-05 [1] CRAN (R 4.4.1)\n P rlang          1.1.4    2024-06-04 [?] CRAN (R 4.4.0)\n P rmarkdown      2.28     2024-08-17 [?] CRAN (R 4.4.0)\n P rstudioapi     0.16.0   2024-03-24 [?] CRAN (R 4.4.0)\n P sandwich       3.1-1    2024-09-15 [?] CRAN (R 4.4.1)\n P sass           0.4.9    2024-03-15 [?] CRAN (R 4.4.0)\n P sessioninfo    1.2.2    2021-12-06 [?] CRAN (R 4.4.0)\n P survival     * 3.7-0    2024-06-05 [?] CRAN (R 4.4.0)\n P TH.data        1.1-2    2023-04-17 [?] CRAN (R 4.4.0)\n P tibble         3.2.1    2023-03-20 [?] CRAN (R 4.4.0)\n P tidyr          1.3.1    2024-01-24 [?] CRAN (R 4.4.0)\n P tidyselect     1.2.1    2024-03-11 [?] CRAN (R 4.4.0)\n P utf8           1.2.4    2023-10-22 [?] CRAN (R 4.4.0)\n P vctrs          0.6.5    2023-12-01 [?] CRAN (R 4.4.0)\n P VGAM         * 1.1-12   2024-09-18 [?] CRAN (R 4.4.1)\n P withr          3.0.1    2024-07-31 [?] CRAN (R 4.4.0)\n   xfun           0.52     2025-04-02 [1] RSPM (R 4.4.0)\n P xml2           1.3.6    2023-12-04 [?] CRAN (R 4.4.0)\n P xtable         1.8-4    2019-04-21 [?] CRAN (R 4.4.0)\n P yaml           2.3.10   2024-07-26 [?] CRAN (R 4.4.0)\n P zoo            1.8-12   2023-04-13 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/marginal_homogeneity_tests.html",
    "href": "R/marginal_homogeneity_tests.html",
    "title": "Marginal Homogeneity Tests",
    "section": "",
    "text": "This page is solely based on coin package documentation including data samples which are generated inline.\ncoin::mh_test() provides the McNemar test, the Cochran Q test, the Stuart(-Maxwell) test and the Madansky test of interchangeability. A general description of these methods is given by Agresti (2002).\nThe null hypothesis of marginal homogeneity is tested. If formula interface is used, the response variable and the measurement conditions are given by y and x, respectively, and block is a factor where each level corresponds to exactly one subject with repeated measurements: coin::mh_test(y ~ x | block, data, subset = NULL, ...). We can also directly pass an object of class \"table\".\ncoin::mh_test() computes different tests depending on x and y:\nThe conditional null distribution of the test statistic is used to obtain p-values and an asymptotic approximation of the exact distribution is used by default (distribution = \"asymptotic\"). Alternatively, the distribution can be approximated via Monte Carlo resampling or computed exactly for univariate two-sample problems (McNemar test) by setting distribution to \"approximate\" or \"exact\", respectively."
  },
  {
    "objectID": "R/marginal_homogeneity_tests.html#mcnemar-test",
    "href": "R/marginal_homogeneity_tests.html#mcnemar-test",
    "title": "Marginal Homogeneity Tests",
    "section": "McNemar test",
    "text": "McNemar test\nFor more information on the McNemar see the McNemar’s test page."
  },
  {
    "objectID": "R/marginal_homogeneity_tests.html#cochran-q-test",
    "href": "R/marginal_homogeneity_tests.html#cochran-q-test",
    "title": "Marginal Homogeneity Tests",
    "section": "Cochran Q test",
    "text": "Cochran Q test\n\n## Effectiveness of different media for the growth of diphtheria\n## Cochran (1950, Tab. 2)\ncases &lt;- c(4, 2, 3, 1, 59)\nn &lt;- sum(cases)\ncochran &lt;- data.frame(\n  diphtheria = factor(\n    unlist(rep(\n      list(\n        c(1, 1, 1, 1),\n        c(1, 1, 0, 1),\n        c(0, 1, 1, 1),\n        c(0, 1, 0, 1),\n        c(0, 0, 0, 0)\n      ),\n      cases\n    ))\n  ),\n  media = factor(rep(LETTERS[1:4], n)),\n  case = factor(rep(seq_len(n), each = 4))\n)\n\nhead(cochran)\n\n  diphtheria media case\n1          1     A    1\n2          1     B    1\n3          1     C    1\n4          1     D    1\n5          1     A    2\n6          1     B    2\n\n## Asymptotic Cochran Q test (Cochran, 1950, p. 260)\ncoin::mh_test(\n  diphtheria ~ media | case,\n  data = cochran\n)\n\n\n    Asymptotic Marginal Homogeneity Test\n\ndata:  diphtheria by media (A, B, C, D) \n     stratified by case\nchi-squared = 8.0526, df = 3, p-value = 0.04494\n\n## Approximative Cochran Q test\nmt &lt;- coin::mh_test(\n  diphtheria ~ media | case,\n  data = cochran,\n  distribution = coin::approximate(nresample = 10000)\n)\ncoin::pvalue(mt) # standard p-value\n\n[1] 0.0548\n99 percent confidence interval:\n 0.04910088 0.06092753 \n\ncoin::midpvalue(mt) # mid-p-value\n\n[1] 0.0455\n99 percent confidence interval:\n 0.04034520 0.05108709 \n\ncoin::pvalue_interval(mt) # p-value interval\n\n   p_0    p_1 \n0.0362 0.0548 \n\ncoin::size(mt, alpha = 0.05) # test size at alpha = 0.05 using the p-value\n\n[1] 0.0362"
  },
  {
    "objectID": "R/marginal_homogeneity_tests.html#stuart-maxwell-test",
    "href": "R/marginal_homogeneity_tests.html#stuart-maxwell-test",
    "title": "Marginal Homogeneity Tests",
    "section": "Stuart-Maxwell test",
    "text": "Stuart-Maxwell test\n\n## Opinions on Pre- and Extramarital Sex\n## Agresti (2002, p. 421)\nopinions &lt;- c(\n  \"Always wrong\",\n  \"Almost always wrong\",\n  \"Wrong only sometimes\",\n  \"Not wrong at all\"\n)\n# fmt: skip\nPreExSex &lt;- matrix(\n  c(144, 33, 84, 126,\n    2,  4, 14,  29,\n    0,  2,  6,  25,\n    0,  0,  1,   5),\n  nrow = 4,\n  dimnames = list(\n    \"Premarital Sex\" = opinions,\n    \"Extramarital Sex\" = opinions\n  )\n)\nPreExSex &lt;- as.table(PreExSex)\n\nPreExSex\n\n                      Extramarital Sex\nPremarital Sex         Always wrong Almost always wrong Wrong only sometimes\n  Always wrong                  144                   2                    0\n  Almost always wrong            33                   4                    2\n  Wrong only sometimes           84                  14                    6\n  Not wrong at all              126                  29                   25\n                      Extramarital Sex\nPremarital Sex         Not wrong at all\n  Always wrong                        0\n  Almost always wrong                 0\n  Wrong only sometimes                1\n  Not wrong at all                    5\n\n## Asymptotic Stuart test\ncoin::mh_test(PreExSex)\n\n\n    Asymptotic Marginal Homogeneity Test\n\ndata:  response by\n     conditions (Premarital.Sex, Extramarital.Sex) \n     stratified by block\nchi-squared = 271.92, df = 3, p-value &lt; 2.2e-16\n\n## Asymptotic Stuart-Birch test\n## Note: response as ordinal\ncoin::mh_test(\n  PreExSex,\n  scores = list(response = 1:length(opinions))\n)\n\n\n    Asymptotic Marginal Homogeneity Test for Ordered Data\n\ndata:  response (ordered) by\n     conditions (Premarital.Sex, Extramarital.Sex) \n     stratified by block\nZ = 16.454, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "R/marginal_homogeneity_tests.html#madansky-test-of-interchangeability",
    "href": "R/marginal_homogeneity_tests.html#madansky-test-of-interchangeability",
    "title": "Marginal Homogeneity Tests",
    "section": "Madansky test of interchangeability",
    "text": "Madansky test of interchangeability\n\n## Vote intention\n## Madansky (1963, pp. 107-108)\n# fmt: skip\nvote &lt;- array(\n    c(120, 1,  8, 2,   2,  1, 2, 1,  7,\n        6, 2,  1, 1, 103,  5, 1, 4,  8,\n       20, 3, 31, 1,   6, 30, 2, 1, 81),\n    dim = c(3, 3, 3),\n    dimnames = list(\n          \"July\" = c(\"Republican\", \"Democratic\", \"Uncertain\"),\n        \"August\" = c(\"Republican\", \"Democratic\", \"Uncertain\"),\n          \"June\" = c(\"Republican\", \"Democratic\", \"Uncertain\")\n    )\n)\nvote &lt;- as.table(vote)\n\nvote\n\n, , June = Republican\n\n            August\nJuly         Republican Democratic Uncertain\n  Republican        120          2         2\n  Democratic          1          2         1\n  Uncertain           8          1         7\n\n, , June = Democratic\n\n            August\nJuly         Republican Democratic Uncertain\n  Republican          6          1         1\n  Democratic          2        103         4\n  Uncertain           1          5         8\n\n, , June = Uncertain\n\n            August\nJuly         Republican Democratic Uncertain\n  Republican         20          1         2\n  Democratic          3          6         1\n  Uncertain          31         30        81\n\n## Asymptotic Madansky test (Q = 70.77)\ncoin::mh_test(vote)\n\n\n    Asymptotic Marginal Homogeneity Test\n\ndata:  response by\n     conditions (July, August, June) \n     stratified by block\nchi-squared = 70.763, df = 4, p-value = 1.565e-14\n\n## Cross-over study\n## http://www.nesug.org/proceedings/nesug00/st/st9005.pdf (link is dead now)\n# fmt: skip\ndysmenorrhea &lt;- array(\n  c(6, 2, 1,  3, 1, 0,  1, 2, 1,\n    4, 3, 0, 13, 3, 0,  8, 1, 1,\n    5, 2, 2, 10, 1, 0, 14, 2, 0),\n  dim = c(3, 3, 3),\n  dimnames =  list(\n    \"Placebo\" = c(\"None\", \"Moderate\", \"Complete\"),\n    \"Low dose\" = c(\"None\", \"Moderate\", \"Complete\"),\n    \"High dose\" = c(\"None\", \"Moderate\", \"Complete\")\n  )\n)\ndysmenorrhea &lt;- as.table(dysmenorrhea)\n\ndysmenorrhea\n\n, , High dose = None\n\n          Low dose\nPlacebo    None Moderate Complete\n  None        6        3        1\n  Moderate    2        1        2\n  Complete    1        0        1\n\n, , High dose = Moderate\n\n          Low dose\nPlacebo    None Moderate Complete\n  None        4       13        8\n  Moderate    3        3        1\n  Complete    0        0        1\n\n, , High dose = Complete\n\n          Low dose\nPlacebo    None Moderate Complete\n  None        5       10       14\n  Moderate    2        1        2\n  Complete    2        0        0\n\n## Asymptotic Madansky-Birch test (Q = 53.76)\n## Note: response as ordinal\ncoin::mh_test(\n  dysmenorrhea,\n  scores = list(response = 1:3)\n)\n\n\n    Asymptotic Marginal Homogeneity Test for Ordered Data\n\ndata:  response (ordered) by\n     conditions (Placebo, Low.dose, High.dose) \n     stratified by block\nchi-squared = 53.762, df = 2, p-value = 2.117e-12\n\n## Asymptotic Madansky-Birch test (Q = 47.29)\n## Note: response and measurement conditions as ordinal\ncoin::mh_test(\n  dysmenorrhea,\n  scores = list(response = 1:3, conditions = 1:3)\n)\n\n\n    Asymptotic Marginal Homogeneity Test for Ordered Data\n\ndata:  response (ordered) by\n     conditions (Placebo &lt; Low.dose &lt; High.dose) \n     stratified by block\nZ = 6.8764, p-value = 6.138e-12\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "R/marginal_homogeneity_tests.html#reference",
    "href": "R/marginal_homogeneity_tests.html#reference",
    "title": "Marginal Homogeneity Tests",
    "section": "Reference",
    "text": "Reference\nHothorn T, Hornik K, van de Wiel MA, Zeileis A (2006). A Lego system for conditional inference. The American Statistician, 60 (3), 257-263. doi:10.1198/000313006X118430 https://doi.org/10.1198/000313006X118430\nAgresti, A. (2002). Categorical Data Analysis, Second Edition. Hoboken, New Jersey: John Wiley & Sons.\nBirch, M. W. (1965). The detection of partial association, II: The general case. Journal of the Royal Statistical Society B 27(1), 111–124. doi:10.1111/j.2517-6161.1965.tb00593.x\nCochran, W. G. (1950). The comparison of percentages in matched samples. Biometrika 37(3/4), 256–266. doi:10.1093/biomet/37.3-4.256\nMadansky, A. (1963). Tests of homogeneity for correlated samples. Journal of the American Statistical Association 58(301), 97–119. doi:10.1080/01621459.1963.10500835\nMaxwell, A. E. (1970). Comparing the classification of subjects by two independent judges. British Journal of Psychiatry 116(535), 651–655. doi:10.1192/bjp.116.535.651\nMcNemar, Q. (1947). Note on the sampling error of the difference between correlated proportions or percentages. Psychometrika 12(2), 153–157. doi:10.1007/BF02295996\nStuart, A. (1955). A test for homogeneity of the marginal distributions in a two-way classification. Biometrika 42(3/4), 412–416. doi:10.1093/biomet/42.3-4.412\nWhite, A. A., Landis, J. R. and Cooper, M. M. (1982). A note on the equivalence of several marginal homogeneity test criteria for categorical data. International Statistical Review 50(1), 27–34. doi:10.2307/1402457\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package     * version date (UTC) lib source\n   codetools     0.2-20  2024-03-31 [2] CRAN (R 4.4.2)\n P coin          1.4-3   2023-09-27 [?] CRAN (R 4.4.0)\n   lattice       0.22-6  2024-03-20 [2] CRAN (R 4.4.2)\n P libcoin       1.0-10  2023-09-27 [?] CRAN (R 4.4.0)\n   MASS          7.3-61  2024-06-13 [2] CRAN (R 4.4.2)\n   Matrix        1.7-1   2024-10-18 [2] CRAN (R 4.4.2)\n P matrixStats   1.4.1   2024-09-08 [?] CRAN (R 4.4.1)\n P modeltools    0.2-23  2020-03-05 [?] CRAN (R 4.4.0)\n P multcomp      1.4-26  2024-07-18 [?] CRAN (R 4.4.0)\n P mvtnorm       1.3-1   2024-09-03 [?] CRAN (R 4.4.1)\n P sandwich      3.1-1   2024-09-15 [?] CRAN (R 4.4.1)\n P survival      3.7-0   2024-06-05 [?] CRAN (R 4.4.0)\n P TH.data       1.1-2   2023-04-17 [?] CRAN (R 4.4.0)\n P zoo           1.8-12  2023-04-13 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/gsd-tte.html",
    "href": "R/gsd-tte.html",
    "title": "Group sequential design in R",
    "section": "",
    "text": "While a group sequential design (GSD) could be applied for different types of endpoints, here we focus on time-to-event endpoints."
  },
  {
    "objectID": "R/gsd-tte.html#group-sequential-design-time-to-event-endpoint",
    "href": "R/gsd-tte.html#group-sequential-design-time-to-event-endpoint",
    "title": "Group sequential design in R",
    "section": "",
    "text": "While a group sequential design (GSD) could be applied for different types of endpoints, here we focus on time-to-event endpoints."
  },
  {
    "objectID": "R/gsd-tte.html#available-r-packages",
    "href": "R/gsd-tte.html#available-r-packages",
    "title": "Group sequential design in R",
    "section": "Available R packages",
    "text": "Available R packages\nThe commonly used R packages for power and sample size calculations utilizing a GSD are: gsDesign (also has a web interface), gsDesign2, and rpact.\n\nlibrary(gsDesign)\nlibrary(gsDesign2)\nlibrary(rpact)\nlibrary(tibble)"
  },
  {
    "objectID": "R/gsd-tte.html#design-assumptions",
    "href": "R/gsd-tte.html#design-assumptions",
    "title": "Group sequential design in R",
    "section": "Design assumptions",
    "text": "Design assumptions\nUsing a toy example, we will assume that a primary objective of a phase III oncology trial is to compare a new therapy to a control in terms of progression-free survival (PFS) and overall survival (OS). Note that, in this example, we have a family of primary endpoints, i.e., if at least one of the endpoints is successful, the study will be declared a success. A GSD will be utilized for each endpoint. PFS will be tested at one interim analysis (IA) for both efficacy and non-binding futility, while OS will be tested at two IAs for efficacy only. An O’Brien-Fleming spending function will be used for efficacy testing and a Hwang-Shih-Decani spending function with \\(\\gamma = -10\\) will be used for futility.\nFurther design assumptions are as follows:\n\n# PFS HR = 0.6\nhr1_pfs &lt;- 0.6\n# Median PFS of 9.4 months in the control arm\nmed_pfs &lt;- 9.4\n# Median follow-up of 10 months for PFS\nminfu_pfs &lt;- 10\n# Monthly dropout of 0.019 for PFS\ndo_rate_pfs &lt;- 0.019\n# IA timing for PFS is at 75% information fraction\ntiming_pfs &lt;- c(0.75, 1)\n# Power of 95% for PFS\npower_pfs &lt;- 0.95\n\n# OS HR = 0.65\nhr1_os &lt;- 0.65\n# Median OS of 3 years in the control arm\nmed_os &lt;- 12 * 3\n# Median follow-up of 42 months for OS\nminfu_os &lt;- 42\n# Monthly dropout of 0.001 for OS\ndo_rate_os &lt;- 0.001\n# IA timing for OS is at 60% and 80% information fraction\ntiming_os &lt;- c(0.6, 0.8, 1)\n# Power of 82% for OS\npower_os &lt;- 0.82\n\n# Enrollment period of 24 months\nenroll_dur &lt;- 24\n# 1:1 randomization ratio\nrand_ratio &lt;- 1\n# alpha level of 1.25% for each endpoint\nalphal &lt;- 0.0125\n\nWe assume that given the above assumptions, we need to calculate the target number of events for each analysis as well as the total sample size."
  },
  {
    "objectID": "R/gsd-tte.html#example-code",
    "href": "R/gsd-tte.html#example-code",
    "title": "Group sequential design in R",
    "section": "Example code",
    "text": "Example code\n\nExample using gsDesign\n\nPFS calculations:\n\n\npfs_gsDesign &lt;- gsDesign::gsSurv(\n  k = length(timing_pfs),\n  timing = timing_pfs,\n  R = enroll_dur,\n  eta = do_rate_pfs,\n  minfup = minfu_pfs,\n  T = enroll_dur + minfu_pfs,\n  lambdaC = log(2) / med_pfs,\n  hr = hr1_pfs,\n  beta = 1 - power_pfs,\n  alpha = alphal,\n  sfu = sfLDOF,\n  sfl = sfHSD,\n  sflpar = -10,\n  test.type = 4\n)\n\npfs_gsDesign |&gt;\n  gsDesign::gsBoundSummary()\n\n    Analysis              Value Efficacy Futility\n   IA 1: 75%                  Z   2.6584   0.7432\n      N: 398        p (1-sided)   0.0039   0.2287\n Events: 176       ~HR at bound   0.6693   0.8938\n   Month: 25   P(Cross) if HR=1   0.0039   0.7713\n             P(Cross) if HR=0.6   0.7668   0.0041\n       Final                  Z   2.2801   2.2801\n      N: 398        p (1-sided)   0.0113   0.0113\n Events: 234       ~HR at bound   0.7421   0.7421\n   Month: 34   P(Cross) if HR=1   0.0125   0.9875\n             P(Cross) if HR=0.6   0.9500   0.0500\n\n\n\nOS calculations:\n\n\nos_gsDesign &lt;- gsDesign::gsSurv(\n  k = length(timing_os),\n  timing = timing_os,\n  R = enroll_dur,\n  eta = do_rate_os,\n  minfup = minfu_os,\n  T = enroll_dur + minfu_os,\n  lambdaC = log(2) / med_os,\n  hr = hr1_os,\n  beta = 1 - power_os,\n  alpha = alphal,\n  sfu = sfLDOF,\n  test.type = 1\n)\n\nos_gsDesign |&gt;\n  gsDesign::gsBoundSummary()\n\n    Analysis               Value Efficacy\n   IA 1: 60%                   Z   3.0205\n      N: 394         p (1-sided)   0.0013\n Events: 131        ~HR at bound   0.5896\n   Month: 38    P(Cross) if HR=1   0.0013\n             P(Cross) if HR=0.65   0.2899\n   IA 2: 80%                   Z   2.5874\n      N: 394         p (1-sided)   0.0048\n Events: 175        ~HR at bound   0.6758\n   Month: 51    P(Cross) if HR=1   0.0052\n             P(Cross) if HR=0.65   0.6082\n       Final                   Z   2.2958\n      N: 394         p (1-sided)   0.0108\n Events: 218        ~HR at bound   0.7327\n   Month: 66    P(Cross) if HR=1   0.0125\n             P(Cross) if HR=0.65   0.8200\n\n\n\n\nExample using gsDesign2\n\nPFS calculations:\n\n\nenroll_rate &lt;- tibble(\n  stratum = \"All\",\n  duration = enroll_dur,\n  rate = 1\n)\nfail_rate_pfs &lt;- tibble(\n  stratum = \"All\",\n  duration = Inf, # Can be set to `Inf` when proportional hazard is assumed\n  fail_rate = log(2) / med_pfs,\n  hr = hr1_pfs,\n  dropout_rate = do_rate_pfs\n)\n\npfs_gsDesign2 &lt;- gsDesign2::gs_design_ahr(\n  enroll_rate = enroll_rate,\n  fail_rate = fail_rate_pfs,\n  ratio = rand_ratio,\n  beta = 1 - power_pfs,\n  alpha = alphal,\n  info_frac = timing_pfs,\n  analysis_time = enroll_dur + minfu_pfs,\n  upper = gs_spending_bound,\n  upar = list(\n    sf = gsDesign::sfLDOF,\n    total_spend = alphal\n  ),\n  lower = gs_spending_bound,\n  lpar = list(\n    sf = gsDesign::sfHSD,\n    total_spend = 1 - power_pfs,\n    param = -10\n  ),\n  info_scale = \"h0_info\"\n)\n\npfs_gsDesign2 |&gt;\n  summary() |&gt;\n  as_gt()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBound summary for AHR design\n\n\nAHR approximations of ~HR at bound\n\n\nBound\nZ\nNominal p1\n~HR at bound2\n\nCumulative boundary crossing probability\n\n\n\nAlternate hypothesis\nNull hypothesis\n\n\n\n\nAnalysis: 1 Time: 25.3 N: 405.8 Events: 179.2 AHR: 0.6 Information fraction: 0.75\n\n\nFutility\n0.74\n0.2287\n0.8940\n0.0041\n0.7713\n\n\nEfficacy\n2.66\n0.0039\n0.6697\n0.7668\n0.0039\n\n\nAnalysis: 2 Time: 34 N: 405.8 Events: 238.9 AHR: 0.6 Information fraction: 1\n\n\nFutility\n2.28\n0.0113\n0.7424\n0.0500\n0.9875\n\n\nEfficacy\n2.28\n0.0113\n0.7424\n0.9500\n0.0125\n\n\n\n1 One-sided p-value for experimental vs control treatment. Value &lt; 0.5 favors experimental, &gt; 0.5 favors control.\n\n\n2 Approximate hazard ratio to cross bound.\n\n\n\n\n\n\n\n\n\nOS calculations:\n\n\nfail_rate_os &lt;- tibble(\n  stratum = \"All\",\n  duration = Inf, # Can be set to `Inf` when proportional hazard is assumed\n  fail_rate = log(2) / med_os,\n  hr = hr1_os,\n  dropout_rate = do_rate_os\n)\n\nos_gsDesign2 &lt;- gsDesign2::gs_design_ahr(\n  enroll_rate = pfs_gsDesign2$enroll_rate,\n  fail_rate = fail_rate_os,\n  ratio = rand_ratio,\n  beta = 1 - power_os,\n  alpha = alphal,\n  info_frac = timing_os,\n  analysis_time = enroll_dur + minfu_os,\n  test_lower = FALSE,\n  upper = gs_spending_bound,\n  upar = list(\n    sf = gsDesign::sfLDOF,\n    total_spend = alphal\n  ),\n  info_scale = \"h0_info\"\n)\n\nos_gsDesign2 |&gt;\n  summary() |&gt;\n  as_gt()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBound summary for AHR design\n\n\nAHR approximations of ~HR at bound\n\n\nBound\nZ\nNominal p1\n~HR at bound2\n\nCumulative boundary crossing probability\n\n\n\nAlternate hypothesis\nNull hypothesis\n\n\n\n\nAnalysis: 1 Time: 38.4 N: 402.6 Events: 133.7 AHR: 0.65 Information fraction: 0.6\n\n\nEfficacy\n3.02\n0.0013\n0.5901\n0.2899\n0.0013\n\n\nAnalysis: 2 Time: 50.6 N: 402.6 Events: 178.2 AHR: 0.65 Information fraction: 0.8\n\n\nEfficacy\n2.59\n0.0048\n0.6762\n0.6082\n0.0052\n\n\nAnalysis: 3 Time: 66 N: 402.6 Events: 222.8 AHR: 0.65 Information fraction: 1\n\n\nEfficacy\n2.30\n0.0108\n0.7330\n0.8200\n0.0125\n\n\n\n1 One-sided p-value for experimental vs control treatment. Value &lt; 0.5 favors experimental, &gt; 0.5 favors control.\n\n\n2 Approximate hazard ratio to cross bound.\n\n\n\n\n\n\n\n\n\n\nExample using rpact\n\nPFS calculations:\n\n\npfs_rpact_gsd &lt;- rpact::getDesignGroupSequential(\n  sided = 1,\n  alpha = alphal,\n  informationRates = timing_pfs,\n  typeOfDesign = \"asOF\",\n  beta = 1 - power_pfs,\n  typeBetaSpending = \"bsHSD\",\n  gammaB = -10,\n  bindingFutility = FALSE\n)\n\npfs_rpact &lt;- rpact::getSampleSizeSurvival(\n  design = pfs_rpact_gsd,\n  accrualTime = enroll_dur,\n  followUpTime = minfu_pfs,\n  lambda2 = log(2) / med_pfs,\n  hazardRatio = hr1_pfs,\n  dropoutRate1 = 0.2,\n  dropoutRate2 = 0.2,\n  dropoutTime = 12\n)\n\nkable(summary(pfs_rpact))\n\nWarning in kable.ParameterSet(summary(pfs_rpact)): Manual use of kable() for\nrpact result objects is no longer needed, as the formatting and display will be\nhandled automatically by the rpact package\n\n\nSample size calculation for a survival endpoint\nSequential analysis with a maximum of 2 looks (group sequential design), one-sided overall significance level 1.25%, power 95%. The results were calculated for a two-sample logrank test, H0: hazard ratio = 1, H1: hazard ratio = 0.6, control lambda(2) = 0.074, accrual time = 24, accrual intensity = 16.5, follow-up time = 10, dropout rate(1) = 0.2, dropout rate(2) = 0.2, dropout time = 12.\n\n\n\nStage\n1\n2\n\n\n\n\nPlanned information rate\n75%\n100%\n\n\nCumulative alpha spent\n0.0039\n0.0125\n\n\nCumulative beta spent\n0.0041\n0.0500\n\n\nStage levels (one-sided)\n0.0039\n0.0113\n\n\nEfficacy boundary (z-value scale)\n2.658\n2.280\n\n\nFutility boundary (z-value scale)\n0.743\n\n\n\nEfficacy boundary (t)\n0.670\n0.742\n\n\nFutility boundary (t)\n0.894\n\n\n\nCumulative power\n0.7668\n0.9500\n\n\nNumber of subjects\n396.9\n396.9\n\n\nExpected number of subjects under H1\n\n396.9\n\n\nCumulative number of events\n175.8\n234.4\n\n\nExpected number of events under H1\n189.2\n\n\n\nAnalysis time\n25.36\n34.00\n\n\nExpected study duration under H1\n\n27.34\n\n\nOverall exit probability (under H0)\n0.7752\n\n\n\nOverall exit probability (under H1)\n0.7709\n\n\n\nExit probability for efficacy (under H0)\n0.0039\n\n\n\nExit probability for efficacy (under H1)\n0.7668\n\n\n\nExit probability for futility (under H0)\n0.7713\n\n\n\nExit probability for futility (under H1)\n0.0041\n\n\n\n\nLegend:\n\n(t): treatment effect scale\n\n\n\nNote: the dropoutRate1, dropoutRate2 arguments in getSampleSizeSurvival() refer to the % of drop-outs by the dropoutTime, while the eta argument in gsDesign::gsSurv() and the dropout_rate value in the fail_rate argument in gsDesign2::gs_design_ahr() refer to the annual drop-out rate parameter under the exponential distribution. In our example, if \\(X\\) is a drop-out time and \\(X \\sim \\text{Exponential} (\\lambda)\\), we assume that by month 12 the drop-out rate was 20%, which implies: \\(P(X\\le12) = 1 - e^{-12\\lambda} = 0.2 \\Rightarrow \\lambda = 0.019\\). Due to the above differences, the value \\(\\lambda = 0.019\\) was used in the gsDesign and gsDesign2 example, while 0.2 was used in the rpact example.\n\nOS calculations:\n\n\nos_rpact_gsd &lt;- rpact::getDesignGroupSequential(\n  sided = 1,\n  alpha = alphal,\n  informationRates = timing_os,\n  typeOfDesign = \"asOF\",\n  beta = 1 - power_os\n)\n\nos_rpact &lt;- rpact::getSampleSizeSurvival(\n  design = os_rpact_gsd,\n  accrualTime = enroll_dur,\n  followUpTime = minfu_os,\n  lambda2 = log(2) / med_os,\n  hazardRatio = hr1_os,\n  dropoutRate1 = 1 - exp(-do_rate_os * 12),\n  dropoutRate2 = 1 - exp(-do_rate_os * 12),\n  dropoutTime = 12\n)\n\nkable(summary(os_rpact))\n\nSample size calculation for a survival endpoint\nSequential analysis with a maximum of 3 looks (group sequential design), one-sided overall significance level 1.25%, power 82%. The results were calculated for a two-sample logrank test, H0: hazard ratio = 1, H1: hazard ratio = 0.65, control lambda(2) = 0.019, accrual time = 24, accrual intensity = 16.5, follow-up time = 42, dropout rate(1) = 0.012, dropout rate(2) = 0.012, dropout time = 12.\n\n\n\nStage\n1\n2\n3\n\n\n\n\nPlanned information rate\n60%\n80%\n100%\n\n\nCumulative alpha spent\n0.0013\n0.0052\n0.0125\n\n\nStage levels (one-sided)\n0.0013\n0.0048\n0.0108\n\n\nEfficacy boundary (z-value scale)\n3.020\n2.587\n2.296\n\n\nEfficacy boundary (t)\n0.590\n0.676\n0.733\n\n\nCumulative power\n0.2899\n0.6082\n0.8200\n\n\nNumber of subjects\n395.1\n395.1\n395.1\n\n\nExpected number of subjects under H1\n\n\n395.1\n\n\nCumulative number of events\n131.2\n174.9\n218.6\n\n\nExpected number of events under H1\n179.4\n\n\n\n\nAnalysis time\n38.44\n50.60\n66.00\n\n\nExpected study duration under H1\n\n\n53.11\n\n\nExit probability for efficacy (under H0)\n0.0013\n0.0040\n\n\n\nExit probability for efficacy (under H1)\n0.2899\n0.3182\n\n\n\n\nLegend:\n\n(t): treatment effect scale"
  },
  {
    "objectID": "R/survival.html",
    "href": "R/survival.html",
    "title": "Survival Analysis Using R",
    "section": "",
    "text": "The most commonly used survival analysis methods in clinical trials include:\nAdditionally, other methods for analyzing time-to-event data are available, such as:\nWhile these models may be explored in a separate document, this particular document focuses solely on the three most prevalent methods: KM estimators, log-rank test and Cox PH model."
  },
  {
    "objectID": "R/survival.html#example-data",
    "href": "R/survival.html#example-data",
    "title": "Survival Analysis Using R",
    "section": "Example Data",
    "text": "Example Data\nData source: https://stats.idre.ucla.edu/sas/seminars/sas-survival/\nThe data include 500 subjects from the Worcester Heart Attack Study. This study examined several factors, such as age, gender and BMI, that may influence survival time after heart attack. Follow up time for all participants begins at the time of hospital admission after heart attack and ends with death or loss to follow up (censoring). The variables used here are:\n\nlenfol: length of followup, terminated either by death or censoring - time variable\nfstat: loss to followup = 0, death = 1 - censoring variable\nafb: atrial fibrillation, no = 0, 1 = yes - explanatory variable\ngender: males = 0, females = 1 - stratification factor\n\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(survival)\nlibrary(survminer)\nlibrary(ggsurvfit)\nlibrary(broom)\nlibrary(knitr)\nknitr::opts_chunk$set(echo = TRUE)\n\ndat &lt;- haven::read_sas(file.path(\"../data/whas500.sas7bdat\")) |&gt;\n  mutate(\n    LENFOLY = round(LENFOL / 365.25, 2), ## change follow-up days to years for better visualization\n    AFB = factor(AFB, levels = c(1, 0))\n  ) ## change AFB order to use \"Yes\" as the reference group to be consistent with SAS"
  },
  {
    "objectID": "R/survival.html#the-non-stratified-model",
    "href": "R/survival.html#the-non-stratified-model",
    "title": "Survival Analysis Using R",
    "section": "The Non-stratified Model",
    "text": "The Non-stratified Model\nFirst we try a non-stratified analysis following the mock-up above to describe the association between survival time and afb (atrial fibrillation).\nThe KM estimators are from survival::survfit function, the log-rank test uses survminer::surv_pvalue, and Cox PH model is conducted using survival::coxph function. Numerous R packages and functions are available for performing survival analysis. The author has selected survival and survminer for use in this context, but alternative options can also be employed for survival analysis.\n\nKM estimators\n\nfit.km &lt;- survival::survfit(survival::Surv(LENFOLY, FSTAT) ~ AFB, data = dat)\n\n## quantile estimates\nquantile(fit.km, probs = c(0.25, 0.5, 0.75))\n\n$quantile\n        25   50   75\nAFB=1 0.26 2.37 6.43\nAFB=0 0.94 5.91 6.44\n\n$lower\n        25   50   75\nAFB=1 0.05 1.27 4.24\nAFB=0 0.55 4.32 6.44\n\n$upper\n        25   50 75\nAFB=1 1.11 4.24 NA\nAFB=0 1.47   NA NA\n\n## landmark estimates at 1, 3, 5-year\nsummary(fit.km, times = c(1, 3, 5))\n\nCall: survfit(formula = survival::Surv(LENFOLY, FSTAT) ~ AFB, data = dat)\n\n                AFB=1 \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    1     50      28    0.641  0.0543        0.543        0.757\n    3     27      12    0.455  0.0599        0.351        0.589\n    5     11       6    0.315  0.0643        0.211        0.470\n\n                AFB=0 \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    1    312     110    0.739  0.0214        0.699        0.782\n    3    199      33    0.642  0.0245        0.595        0.691\n    5     77      20    0.530  0.0311        0.472        0.595\n\n\n\n\nLog-rank test\nThere are multiple ways to output the log-rank test. The survdiff() function from {survival} package performs a log-rank test (or its weighted variants) to compare survival curves between two or more treatment groups. rho=0 is the default and gives the standard log-rank test. rho=1 would output the Peto-Peto test (which weights earliest events more heavily).\nYou can also use {survminer} package as shown below or {ggsurvfit} package using add_pvalue option if you want the p-value to be put into a KM plot - See example in Kaplan Meier section below.\n\n#survdiff() from survival package: unrounded pvalue=0.0009646027\nsurvdiff(Surv(LENFOLY, FSTAT) ~ AFB, data = dat, rho=0)\n\nCall:\nsurvdiff(formula = Surv(LENFOLY, FSTAT) ~ AFB, data = dat, rho = 0)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\nAFB=1  78       47     30.3      9.26      10.9\nAFB=0 422      168    184.7      1.52      10.9\n\n Chisq= 10.9  on 1 degrees of freedom, p= 0.001 \n\n#surv_pvalue() from survminer\nsurvminer::surv_pvalue(fit.km, data = dat)\n\n  variable         pval   method    pval.txt\n1      AFB 0.0009646027 Log-rank p = 0.00096\n\n\n\n\nCox PH model\n\nfit.cox &lt;- survival::coxph(survival::Surv(LENFOLY, FSTAT) ~ AFB, data = dat)\nfit.cox |&gt;\n  tidy(exponentiate = TRUE, conf.int = TRUE, conf.level = 0.95) |&gt;\n  select(term, estimate, conf.low, conf.high)\n\n# A tibble: 1 × 4\n  term  estimate conf.low conf.high\n  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 AFB0     0.583    0.421     0.806"
  },
  {
    "objectID": "R/survival.html#the-stratified-model",
    "href": "R/survival.html#the-stratified-model",
    "title": "Survival Analysis Using R",
    "section": "The Stratified Model",
    "text": "The Stratified Model\nIn a stratified model, the Kaplan-Meier estimators remain the same as those in the non-stratified model. To implement stratified log-rank tests and Cox proportional hazards models, simply include the strata() function within the model formula.\n\nStratified Log-rank test\n\nfit.km.str &lt;- survival::survfit(\n  survival::Surv(LENFOLY, FSTAT) ~ AFB + survival::strata(GENDER),\n  data = dat\n)\n\nsurvminer::surv_pvalue(fit.km.str, data = dat)\n\n                      variable         pval   method    pval.txt\n1 AFB+survival::strata(GENDER) 0.0004479027 Log-rank p = 0.00045\n\n\n\n\nStratified Cox PH model\n\nfit.cox.str &lt;- survival::coxph(\n  survival::Surv(LENFOLY, FSTAT) ~ AFB + survival::strata(GENDER),\n  data = dat\n)\nfit.cox.str |&gt;\n  tidy(exponentiate = TRUE, conf.int = TRUE, conf.level = 0.95) |&gt;\n  select(term, estimate, conf.low, conf.high)\n\n# A tibble: 2 × 4\n  term                             estimate conf.low conf.high\n  &lt;chr&gt;                               &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 AFB0                                0.596    0.431     0.825\n2 survival::strata(GENDER)GENDER=1    1.44     1.10      1.88 \n\n\n\n\nKaplan-Meier Graphs\nYou can use {survminer} or {ggsurvfit} packages to create kaplan-meier graphs including presentation of the number at risk and number of events under the graph. Both methods are highly customizable.\nIt is good practice to ensure your categorical factors are specified as such and are clearly labelled. {forcats} package is useful for recoding factors as shown below using fct_recode().\n{ggsurvfit} is shown here because the code coverage is higher for this package than for {survminer}.\nThe code below, fits the model, adds a log-rank test p-value, limits the X axis, controls the major scale and minor scale of Y and X axis, adds a risk table under the graph showing number at risk and the cumulative events, color codes the lines to allow easy identification of AFB and Gender and adds appropriate titles and axis labels.\n\ndat2&lt;- dat %&gt;%\n  mutate(Treatment=fct_recode(AFB, 'Without AFB'='0','With AFB'='1')) %&gt;% \n  mutate(GENDER_F = factor(GENDER, labels=c('Female','Male')))\n\nsurvfit2(Surv(LENFOLY, FSTAT) ~ Treatment + strata(GENDER_F), data = dat2) %&gt;% \n      ggsurvfit() + \n      add_pvalue(rho=0) +\n      coord_cartesian(xlim = c(0, 6)) +\n       scale_y_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks=NULL) +\n       scale_x_continuous(breaks = seq(0, 6, by = 1), minor_breaks=NULL) +\n       add_risktable(risktable_stats='{n.risk}({cum.event})') +\n       scale_color_manual(values=c('Blue','lightskyblue','red','hotpink')) +\n       labs(y='Percentage Survival',\n            x='Time (days)',\n            title='Time to death for patients with or without AFB')"
  },
  {
    "objectID": "R/mcnemar.html",
    "href": "R/mcnemar.html",
    "title": "McNemar’s test in R",
    "section": "",
    "text": "The McNemar test is a statistical test used to determine if there are significant differences in the paired proportions of categorical data. It is particularly useful for testing the change in responses before and after an intervention on the same subjects, such as in pre-test/post-test study designs. By comparing the discordant pairs, where outcomes change in one direction versus the opposite, the McNemar test assesses if the intervention or treatment has a statistically significant effect on the outcome.\nTo demonstrate McNemar’s test, data was used concerning the presence or absence of cold symptoms reported by the same children at age 12 and age 14. A total of 2638 participants were involved, with the interest being in whether the prevalence was significantly different at either age. In order to use any of the packages to calculate first we need to convert our data into a frequency table."
  },
  {
    "objectID": "R/mcnemar.html#example-code-using-stats",
    "href": "R/mcnemar.html#example-code-using-stats",
    "title": "McNemar’s test in R",
    "section": "Example Code using {stats}",
    "text": "Example Code using {stats}\nMcNemar’s test can also be performed using stats::mcnemar.test as shown below, using the same table X as in the previous section.\n\nstats::mcnemar.test(freq_tbl)\n\n\n    McNemar's Chi-squared test with continuity correction\n\ndata:  freq_tbl\nMcNemar's chi-squared = 30.802, df = 1, p-value = 2.857e-08\n\n\nThe other possible input to mcnemar.test is correct = which is a true/false value to indicate if the continuity correction should be applied. To get the result without continuity correction by specify correct=FALSE.\n\nstats::mcnemar.test(freq_tbl, correct = FALSE)\n\n\n    McNemar's Chi-squared test\n\ndata:  freq_tbl\nMcNemar's chi-squared = 31.36, df = 1, p-value = 2.144e-08"
  },
  {
    "objectID": "R/mcnemar.html#example-code-using-coin",
    "href": "R/mcnemar.html#example-code-using-coin",
    "title": "McNemar’s test in R",
    "section": "Example Code using {coin}",
    "text": "Example Code using {coin}\nMcNemar test is calculated without continuity correction which corresponds to SAS FREQ procedure (see R v SAS McNemar’s test for more details).\n\nlibrary(coin)\n\nLoading required package: survival\n\n## Asymptotic McNemar Test\n# Corresponds to SAS FREQ procedure\ncoin::mh_test(freq_tbl)\n\n\n    Asymptotic Marginal Homogeneity Test\n\ndata:  response by\n     conditions (age12, age14) \n     stratified by block\nchi-squared = 31.36, df = 1, p-value = 2.144e-08\n\n## Approximative McNemar Test\ncoin::mh_test(\n  freq_tbl,\n  distribution = coin::approximate(nresample = 10000)\n)\n\n\n    Approximative Marginal Homogeneity Test\n\ndata:  response by\n     conditions (age12, age14) \n     stratified by block\nchi-squared = 31.36, p-value &lt; 1e-04\n\n## Exact McNemar Test\ncoin::mh_test(freq_tbl, distribution = \"exact\")\n\n\n    Exact Marginal Homogeneity Test\n\ndata:  response by\n     conditions (age12, age14) \n     stratified by block\nchi-squared = 31.36, p-value = 2.331e-08\n\n\n\nCalculating Confidence Intervals with {vcd}\nIt is common when calculating McNemar, to also want to check the level agreement between the two rates. To do this we use Cohen’s Kappa and its associated confidence intervals. To do this, we use the vcd package as follows:\n\nlibrary(vcd)\n\nLoading required package: grid\n\ncohen_kappa &lt;- vcd::Kappa(freq_tbl)\ncohen_kappa\n\n            value     ASE     z Pr(&gt;|z|)\nUnweighted 0.2999 0.02733 10.97 5.07e-28\nWeighted   0.2999 0.02733 10.97 5.07e-28\n\nconfint(cohen_kappa, level = 0.95)\n\n            \nKappa              lwr       upr\n  Unweighted 0.2463654 0.3534966\n  Weighted   0.2463654 0.3534966\n\n\n\n\nUsing the epibasix::mcnemar function\nAnother package that is sometimes used to calculate McNemar is {epibasix}. This package isn’t recommended by CAMIS. It was found that the author is no longer maintaining the package and there was no documentation available for certain methods used. Therefore, the use of the {epibasix} package is advised against and other packages may be more suitable.\n\n\nResults\nstats::mcnemar.test and coin::mh_test are both sutiable options for calculating McNemar. The {coin} package also has a variety of other marginal homogeneity test, for more information see here. stats::mcnemar.test uses a continuity correction as default but does allow for this to be removed. This function does not output any other coefficients for agreement or proportions but (if required) these can be achieved within other functions or packages in R."
  },
  {
    "objectID": "R/mcnemar.html#reference",
    "href": "R/mcnemar.html#reference",
    "title": "McNemar’s test in R",
    "section": "Reference",
    "text": "Reference\nAgresti, A. (2002). Categorical Data Analysis, Second Edition. Hoboken, New Jersey: John Wiley & Sons.\nCohen, J. (1960), A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20, 37–46.\nEveritt, B.S. (1968), Moments of statistics kappa and weighted kappa. The British Journal of Mathematical and Statistical Psychology, 21, 97–103.\nFleiss, J.L., Cohen, J., and Everitt, B.S. (1969), Large sample standard errors of kappa and weighted kappa. Psychological Bulletin, 72, 332–327."
  },
  {
    "objectID": "R/wilcoxonsr_hodges_lehman.html",
    "href": "R/wilcoxonsr_hodges_lehman.html",
    "title": "Wilcoxon signed-rank test",
    "section": "",
    "text": "Introduction\nWilcoxon signed-rank test is a non-parametric test which is sometimes used instead of the paired Student’s t-test when assumptions regarding a normal distribution are not valid. It is a rank test, designed for analyzing repeated measures or paired observations by a paired comparison (a type of location test) to assess whether their population means differ. Whilst it does not ‘compare’ means or medians for a set of paired data, it ranks the results on A and ranks the results on B, then compares if Prob(A&gt;B) &gt; Prob(B&gt;A).\nTies are when you have two observations with the same result. For example, in a 2-period cross-over study, you take the difference between result on Treatment A minus result on Treatment B and find that two or more subjects have the same difference.\nAdditionally, “0s” can cause some trouble as well. For example when the difference between result on Treatment A minus result on Treatment B equals 0.\n\n\nData\nAnalysis will be conducted on the example of anonymized data from 2-period, cross-over study comparing treatments A and B in patients with asthma and acute airway obstruction induced by repeated mannitol challenges.\nWilcoxon signed rank test was applied to analyse the time to return to baseline FEV1 post-mannitol challenge 2. Median difference, p value and 95% CI were provided using the Hodges-Lehmann estimate.\n\nhead(blood_p)\n\n  patient  sex agegrp bp_before bp_after\n1       1 Male  30-45   143.670  153.316\n2       2 Male  30-45   163.082  170.576\n3       3 Male  30-45   153.393  168.599\n4       4 Male  30-45   153.082  142.358\n5       5 Male  30-45   146.720  141.193\n6       6 Male  30-45   150.668  147.204\n\n\n\n\nDataset without ties\nLet’s consider a case where the dataset has no ties.\n\n\nAvailable packages\nIn R Wilcoxon signed rank test can be performed using for example DOS (version 0.5.2) or stats (version 3.6.2) package.\n\nstats\nFunction wilcox.test used for Wilcoxon Rank Sum and Signed Rank Tests will be applied. For more information about that function go here\nWe will focus on the below arguments: - alternative - paired - exact - correct - conf.int.\n\n\n\nExamples\n\n# Exact\nstats::wilcox.test(\n  x = blood_p$bp_after,\n  y = blood_p$bp_before,\n  paired = TRUE,\n  conf.int = TRUE,\n  conf.level = 0.9,\n  alterative = \"two.sided\",\n  exact = TRUE\n)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  blood_p$bp_after and blood_p$bp_before\nV = 17251, p-value = 0.009379\nalternative hypothesis: true location shift is not equal to 0\n90 percent confidence interval:\n 1.5045 5.9945\nsample estimates:\n(pseudo)median \n       3.68875 \n\n# No exact & continuity correction\nstats::wilcox.test(\n  x = blood_p$bp_after,\n  y = blood_p$bp_before,\n  paired = TRUE,\n  conf.int = TRUE,\n  conf.level = 0.9,\n  alterative = \"two.sided\",\n  exact = FALSE,\n  correct = TRUE\n)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  blood_p$bp_after and blood_p$bp_before\nV = 17251, p-value = 0.009548\nalternative hypothesis: true location shift is not equal to 0\n90 percent confidence interval:\n 1.504565 5.994467\nsample estimates:\n(pseudo)median \n      3.688796 \n\n# No exact & No continuity correction\nstats::wilcox.test(\n  x = blood_p$bp_after,\n  y = blood_p$bp_before,\n  paired = TRUE,\n  conf.int = TRUE,\n  conf.level = 0.9,\n  alterative = \"two.sided\",\n  exact = FALSE,\n  correct = FALSE\n)\n\n\n    Wilcoxon signed rank test\n\ndata:  blood_p$bp_after and blood_p$bp_before\nV = 17251, p-value = 0.009535\nalternative hypothesis: true location shift is not equal to 0\n90 percent confidence interval:\n 1.504991 5.993011\nsample estimates:\n(pseudo)median \n      3.688796 \n\n\n\n\nImportant notes on stats:wilcox.test\n\nBy default an exact p-value is computed if the samples size is less than 50 and there are no ties. Otherwise, a normal approximation is used.\nIf exact p-values are available, an exact confidence interval is obtained by the algorithm described in Bauer (1972), and the Hodges-Lehmann estimator is employed. Otherwise, the returned confidence interval and point estimate are based on normal approximations.\nIf non-exact p-value is calculated, continuity correction in the normal approximation for the p-value can be applied with correct argument.\nStatistic V is provided, which is a test statistic based on Sprent (1993) algorithm\n\n\nDOS2\nFunction senWilcox used for Sensitivity Analysis for Wilcoxon’s Signed-rank Statistic will be applied. For more information about that function go here\n\n\n\nExamples\n\nDOS2::senWilcox(\n  blood_p$bp_after - blood_p$bp_before,\n  gamma = 1,\n  conf.int = TRUE,\n  alpha = 0.1,\n  alternative = \"twosided\"\n)\n\n$pval\n[1] 0.009534732\n\n$estimate\n     low     high \n3.688796 3.688796 \n\n$ci\n    low    high \n1.50494 5.99305 \n\n\n\n\nImportant notes on DOS2:senWilcox\n\nGamma &gt;= 1 is the value of the sensitivity parameter. If gamma=1, then you are assuming ignorable treatment assignment or equivalently no unmeasured confounding - that is the considered scenario in our example, sensitivity analysis is not performed.\nOnly p value, estimate and CI are provided\n\n\n\nCoin package - coming soon!"
  },
  {
    "objectID": "R/ancova.html",
    "href": "R/ancova.html",
    "title": "Ancova",
    "section": "",
    "text": "ANOVA is a statistical method used to compare the means of three or more groups to determine if at least one group mean is significantly different from the others. Please see the ANOVA document for more information. ANCOVA is an extension to ANOVA.\nANCOVA (Analysis of Covariance) is a statistical method that compares the means of two or more groups while controlling for one or more continuous covariates. By adjusting for these covariates, ANCOVA helps to reduce potential confounding effects, allowing for a clearer assessment of the main treatment effects. It assumes linear relationships between covariates and the dependent variable, along with normality and homogeneity of variances.\nWe follow the example from link Analysis of Covariance"
  },
  {
    "objectID": "R/ancova.html#introduction",
    "href": "R/ancova.html#introduction",
    "title": "Ancova",
    "section": "",
    "text": "ANOVA is a statistical method used to compare the means of three or more groups to determine if at least one group mean is significantly different from the others. Please see the ANOVA document for more information. ANCOVA is an extension to ANOVA.\nANCOVA (Analysis of Covariance) is a statistical method that compares the means of two or more groups while controlling for one or more continuous covariates. By adjusting for these covariates, ANCOVA helps to reduce potential confounding effects, allowing for a clearer assessment of the main treatment effects. It assumes linear relationships between covariates and the dependent variable, along with normality and homogeneity of variances.\nWe follow the example from link Analysis of Covariance"
  },
  {
    "objectID": "R/ancova.html#data-summary",
    "href": "R/ancova.html#data-summary",
    "title": "Ancova",
    "section": "Data Summary",
    "text": "Data Summary\n\ndf_sas |&gt; glimpse()\n\nRows: 30\nColumns: 3\n$ drug &lt;fct&gt; A, A, A, A, A, A, A, A, A, A, D, D, D, D, D, D, D, D, D, D, F, F,…\n$ pre  &lt;dbl&gt; 11, 8, 5, 14, 19, 6, 10, 6, 11, 3, 6, 6, 7, 8, 18, 8, 19, 8, 5, 1…\n$ post &lt;dbl&gt; 6, 0, 2, 8, 11, 4, 13, 1, 8, 0, 0, 2, 3, 1, 18, 4, 14, 9, 1, 9, 1…\n\ndf_sas |&gt; summary()\n\n drug        pre             post      \n A:10   Min.   : 3.00   Min.   : 0.00  \n D:10   1st Qu.: 7.00   1st Qu.: 2.00  \n F:10   Median :10.50   Median : 7.00  \n        Mean   :10.73   Mean   : 7.90  \n        3rd Qu.:13.75   3rd Qu.:12.75  \n        Max.   :21.00   Max.   :23.00"
  },
  {
    "objectID": "R/ancova.html#the-model",
    "href": "R/ancova.html#the-model",
    "title": "Ancova",
    "section": "The Model",
    "text": "The Model\n\nmodel_ancova &lt;- lm(post ~ drug + pre, data = df_sas)\n\nmodel_glance &lt;- model_ancova |&gt;\n  glance()\nmodel_tidy &lt;- model_ancova |&gt;\n  tidy()\nmodel_glance |&gt;\n  gt()\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.6762609\n0.6389064\n4.005778\n18.10386\n1.501369e-06\n3\n-82.05377\n174.1075\n181.1135\n417.2026\n26\n30\n\n\n\n\n\n\nmodel_tidy |&gt;\n  gt()\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-3.8808094\n1.9862017\n-1.9538849\n6.155192e-02\n\n\ndrugD\n0.1089713\n1.7951351\n0.0607037\n9.520594e-01\n\n\ndrugF\n3.4461383\n1.8867806\n1.8264647\n7.928458e-02\n\n\npre\n0.9871838\n0.1644976\n6.0012061\n2.454330e-06\n\n\n\n\n\n\n\n\nmodel_table &lt;- model_ancova |&gt;\n  anova() |&gt;\n  tidy()\n\ntotal_df &lt;- sum(model_table$df)\ntotal_sumsq &lt;- sum(model_table$sumsq)\n\nmodel_table |&gt;\n  add_row(term = \"Total\", df = total_df, sumsq = total_sumsq) |&gt;\n  gt()\n\n\n\n\n\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\ndrug\n2\n293.6000\n146.80000\n9.148553\n9.812371e-04\n\n\npre\n1\n577.8974\n577.89740\n36.014475\n2.454330e-06\n\n\nResiduals\n26\n417.2026\n16.04625\nNA\nNA\n\n\nTotal\n29\n1288.7000\nNA\nNA\nNA\n\n\n\n\n\n\n\n\nSums of Squares Tables\n\nType I\nThis can be calculated using, the base R {stats} package or the {rstatix} package. Both give the same result.\n\nstats\n\nstats::anova(model_ancova)\n\nAnalysis of Variance Table\n\nResponse: post\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \ndrug       2  293.6  146.80  9.1486 0.0009812 ***\npre        1  577.9  577.90 36.0145 2.454e-06 ***\nResiduals 26  417.2   16.05                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nrstatix\n\ndf_sas |&gt;\n  anova_test(post ~ drug + pre, type = 1, detailed = TRUE) |&gt;\n  get_anova_table() |&gt;\n  gt()\n\n\n\n\n\n\n\nEffect\nDFn\nDFd\nSSn\nSSd\nF\np\np&lt;.05\nges\n\n\n\n\ndrug\n2\n26\n293.600\n417.203\n9.149\n9.81e-04\n*\n0.413\n\n\npre\n1\n26\n577.897\n417.203\n36.014\n2.45e-06\n*\n0.581\n\n\n\n\n\n\n\n\n\n\nType II\nThis can be calculated using the {car} package or the {rstatix} package. Both give the same result.\n\ncar\n\ncar::Anova(model_ancova, type = \"II\")\n\nAnova Table (Type II tests)\n\nResponse: post\n          Sum Sq Df F value    Pr(&gt;F)    \ndrug       68.55  2  2.1361    0.1384    \npre       577.90  1 36.0145 2.454e-06 ***\nResiduals 417.20 26                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nrstatix\n\ndf_sas |&gt;\n  anova_test(post ~ drug + pre, type = 2, detailed = TRUE) |&gt;\n  get_anova_table() |&gt;\n  gt()\n\n\n\n\n\n\n\nEffect\nSSn\nSSd\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\n\ndrug\n68.554\n417.203\n2\n26\n2.136\n1.38e-01\n\n0.141\n\n\npre\n577.897\n417.203\n1\n26\n36.014\n2.45e-06\n*\n0.581\n\n\n\n\n\n\n\n\n\n\nType III\nThis can be calculated using the base R {stats} package, the {car} package or the {rstatix} package. All give the same result.\nNote: Calculating type III sums of squares in R is a bit tricky, because the multi-way ANOVA model is over-paramerterised. So when running the linear model we need to select a design matrix that sums to zero. In R those options will be either \"contr.sum\" or \"contr.poly\"\n\n# Drug design matrix\ncontr.sum(4) # Using 4 here as we have 4 levels of drug\n\n  [,1] [,2] [,3]\n1    1    0    0\n2    0    1    0\n3    0    0    1\n4   -1   -1   -1\n\n# Disease design matrix\ncontr.sum(3)\n\n  [,1] [,2]\n1    1    0\n2    0    1\n3   -1   -1\n\n\nWhile not relevant for this example as the disease variable isn’t ordinal the polynomial design matrix would look like\n\ncontr.poly(3)\n\n                .L         .Q\n[1,] -7.071068e-01  0.4082483\n[2,] -9.073800e-17 -0.8164966\n[3,]  7.071068e-01  0.4082483\n\n\n\nmodel_ancova &lt;- lm(\n  post ~ drug + pre, data = df_sas,\n  contrasts = list(drug = \"contr.sum\")\n)\n\n\nstats\nUsing the base stats package, you can use the drop1() function which drops all possible single terms in a model. The scope term specifies how things can be dropped.\n\nstats::drop1(model_ancova, scope = . ~ ., test = \"F\")\n\nSingle term deletions\n\nModel:\npost ~ drug + pre\n       Df Sum of Sq    RSS     AIC F value    Pr(&gt;F)    \n&lt;none&gt;              417.20  86.971                      \ndrug    2     68.55 485.76  87.535  2.1361    0.1384    \npre     1    577.90 995.10 111.049 36.0145 2.454e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\ncar\n\ncar::Anova(model_ancova, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: post\n            Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)  31.93  1  1.9898    0.1702    \ndrug         68.55  2  2.1361    0.1384    \npre         577.90  1 36.0145 2.454e-06 ***\nResiduals   417.20 26                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ndf_sas |&gt;\n  anova_test(post ~ drug + pre, type = 3, detailed = TRUE) |&gt;\n  get_anova_table() |&gt;\n  gt()\n\n\n\n\n\n\n\nEffect\nSSn\nSSd\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\n\n(Intercept)\n31.929\n417.203\n1\n26\n1.990\n1.70e-01\n\n0.071\n\n\ndrug\n68.554\n417.203\n2\n26\n2.136\n1.38e-01\n\n0.141\n\n\npre\n577.897\n417.203\n1\n26\n36.014\n2.45e-06\n*\n0.581\n\n\n\n\n\n\n\n\n\n\n\nLeast Squares Means\n\nmodel_ancova |&gt;\n  emmeans::lsmeans(\"drug\") |&gt;\n  emmeans::pwpm(pvals = TRUE, means = TRUE)\n\n        A       D       F\nA [ 6.71]  0.9980  0.1809\nD  -0.109 [ 6.82]  0.1893\nF  -3.446  -3.337 [10.16]\n\nRow and column labels: drug\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (lsmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nmodel_ancova |&gt;\n  emmeans::lsmeans(\"drug\") |&gt;\n  plot(comparisons = TRUE)"
  },
  {
    "objectID": "R/ancova.html#saslm-package",
    "href": "R/ancova.html#saslm-package",
    "title": "Ancova",
    "section": "sasLM Package",
    "text": "sasLM Package\nThe following code performs an ANCOVA analysis using the sasLM package. This package was written specifically to replicate SAS statistics. The console output is also organized in a manner that is similar to SAS.\n\nlibrary(sasLM)\n\nsasLM::GLM(post ~ drug + pre, df_sas, BETA = TRUE, EMEAN = TRUE)\n\n$ANOVA\nResponse : post\n                Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nMODEL            3  871.5 290.499  18.104 1.501e-06 ***\nRESIDUALS       26  417.2  16.046                      \nCORRECTED TOTAL 29 1288.7                              \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n$Fitness\n Root MSE post Mean Coef Var  R-square  Adj R-sq\n 4.005778       7.9 50.70604 0.6762609 0.6389064\n\n$`Type I`\n     Df Sum Sq Mean Sq F value    Pr(&gt;F)    \ndrug  2  293.6   146.8  9.1486 0.0009812 ***\npre   1  577.9   577.9 36.0145 2.454e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n$`Type II`\n     Df Sum Sq Mean Sq F value    Pr(&gt;F)    \ndrug  2  68.55   34.28  2.1361    0.1384    \npre   1 577.90  577.90 36.0145 2.454e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n$`Type III`\n     Df Sum Sq Mean Sq F value    Pr(&gt;F)    \ndrug  2  68.55   34.28  2.1361    0.1384    \npre   1 577.90  577.90 36.0145 2.454e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n$Parameter\n            Estimate Estimable Std. Error Df t value  Pr(&gt;|t|)    \n(Intercept)  -0.4347         0     2.4714 26 -0.1759   0.86175    \ndrugA        -3.4461         0     1.8868 26 -1.8265   0.07928 .  \ndrugD        -3.3372         0     1.8539 26 -1.8001   0.08346 .  \ndrugF         0.0000         0     0.0000 26                      \npre           0.9872         1     0.1645 26  6.0012 2.454e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n$`Expected Mean`\n               LSmean  LowerCL   UpperCL        SE Df\n(Intercept)  7.900000 6.396685  9.403315 0.7313516 26\ndrugA        6.714963 4.066426  9.363501 1.2884943 26\ndrugD        6.823935 4.208337  9.439532 1.2724690 26\ndrugF       10.161102 7.456182 12.866021 1.3159234 26\npre          7.900000 6.396685  9.403315 0.7313516 26\n\n\nNote that the LSMEANS statistics are produced using the EMEAN = TRUE option. The BETA = TRUE option is equivalent to the SOLUTION option in SAS. See the sasLM documentation for additional information.\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package * version date (UTC) lib source\n P broom   * 1.0.7   2024-09-26 [?] CRAN (R 4.4.1)\n   car       3.1-3   2024-09-27 [1] RSPM (R 4.4.0)\n P dplyr   * 1.1.4   2023-11-17 [?] CRAN (R 4.4.0)\n P emmeans * 1.10.4  2024-08-21 [?] CRAN (R 4.4.1)\n P gt      * 0.11.1  2024-10-04 [?] CRAN (R 4.4.1)\n P rstatix * 0.7.2   2023-02-01 [?] CRAN (R 4.4.0)\n P sasLM   * 0.10.5  2024-10-02 [?] CRAN (R 4.4.1)\n P tibble  * 3.2.1   2023-03-20 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/nonpara_wilcoxon_ranksum.html",
    "href": "R/nonpara_wilcoxon_ranksum.html",
    "title": "Wilcoxon Rank Sum (Mann Whitney-U) in R",
    "section": "",
    "text": "Wilcoxon rank sum test, or equivalently, Mann-Whitney U-test is a rank based non-parametric method. The aim is to compare two independent groups of observations. Under certain scenarios, it can be thought of as a test for median differences, however this is only valid when: 1) both samples are independent and identically distributed (same dispersion, same shape, not necessarily normal) and 2) are symmetric around their medians.\nGenerally, with two samples of observations (A and B), the test uses the mean of each possible pair of observations in each group (including the pair of each value with itself) to test if the probability that (A&gt;B) &gt; probability (B&gt;A).\nThe Wilcoxon rank sum test is often presented alongside a Hodges-Lehmann estimate of the pseudo-median (the median of the Walsh averages), and an associated confidence interval for the pseudo-median.\nA tie in the data exists when an observation in group A, has the same result as an observation in group B.\n\n\nThere are three main implementations of the Wilcoxon rank sum test in R.\n\nstats::wilcox.test()\ncoin::wilcox_test()\nasht::wmwTest()\n\nThe stats package implements various classic statistical tests, including Wilcoxon rank sum test. Although this is arguably the most commonly applied package, this one does not account for any ties in the data. To account for ties in the data, the coin or asht package should be used.\n\n# x, y are two unpaired vectors. Do not necessary need to be of the same length.\nstats::wilcox.test(x, y, paired = FALSE)\n\n\n\n\nData source: Table 30.4, Kirkwood BR. and Sterne JAC. Essentials of medical statistics. Second Edition. ISBN 978-0-86542-871-3\nComparison of birth weights (kg) of children born to 15 non-smokers with those of children born to 14 heavy smokers.\n\n# bw_ns: non smokers\n# bw_s: smokers\n# fmt: skip\nbw_ns &lt;- c(3.99, 3.89, 3.6, 3.73, 3.31, \n            3.7, 4.08, 3.61, 3.83, 3.41, \n            4.13, 3.36, 3.54, 3.51, 2.71)\n# fmt: skip\nbw_s &lt;- c(3.18, 2.74, 2.9, 3.27, 3.65, \n          3.42, 3.23, 2.86, 3.6, 3.65, \n          3.69, 3.53, 2.38, 2.34)\n\nWe do note that there are ties present in the data. Can visualize the data on two histograms. Red lines indicate the location of medians.\n\npar(mfrow = c(1, 2))\nhist(bw_ns, main = 'Birthweight: non-smokers')\nabline(v = median(bw_ns), col = 'red', lwd = 2)\nhist(bw_s, main = 'Birthweight: smokers')\nabline(v = median(bw_s), col = 'red', lwd = 2)\n\n\n\n\n\n\n\n\nIt is possible to see that for non-smokers, the median birthweight is higher than those of smokers. Now we can formally test it with wilcoxon rank sum test.\n\n\n\nIn stats::wilcox.test() the exact p-value is computed when there are less than 50 values and no ties otherwise the normal approximation is used. In our data case, because there are ties the normal approximation is used.\nThe default for the normal approximation is to use a continuity correction. One can add the argument correct=FALSE to not perform a continuity correction.\n\n# default is two sided\nstats::wilcox.test(bw_s, bw_ns, paired = FALSE)\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE): cannot compute\nexact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  bw_s and bw_ns\nW = 45.5, p-value = 0.01001\nalternative hypothesis: true location shift is not equal to 0\n\nstats::wilcox.test(bw_s, bw_ns, paired = FALSE, correct = FALSE)\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE, correct = FALSE):\ncannot compute exact p-value with ties\n\n\n\n    Wilcoxon rank sum test\n\ndata:  bw_s and bw_ns\nW = 45.5, p-value = 0.009392\nalternative hypothesis: true location shift is not equal to 0\n\n\nWe can also carry out a one-sided test, by specifying alternative = \"less\" (if the first group is expected to be smaller than the second group) or alternative = \"greater\".\n\n# perform one-sided test\nstats::wilcox.test(bw_s, bw_ns, paired = FALSE, alternative = \"less\")\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE, alternative =\n\"less\"): cannot compute exact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  bw_s and bw_ns\nW = 45.5, p-value = 0.005003\nalternative hypothesis: true location shift is less than 0\n\n\nBy setting conf.int=TRUE a confidence interval of the location parameter (x-y) is computed. Note that in the two-sample case the estimator for the difference in location parameters does not estimate the difference in medians (a common misconception) but rather the median of the difference between a sample from x and a sample from y. Note that the algorithm used for the estimation of the location parameter and confidence interval is not discussed in the help of the function (in the source code of the stats::wilcox.test() it is only mentioned that “Algorithm not published, thus better documented here.”).\nBy default a 95% confidence interval is provided. This can be changed by the argument conf.level.\n\n# Add conf.int = TRUE\nstats::wilcox.test(bw_s, bw_ns, paired = FALSE, conf.int = TRUE)\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE, conf.int = TRUE):\ncannot compute exact p-value with ties\n\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE, conf.int = TRUE):\ncannot compute exact confidence intervals with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  bw_s and bw_ns\nW = 45.5, p-value = 0.01001\nalternative hypothesis: true location shift is not equal to 0\n95 percent confidence interval:\n -0.76995896 -0.09000999\nsample estimates:\ndifference in location \n            -0.4261377 \n\n\nThe argument exact = TRUE can be added to ask for an exact p-value to be computed. However, in our data case as there are ties this does not work.\n\n# force exact, but does not work because we have ties\nstats::wilcox.test(bw_s, bw_ns, paired = FALSE, conf.int = TRUE, exact = TRUE)\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE, conf.int = TRUE, :\ncannot compute exact p-value with ties\n\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE, conf.int = TRUE, :\ncannot compute exact confidence intervals with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  bw_s and bw_ns\nW = 45.5, p-value = 0.01001\nalternative hypothesis: true location shift is not equal to 0\n95 percent confidence interval:\n -0.76995896 -0.09000999\nsample estimates:\ndifference in location \n            -0.4261377 \n\n\n\n\n\nIn order to account for the ties, wilcox_test from the coin package should be used. For this function, the data needs to be inputted via a formula where the right hand side is a factor, so we need to create a dataset. In order to get results for smokers - non-smokers we need to relevel the factors.\n\nsmk_data &lt;- data.frame(\n  value = c(bw_ns, bw_s),\n  smoke = as.factor(rep(c(\"non\", \"smoke\"), c(length(bw_ns), length(bw_s))))\n)\nsmk_data$smoke &lt;- forcats::fct_relevel(smk_data$smoke, \"smoke\")\nsmk_data$smoke\n\n [1] non   non   non   non   non   non   non   non   non   non   non   non  \n[13] non   non   non   smoke smoke smoke smoke smoke smoke smoke smoke smoke\n[25] smoke smoke smoke smoke smoke\nLevels: smoke non\n\n\nNow the data is in the right shape we can run wilcox_test. By default, coin::wilcox_test does a normal approximation approach without continuity correction. One can add again alternative=\"less\" (or alternative=\"greater\") for one-sided testing.\n\ncoin::wilcox_test(value ~ smoke, data = smk_data)\n\n\n    Asymptotic Wilcoxon-Mann-Whitney Test\n\ndata:  value by smoke (smoke, non)\nZ = -2.5974, p-value = 0.009392\nalternative hypothesis: true mu is not equal to 0\n\n\nWe do note that a normal approximation approach with continuity correction cannot be obtained with this function. One can add correct=TRUE, but note that no error is given and the results of a normal approximation approach without continuity correction is provided.\n\ncoin::wilcox_test(value ~ smoke, data = smk_data, correct = TRUE)\n\n\n    Asymptotic Wilcoxon-Mann-Whitney Test\n\ndata:  value by smoke (smoke, non)\nZ = -2.5974, p-value = 0.009392\nalternative hypothesis: true mu is not equal to 0\n\n\nBy including the conf.int = TRUE argument, confidence intervals for the difference in location are computed. According to the coin package documentation this is done according to Bauer (1972) [Bauer, D. F. (1972). Constructing confidence sets using rank statistics. Journal of the American Statistical Association 67(339), 687–690] and Hollander and Wolfe (1999) [Hollander, M. and Wolfe, D. A. (1999). Nonparametric Statistical Methods, Second Edition. New York: John Wiley & Sons.]. Note that the conf.level argument controls the confidence level, but must be used with conf.int = TRUE otherwise you won’t get a confidence interval.\n\ncoin::wilcox_test(value ~ smoke, data = smk_data, conf.int = TRUE)\n\n\n    Asymptotic Wilcoxon-Mann-Whitney Test\n\ndata:  value by smoke (smoke, non)\nZ = -2.5974, p-value = 0.009392\nalternative hypothesis: true mu is not equal to 0\n95 percent confidence interval:\n -0.76000001 -0.09999999\nsample estimates:\ndifference in location \n            -0.4261403 \n\n\nUsing coin one can calculate exact and Monte Carlo conditional p-values using the distribution argument. The exact p-value is best used in small sample sizes.\n\ncoin::wilcox_test(\n  value ~ smoke,\n  data = smk_data,\n  conf.int = TRUE,\n  distribution = \"exact\"\n)\n\n\n    Exact Wilcoxon-Mann-Whitney Test\n\ndata:  value by smoke (smoke, non)\nZ = -2.5974, p-value = 0.008181\nalternative hypothesis: true mu is not equal to 0\n95 percent confidence interval:\n -0.76 -0.10\nsample estimates:\ndifference in location \n                -0.425 \n\n\nFor doing an approximative (Monte Carlo) (with 500 and 500000 samples) the following code can be used.\n\ncoin::wilcox_test(\n  value ~ smoke,\n  data = smk_data,\n  conf.int = TRUE,\n  distribution = approximate(nresample = 500)\n)\n\n\n    Approximative Wilcoxon-Mann-Whitney Test\n\ndata:  value by smoke (smoke, non)\nZ = -2.5974, p-value = 0.004\nalternative hypothesis: true mu is not equal to 0\n95 percent confidence interval:\n -0.71 -0.10\nsample estimates:\ndifference in location \n                -0.425 \n\ncoin::wilcox_test(\n  value ~ smoke,\n  data = smk_data,\n  conf.int = TRUE,\n  distribution = approximate(nresample = 500000)\n)\n\n\n    Approximative Wilcoxon-Mann-Whitney Test\n\ndata:  value by smoke (smoke, non)\nZ = -2.5974, p-value = 0.00827\nalternative hypothesis: true mu is not equal to 0\n95 percent confidence interval:\n -0.77 -0.10\nsample estimates:\ndifference in location \n                -0.425 \n\n\n\n\n\n\nThe asht::wmwTest() function calculates the Wilcoxon-Mann-Whitney test (normal approximation, exact complete enumeration, and exact Monte Carlo implementation) together with confidence intervals on the Mann-Whitney parameter, Pr[X&lt;Y] + 0.5 Pr[X=Y].\nBy default, the function returns the normal approximation using a continuity correction when \\(combination(m+n, m)&gt;5000\\), where \\(m\\) and \\(n\\) are the sample sizes in the two groups, respectively. Otherwise by default (thus for small sample sizes), the exact Wilcoxon rank sum test is performed. The correct argument is available to turn-off the continuity correction. The alternative argument is available for one-sided testing. By default, the 95% confidence interval is calculated for the Mann-Whitney parameter (use argument conf.int and conf.level to change these defaults.). Details on the calculation of the confidence interval are provided in Newcombe (2006) [Newcombe, Robert G. (2006). Confidence intervals for an effect size measure based on the Mann-Whitney statistic. Part 2: asymptotic methods and evaluation. Statistics in medicine 25(4): 559-573].\n\nasht::wmwTest(bw_s, bw_ns)\n\n\n    Wilcoxon-Mann-Whitney test with continuity correction (confidence\n    interval requires proportional odds assumption, but test does not)\n\ndata:  bw_s and bw_ns\nMann-Whitney estimate = 0.78333, tie factor = 0.99951, p-value =\n0.01001\nalternative hypothesis: two distributions are not equal\n95 percent confidence interval:\n 0.5696522 0.9030435\nsample estimates:\nMann-Whitney estimate \n            0.7833333 \n\n\nUsing the method argument one can change from normal approximation to exact complete enumeration (method = \"exact.ce\"), and exact Monte Carlo (method = \"exact.mc\") implementation. When method = \"exact.mc\", the test is implemented using complete enumeration of all permutations, and hence is only tractible for very small sample sizes (less than 10 in each group). Here, we show an example of method = \"exact.mc\".\n\nasht::wmwTest(\n  bw_s,\n  bw_ns,\n  method = \"exact.mc\",\n  control = asht::wmwControl(nMC = 100000)\n)\n\n\n    exact Wilcoxon-Man-Whitney test (Monte Carlo with nMC=1e+05)\n    (confidence interval requires proportional odds assumption, but test\n    does not)\n\ndata:  bw_s and bw_ns\nMann-Whitney estimate = 0.78333, p-value = 0.00768\nalternative hypothesis: two distributions are not equal\n95 percent confidence interval:\n 0.5794248 0.9237564\nsample estimates:\nMann-Whitney estimate \n            0.7833333 \n\n\n\n\n\n\nMethods and Formulae\nMann Whitney is not about medians in general\nRelationship between walsh averages and WRS\nHodges Lehmann Problems"
  },
  {
    "objectID": "R/nonpara_wilcoxon_ranksum.html#available-r-packages",
    "href": "R/nonpara_wilcoxon_ranksum.html#available-r-packages",
    "title": "Wilcoxon Rank Sum (Mann Whitney-U) in R",
    "section": "",
    "text": "There are three main implementations of the Wilcoxon rank sum test in R.\n\nstats::wilcox.test()\ncoin::wilcox_test()\nasht::wmwTest()\n\nThe stats package implements various classic statistical tests, including Wilcoxon rank sum test. Although this is arguably the most commonly applied package, this one does not account for any ties in the data. To account for ties in the data, the coin or asht package should be used.\n\n# x, y are two unpaired vectors. Do not necessary need to be of the same length.\nstats::wilcox.test(x, y, paired = FALSE)"
  },
  {
    "objectID": "R/nonpara_wilcoxon_ranksum.html#example-birth-weight",
    "href": "R/nonpara_wilcoxon_ranksum.html#example-birth-weight",
    "title": "Wilcoxon Rank Sum (Mann Whitney-U) in R",
    "section": "",
    "text": "Data source: Table 30.4, Kirkwood BR. and Sterne JAC. Essentials of medical statistics. Second Edition. ISBN 978-0-86542-871-3\nComparison of birth weights (kg) of children born to 15 non-smokers with those of children born to 14 heavy smokers.\n\n# bw_ns: non smokers\n# bw_s: smokers\n# fmt: skip\nbw_ns &lt;- c(3.99, 3.89, 3.6, 3.73, 3.31, \n            3.7, 4.08, 3.61, 3.83, 3.41, \n            4.13, 3.36, 3.54, 3.51, 2.71)\n# fmt: skip\nbw_s &lt;- c(3.18, 2.74, 2.9, 3.27, 3.65, \n          3.42, 3.23, 2.86, 3.6, 3.65, \n          3.69, 3.53, 2.38, 2.34)\n\nWe do note that there are ties present in the data. Can visualize the data on two histograms. Red lines indicate the location of medians.\n\npar(mfrow = c(1, 2))\nhist(bw_ns, main = 'Birthweight: non-smokers')\nabline(v = median(bw_ns), col = 'red', lwd = 2)\nhist(bw_s, main = 'Birthweight: smokers')\nabline(v = median(bw_s), col = 'red', lwd = 2)\n\n\n\n\n\n\n\n\nIt is possible to see that for non-smokers, the median birthweight is higher than those of smokers. Now we can formally test it with wilcoxon rank sum test."
  },
  {
    "objectID": "R/nonpara_wilcoxon_ranksum.html#statswilcox.test",
    "href": "R/nonpara_wilcoxon_ranksum.html#statswilcox.test",
    "title": "Wilcoxon Rank Sum (Mann Whitney-U) in R",
    "section": "",
    "text": "In stats::wilcox.test() the exact p-value is computed when there are less than 50 values and no ties otherwise the normal approximation is used. In our data case, because there are ties the normal approximation is used.\nThe default for the normal approximation is to use a continuity correction. One can add the argument correct=FALSE to not perform a continuity correction.\n\n# default is two sided\nstats::wilcox.test(bw_s, bw_ns, paired = FALSE)\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE): cannot compute\nexact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  bw_s and bw_ns\nW = 45.5, p-value = 0.01001\nalternative hypothesis: true location shift is not equal to 0\n\nstats::wilcox.test(bw_s, bw_ns, paired = FALSE, correct = FALSE)\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE, correct = FALSE):\ncannot compute exact p-value with ties\n\n\n\n    Wilcoxon rank sum test\n\ndata:  bw_s and bw_ns\nW = 45.5, p-value = 0.009392\nalternative hypothesis: true location shift is not equal to 0\n\n\nWe can also carry out a one-sided test, by specifying alternative = \"less\" (if the first group is expected to be smaller than the second group) or alternative = \"greater\".\n\n# perform one-sided test\nstats::wilcox.test(bw_s, bw_ns, paired = FALSE, alternative = \"less\")\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE, alternative =\n\"less\"): cannot compute exact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  bw_s and bw_ns\nW = 45.5, p-value = 0.005003\nalternative hypothesis: true location shift is less than 0\n\n\nBy setting conf.int=TRUE a confidence interval of the location parameter (x-y) is computed. Note that in the two-sample case the estimator for the difference in location parameters does not estimate the difference in medians (a common misconception) but rather the median of the difference between a sample from x and a sample from y. Note that the algorithm used for the estimation of the location parameter and confidence interval is not discussed in the help of the function (in the source code of the stats::wilcox.test() it is only mentioned that “Algorithm not published, thus better documented here.”).\nBy default a 95% confidence interval is provided. This can be changed by the argument conf.level.\n\n# Add conf.int = TRUE\nstats::wilcox.test(bw_s, bw_ns, paired = FALSE, conf.int = TRUE)\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE, conf.int = TRUE):\ncannot compute exact p-value with ties\n\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE, conf.int = TRUE):\ncannot compute exact confidence intervals with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  bw_s and bw_ns\nW = 45.5, p-value = 0.01001\nalternative hypothesis: true location shift is not equal to 0\n95 percent confidence interval:\n -0.76995896 -0.09000999\nsample estimates:\ndifference in location \n            -0.4261377 \n\n\nThe argument exact = TRUE can be added to ask for an exact p-value to be computed. However, in our data case as there are ties this does not work.\n\n# force exact, but does not work because we have ties\nstats::wilcox.test(bw_s, bw_ns, paired = FALSE, conf.int = TRUE, exact = TRUE)\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE, conf.int = TRUE, :\ncannot compute exact p-value with ties\n\n\nWarning in wilcox.test.default(bw_s, bw_ns, paired = FALSE, conf.int = TRUE, :\ncannot compute exact confidence intervals with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  bw_s and bw_ns\nW = 45.5, p-value = 0.01001\nalternative hypothesis: true location shift is not equal to 0\n95 percent confidence interval:\n -0.76995896 -0.09000999\nsample estimates:\ndifference in location \n            -0.4261377"
  },
  {
    "objectID": "R/nonpara_wilcoxon_ranksum.html#coinwilcox_test",
    "href": "R/nonpara_wilcoxon_ranksum.html#coinwilcox_test",
    "title": "Wilcoxon Rank Sum (Mann Whitney-U) in R",
    "section": "",
    "text": "In order to account for the ties, wilcox_test from the coin package should be used. For this function, the data needs to be inputted via a formula where the right hand side is a factor, so we need to create a dataset. In order to get results for smokers - non-smokers we need to relevel the factors.\n\nsmk_data &lt;- data.frame(\n  value = c(bw_ns, bw_s),\n  smoke = as.factor(rep(c(\"non\", \"smoke\"), c(length(bw_ns), length(bw_s))))\n)\nsmk_data$smoke &lt;- forcats::fct_relevel(smk_data$smoke, \"smoke\")\nsmk_data$smoke\n\n [1] non   non   non   non   non   non   non   non   non   non   non   non  \n[13] non   non   non   smoke smoke smoke smoke smoke smoke smoke smoke smoke\n[25] smoke smoke smoke smoke smoke\nLevels: smoke non\n\n\nNow the data is in the right shape we can run wilcox_test. By default, coin::wilcox_test does a normal approximation approach without continuity correction. One can add again alternative=\"less\" (or alternative=\"greater\") for one-sided testing.\n\ncoin::wilcox_test(value ~ smoke, data = smk_data)\n\n\n    Asymptotic Wilcoxon-Mann-Whitney Test\n\ndata:  value by smoke (smoke, non)\nZ = -2.5974, p-value = 0.009392\nalternative hypothesis: true mu is not equal to 0\n\n\nWe do note that a normal approximation approach with continuity correction cannot be obtained with this function. One can add correct=TRUE, but note that no error is given and the results of a normal approximation approach without continuity correction is provided.\n\ncoin::wilcox_test(value ~ smoke, data = smk_data, correct = TRUE)\n\n\n    Asymptotic Wilcoxon-Mann-Whitney Test\n\ndata:  value by smoke (smoke, non)\nZ = -2.5974, p-value = 0.009392\nalternative hypothesis: true mu is not equal to 0\n\n\nBy including the conf.int = TRUE argument, confidence intervals for the difference in location are computed. According to the coin package documentation this is done according to Bauer (1972) [Bauer, D. F. (1972). Constructing confidence sets using rank statistics. Journal of the American Statistical Association 67(339), 687–690] and Hollander and Wolfe (1999) [Hollander, M. and Wolfe, D. A. (1999). Nonparametric Statistical Methods, Second Edition. New York: John Wiley & Sons.]. Note that the conf.level argument controls the confidence level, but must be used with conf.int = TRUE otherwise you won’t get a confidence interval.\n\ncoin::wilcox_test(value ~ smoke, data = smk_data, conf.int = TRUE)\n\n\n    Asymptotic Wilcoxon-Mann-Whitney Test\n\ndata:  value by smoke (smoke, non)\nZ = -2.5974, p-value = 0.009392\nalternative hypothesis: true mu is not equal to 0\n95 percent confidence interval:\n -0.76000001 -0.09999999\nsample estimates:\ndifference in location \n            -0.4261403 \n\n\nUsing coin one can calculate exact and Monte Carlo conditional p-values using the distribution argument. The exact p-value is best used in small sample sizes.\n\ncoin::wilcox_test(\n  value ~ smoke,\n  data = smk_data,\n  conf.int = TRUE,\n  distribution = \"exact\"\n)\n\n\n    Exact Wilcoxon-Mann-Whitney Test\n\ndata:  value by smoke (smoke, non)\nZ = -2.5974, p-value = 0.008181\nalternative hypothesis: true mu is not equal to 0\n95 percent confidence interval:\n -0.76 -0.10\nsample estimates:\ndifference in location \n                -0.425 \n\n\nFor doing an approximative (Monte Carlo) (with 500 and 500000 samples) the following code can be used.\n\ncoin::wilcox_test(\n  value ~ smoke,\n  data = smk_data,\n  conf.int = TRUE,\n  distribution = approximate(nresample = 500)\n)\n\n\n    Approximative Wilcoxon-Mann-Whitney Test\n\ndata:  value by smoke (smoke, non)\nZ = -2.5974, p-value = 0.004\nalternative hypothesis: true mu is not equal to 0\n95 percent confidence interval:\n -0.71 -0.10\nsample estimates:\ndifference in location \n                -0.425 \n\ncoin::wilcox_test(\n  value ~ smoke,\n  data = smk_data,\n  conf.int = TRUE,\n  distribution = approximate(nresample = 500000)\n)\n\n\n    Approximative Wilcoxon-Mann-Whitney Test\n\ndata:  value by smoke (smoke, non)\nZ = -2.5974, p-value = 0.00827\nalternative hypothesis: true mu is not equal to 0\n95 percent confidence interval:\n -0.77 -0.10\nsample estimates:\ndifference in location \n                -0.425"
  },
  {
    "objectID": "R/nonpara_wilcoxon_ranksum.html#ashtwmwtest",
    "href": "R/nonpara_wilcoxon_ranksum.html#ashtwmwtest",
    "title": "Wilcoxon Rank Sum (Mann Whitney-U) in R",
    "section": "",
    "text": "The asht::wmwTest() function calculates the Wilcoxon-Mann-Whitney test (normal approximation, exact complete enumeration, and exact Monte Carlo implementation) together with confidence intervals on the Mann-Whitney parameter, Pr[X&lt;Y] + 0.5 Pr[X=Y].\nBy default, the function returns the normal approximation using a continuity correction when \\(combination(m+n, m)&gt;5000\\), where \\(m\\) and \\(n\\) are the sample sizes in the two groups, respectively. Otherwise by default (thus for small sample sizes), the exact Wilcoxon rank sum test is performed. The correct argument is available to turn-off the continuity correction. The alternative argument is available for one-sided testing. By default, the 95% confidence interval is calculated for the Mann-Whitney parameter (use argument conf.int and conf.level to change these defaults.). Details on the calculation of the confidence interval are provided in Newcombe (2006) [Newcombe, Robert G. (2006). Confidence intervals for an effect size measure based on the Mann-Whitney statistic. Part 2: asymptotic methods and evaluation. Statistics in medicine 25(4): 559-573].\n\nasht::wmwTest(bw_s, bw_ns)\n\n\n    Wilcoxon-Mann-Whitney test with continuity correction (confidence\n    interval requires proportional odds assumption, but test does not)\n\ndata:  bw_s and bw_ns\nMann-Whitney estimate = 0.78333, tie factor = 0.99951, p-value =\n0.01001\nalternative hypothesis: two distributions are not equal\n95 percent confidence interval:\n 0.5696522 0.9030435\nsample estimates:\nMann-Whitney estimate \n            0.7833333 \n\n\nUsing the method argument one can change from normal approximation to exact complete enumeration (method = \"exact.ce\"), and exact Monte Carlo (method = \"exact.mc\") implementation. When method = \"exact.mc\", the test is implemented using complete enumeration of all permutations, and hence is only tractible for very small sample sizes (less than 10 in each group). Here, we show an example of method = \"exact.mc\".\n\nasht::wmwTest(\n  bw_s,\n  bw_ns,\n  method = \"exact.mc\",\n  control = asht::wmwControl(nMC = 100000)\n)\n\n\n    exact Wilcoxon-Man-Whitney test (Monte Carlo with nMC=1e+05)\n    (confidence interval requires proportional odds assumption, but test\n    does not)\n\ndata:  bw_s and bw_ns\nMann-Whitney estimate = 0.78333, p-value = 0.00768\nalternative hypothesis: two distributions are not equal\n95 percent confidence interval:\n 0.5794248 0.9237564\nsample estimates:\nMann-Whitney estimate \n            0.7833333"
  },
  {
    "objectID": "R/nonpara_wilcoxon_ranksum.html#useful-references",
    "href": "R/nonpara_wilcoxon_ranksum.html#useful-references",
    "title": "Wilcoxon Rank Sum (Mann Whitney-U) in R",
    "section": "",
    "text": "Methods and Formulae\nMann Whitney is not about medians in general\nRelationship between walsh averages and WRS\nHodges Lehmann Problems"
  },
  {
    "objectID": "R/mmrm.html",
    "href": "R/mmrm.html",
    "title": "MMRM in R",
    "section": "",
    "text": "Mixed models for repeated measures (MMRM) are a popular choice for analyzing longitudinal continuous outcomes in randomized clinical trials and beyond; see Cnaan, Laird and Slasor (1997) for a tutorial and Mallinckrodt, Lane and Schnell (2008) for a review.\nThis vignette shows examples from the mmrm package.\nThe mmrm package implements MMRM based on the marginal linear model without random effects using Template Model Builder (TMB) which enables fast and robust model fitting. Users can specify a variety of covariance matrices, weight observations, fit models with restricted or standard maximum likelihood inference, perform hypothesis testing with Satterthwaite or Kenward-Roger adjustment, and extract least square means estimates by using emmeans.\n\n\n\nFlexible covariance specification:\n\nStructures: unstructured, Toeplitz, AR1, compound symmetry, ante-dependence, and spatial exponential.\nGroups: shared covariance structure for all subjects or group-specific covariance estimates.\nVariances: homogeneous or heterogeneous across time points.\n\nInference:\n\nSupports REML and ML.\nSupports weights.\n\nHypothesis testing:\n\nLeast square means: can be obtained with the emmeans package\nOne- and multi-dimensional linear contrasts of model parameters can be tested.\nSatterthwaite adjusted degrees of freedom.\nKenward-Roger adjusted degrees of freedom and coefficients covariance matrix.\nCoefficient Covariance\n\nC++ backend:\n\nFast implementation using C++ and automatic differentiation to obtain precise gradient information for model fitting.\nModel fitting algorithm details used in mmrm.\n\nPackage ecosystems integration:\n\nIntegration with tidymodels package ecosystem\n\nDedicated parsnip engine for linear regression\nIntegration with recipes\n\nIntegration with tern package ecosystems\n\nThe tern.mmrm package can be used to run the mmrm fit and generate tabulation and plots of least square means per visit and treatment arm, tabulation of model diagnostics, diagnostic graphs, and other standard model outputs.\n\n\n\n\n\n\nSee also the introductory vignette\nThe code below implements an MMRM fit in R with the mmrm::mmrm function.\n\nlibrary(mmrm)\nfit &lt;- mmrm::mmrm(\n  formula = FEV1 ~ RACE + SEX + ARMCD * AVISIT + us(AVISIT | USUBJID),\n  data = fev_data\n)\n\nThe code specifies an MMRM with the given covariates and an unstructured covariance matrix for the timepoints (also called visits in the clinical trial context, here given by AVISIT) within the subjects (here USUBJID). While by default this uses restricted maximum likelihood (REML), it is also possible to use ML, see ?mmrm.\nPrinting the object will show you output which should be familiar to anyone who has used any popular modeling functions such as stats::lm(), stats::glm(), glmmTMB::glmmTMB(), and lme4::nlmer(). From this print out we see the function call, the data used, the covariance structure with number of variance parameters, as well as the likelihood method, and model deviance achieved. Additionally the user is provided a printout of the estimated coefficients and the model convergence information:\n\nfit\n\nmmrm fit\n\nFormula:     FEV1 ~ RACE + SEX + ARMCD * AVISIT + us(AVISIT | USUBJID)\nData:        fev_data (used 537 observations from 197 subjects with maximum 4 \ntimepoints)\nCovariance:  unstructured (10 variance parameters)\nInference:   REML\nDeviance:    3386.45\n\nCoefficients: \n                  (Intercept) RACEBlack or African American \n                  30.77747548                    1.53049977 \n                    RACEWhite                     SEXFemale \n                   5.64356535                    0.32606192 \n                     ARMCDTRT                    AVISITVIS2 \n                   3.77423004                    4.83958845 \n                   AVISITVIS3                    AVISITVIS4 \n                  10.34211288                   15.05389826 \n          ARMCDTRT:AVISITVIS2           ARMCDTRT:AVISITVIS3 \n                  -0.04192625                   -0.69368537 \n          ARMCDTRT:AVISITVIS4 \n                   0.62422703 \n\nModel Inference Optimization:\nConverged with code 0 and message: convergence: rel_reduction_of_f &lt;= factr*epsmch\n\n\nThe summary() method then provides the coefficients table with Satterthwaite degrees of freedom as well as the covariance matrix estimate:\n\nfit |&gt;\n  summary()\n\nmmrm fit\n\nFormula:     FEV1 ~ RACE + SEX + ARMCD * AVISIT + us(AVISIT | USUBJID)\nData:        fev_data (used 537 observations from 197 subjects with maximum 4 \ntimepoints)\nCovariance:  unstructured (10 variance parameters)\nMethod:      Satterthwaite\nVcov Method: Asymptotic\nInference:   REML\n\nModel selection criteria:\n     AIC      BIC   logLik deviance \n  3406.4   3439.3  -1693.2   3386.4 \n\nCoefficients: \n                               Estimate Std. Error        df t value Pr(&gt;|t|)\n(Intercept)                    30.77748    0.88656 218.80000  34.715  &lt; 2e-16\nRACEBlack or African American   1.53050    0.62448 168.67000   2.451 0.015272\nRACEWhite                       5.64357    0.66561 157.14000   8.479 1.56e-14\nSEXFemale                       0.32606    0.53195 166.13000   0.613 0.540744\nARMCDTRT                        3.77423    1.07415 145.55000   3.514 0.000589\nAVISITVIS2                      4.83959    0.80172 143.88000   6.037 1.27e-08\nAVISITVIS3                     10.34211    0.82269 155.56000  12.571  &lt; 2e-16\nAVISITVIS4                     15.05390    1.31281 138.47000  11.467  &lt; 2e-16\nARMCDTRT:AVISITVIS2            -0.04193    1.12932 138.56000  -0.037 0.970439\nARMCDTRT:AVISITVIS3            -0.69369    1.18765 158.17000  -0.584 0.559996\nARMCDTRT:AVISITVIS4             0.62423    1.85085 129.72000   0.337 0.736463\n                                 \n(Intercept)                   ***\nRACEBlack or African American *  \nRACEWhite                     ***\nSEXFemale                        \nARMCDTRT                      ***\nAVISITVIS2                    ***\nAVISITVIS3                    ***\nAVISITVIS4                    ***\nARMCDTRT:AVISITVIS2              \nARMCDTRT:AVISITVIS3              \nARMCDTRT:AVISITVIS4              \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCovariance estimate:\n        VIS1    VIS2    VIS3    VIS4\nVIS1 40.5537 14.3960  4.9747 13.3867\nVIS2 14.3960 26.5715  2.7855  7.4745\nVIS3  4.9747  2.7855 14.8979  0.9082\nVIS4 13.3867  7.4745  0.9082 95.5568\n\n\n\n\n\nIn order to extract relevant marginal means (LSmeans) and contrasts we can use the emmeans package. This package includes methods that allow mmrm objects to be used with the emmeans package. emmeans computes estimated marginal means (also called least-square means) for the coefficients of the MMRM.\n\nlibrary(emmeans)\n\nmmrm() registered as emmeans extension\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nemmeans(fit, ~ ARMCD | AVISIT)\n\nAVISIT = VIS1:\n ARMCD emmean    SE  df lower.CL upper.CL\n PBO     33.3 0.755 148     31.8     34.8\n TRT     37.1 0.763 143     35.6     38.6\n\nAVISIT = VIS2:\n ARMCD emmean    SE  df lower.CL upper.CL\n PBO     38.2 0.612 147     37.0     39.4\n TRT     41.9 0.602 143     40.7     43.1\n\nAVISIT = VIS3:\n ARMCD emmean    SE  df lower.CL upper.CL\n PBO     43.7 0.462 130     42.8     44.6\n TRT     46.8 0.509 130     45.7     47.8\n\nAVISIT = VIS4:\n ARMCD emmean    SE  df lower.CL upper.CL\n PBO     48.4 1.189 134     46.0     50.7\n TRT     52.8 1.188 133     50.4     55.1\n\nResults are averaged over the levels of: RACE, SEX \nConfidence level used: 0.95 \n\n\nNote that the degrees of freedom choice is inherited here from the initial mmrm fit."
  },
  {
    "objectID": "R/mmrm.html#fitting-the-mmrm-in-r",
    "href": "R/mmrm.html#fitting-the-mmrm-in-r",
    "title": "MMRM in R",
    "section": "",
    "text": "Mixed models for repeated measures (MMRM) are a popular choice for analyzing longitudinal continuous outcomes in randomized clinical trials and beyond; see Cnaan, Laird and Slasor (1997) for a tutorial and Mallinckrodt, Lane and Schnell (2008) for a review.\nThis vignette shows examples from the mmrm package.\nThe mmrm package implements MMRM based on the marginal linear model without random effects using Template Model Builder (TMB) which enables fast and robust model fitting. Users can specify a variety of covariance matrices, weight observations, fit models with restricted or standard maximum likelihood inference, perform hypothesis testing with Satterthwaite or Kenward-Roger adjustment, and extract least square means estimates by using emmeans.\n\n\n\nFlexible covariance specification:\n\nStructures: unstructured, Toeplitz, AR1, compound symmetry, ante-dependence, and spatial exponential.\nGroups: shared covariance structure for all subjects or group-specific covariance estimates.\nVariances: homogeneous or heterogeneous across time points.\n\nInference:\n\nSupports REML and ML.\nSupports weights.\n\nHypothesis testing:\n\nLeast square means: can be obtained with the emmeans package\nOne- and multi-dimensional linear contrasts of model parameters can be tested.\nSatterthwaite adjusted degrees of freedom.\nKenward-Roger adjusted degrees of freedom and coefficients covariance matrix.\nCoefficient Covariance\n\nC++ backend:\n\nFast implementation using C++ and automatic differentiation to obtain precise gradient information for model fitting.\nModel fitting algorithm details used in mmrm.\n\nPackage ecosystems integration:\n\nIntegration with tidymodels package ecosystem\n\nDedicated parsnip engine for linear regression\nIntegration with recipes\n\nIntegration with tern package ecosystems\n\nThe tern.mmrm package can be used to run the mmrm fit and generate tabulation and plots of least square means per visit and treatment arm, tabulation of model diagnostics, diagnostic graphs, and other standard model outputs.\n\n\n\n\n\n\nSee also the introductory vignette\nThe code below implements an MMRM fit in R with the mmrm::mmrm function.\n\nlibrary(mmrm)\nfit &lt;- mmrm::mmrm(\n  formula = FEV1 ~ RACE + SEX + ARMCD * AVISIT + us(AVISIT | USUBJID),\n  data = fev_data\n)\n\nThe code specifies an MMRM with the given covariates and an unstructured covariance matrix for the timepoints (also called visits in the clinical trial context, here given by AVISIT) within the subjects (here USUBJID). While by default this uses restricted maximum likelihood (REML), it is also possible to use ML, see ?mmrm.\nPrinting the object will show you output which should be familiar to anyone who has used any popular modeling functions such as stats::lm(), stats::glm(), glmmTMB::glmmTMB(), and lme4::nlmer(). From this print out we see the function call, the data used, the covariance structure with number of variance parameters, as well as the likelihood method, and model deviance achieved. Additionally the user is provided a printout of the estimated coefficients and the model convergence information:\n\nfit\n\nmmrm fit\n\nFormula:     FEV1 ~ RACE + SEX + ARMCD * AVISIT + us(AVISIT | USUBJID)\nData:        fev_data (used 537 observations from 197 subjects with maximum 4 \ntimepoints)\nCovariance:  unstructured (10 variance parameters)\nInference:   REML\nDeviance:    3386.45\n\nCoefficients: \n                  (Intercept) RACEBlack or African American \n                  30.77747548                    1.53049977 \n                    RACEWhite                     SEXFemale \n                   5.64356535                    0.32606192 \n                     ARMCDTRT                    AVISITVIS2 \n                   3.77423004                    4.83958845 \n                   AVISITVIS3                    AVISITVIS4 \n                  10.34211288                   15.05389826 \n          ARMCDTRT:AVISITVIS2           ARMCDTRT:AVISITVIS3 \n                  -0.04192625                   -0.69368537 \n          ARMCDTRT:AVISITVIS4 \n                   0.62422703 \n\nModel Inference Optimization:\nConverged with code 0 and message: convergence: rel_reduction_of_f &lt;= factr*epsmch\n\n\nThe summary() method then provides the coefficients table with Satterthwaite degrees of freedom as well as the covariance matrix estimate:\n\nfit |&gt;\n  summary()\n\nmmrm fit\n\nFormula:     FEV1 ~ RACE + SEX + ARMCD * AVISIT + us(AVISIT | USUBJID)\nData:        fev_data (used 537 observations from 197 subjects with maximum 4 \ntimepoints)\nCovariance:  unstructured (10 variance parameters)\nMethod:      Satterthwaite\nVcov Method: Asymptotic\nInference:   REML\n\nModel selection criteria:\n     AIC      BIC   logLik deviance \n  3406.4   3439.3  -1693.2   3386.4 \n\nCoefficients: \n                               Estimate Std. Error        df t value Pr(&gt;|t|)\n(Intercept)                    30.77748    0.88656 218.80000  34.715  &lt; 2e-16\nRACEBlack or African American   1.53050    0.62448 168.67000   2.451 0.015272\nRACEWhite                       5.64357    0.66561 157.14000   8.479 1.56e-14\nSEXFemale                       0.32606    0.53195 166.13000   0.613 0.540744\nARMCDTRT                        3.77423    1.07415 145.55000   3.514 0.000589\nAVISITVIS2                      4.83959    0.80172 143.88000   6.037 1.27e-08\nAVISITVIS3                     10.34211    0.82269 155.56000  12.571  &lt; 2e-16\nAVISITVIS4                     15.05390    1.31281 138.47000  11.467  &lt; 2e-16\nARMCDTRT:AVISITVIS2            -0.04193    1.12932 138.56000  -0.037 0.970439\nARMCDTRT:AVISITVIS3            -0.69369    1.18765 158.17000  -0.584 0.559996\nARMCDTRT:AVISITVIS4             0.62423    1.85085 129.72000   0.337 0.736463\n                                 \n(Intercept)                   ***\nRACEBlack or African American *  \nRACEWhite                     ***\nSEXFemale                        \nARMCDTRT                      ***\nAVISITVIS2                    ***\nAVISITVIS3                    ***\nAVISITVIS4                    ***\nARMCDTRT:AVISITVIS2              \nARMCDTRT:AVISITVIS3              \nARMCDTRT:AVISITVIS4              \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCovariance estimate:\n        VIS1    VIS2    VIS3    VIS4\nVIS1 40.5537 14.3960  4.9747 13.3867\nVIS2 14.3960 26.5715  2.7855  7.4745\nVIS3  4.9747  2.7855 14.8979  0.9082\nVIS4 13.3867  7.4745  0.9082 95.5568\n\n\n\n\n\nIn order to extract relevant marginal means (LSmeans) and contrasts we can use the emmeans package. This package includes methods that allow mmrm objects to be used with the emmeans package. emmeans computes estimated marginal means (also called least-square means) for the coefficients of the MMRM.\n\nlibrary(emmeans)\n\nmmrm() registered as emmeans extension\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nemmeans(fit, ~ ARMCD | AVISIT)\n\nAVISIT = VIS1:\n ARMCD emmean    SE  df lower.CL upper.CL\n PBO     33.3 0.755 148     31.8     34.8\n TRT     37.1 0.763 143     35.6     38.6\n\nAVISIT = VIS2:\n ARMCD emmean    SE  df lower.CL upper.CL\n PBO     38.2 0.612 147     37.0     39.4\n TRT     41.9 0.602 143     40.7     43.1\n\nAVISIT = VIS3:\n ARMCD emmean    SE  df lower.CL upper.CL\n PBO     43.7 0.462 130     42.8     44.6\n TRT     46.8 0.509 130     45.7     47.8\n\nAVISIT = VIS4:\n ARMCD emmean    SE  df lower.CL upper.CL\n PBO     48.4 1.189 134     46.0     50.7\n TRT     52.8 1.188 133     50.4     55.1\n\nResults are averaged over the levels of: RACE, SEX \nConfidence level used: 0.95 \n\n\nNote that the degrees of freedom choice is inherited here from the initial mmrm fit."
  },
  {
    "objectID": "R/rbmi_continuous_joint.html",
    "href": "R/rbmi_continuous_joint.html",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "",
    "text": "# General\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(gt)\nlibrary(labelled)\n\n# Methodlolgy specific\nlibrary(mmrm)\nlibrary(emmeans)\nlibrary(rbmi)\nlibrary(mice) # only used md.pattern()"
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#libraries",
    "href": "R/rbmi_continuous_joint.html#libraries",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "",
    "text": "# General\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(gt)\nlibrary(labelled)\n\n# Methodlolgy specific\nlibrary(mmrm)\nlibrary(emmeans)\nlibrary(rbmi)\nlibrary(mice) # only used md.pattern()"
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#reference-based-multiple-imputation-rbmi",
    "href": "R/rbmi_continuous_joint.html#reference-based-multiple-imputation-rbmi",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Reference-based multiple imputation (rbmi)",
    "text": "Reference-based multiple imputation (rbmi)\n\nMethodology introduction\nReference-based multiple imputation methods have become popular for handling missing data, as well as for conducting sensitivity analyses, in randomized clinical trials. In the context of a repeatedly measured continuous endpoint assuming a multivariate normal model, Carpenter et al. (2013) proposed a framework to extend the usual MAR-based MI approach by postulating assumptions about the joint distribution of pre- and post-deviation data. Under this framework, one makes qualitative assumptions about how individuals’ missing outcomes relate to those observed in relevant groups in the trial, based on plausible clinical scenarios. Statistical analysis then proceeds using the method of multiple imputation (Rubin 1976, Rubin 1987).\nIn general, multiple imputation of a repeatedly measured continuous outcome can be done via 2 computational routes (Roger 2022):\n\nStepwise: split problem into separate imputations of data at each visit\n\nrequires monotone missingness, such as missingness due to withdrawal\nconditions on the imputed values at previous visit\nBayesian linear regression problem is much simpler with monotone missing, as one can sample directly using conjugate priors\n\nOne-step approach (joint modelling): Fit a Bayesian full multivariate normal repeated measures model using MCMC and then draw a sample.\n\nHere, we illustrate reference-based multiple imputation of a continuous outcome measured repeatedly via the so-called one-step approach.\n\n\nrbmi package\nThe rbmi package Gower-Page et al. (2022) will be used for the one-step approach of the reference-based multiple imputation using R. The package implements standard and reference based multiple imputation methods for continuous longitudinal endpoints . In particular, this package supports deterministic conditional mean imputation and jackknifing as described in Wolbers et al. (2022), convential MI based on Bayesian posterior draws as described in Carpenter et al. (2013), and bootstrapped maximum likelihood imputation as described in von Hippel and Bartlett (2021).\nThe following standard and reference-based multiple imputation approaches will be illustrated here:\n* MAR (Missing At Random)\n\n* CIR (Copy Increment from Reference)\n\n* J2R (Jump to Reference)\n\n* CR (Copy Reference)"
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#data-used",
    "href": "R/rbmi_continuous_joint.html#data-used",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Data used",
    "text": "Data used\nA publicly available example dataset from an antidepressant clinical trial of an active drug versus placebo is used. Overall, data of 172 patients is available with 88 patients receiving placebo and 84 receiving active drug. This data is also used in the rbmi package quickstart vignette.\nThe relevant endpoint is the Hamilton 17-item depression rating scale (HAMD17) which was assessed at baseline and at weeks 1, 2, 4, and 6 (visits 4-7). Study drug discontinuation occurred in 24% (20/84) of subjects from the active drug and 26% (23/88) of subjects from placebo. All data after study drug discontinuation are missing.\n\ndata(\"antidepressant_data\")\ndat &lt;- antidepressant_data |&gt;\n  dplyr::select(\n    PATIENT,\n    GENDER,\n    THERAPY,\n    RELDAYS,\n    VISIT,\n    BASVAL,\n    HAMDTL17,\n    CHANGE\n  ) |&gt;\n  dplyr::mutate(THERAPY = factor(THERAPY, levels = c(\"PLACEBO\", \"DRUG\"))) |&gt;\n  labelled::remove_labels()\n\ngt(head(dat, n = 10))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\n\n\n\n\n1503\nF\nDRUG\n7\n4\n32\n21\n-11\n\n\n1503\nF\nDRUG\n14\n5\n32\n20\n-12\n\n\n1503\nF\nDRUG\n28\n6\n32\n19\n-13\n\n\n1503\nF\nDRUG\n42\n7\n32\n17\n-15\n\n\n1507\nF\nPLACEBO\n7\n4\n14\n11\n-3\n\n\n1507\nF\nPLACEBO\n15\n5\n14\n14\n0\n\n\n1507\nF\nPLACEBO\n29\n6\n14\n9\n-5\n\n\n1507\nF\nPLACEBO\n42\n7\n14\n5\n-9\n\n\n1509\nF\nDRUG\n7\n4\n21\n20\n-1\n\n\n1509\nF\nDRUG\n14\n5\n21\n18\n-3\n\n\n\n\n\n\n\nThe number of patients per visit and arm are:\n\ndat |&gt;\n  group_by(VISIT, THERAPY) |&gt;\n  dplyr::summarise(N = n())\n\n`summarise()` has grouped output by 'VISIT'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   VISIT [4]\n  VISIT THERAPY     N\n  &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n1 4     PLACEBO    88\n2 4     DRUG       84\n3 5     PLACEBO    81\n4 5     DRUG       77\n5 6     PLACEBO    76\n6 6     DRUG       73\n7 7     PLACEBO    65\n8 7     DRUG       64\n\n\nThe mean change from baseline of the endpoint (Hamilton 17-item depression rating scale, HAMD17) per visit per treatment group using only the complete cases are:\n\ndat |&gt;\n  group_by(VISIT, THERAPY) |&gt;\n  dplyr::summarise(N = n(), MEAN = mean(CHANGE))\n\n`summarise()` has grouped output by 'VISIT'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 4\n# Groups:   VISIT [4]\n  VISIT THERAPY     N  MEAN\n  &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;dbl&gt;\n1 4     PLACEBO    88 -1.51\n2 4     DRUG       84 -1.82\n3 5     PLACEBO    81 -2.70\n4 5     DRUG       77 -4.71\n5 6     PLACEBO    76 -4.07\n6 6     DRUG       73 -6.79\n7 7     PLACEBO    65 -5.14\n8 7     DRUG       64 -8.34\n\n\nThe missingness pattern is show below (1=observed data point (blue), 0=missing data point (red)). The incomplete data is primarily monotone in nature. 128 patients have complete data for all visits (all 1’s at each visit). 20, 10 and 13 patients have 1, 2 or 3 monotone missing data, respectively. Further, there is a single additional intermittent missing observation (patient 3618).\n\ndat_wide = dat |&gt;\n  dplyr::select(PATIENT, VISIT, CHANGE) |&gt;\n  pivot_wider(\n    id_cols = PATIENT,\n    names_from = VISIT,\n    names_prefix = \"VISIT_\",\n    values_from = CHANGE\n  )\n\ndat_wide |&gt;\n  dplyr::select(starts_with(\"VISIT_\")) |&gt;\n  mice::md.pattern(plot = TRUE, rotate.names = TRUE)\n\n\n\n\n\n\n\n\n    VISIT_4 VISIT_5 VISIT_6 VISIT_7   \n128       1       1       1       1  0\n20        1       1       1       0  1\n10        1       1       0       0  2\n1         1       0       1       1  1\n13        1       0       0       0  3\n          0      14      23      43 80"
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#complete-case-analysis",
    "href": "R/rbmi_continuous_joint.html#complete-case-analysis",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Complete case analysis",
    "text": "Complete case analysis\nA complete case analysis is performed using mixed model for repeated measures (MMRM) with covariates: treatment [THERAPY], gender [GENDER], visit [VISIT] as factors; baseline score [BASVAL] as continuous; and visit-by-treatment [THERAPY * VISIT] interaction, and visit-by-baseline [BASVAL * VISIT] interaction. An unstructured covariance matrix is used.\n\nmmrm_fit = mmrm::mmrm(\n  CHANGE ~\n    1 +\n      THERAPY +\n      GENDER +\n      VISIT +\n      BASVAL +\n      THERAPY * VISIT +\n      BASVAL * VISIT +\n      us(VISIT | PATIENT),\n  data = dat,\n  reml = TRUE\n)\nsummary(mmrm_fit)\n\nmmrm fit\n\nFormula:     \nCHANGE ~ 1 + THERAPY + GENDER + VISIT + BASVAL + THERAPY * VISIT +  \n    BASVAL * VISIT + us(VISIT | PATIENT)\nData:        dat (used 608 observations from 172 subjects with maximum 4 \ntimepoints)\nCovariance:  unstructured (10 variance parameters)\nMethod:      Satterthwaite\nVcov Method: Asymptotic\nInference:   REML\n\nModel selection criteria:\n     AIC      BIC   logLik deviance \n  3512.9   3544.4  -1746.5   3492.9 \n\nCoefficients: \n                    Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)          3.16355    1.20260 168.64000   2.631  0.00931 ** \nTHERAPYDRUG          0.06603    0.68662 168.11000   0.096  0.92350    \nGENDERM              0.31961    0.68216 168.46000   0.469  0.64001    \nVISIT5              -0.50646    1.22706 157.16000  -0.413  0.68036    \nVISIT6              -0.39390    1.41983 149.35000  -0.277  0.78184    \nVISIT7              -2.29237    1.62198 142.91000  -1.413  0.15974    \nBASVAL              -0.27866    0.06222 168.05000  -4.479 1.38e-05 ***\nTHERAPYDRUG:VISIT5  -1.49495    0.73342 156.86000  -2.038  0.04320 *  \nTHERAPYDRUG:VISIT6  -2.31710    0.85860 151.23000  -2.699  0.00775 ** \nTHERAPYDRUG:VISIT7  -2.89468    0.96582 139.86000  -2.997  0.00323 ** \nVISIT5:BASVAL       -0.03429    0.06567 157.48000  -0.522  0.60231    \nVISIT6:BASVAL       -0.11482    0.07646 150.73000  -1.502  0.13527    \nVISIT7:BASVAL       -0.04656    0.08679 142.04000  -0.537  0.59244    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCovariance estimate:\n        4       5       6       7\n4 19.7877 16.6237 15.4265 16.4578\n5 16.6237 34.3231 25.4682 26.2897\n6 15.4265 25.4682 38.4094 33.9331\n7 16.4578 26.2897 33.9331 45.3625\n\n\nUsing the emmeans package/function least square means and contrast can be obtained.\n\nem = emmeans::emmeans(\n  mmrm_fit,\n  specs = trt.vs.ctrl ~ THERAPY * VISIT,\n  at = list(VISIT = \"7\"),\n  level = 0.95,\n  adjust = \"none\",\n  mode = \"df.error\"\n)\n\nem_contrast = broom::tidy(em$contrasts, conf.int = TRUE, conf.level = 0.95)\nem_contrast |&gt;\n  gt() |&gt;\n  fmt_number(decimals = 3)\n\n\n\n\n\n\n\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nconf.low\nconf.high\nstatistic\np.value\n\n\n\n\nTHERAPY*VISIT\nDRUG VISIT7 - PLACEBO VISIT7\n0.000\n−2.829\n1.117\n150.711\n−5.035\n−0.622\n−2.533\n0.012\n\n\n\n\n\n\n\nThe treatment difference at visit 7 is of interest, and is estimated to be -2.829 (se=1.117) with 95% CI of [-5.035 to -0.622] (p=0.0123)."
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#rbmi-mar-approach",
    "href": "R/rbmi_continuous_joint.html#rbmi-mar-approach",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "rbmi: MAR approach",
    "text": "rbmi: MAR approach\nThe code presented here is based on the rbmi package quickstart vignette.\n\nCreate needed datasets and specify imputation strategy\nrbmi expects its input dataset to be complete; that is, there must be one row per subject for each visit (note: in clinical trials ADAMs typically do not have this required complete data structure). Missing outcome values should be coded as NA, while missing covariate values are not allowed. If the dataset is incomplete, then the expand_locf() function can be used to add any missing rows, using LOCF imputation to carry forward the observed baseline covariate values to visits with missing outcomes.\n\ndat_expand &lt;- rbmi::expand_locf(\n  dat,\n  PATIENT = levels(dat$PATIENT), # expand by PATIENT and VISIT\n  VISIT = levels(dat$VISIT),\n  vars = c(\"BASVAL\", \"THERAPY\", \"GENDER\"), # complete covariates using LOCF\n  group = c(\"PATIENT\"),\n  order = c(\"PATIENT\", \"VISIT\") # sort\n)\n\nFor example, the data of patient 1513 in the original data and expanded data are:\n\ndat |&gt;\n  dplyr::filter(PATIENT == \"1513\") |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\n\n\n\n\n1513\nM\nDRUG\n7\n4\n19\n24\n5\n\n\n\n\n\n\ndat_expand |&gt;\n  dplyr::filter(PATIENT == \"1513\") |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\n\n\n\n\n1513\nM\nDRUG\n7\n4\n19\n24\n5\n\n\n1513\nM\nDRUG\nNA\n5\n19\nNA\nNA\n\n\n1513\nM\nDRUG\nNA\n6\n19\nNA\nNA\n\n\n1513\nM\nDRUG\nNA\n7\n19\nNA\nNA\n\n\n\n\n\n\n\nNext, a dataset must be created specifying which data points should be imputed with the specified imputation strategy. The dataset dat_ice is created which specifies the first visit affected by an intercurrent event (ICE) and the imputation strategy for handling missing outcome data after the ICE. At most one ICE which is to be imputed is allowed per subject. In the example, the subject’s first visit affected by the ICE “study drug discontinuation” corresponds to the first terminal missing observation\n\ndat_ice &lt;- dat_expand |&gt;\n  arrange(PATIENT, VISIT) |&gt;\n  filter(is.na(CHANGE)) |&gt;\n  group_by(PATIENT) |&gt;\n  slice(1) |&gt;\n  ungroup() |&gt;\n  select(PATIENT, VISIT) |&gt;\n  mutate(strategy = \"MAR\")\n\ngt(head(dat_ice))\n\n\n\n\n\n\n\nPATIENT\nVISIT\nstrategy\n\n\n\n\n1513\n5\nMAR\n\n\n1514\n5\nMAR\n\n\n1517\n5\nMAR\n\n\n1804\n7\nMAR\n\n\n2104\n7\nMAR\n\n\n2118\n5\nMAR\n\n\n\n\n\n\n\nIn this dataset, subject 3618 has an intermittent missing values which does not correspond to a study drug discontinuation. We therefore remove this subject from dat_ice. In the later imputation step, it will automatically be imputed under the default MAR assumption.\n\ndat_ice &lt;- dat_ice[-which(dat_ice$PATIENT == 3618), ]\n\n\n\nFit imputation model and draw posterior parameters\nThe vars object using using set_vars() defines the names of key variables in the dataset and the covariates included in the imputation model. If you wish to include interaction terms these need to be added in the covariates input.\nThe method object specifies the statistical method used to fit the imputation models and to create imputed datasets.\nThe draws() function fits the imputation model and stores the corresponding parameter estimates and Bayesian posterior parameter draws.\n\nvars &lt;- rbmi::set_vars(\n  outcome = \"CHANGE\",\n  visit = \"VISIT\",\n  subjid = \"PATIENT\",\n  group = \"THERAPY\",\n  covariates = c(\"GENDER\", \"BASVAL*VISIT\", \"THERAPY*VISIT\")\n)\n\nmethod &lt;- rbmi::method_bayes(\n  n_samples = 500,\n  control = rbmi::control_bayes(warmup = 500, thin = 10)\n)\n\nset.seed(12345)\ndrawObj &lt;- draws(\n  data = dat_expand,\n  data_ice = dat_ice,\n  vars = vars,\n  method = method,\n  quiet = TRUE\n)\n\ndrawObj\n\n\nDraws Object\n------------\nNumber of Samples: 500\nNumber of Failed Samples: 0\nModel Formula: CHANGE ~ 1 + THERAPY + VISIT + GENDER + BASVAL * VISIT + THERAPY * VISIT\nImputation Type: random\nMethod:\n    name: Bayes\n    same_cov: TRUE\n    n_samples: 500\nControls:\n    warmup: 500\n    thin: 10\n    chains: 1\n    init: mmrm\n    seed: 1768860223\n\n\n\n\nGenerate imputed datasets\nThe next step is to use the parameters from the imputation model to generate the imputed datasets. This is done via the impute() function. The function only has two key inputs: the imputation model output from draws() and the references groups relevant to reference-based imputation methods. Since we are using the MAR approach here, we can set it to NULL.\n\nimputeObj &lt;- rbmi::impute(draws = drawObj, references = NULL)\n\nIn case we would like to access the imputed datasets, we can use the extract_imputed_dfs() function. For example, the imputed values in the 10th imputed dataset for patient 1513 are:\n\nimputed_dfs = rbmi::extract_imputed_dfs(imputeObj)\nMI_10 = imputed_dfs[[10]]\nMI_10$PATIENT_ID = dat_expand$PATIENT\n\nMI_10 |&gt;\n  dplyr::filter(PATIENT_ID == \"1513\") |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT_ID\n\n\n\n\nnew_pt_5\nM\nDRUG\n7\n4\n19\n24\n5.000000\n1513\n\n\nnew_pt_5\nM\nDRUG\nNA\n5\n19\nNA\n3.647917\n1513\n\n\nnew_pt_5\nM\nDRUG\nNA\n6\n19\nNA\n-8.796555\n1513\n\n\nnew_pt_5\nM\nDRUG\nNA\n7\n19\nNA\n-9.459383\n1513\n\n\n\n\n\n\n\n\n\nAnalyse imputed datasets\nThe next step is to run the analysis model on each imputed dataset. This is done by defining an analysis function and then calling the analyse() function to apply this function to each imputed dataset. The ancova() function provided by the rbmi package which fits a separate ANCOVA model for the outcomes from each visit is used.\nThe ancova() function uses the set_vars() function which determines the names of the key variables within the data and the covariates (in addition to the treatment group) for which the analysis model will be adjusted.\nNote: In Appendix 1 below we show how you can easily use a different analysis method (e.g., mmrm).\n\nvars_analyse &lt;- rbmi::set_vars(\n  outcome = \"CHANGE\",\n  visit = \"VISIT\",\n  subjid = \"PATIENT\",\n  group = \"THERAPY\",\n  covariates = c(\"BASVAL\", \"GENDER\")\n)\n\nanaObj &lt;- rbmi::analyse(\n  imputations = imputeObj,\n  fun = ancova,\n  vars = vars_analyse\n)\n\n\n\nPool results\nFinally, the pool() function can be used to summarise the analysis results across multiple imputed datasets to provide an overall statistic with a standard error, confidence intervals and a p-value for the hypothesis test of the null hypothesis that the effect is equal to 0. Since we used method_bayes(), pooling and inference are based on Rubin’s rules.\nHere, the treatment difference at visit 7 is of interest. Since we set PLACEBO as the first factor in the variable THERAPY this corresponds to ref, whereas DRUG corresponds to alt.\n\npoolObj &lt;- rbmi::pool(anaObj, conf.level = 0.95, alternative = \"two.sided\")\n\npoolObj |&gt;\n  data.frame() |&gt;\n  dplyr::filter(grepl(\"7\", parameter)) |&gt;\n  gt()\n\n\n\n\n\n\n\nparameter\nest\nse\nlci\nuci\npval\n\n\n\n\ntrt_7\n-2.844633\n1.1141210\n-5.046821\n-0.642445\n1.171535e-02\n\n\nlsm_ref_7\n-4.804639\n0.7760481\n-6.338665\n-3.270613\n5.990419e-09\n\n\nlsm_alt_7\n-7.649272\n0.7897268\n-9.210166\n-6.088377\n2.072107e-17"
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#rbmi-mnar-cr-approach",
    "href": "R/rbmi_continuous_joint.html#rbmi-mnar-cr-approach",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "rbmi: MNAR CR approach",
    "text": "rbmi: MNAR CR approach\nThe following changes need to be made in the code above to apply the Copy Reference (CR) approach in rbmi. For dat_ice the strategy need to be changed to CR. In the impute() step the references need to be specified. Here we set the reference for the DRUG group to PLACEBO.\n\ndat_ice &lt;- dat_expand |&gt;\n  arrange(PATIENT, VISIT) |&gt;\n  filter(is.na(CHANGE)) |&gt;\n  group_by(PATIENT) |&gt;\n  slice(1) |&gt;\n  ungroup() |&gt;\n  select(PATIENT, VISIT) |&gt;\n  mutate(strategy = \"CR\")\n\nimputeObj &lt;- rbmi::impute(\n  drawObj,\n  references = c(\"PLACEBO\" = \"PLACEBO\", \"DRUG\" = \"PLACEBO\")\n)\n\nThe results for M=500 imputed datasets using the MNAR CR approach are:\n\npoolObj |&gt;\n  data.frame() |&gt;\n  dplyr::filter(grepl(\"7\", parameter)) |&gt;\n  gt()\n\n\n\n\n\n\n\nparameter\nest\nse\nlci\nuci\npval\n\n\n\n\ntrt_7\n-2.389191\n1.1098207\n-4.582347\n-0.196036\n3.295851e-02\n\n\nlsm_ref_7\n-4.825593\n0.7888179\n-6.385046\n-3.266140\n8.877860e-09\n\n\nlsm_alt_7\n-7.214784\n0.7950363\n-8.786085\n-5.643483\n7.284035e-16"
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#rbmi-mnar-jr-approach",
    "href": "R/rbmi_continuous_joint.html#rbmi-mnar-jr-approach",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "rbmi: MNAR JR approach",
    "text": "rbmi: MNAR JR approach\nThe following changes need to be made in the code above to apply the Jump to Reference (JR) approach in rbmi. For dat_ice the strategy need to be changed to JR. In the impute() step the references need to be specified. Here we set the reference for the DRUG group to PLACEBO.\n\ndat_ice &lt;- dat_expand |&gt;\n  arrange(PATIENT, VISIT) |&gt;\n  filter(is.na(CHANGE)) |&gt;\n  group_by(PATIENT) |&gt;\n  slice(1) |&gt;\n  ungroup() |&gt;\n  select(PATIENT, VISIT) |&gt;\n  mutate(strategy = \"JR\")\n\nimputeObj &lt;- rbmi::impute(\n  drawObj,\n  references = c(\"PLACEBO\" = \"PLACEBO\", \"DRUG\" = \"PLACEBO\")\n)\n\nThe results for M=500 imputed datasets using the MNAR JR approach are:\n\npoolObj |&gt;\n  data.frame() |&gt;\n  dplyr::filter(grepl(\"7\", parameter)) |&gt;\n  gt()\n\n\n\n\n\n\n\nparameter\nest\nse\nlci\nuci\npval\n\n\n\n\ntrt_7\n-2.132841\n1.1250122\n-4.356232\n0.09054952\n5.995510e-02\n\n\nlsm_ref_7\n-4.823816\n0.7863147\n-6.378002\n-3.26963023\n7.786615e-09\n\n\nlsm_alt_7\n-6.956657\n0.8169909\n-8.571911\n-5.34140363\n2.355930e-14"
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#rbmi-mnar-cir-approach",
    "href": "R/rbmi_continuous_joint.html#rbmi-mnar-cir-approach",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "rbmi: MNAR CIR approach",
    "text": "rbmi: MNAR CIR approach\nThe following changes need to be made in the code above to apply the Copy Increments in Reference (CIR) approach in rbmi. For dat_ice the strategy need to be changed to CIR. In the impute() step the references need to be specified. Here we set the reference for the DRUG group to PLACEBO.\n\ndat_ice &lt;- dat_expand |&gt;\n  arrange(PATIENT, VISIT) |&gt;\n  filter(is.na(CHANGE)) |&gt;\n  group_by(PATIENT) |&gt;\n  slice(1) |&gt;\n  ungroup() |&gt;\n  select(PATIENT, VISIT) |&gt;\n  mutate(strategy = \"CIR\")\n\nimputeObj &lt;- rbmi::impute(\n  drawObj,\n  references = c(\"PLACEBO\" = \"PLACEBO\", \"DRUG\" = \"PLACEBO\")\n)\n\nThe results for M=500 imputed datasets using the MNAR CIR approach are:\n\npoolObj |&gt;\n  data.frame() |&gt;\n  dplyr::filter(grepl(\"7\", parameter)) |&gt;\n  gt()\n\n\n\n\n\n\n\nparameter\nest\nse\nlci\nuci\npval\n\n\n\n\ntrt_7\n-2.474262\n1.1073210\n-4.662462\n-0.2860616\n2.695134e-02\n\n\nlsm_ref_7\n-4.816549\n0.7796549\n-6.357611\n-3.2754870\n6.315542e-09\n\n\nlsm_alt_7\n-7.290811\n0.7932726\n-8.858615\n-5.7230060\n3.665328e-16"
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#summary-of-results",
    "href": "R/rbmi_continuous_joint.html#summary-of-results",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Summary of results",
    "text": "Summary of results\nIn the table we present the results of the different imputation strategies (and with varying number, M, of multiple imputation draws). Note that the results can be (slightly) different from the results above due to a possible different seed. The table show the contrast at Visit 7 between DRUG and PLACEBO [DRUG - PLACEBO]:\n\n\n\nMethod\nEstimate\nSE\n95% CI\np-value\n\n\n\n\nComplete Case\n-2.829\n1.117\n-5.035 to -0.622\n0.0123\n\n\nMI - MAR (M=500)\n-2.833\n1.120\n-5.046 to -0.620\n0.0125\n\n\nMI - MAR (M=2000)\n-2.837\n1.118\n-5.047 to -0.627\n0.0122\n\n\nMI - MAR (M=5000)\n-2.830\n1.123\n-5.040 to -0.610\n0.0128\n\n\nMI - MNAR CR (M=500)\n-2.377\n1.119\n-4.588 to -0.167\n0.0352\n\n\nMI - MNAR CR (M=2000)\n-2.391\n1.110\n-4.585 to -0.198\n0.0328\n\n\nMI - MNAR CR (M=5000)\n-2.394\n1.112\n-4.592 to -0.197\n0.0329\n\n\nMI - MNAR JR (M=500)\n-2.169\n1.134\n-4.411 to 0.072\n0.0577\n\n\nMI - MNAR JR (M=2000)\n-2.146\n1.135\n-4.389 to 0.097\n0.0606\n\n\nMI - MNAR JR (M=5000)\n-2.148\n1.135\n-4.390 to 0.095\n0.0603\n\n\nMI - MNAR CIR (M=500)\n-2.495\n1.113\n-4.695 to -0.295\n0.0265\n\n\nMI - MNAR CIR (M=2000)\n-2.469\n1.116\n-4.674 to -0.263\n0.0285\n\n\nMI - MNAR CIR (M=5000)\n-2.479\n1.112\n-4.676 to -0.282\n0.0273"
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#approximate-bayesian",
    "href": "R/rbmi_continuous_joint.html#approximate-bayesian",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Approximate Bayesian",
    "text": "Approximate Bayesian\nIn the draws() function it is possible to specify other methods. For example, the approximate Bayesian MI method_approxbayes() which is based on bootstrapping. draws() returns the draws from the posterior distribution of the parameters using an approximate Bayesian approach, where the sampling from the posterior distribution is simulated by fitting the MMRM model on bootstrap samples of the original dataset.\n\nmethod &lt;- rbmi::method_approxbayes(\n  covariance = \"us\",\n  threshold = 0.01,\n  REML = TRUE,\n  n_samples = 500\n)\n\nIn the table we present the results of the approximate Bayesian approach for a CR imputation strategy. The table show the contrast at Visit 7 between DRUG and PLACEBO [DRUG - PLACEBO]:\n\n\n\nMethod\nEstimate\nSE\n95% CI\np-value\n\n\n\n\nMI - MNAR CR (M=500)\n-2.415\n1.109\n-4.617 to -0.210\n0.0320\n\n\nMI - MNAR CR (M=2000)\n-2.403\n1.112\n-4.600 to -0.205\n0.0323"
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#discussion",
    "href": "R/rbmi_continuous_joint.html#discussion",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Discussion",
    "text": "Discussion\nA note on computational time: The total running time (including data loading, setting up data sets, MCMC run, imputing data and analysis MI data) for M=500 was about 26 seconds on a personal laptop. It increased to about 92 seconds for M=2000. Computational time was similar across different imputation strategies.\nWith a small number of n_samples in method_bayes() a warning could pop-up “The largest R-hat is 1.08, indicating chains have not mixed. Running the chains for more iterations may help”. Increasing the number of n_samples will mostly solve this warning. For example, for this data example, this message is received when setting n_samples equal to a number below 100."
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#appendix-1-mmrm-as-analysis-model",
    "href": "R/rbmi_continuous_joint.html#appendix-1-mmrm-as-analysis-model",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Appendix 1: mmrm as analysis model",
    "text": "Appendix 1: mmrm as analysis model\nIn the analyse() function (at the moment of writing) the only available analysis function is ancova. However, the user is able to specify its own analysis function. See the analyse() function for more details.\nAnother possibility (although, not the most efficient) is to implement a for loop in which the model is fit on each imputed dataset. The obtained results could then be pooled using Rubin’s rule. For example, suppose an MMRM should be fit on each imputed dataset:\n\nmmrm_analyse_mi_function &lt;- function(Impute_Obj) {\n  # create all imputed datasets\n  imputed_dfs = rbmi::extract_imputed_dfs(Impute_Obj)\n\n  # create empty vectors to store mmrm analysis results\n  est_vec = sd_vec = df_vec = NULL\n\n  # for loop to save estimates per imputation\n  for (k in 1:length(imputed_dfs)) {\n    temp_dat = imputed_dfs[[k]]\n    mmrm_fit_temp = mmrm::mmrm(\n      CHANGE ~\n        1 +\n          THERAPY +\n          VISIT +\n          BASVAL * VISIT +\n          THERAPY * VISIT +\n          GENDER +\n          us(VISIT | PATIENT),\n      data = temp_dat,\n      reml = TRUE\n    )\n    em = emmeans::emmeans(\n      mmrm_fit_temp,\n      specs = trt.vs.ctrl ~ THERAPY * VISIT,\n      at = list(VISIT = \"7\"),\n      level = 0.95,\n      adjust = \"none\",\n      mode = \"df.error\"\n    )\n    est_vec[k] = summary(em$contrasts)$estimate\n    sd_vec[k] = summary(em$contrasts)$SE\n    df_vec[k] = summary(em$contrasts)$df\n  }\n\n  # summarize results using rubin's rule\n  rr = rbmi:::rubin_rules(ests = est_vec, ses = sd_vec, v_com = mean(df_vec))\n  rr$se_t = sqrt(rr$var_t)\n  rr$t.stat = rr$est_point / sqrt(rr$var_t)\n  rr$p_value = 2 * pt(q = rr$t.stat, df = rr$df, lower.tail = TRUE)\n\n  return(rr = rr)\n}\n\nThe following code then performs the analysis and pooling\n\nmmrm_analyse_mi_function(Impute_Obj = imputeObj)\n\nIn the table we present the results of the Bayesian approach for a CR imputation strategy with an MMRM analysis model. The table show the contrast at Visit 7 between DRUG and PLACEBO [DRUG - PLACEBO]:\n\n\n\nMethod\nEstimate\nSE\n95% CI\np-value\n\n\n\n\nMI - MNAR CR (M=500)\n-2.415\n1.109\n-4.607 to -0.223\n0.0310\n\n\nMI - MNAR CR (M=2000)\n-2.388\n1.111\n-4.584 to -0.193\n0.0332"
  },
  {
    "objectID": "R/rbmi_continuous_joint.html#reference",
    "href": "R/rbmi_continuous_joint.html#reference",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Reference",
    "text": "Reference\nCarpenter JR, Roger JH & Kenward MG (2013). Analysis of Longitudinal Trials with Protocol Deviation: A Framework for Relevant, Accessible Assumptions, and Inference via MI. Journal of Biopharmaceutical Statistics 23: 1352-1371.\nGower-Page C, Noci A & Wolbers M (2022). rbmi: A R package for standard and reference-based multiple imputation methods. Journal of Open Source Software 7(74): 4251.\nrbmi: Reference Based Multiple Imputation\nrbmi: Quickstart\nRoger J (2022, Dec 8). Other statistical software for continuous longitudinal endpoints: SAS macros for multiple imputation. Addressing intercurrent events: Treatment policy and hypothetical strategies. Joint EFSPI and BBS virtual event.\nRubin DB (1976). Inference and Missing Data. Biometrika 63: 581–592.\nRubin DB (1987). Multiple Imputation for Nonresponse in Surveys. New York: John Wiley & Sons.\nvon Hippel PT & Bartlett JW (2021). Maximum likelihood multiple imputation: Faster imputations and consistent standard errors without posterior draws. Statistical Science 36(3): 400–420.\nWolbers M, Noci A, Delmar P, Gower-Page C, Yiu S & Bartlett JW (2022). Standard and reference-based conditional mean imputation. Pharmaceutical Statistics 21(6): 1246-1257.\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package      * version  date (UTC) lib source\n P assertthat     0.2.1    2019-03-21 [?] RSPM\n P backports      1.5.0    2024-05-23 [?] CRAN (R 4.4.0)\n P BiocManager    1.30.25  2024-08-28 [?] CRAN (R 4.4.1)\n   boot           1.3-31   2024-08-28 [2] CRAN (R 4.4.2)\n P broom          1.0.7    2024-09-26 [?] CRAN (R 4.4.1)\n P checkmate      2.3.2    2024-07-29 [?] CRAN (R 4.4.0)\n P cli            3.6.3    2024-06-21 [?] CRAN (R 4.4.0)\n P coda           0.19-4.1 2024-01-31 [?] CRAN (R 4.4.0)\n   codetools      0.2-20   2024-03-31 [2] CRAN (R 4.4.2)\n P colorspace     2.1-1    2024-07-26 [?] CRAN (R 4.4.0)\n P curl           5.2.3    2024-09-20 [?] CRAN (R 4.4.1)\n P digest         0.6.37   2024-08-19 [?] CRAN (R 4.4.1)\n P dplyr        * 1.1.4    2023-11-17 [?] CRAN (R 4.4.0)\n P emmeans      * 1.10.4   2024-08-21 [?] CRAN (R 4.4.1)\n P estimability   1.5.1    2024-05-12 [?] CRAN (R 4.4.0)\n P evaluate       1.0.0    2024-09-17 [?] CRAN (R 4.4.1)\n P fansi          1.0.6    2023-12-08 [?] CRAN (R 4.4.0)\n P fastmap        1.2.0    2024-05-15 [?] CRAN (R 4.4.0)\n P forcats        1.0.0    2023-01-29 [?] CRAN (R 4.4.0)\n P foreach        1.5.2    2022-02-02 [?] CRAN (R 4.4.0)\n P generics       0.1.3    2022-07-05 [?] CRAN (R 4.4.0)\n P ggplot2        3.5.1    2024-04-23 [?] CRAN (R 4.4.0)\n P glmnet         4.1-8    2023-08-22 [?] CRAN (R 4.4.0)\n P glue           1.8.0    2024-09-30 [?] CRAN (R 4.4.1)\n P gridExtra      2.3      2017-09-09 [?] CRAN (R 4.4.0)\n P gt           * 0.11.1   2024-10-04 [?] CRAN (R 4.4.1)\n P gtable         0.3.5    2024-04-22 [?] CRAN (R 4.4.0)\n P haven          2.5.4    2023-11-30 [?] CRAN (R 4.4.0)\n P hms            1.1.3    2023-03-21 [?] CRAN (R 4.4.0)\n P htmltools      0.5.8.1  2024-04-04 [?] CRAN (R 4.4.0)\n P htmlwidgets    1.6.4    2023-12-06 [?] CRAN (R 4.4.0)\n P inline         0.3.21   2025-01-09 [?] RSPM\n P iterators      1.0.14   2022-02-05 [?] CRAN (R 4.4.0)\n P jomo           2.7-6    2023-04-15 [?] CRAN (R 4.4.0)\n P jsonlite       1.8.9    2024-09-20 [?] CRAN (R 4.4.1)\n   knitr          1.50     2025-03-16 [1] RSPM (R 4.4.0)\n P labelled     * 2.14.0   2025-01-08 [?] RSPM\n   lattice        0.22-6   2024-03-20 [2] CRAN (R 4.4.2)\n P lifecycle      1.0.4    2023-11-07 [?] CRAN (R 4.4.0)\n P lme4           1.1-35.5 2024-07-03 [?] CRAN (R 4.4.0)\n P loo            2.8.0    2024-07-03 [?] RSPM\n P magrittr       2.0.3    2022-03-30 [?] CRAN (R 4.4.0)\n   MASS           7.3-61   2024-06-13 [2] CRAN (R 4.4.2)\n   Matrix         1.7-1    2024-10-18 [2] CRAN (R 4.4.2)\n P matrixStats    1.4.1    2024-09-08 [?] CRAN (R 4.4.1)\n P mice         * 3.16.0   2023-06-05 [?] CRAN (R 4.4.0)\n P minqa          1.2.8    2024-08-17 [?] CRAN (R 4.4.0)\n P mitml          0.4-5    2023-03-08 [?] CRAN (R 4.4.0)\n P mmrm         * 0.3.14   2024-09-27 [?] CRAN (R 4.4.1)\n P multcomp       1.4-26   2024-07-18 [?] CRAN (R 4.4.0)\n P munsell        0.5.1    2024-04-01 [?] CRAN (R 4.4.0)\n P mvtnorm        1.3-1    2024-09-03 [?] CRAN (R 4.4.1)\n   nlme           3.1-166  2024-08-14 [2] CRAN (R 4.4.2)\n P nloptr         2.1.1    2024-06-25 [?] CRAN (R 4.4.0)\n   nnet           7.3-19   2023-05-03 [2] CRAN (R 4.4.2)\n P pan            1.9      2023-12-07 [?] CRAN (R 4.4.0)\n P pillar         1.9.0    2023-03-22 [?] CRAN (R 4.4.0)\n P pkgbuild       1.4.4    2024-03-17 [?] CRAN (R 4.4.0)\n P pkgconfig      2.0.3    2019-09-22 [?] CRAN (R 4.4.0)\n P purrr          1.0.2    2023-08-10 [?] CRAN (R 4.4.0)\n P QuickJSR       1.8.0    2025-06-09 [?] RSPM\n P R6             2.5.1    2021-08-19 [?] CRAN (R 4.4.0)\n P rbibutils      2.3      2024-10-04 [?] CRAN (R 4.4.1)\n P rbmi         * 1.4.0    2025-02-07 [?] RSPM\n P Rcpp           1.0.13   2024-07-17 [?] CRAN (R 4.4.0)\n P RcppParallel   5.1.10   2025-01-24 [?] RSPM\n P Rdpack         2.6.1    2024-08-06 [?] CRAN (R 4.4.0)\n   renv           1.0.10   2024-10-05 [1] CRAN (R 4.4.1)\n P rlang          1.1.4    2024-06-04 [?] CRAN (R 4.4.0)\n P rmarkdown      2.28     2024-08-17 [?] CRAN (R 4.4.0)\n   rpart          4.1.23   2023-12-05 [2] CRAN (R 4.4.2)\n P rstan          2.32.7   2025-03-10 [?] RSPM\n P rstudioapi     0.16.0   2024-03-24 [?] CRAN (R 4.4.0)\n P sandwich       3.1-1    2024-09-15 [?] CRAN (R 4.4.1)\n P sass           0.4.9    2024-03-15 [?] CRAN (R 4.4.0)\n P scales         1.3.0    2023-11-28 [?] CRAN (R 4.4.0)\n P sessioninfo    1.2.2    2021-12-06 [?] CRAN (R 4.4.0)\n P shape          1.4.6.1  2024-02-23 [?] CRAN (R 4.4.0)\n P StanHeaders    2.32.10  2024-07-15 [?] RSPM\n P stringi        1.8.4    2024-05-06 [?] CRAN (R 4.4.0)\n P stringr        1.5.1    2023-11-14 [?] CRAN (R 4.4.0)\n P survival       3.7-0    2024-06-05 [?] CRAN (R 4.4.0)\n P TH.data        1.1-2    2023-04-17 [?] CRAN (R 4.4.0)\n P tibble         3.2.1    2023-03-20 [?] CRAN (R 4.4.0)\n P tidyr        * 1.3.1    2024-01-24 [?] CRAN (R 4.4.0)\n P tidyselect     1.2.1    2024-03-11 [?] CRAN (R 4.4.0)\n P TMB            1.9.15   2024-09-09 [?] CRAN (R 4.4.1)\n P utf8           1.2.4    2023-10-22 [?] CRAN (R 4.4.0)\n P V8             5.0.1    2024-09-20 [?] CRAN (R 4.4.1)\n P vctrs          0.6.5    2023-12-01 [?] CRAN (R 4.4.0)\n P withr          3.0.1    2024-07-31 [?] CRAN (R 4.4.0)\n   xfun           0.52     2025-04-02 [1] RSPM (R 4.4.0)\n P xml2           1.3.6    2023-12-04 [?] CRAN (R 4.4.0)\n P xtable         1.8-4    2019-04-21 [?] CRAN (R 4.4.0)\n P yaml           2.3.10   2024-07-26 [?] CRAN (R 4.4.0)\n P zoo            1.8-12   2023-04-13 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/Accelerated_Failure_time_model.html",
    "href": "R/Accelerated_Failure_time_model.html",
    "title": "Accelerated Failure Time Model",
    "section": "",
    "text": "The accelerated failure time model is a parametric survival analysis technique used to model the relationship between the time to event of interest (e.g., time to failure) and a set of predictor variables. It assumes that the covariates have a multiplicative effect on the time to the event. In other words, the time to event is accelerated or decelerated by a factor that depends on the values of the covariates.This differs from the Cox proportional hazards model, which assumes that covariates have a multiplicative effect on the hazard rate, not the time to the event."
  },
  {
    "objectID": "R/Accelerated_Failure_time_model.html#mathematical-expression",
    "href": "R/Accelerated_Failure_time_model.html#mathematical-expression",
    "title": "Accelerated Failure Time Model",
    "section": "Mathematical Expression",
    "text": "Mathematical Expression\nMathematically, the AFT model can be expressed as:\n\\(\\log(T) = X\\beta + \\sigma\\varepsilon\\)\nWhere:\n\nT is the survival time\nlog(T) is the logarithm of the survival time\nX is a matrix of predictor variables\nβ is a vector of coefficients representing the effects of the predictor variables on the logarithm of the survival time\nσ is a scaler quantity representing the scale parameter, which influences the variability of the error term ε in the model.\nε is the error term assumed to follow a specific distribution (e.g., normal distribution for log-normal, extreme value distribution for Weibull) that corresponds to the chosen parametric form of the model."
  },
  {
    "objectID": "R/Accelerated_Failure_time_model.html#example-of-aft-model-using-log-normal-distribution",
    "href": "R/Accelerated_Failure_time_model.html#example-of-aft-model-using-log-normal-distribution",
    "title": "Accelerated Failure Time Model",
    "section": "Example of AFT model using “Log-Normal Distribution”",
    "text": "Example of AFT model using “Log-Normal Distribution”\n\nlibrary(survival)\nattach(lung)\n\n# Fit an AFT model using lognormal distribution\nmodel_aft &lt;- survival::survreg(\n  survival::Surv(time, status) ~ age + sex + ph.ecog,\n  data = lung,\n  dist = \"lognormal\"\n)\n# Model summary\nsummary(model_aft)\n\n\nCall:\nsurvival::survreg(formula = survival::Surv(time, status) ~ age + \n    sex + ph.ecog, data = lung, dist = \"lognormal\")\n               Value Std. Error     z       p\n(Intercept)  6.49479    0.58276 11.14 &lt; 2e-16\nage         -0.01918    0.00833 -2.30 0.02126\nsex          0.52195    0.15278  3.42 0.00063\nph.ecog     -0.35557    0.10331 -3.44 0.00058\nLog(scale)   0.02823    0.05596  0.50 0.61391\n\nScale= 1.03 \n\nLog Normal distribution\nLoglik(model)= -1146.9   Loglik(intercept only)= -1163.2\n    Chisq= 32.59 on 3 degrees of freedom, p= 3.9e-07 \nNumber of Newton-Raphson Iterations: 3 \nn=227 (1 observation deleted due to missingness)\n\n\nThe summary output will provide the estimated coefficients, standard errors, and p-values for each predictor variable."
  },
  {
    "objectID": "R/Accelerated_Failure_time_model.html#acceleration-factor-calculation",
    "href": "R/Accelerated_Failure_time_model.html#acceleration-factor-calculation",
    "title": "Accelerated Failure Time Model",
    "section": "Acceleration Factor Calculation",
    "text": "Acceleration Factor Calculation\n\n# Compute acceleration factor (exponentiated coefficients)\nacceleration_factor &lt;- exp(coef(model_aft))\nacceleration_factor\n\n(Intercept)         age         sex     ph.ecog \n661.6830913   0.9810009   1.6853157   0.7007762"
  },
  {
    "objectID": "R/Accelerated_Failure_time_model.html#interpretation",
    "href": "R/Accelerated_Failure_time_model.html#interpretation",
    "title": "Accelerated Failure Time Model",
    "section": "Interpretation",
    "text": "Interpretation\n\nFor age,acceleration factor \\(&lt; 1\\) indicates that for each one-unit increase in age, the survival time is slowed down by a factor of 0.98 (or a 2% decreasein survival time).\nFor sex, acceleration factor \\(&gt; 1\\) indicates that males have 68% accelerated survival time.\nAn acceleration factor of ph.ecog \\(&lt; 1\\) suggests a 30% decelerated survival time associated with ph.ecog."
  },
  {
    "objectID": "R/Accelerated_Failure_time_model.html#plotting-aft-model-graphically",
    "href": "R/Accelerated_Failure_time_model.html#plotting-aft-model-graphically",
    "title": "Accelerated Failure Time Model",
    "section": "Plotting AFT Model Graphically",
    "text": "Plotting AFT Model Graphically\n\nsuppressPackageStartupMessages({\n  library(survival)\n  library(survminer)\n  library(ggplot2)\n})\n\n# Fit the AFT model on the lung dataset\naft_model &lt;- survival::survreg(\n  survival::Surv(time, status) ~ age + sex + ph.ecog,\n  data = lung,\n  dist = \"lognormal\"\n)\n\n# Create a new data frame with predicted survival times\ndf &lt;- data.frame(\n  time = lung$time,\n  age = lung$age,\n  sex = lung$sex,\n  ph.ecog = lung$ph.ecog,\n  status = lung$status\n)\ndf$surv_times &lt;- predict(aft_model, newdata = df)\n\n# Plot the survival curves based on the AFT model\nsurvminer::ggsurvplot(\n  survival::survfit(survival::Surv(surv_times, status) ~ 1, data = df),\n  data = df,\n  xlab = \"Time\",\n  ylab = \"Survival Probability\"\n)\n\n\n\n\n\n\n\n\nThe survival curve plotted based on the AFT model for the lung dataset illustrates how the probability of survival changes as time progresses, showing the impact of different covariate levels on survival probabilities."
  },
  {
    "objectID": "R/Accelerated_Failure_time_model.html#example-of-aft-model-using-weibull-distribution",
    "href": "R/Accelerated_Failure_time_model.html#example-of-aft-model-using-weibull-distribution",
    "title": "Accelerated Failure Time Model",
    "section": "Example of AFT model using “Weibull Distribution”",
    "text": "Example of AFT model using “Weibull Distribution”\n\n# Fit an AFT model using weibull distribution\nmodel_aft_wb &lt;- survival::survreg(\n  survival::Surv(futime, fustat) ~ age + resid.ds + rx,\n  data = ovarian,\n  dist = \"weibull\"\n)\n# Model summary\nsummary(model_aft_wb)\n\n\nCall:\nsurvival::survreg(formula = survival::Surv(futime, fustat) ~ \n    age + resid.ds + rx, data = ovarian, dist = \"weibull\")\n              Value Std. Error     z      p\n(Intercept) 10.5634     1.3810  7.65  2e-14\nage         -0.0661     0.0190 -3.48 0.0005\nresid.ds    -0.5002     0.3799 -1.32 0.1879\nrx           0.5152     0.3236  1.59 0.1114\nLog(scale)  -0.6577     0.2384 -2.76 0.0058\n\nScale= 0.518 \n\nWeibull distribution\nLoglik(model)= -87.9   Loglik(intercept only)= -98\n    Chisq= 20.17 on 3 degrees of freedom, p= 0.00016 \nNumber of Newton-Raphson Iterations: 6 \nn= 26"
  },
  {
    "objectID": "R/Accelerated_Failure_time_model.html#acceleration-factor-calculation-1",
    "href": "R/Accelerated_Failure_time_model.html#acceleration-factor-calculation-1",
    "title": "Accelerated Failure Time Model",
    "section": "Acceleration Factor Calculation",
    "text": "Acceleration Factor Calculation\n\n# Compute acceleration factor (exponentiated coefficients)\nacceleration_factor_wb &lt;- exp(coef(model_aft_wb))\nacceleration_factor_wb\n\n (Intercept)          age     resid.ds           rx \n3.869157e+04 9.360366e-01 6.063911e-01 1.673914e+00"
  },
  {
    "objectID": "R/Accelerated_Failure_time_model.html#interpretation-1",
    "href": "R/Accelerated_Failure_time_model.html#interpretation-1",
    "title": "Accelerated Failure Time Model",
    "section": "Interpretation",
    "text": "Interpretation\n\nFor age, an acceleration factor of 0.93 indicates that for each one-unit increase in age, the survival time is decelerated by a factor of 0.93(or a 7% decrease in the survival time)\nFor residual disease status, an acceleration factor of 0.60 suggests that a decrease in residual disease status is associated with a 40% decelerated survival time.\nan acceleration factor of 1.67 suggests a 67% accelerated survival time for patients receiving a different type of radiation therapy (rx = 2) compared to the reference group (rx = 1)."
  },
  {
    "objectID": "R/Accelerated_Failure_time_model.html#survival-curve-plotting-on-ovarian-dataset",
    "href": "R/Accelerated_Failure_time_model.html#survival-curve-plotting-on-ovarian-dataset",
    "title": "Accelerated Failure Time Model",
    "section": "Survival Curve Plotting on ‘Ovarian’ Dataset",
    "text": "Survival Curve Plotting on ‘Ovarian’ Dataset\n\n# Fit the AFT model (weibull distribution) on your data\nmodel_aft &lt;- survival::survreg(\n  survival::Surv(futime, fustat) ~ age + resid.ds + rx,\n  data = ovarian,\n  dist = \"weibull\"\n)\n\n# Create survival curves for different levels of predictor variables\nplot_data &lt;- with(\n  ovarian,\n  data.frame(\n    age = seq(min(age), max(age), length.out = 100),\n    resid.ds = mean(resid.ds),\n    rx = mean(rx)\n  )\n)\n\n# Predict survival times based on the AFT model\nplot_data$survival &lt;- predict(model_aft, newdata = plot_data)\n\n# Plot the survival curves\nggplot(\n  plot_data,\n  aes(x = age, y = survival, color = factor(rx), linetype = factor(rx))\n) +\n  geom_line() +\n  labs(\n    x = \"Age\",\n    y = \"Survival Probability\",\n    color = \"Radiation Therapy\",\n    linetype = \"Radiation Therapy\"\n  ) +\n  scale_linetype_manual(values = c(\"solid\", \"dashed\", \"dotted\")) +\n  scale_color_manual(values = c(\"blue\", \"red\", \"green\"))\n\n\n\n\n\n\n\n\nThe survival curve plotted based on the AFT model for the ovarian dataset how the probability of survival changes as age increases."
  },
  {
    "objectID": "R/Accelerated_Failure_time_model.html#conclusion",
    "href": "R/Accelerated_Failure_time_model.html#conclusion",
    "title": "Accelerated Failure Time Model",
    "section": "Conclusion",
    "text": "Conclusion\nIn AFT models, unlike Cox proportional hazards models, survival times follow an assumed parametric distribution (e.g., Weibull, log-logistic, log-normal), directly modelling the effect of covariates on the time scale."
  },
  {
    "objectID": "R/cmh.html",
    "href": "R/cmh.html",
    "title": "CMH Test",
    "section": "",
    "text": "The CMH procedure tests for conditional independence in partial contingency tables for a 2 x 2 x K design. However, it can be generalized to tables of X x Y x K dimensions.\n\n\nWe did not find any R package that delivers all the same measures as SAS at once. Therefore, we tried out multiple packages:\n\n\n\n\n\n\n\n\nPackage\nGeneral Association\nRow Means Differ\nNonzero Correlation\nM-H Odds Ratio\nHomogeneity Test\nNote\n\n\n\n\nstats::mantelhaen.test()\n✅\n❌\n❌\n✅\n❌\nWorks well for 2x2xK\n\n\nvcdExtra::CMHtest()\n✅\n✅\n✅\n❌\n❌\nProblems with sparsity, potential bug\n\n\nepiDisplay::mhor()\n❌\n❌\n❌\n✅\n✅\nOR are limited to 2x2xK design\n\n\n\n\n\n\n\n\n\n\nWe will use the CDISC Pilot data set, which is publicly available on the PHUSE Test Data Factory repository. This data set served as the basis of the examples to follow.\n\n\n  X      STUDYID SITEID SITEGR1     USUBJID     TRTSDT     TRTEDT\n1 1 CDISCPILOT01    701     701 01-701-1015 2014-01-02 2014-07-02\n2 2 CDISCPILOT01    701     701 01-701-1023 2012-08-05 2012-09-01\n3 3 CDISCPILOT01    701     701 01-701-1028 2013-07-19 2014-01-14\n4 4 CDISCPILOT01    701     701 01-701-1033 2014-03-18 2014-03-31\n5 5 CDISCPILOT01    701     701 01-701-1034 2014-07-01 2014-12-30\n6 6 CDISCPILOT01    701     701 01-701-1047 2013-02-12 2013-03-09\n                  TRTP TRTPN AGE AGEGR1 AGEGR1N  RACE RACEN SEX ITTFL EFFFL\n1              Placebo     0  63    &lt;65       1 WHITE     1   F     Y     Y\n2              Placebo     0  64    &lt;65       1 WHITE     1   M     Y     Y\n3 Xanomeline High Dose    81  71  65-80       2 WHITE     1   M     Y     Y\n4  Xanomeline Low Dose    54  74  65-80       2 WHITE     1   M     Y     Y\n5 Xanomeline High Dose    81  77  65-80       2 WHITE     1   F     Y     Y\n6              Placebo     0  85    &gt;80       3 WHITE     1   F     Y     Y\n  COMP24FL AVISIT AVISITN             VISIT VISITNUM ADY        ADT  PARAMCD\n1        Y Week 8       8            WEEK 8        8  63 2014-03-05 CIBICVAL\n2        N Week 8       8            WEEK 4        5  29 2012-09-02 CIBICVAL\n3        Y Week 8       8            WEEK 8        8  54 2013-09-10 CIBICVAL\n4        N Week 8       8            WEEK 4        5  28 2014-04-14 CIBICVAL\n5        Y Week 8       8            WEEK 8        8  57 2014-08-26 CIBICVAL\n6        N Week 8       8 AMBUL ECG REMOVAL        6  46 2013-03-29 CIBICVAL\n        PARAM PARAMN AVAL ANL01FL DTYPE AWRANGE AWTARGET AWTDIFF AWLO AWHI  AWU\n1 CIBIC Score      1    4       Y    NA    2-84       56       7    2   84 DAYS\n2 CIBIC Score      1    3       Y    NA    2-84       56      27    2   84 DAYS\n3 CIBIC Score      1    4       Y    NA    2-84       56       2    2   84 DAYS\n4 CIBIC Score      1    4       Y    NA    2-84       56      28    2   84 DAYS\n5 CIBIC Score      1    4       Y    NA    2-84       56       1    2   84 DAYS\n6 CIBIC Score      1    4       Y    NA    2-84       56      10    2   84 DAYS\n  QSSEQ\n1  6001\n2  6001\n3  6001\n4  6001\n5  6001\n6  6001\n\n\n\n\n\n\n\nThis is included in a base installation of R, as part of the stats package. Requires inputting data as a table or as vectors. Two examples 2x2x2 examples: X=2 treatments, Y=Sex (M/F), controlling for 2 age groups and 3x2x3 example X=3 treatments, Y=Sex (M/F), controlling for 3 age groups.\n\n# 2x2x2 example\ndata2 &lt;- data |&gt;\n  filter(TRTPN != \"54\" & AGEGR1 != \"&gt;80\")\n\nstats::mantelhaen.test(x = data2$TRTP, y = data2$SEX, z = data2$AGEGR1)\n\n\n    Mantel-Haenszel chi-squared test with continuity correction\n\ndata:  data2$TRTP and data2$SEX and data2$AGEGR1\nMantel-Haenszel X-squared = 0.076264, df = 1, p-value = 0.7824\nalternative hypothesis: true common odds ratio is not equal to 1\n95 percent confidence interval:\n 0.5671347 2.5129874\nsample estimates:\ncommon odds ratio \n         1.193818 \n\n# 3x2x3 example\nstats::mantelhaen.test(x = data$TRTP, y = data$SEX, z = data$AGEGR1)\n\n\n    Cochran-Mantel-Haenszel test\n\ndata:  data$TRTP and data$SEX and data$AGEGR1\nCochran-Mantel-Haenszel M^2 = 2.482, df = 2, p-value = 0.2891\n\n\n\n\n\nThe vcdExtra package provides results for the generalized CMH test, for each of the three model it outputs the Chi-square value and the respective p-values. Flexible data input methods available: table or formula (aggregated level data in a data frame).\n\nlibrary(vcdExtra)\n\nLoading required package: vcd\n\n\nLoading required package: grid\n\n\nLoading required package: gnm\n\n\n\nAttaching package: 'vcdExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n\n# Formula: Freq ~ X + Y | K\nvcdExtra::CMHtest(Freq ~ TRTP + SEX | AGEGR1, data = data, overall = TRUE)\n\n$`AGEGR1:&lt;65`\nCochran-Mantel-Haenszel Statistics for TRTP by SEX \n    in stratum AGEGR1:&lt;65 \n\n                 AltHypothesis   Chisq Df    Prob\ncor        Nonzero correlation 0.33168  1 0.56467\nrmeans  Row mean scores differ 1.52821  2 0.46575\ncmeans  Col mean scores differ 0.33168  1 0.56467\ngeneral    General association 1.52821  2 0.46575\n\n\n$`AGEGR1:&gt;80`\nCochran-Mantel-Haenszel Statistics for TRTP by SEX \n    in stratum AGEGR1:&gt;80 \n\n                 AltHypothesis   Chisq Df    Prob\ncor        Nonzero correlation 0.39433  1 0.53003\nrmeans  Row mean scores differ 3.80104  2 0.14949\ncmeans  Col mean scores differ 0.39433  1 0.53003\ngeneral    General association 3.80104  2 0.14949\n\n\n$`AGEGR1:65-80`\nCochran-Mantel-Haenszel Statistics for TRTP by SEX \n    in stratum AGEGR1:65-80 \n\n                 AltHypothesis   Chisq Df    Prob\ncor        Nonzero correlation 0.52744  1 0.46768\nrmeans  Row mean scores differ 0.62921  2 0.73008\ncmeans  Col mean scores differ 0.52744  1 0.46768\ngeneral    General association 0.62921  2 0.73008\n\n\n$ALL\nCochran-Mantel-Haenszel Statistics for TRTP by SEX \n    Overall tests, controlling for all strata \n\n                 AltHypothesis      Chisq Df    Prob\ncor        Nonzero correlation 0.00086897  1 0.97648\nrmeans  Row mean scores differ      2.482  2 0.28909\ncmeans  Col mean scores differ 0.00086897  1 0.97648\ngeneral    General association      2.482  2 0.28909\n\n\n\n\n\nTo get the M-H common odds ratio and the homogeneity test, the epiDisplay package can be used.\n\nlibrary(epiDisplay)\nepiDisplay::mhor(x, y, k, graph = FALSE)\n\n\n\nTo tackle the issue with sparse data it is recommended that a use of solve() is replaced with MASS::ginv. This was implemented in the forked version of vcdExtra which can be installed from here:\n\ndevtools::install_github(\"mstackhouse/vcdExtra\")\n\nHowever, also the forked version for the vcdExtra package works only until a certain level of sparsity. In case of our data, it still works if the data are stratified by the pooled Site ID (SITEGR1 - 11 unique values) whereas using the unpooled Site ID (SITEID - 17 unique values) also throws an error. Note: this version is not up to date and sometimes calculates degrees of freedom incorrectly."
  },
  {
    "objectID": "R/cmh.html#available-r-packages",
    "href": "R/cmh.html#available-r-packages",
    "title": "CMH Test",
    "section": "",
    "text": "We did not find any R package that delivers all the same measures as SAS at once. Therefore, we tried out multiple packages:\n\n\n\n\n\n\n\n\nPackage\nGeneral Association\nRow Means Differ\nNonzero Correlation\nM-H Odds Ratio\nHomogeneity Test\nNote\n\n\n\n\nstats::mantelhaen.test()\n✅\n❌\n❌\n✅\n❌\nWorks well for 2x2xK\n\n\nvcdExtra::CMHtest()\n✅\n✅\n✅\n❌\n❌\nProblems with sparsity, potential bug\n\n\nepiDisplay::mhor()\n❌\n❌\n❌\n✅\n✅\nOR are limited to 2x2xK design"
  },
  {
    "objectID": "R/cmh.html#data-used",
    "href": "R/cmh.html#data-used",
    "title": "CMH Test",
    "section": "",
    "text": "We will use the CDISC Pilot data set, which is publicly available on the PHUSE Test Data Factory repository. This data set served as the basis of the examples to follow.\n\n\n  X      STUDYID SITEID SITEGR1     USUBJID     TRTSDT     TRTEDT\n1 1 CDISCPILOT01    701     701 01-701-1015 2014-01-02 2014-07-02\n2 2 CDISCPILOT01    701     701 01-701-1023 2012-08-05 2012-09-01\n3 3 CDISCPILOT01    701     701 01-701-1028 2013-07-19 2014-01-14\n4 4 CDISCPILOT01    701     701 01-701-1033 2014-03-18 2014-03-31\n5 5 CDISCPILOT01    701     701 01-701-1034 2014-07-01 2014-12-30\n6 6 CDISCPILOT01    701     701 01-701-1047 2013-02-12 2013-03-09\n                  TRTP TRTPN AGE AGEGR1 AGEGR1N  RACE RACEN SEX ITTFL EFFFL\n1              Placebo     0  63    &lt;65       1 WHITE     1   F     Y     Y\n2              Placebo     0  64    &lt;65       1 WHITE     1   M     Y     Y\n3 Xanomeline High Dose    81  71  65-80       2 WHITE     1   M     Y     Y\n4  Xanomeline Low Dose    54  74  65-80       2 WHITE     1   M     Y     Y\n5 Xanomeline High Dose    81  77  65-80       2 WHITE     1   F     Y     Y\n6              Placebo     0  85    &gt;80       3 WHITE     1   F     Y     Y\n  COMP24FL AVISIT AVISITN             VISIT VISITNUM ADY        ADT  PARAMCD\n1        Y Week 8       8            WEEK 8        8  63 2014-03-05 CIBICVAL\n2        N Week 8       8            WEEK 4        5  29 2012-09-02 CIBICVAL\n3        Y Week 8       8            WEEK 8        8  54 2013-09-10 CIBICVAL\n4        N Week 8       8            WEEK 4        5  28 2014-04-14 CIBICVAL\n5        Y Week 8       8            WEEK 8        8  57 2014-08-26 CIBICVAL\n6        N Week 8       8 AMBUL ECG REMOVAL        6  46 2013-03-29 CIBICVAL\n        PARAM PARAMN AVAL ANL01FL DTYPE AWRANGE AWTARGET AWTDIFF AWLO AWHI  AWU\n1 CIBIC Score      1    4       Y    NA    2-84       56       7    2   84 DAYS\n2 CIBIC Score      1    3       Y    NA    2-84       56      27    2   84 DAYS\n3 CIBIC Score      1    4       Y    NA    2-84       56       2    2   84 DAYS\n4 CIBIC Score      1    4       Y    NA    2-84       56      28    2   84 DAYS\n5 CIBIC Score      1    4       Y    NA    2-84       56       1    2   84 DAYS\n6 CIBIC Score      1    4       Y    NA    2-84       56      10    2   84 DAYS\n  QSSEQ\n1  6001\n2  6001\n3  6001\n4  6001\n5  6001\n6  6001"
  },
  {
    "objectID": "R/cmh.html#example-code",
    "href": "R/cmh.html#example-code",
    "title": "CMH Test",
    "section": "",
    "text": "This is included in a base installation of R, as part of the stats package. Requires inputting data as a table or as vectors. Two examples 2x2x2 examples: X=2 treatments, Y=Sex (M/F), controlling for 2 age groups and 3x2x3 example X=3 treatments, Y=Sex (M/F), controlling for 3 age groups.\n\n# 2x2x2 example\ndata2 &lt;- data |&gt;\n  filter(TRTPN != \"54\" & AGEGR1 != \"&gt;80\")\n\nstats::mantelhaen.test(x = data2$TRTP, y = data2$SEX, z = data2$AGEGR1)\n\n\n    Mantel-Haenszel chi-squared test with continuity correction\n\ndata:  data2$TRTP and data2$SEX and data2$AGEGR1\nMantel-Haenszel X-squared = 0.076264, df = 1, p-value = 0.7824\nalternative hypothesis: true common odds ratio is not equal to 1\n95 percent confidence interval:\n 0.5671347 2.5129874\nsample estimates:\ncommon odds ratio \n         1.193818 \n\n# 3x2x3 example\nstats::mantelhaen.test(x = data$TRTP, y = data$SEX, z = data$AGEGR1)\n\n\n    Cochran-Mantel-Haenszel test\n\ndata:  data$TRTP and data$SEX and data$AGEGR1\nCochran-Mantel-Haenszel M^2 = 2.482, df = 2, p-value = 0.2891\n\n\n\n\n\nThe vcdExtra package provides results for the generalized CMH test, for each of the three model it outputs the Chi-square value and the respective p-values. Flexible data input methods available: table or formula (aggregated level data in a data frame).\n\nlibrary(vcdExtra)\n\nLoading required package: vcd\n\n\nLoading required package: grid\n\n\nLoading required package: gnm\n\n\n\nAttaching package: 'vcdExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n\n# Formula: Freq ~ X + Y | K\nvcdExtra::CMHtest(Freq ~ TRTP + SEX | AGEGR1, data = data, overall = TRUE)\n\n$`AGEGR1:&lt;65`\nCochran-Mantel-Haenszel Statistics for TRTP by SEX \n    in stratum AGEGR1:&lt;65 \n\n                 AltHypothesis   Chisq Df    Prob\ncor        Nonzero correlation 0.33168  1 0.56467\nrmeans  Row mean scores differ 1.52821  2 0.46575\ncmeans  Col mean scores differ 0.33168  1 0.56467\ngeneral    General association 1.52821  2 0.46575\n\n\n$`AGEGR1:&gt;80`\nCochran-Mantel-Haenszel Statistics for TRTP by SEX \n    in stratum AGEGR1:&gt;80 \n\n                 AltHypothesis   Chisq Df    Prob\ncor        Nonzero correlation 0.39433  1 0.53003\nrmeans  Row mean scores differ 3.80104  2 0.14949\ncmeans  Col mean scores differ 0.39433  1 0.53003\ngeneral    General association 3.80104  2 0.14949\n\n\n$`AGEGR1:65-80`\nCochran-Mantel-Haenszel Statistics for TRTP by SEX \n    in stratum AGEGR1:65-80 \n\n                 AltHypothesis   Chisq Df    Prob\ncor        Nonzero correlation 0.52744  1 0.46768\nrmeans  Row mean scores differ 0.62921  2 0.73008\ncmeans  Col mean scores differ 0.52744  1 0.46768\ngeneral    General association 0.62921  2 0.73008\n\n\n$ALL\nCochran-Mantel-Haenszel Statistics for TRTP by SEX \n    Overall tests, controlling for all strata \n\n                 AltHypothesis      Chisq Df    Prob\ncor        Nonzero correlation 0.00086897  1 0.97648\nrmeans  Row mean scores differ      2.482  2 0.28909\ncmeans  Col mean scores differ 0.00086897  1 0.97648\ngeneral    General association      2.482  2 0.28909\n\n\n\n\n\nTo get the M-H common odds ratio and the homogeneity test, the epiDisplay package can be used.\n\nlibrary(epiDisplay)\nepiDisplay::mhor(x, y, k, graph = FALSE)\n\n\n\nTo tackle the issue with sparse data it is recommended that a use of solve() is replaced with MASS::ginv. This was implemented in the forked version of vcdExtra which can be installed from here:\n\ndevtools::install_github(\"mstackhouse/vcdExtra\")\n\nHowever, also the forked version for the vcdExtra package works only until a certain level of sparsity. In case of our data, it still works if the data are stratified by the pooled Site ID (SITEGR1 - 11 unique values) whereas using the unpooled Site ID (SITEID - 17 unique values) also throws an error. Note: this version is not up to date and sometimes calculates degrees of freedom incorrectly."
  },
  {
    "objectID": "R/summary-stats.html",
    "href": "R/summary-stats.html",
    "title": "Deriving Quantiles or Percentiles in R",
    "section": "",
    "text": "Percentiles can be calculated in R using the quantile function. The function has the argument type which allows for nine different percentile definitions to be used. The default is type = 7, which uses a piecewise-linear estimate of the cumulative distribution function to find percentiles.\nThis is how the 25th and 40th percentiles of aval could be calculated using the default type.\n\nquantile(aval, probs = c(0.25, 0.4))\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package     * version date (UTC) lib source\n P BiocManager   1.30.25 2024-08-28 [?] CRAN (R 4.4.1)\n P cli           3.6.3   2024-06-21 [?] CRAN (R 4.4.0)\n P digest        0.6.37  2024-08-19 [?] CRAN (R 4.4.1)\n P evaluate      1.0.0   2024-09-17 [?] CRAN (R 4.4.1)\n P fastmap       1.2.0   2024-05-15 [?] CRAN (R 4.4.0)\n P htmltools     0.5.8.1 2024-04-04 [?] CRAN (R 4.4.0)\n P htmlwidgets   1.6.4   2023-12-06 [?] CRAN (R 4.4.0)\n P jsonlite      1.8.9   2024-09-20 [?] CRAN (R 4.4.1)\n   knitr         1.50    2025-03-16 [1] RSPM (R 4.4.0)\n   renv          1.0.10  2024-10-05 [1] CRAN (R 4.4.1)\n P rlang         1.1.6   2025-04-11 [?] RSPM\n P rmarkdown     2.28    2024-08-17 [?] CRAN (R 4.4.0)\n P rstudioapi    0.16.0  2024-03-24 [?] CRAN (R 4.4.0)\n P sessioninfo   1.2.2   2021-12-06 [?] CRAN (R 4.4.0)\n   xfun          0.52    2025-04-02 [1] RSPM (R 4.4.0)\n P yaml          2.3.10  2024-07-26 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "method_summary/sample_s_theory.html",
    "href": "method_summary/sample_s_theory.html",
    "title": "Sample size (and power) calculation – theoretical intro",
    "section": "",
    "text": "Sample size calculation plays a key role in the planning stage of most clinical trials, to ensure sufficient number of subjects for providing accurate and reliable results using statistical methods. A valid sample size calculation can only be done based on the appropriate statistical test for the hypotheses that reflect the study objective under a valid study design. Sample size calculation can be classified into: sample size estimation/determination, sample size justification, sample size adjustment, sample size reestimation. We will mainly focus on the determination, which is calculation of the required sample size for achieving the desired statistical accuracy and reliability, such as e.g. 80% power.\nOn CAMIS we will cover most commonly used tests in clinical trials and it’s calculations in R, SAS (if available), EAST and StatXact (e.g. if not available in SAS).\n\nHypotheses\nIn most clinical trials, the primary objective is usually related to the evaluation of the effectiveness and safety. Commonly considered hypotheses include point hypotheses for equality and interval hypothesis for testing equivalence, non-inferiority and superiority.\nSuperiority trials aim to prove that the investigated treatment is better than the comparator. The null hypothesis states that is no difference between the treatments and the alternative that there is some difference between the treatments (difference ≠ 0).\nEquivalence trials are defined as trials that test whether a drug has the same (or similar) efficacy as an active agent or standard therapy. In practice, this is done by defining an “equivalence margin”, or limits, within which the treatment effect must lie to be considered equivalent.\nNon-inferiority trials aim to prove that the investigated treatment is better than the comparator.\nEach of the hypotheses has different requirements for sample size to achieve the desired statistical assurance.\n\n\nStudy design\nFor examples based on superiority, equivalence and non-inferiority studies, crossover vs parallel designs will be considered. Additionally examples of sample size calculations for selected subgroup/interim analyses are provided based on group sequential designs.\nA crossover (paired) design is a modified randomised block design in which each block receives more than one treatment in different dosing periods. Subjects are assigned to receive a sequence of treatments, which contains all the treatments in the study. For example, is a 2-sequence, 2-period study 2x2 crossover design, subjects are randomly assigned to one of the 2 sequences (AB, BA). The main advantage is that it allows a within-subject (intrasubject) comparison between treatments.\nA parallel (unpaired) design is a complete randomised design in which each subject receives one and only one treatment in a random fashion. The parallel design doe not provide independent estimates for the subject variability for each treatment – assessment of treatment effect is made based on the total variability (including intersubject and intrasubject variability).\n\n\nRequired paramaters\nFor determination of the sample size, in most cases, all of the below parameters will be required to perform the calculations:\n\nPower\nclinically relevant/significant difference\nalpha (α)\nbeta (β)\nEffect size (Cohen’s d) (required only in some R packages), can be defined as:\nDifference between the means divided by the pooled standard deviation. In general, 0.2 can be considered a small effect, 0.5 a medium effect and 0.8 a large effect.\n\n\n\nPackages in R\nDepending on the study design and the endpoint multiple packages in R can be used. The below table [1] summarises the most popular tests and R packages where the sample size calculation is available. However, only the superiority hypothesis is considered.\n\n\n\n\n\n\n\n\n\nThere are some more interesting packages, particularly focused on clinical trials applications, with different hypotheses or designed available:\n\nsamplesize: Sample Size Calculation for Various t-Tests and Wilcoxon-Test package docs\nepiR: Tools for the Analysis of Epidemiological Data package docs\nTrialSize: R Functions for Chapter 3,4,6,7,9,10,11,12,14,15 of Sample Size Calculation in Clinical Research [2] package docs\nSampleSize4ClinicalTrials: Sample Size Calculation for the Comparison of Means or Proportions in Phase III Clinical Trials package docs\n\n\n\nReferences\n\n[1] Park S, Kim YH, Bang HI, Park Y. Sample size calculation in clinical trial using R. J Minim Invasive Surg. 2023 Mar 15;26(1):9-18. doi: 10.7602/jmis.2023.26.1.9. PMID: 36936043; PMCID: PMC10020745.\n[2] for theoretical section and examples: Chow, S.-C., Shao, J., Wang, H., & Lokhnygina, Y. (2017). Sample Size Calculations in Clinical Research (3rd ed.). Chapman and Hall/CRC. https://doi.org/10.1201/9781315183084."
  },
  {
    "objectID": "publication/white_paper.html",
    "href": "publication/white_paper.html",
    "title": "Whitepaper",
    "section": "",
    "text": "Key Considerations When Understanding Differences in Statistical Methodology Implementations Across Programming Languages - An Introduction to the CAMIS Project\nThis white paper aims to empower clinical data scientists to make informed choices on the implementation of statistical analyses when multiple languages yield different results. Our objective is not to prescribe what that choice should be, but rather provide guidance on the types of questions clinical data scientists should ask, to identify the fundamental sources of discrepant results. Our objective is also to invite the wider community to contribute to an open-source repository designed for Comparing Analysis Method Implementations in Software (CAMIS: https://github.com/PSIAIMS/CAMIS).\nRead the whitepaper"
  },
  {
    "objectID": "publication/conference.html",
    "href": "publication/conference.html",
    "title": "Conferences",
    "section": "",
    "text": "2025 Conference Schedule\nList of seminars and conferences that the CAMIS team will be attending in 2025.\nIf you are a volunteer on the CAMIS project and plan to present at a seminar or conference, please add details of the conference below. For help with slides or content go to HERE.\nIf you want a single slide which advertises the CAMIS project, you can find this HERE\nTo cite the CAMIS project work in online content or presentations please use: “Content reproduced with the permission of PHUSE CAMIS - A DVOST Working Group”.\n2025 Conference Attendance\n\n\n\nConference name\nDate (2025)\nLocation\nName Attending\nDetails\nWebsite\n\n\n\n\nPHUSE US connect\n16th-19th march\nOrlando, Florida\nHamming Tu Vikash Jain\n\n\n\n\nPSI Conference\n9-11th June\nLondon, England\nLyn Taylor, Christina Fillmore, Agniezska Tomczyk\n2x slides: CAMIS or Samplesize\nPSI |\n\n\nR medicine\n12th June\nRemote\nLyn Taylor, Christina Fillmore\nSlides CAMIS\n\n\n\nISBC46\n24-28th August\nBasel, Switzerland\nYannick Vandendijck\nPoster presentation CAMIS\nISCB46\n\n\nSESUG\n22-24 Sept\nSAS campus, Cary, NC, USA\nBrian Varney\nwill include slide on CAMIS\n\n\n\nPHUSE EU Connect\n16-19th Nov\nHamburg, Germany\nYannick Vandendijck\nTobit regression, Reference-based multiple imputation, tipping point analysis\nPHUSE |\n\n\nPHUSE EU Connect\n16-19th Nov\nHamburg, Germany\nMiriam Amor\nGLMM - laplace, ghq, pql and GEE models\nPHUSE |\n\n\n\n2024 Conference Attendance\n\n\n\nConference name\nDate (2024)\nLocation\nName Attending\nDetails\nWebsite\n\n\n\n\nRSS Local Group Seminar\n28 Feb\nSheffield, England\nLyn Taylor\nSlides\nRSS\n\n\nphuse US Connect\n25-28 Feb\nBethesa, Maryland, USA\nSoma Sekhar Sriadibhatla, Vikash Jain, Brian Varney\nPoster\nConnect\n\n\nphuse chapter connect\n03 APR\nBangalore\nHarshal Khanolkar\n\n\n\n\nphuse/FDA CSS\n3-5 June\nSilver Spring Maryland, USA\nMike Stackhouse\nCAMIS Discussion\nCSS\n\n\nR/Medicine\n10-14 June\nOnline\nAgnieszka Tomczyk, Lyn Taylor\nslides\nR/Medicine 2024\n\n\nUseR!\n8-11 July\nSalzburg, Austria\nChi Zhang\nPresentation\nuseR! 2024\n\n\nPHUSE Belgian SDE\n23 Sept\nBrussels, Belgium\nQian Wang (msd)\nPresentation\nPHUSE SDE\n\n\nSESUG\n22-24 Sept\nBethesda, MD, USA\nBrian\n\nSESUG 2024\n\n\nR/pharma APAC track\n30 Oct- 1 Nov\nOnline, APAC\nSamrit Pramanik\nPresentation\n\n\n\nphuse EU\n11-13 Nov\nStrasbourg, France\nAgnieszka Tomczyk, Christina Fillmore, Stephen Mccawille and Anwesha Roy\nPresentation\nPHUSE EU Connect\n\n\nEffective statistician conference\n11-12 Nov\nVirtual\nLyn Taylor\nPresentation\nlink\n\n\n\n\n\nYearly Conference Planner\nTo help to plan our attendance throughout the year, here is a list of conferences we are looking to send representation to. If you plan to attend one of these conferences and are interested in representing us, then please get in touch.\n\n\n\nConference name\nUsual Abstract Deadline\nUsual Conference Date\nRegion\nLinks\n\n\n\n\nJoint Statistical Meetings (JSM) American Statistical Association (ASA)\n1st February\n1st week of August\nUSA\nJSM-ASA\n\n\nASA Biopharmaceutical Section Regulatory-Industry Statistics workshop\nEnd March\nLast week of September\nUSA\nBIOP\n\n\nPhuse US Connect\nNovember\nLast week of Feb\nUSA\nCDISC\n\n\nPhuse/FDA Computational Science Symposium(CSS)\nDecember\n1st week of June\nUSA\nCSS\n\n\nIASCT (ConSPIC)\nMid March\nEarly May\nIndia\nIASCT\n\n\nSociety of Clinical Trials (SCT)\nJanuary\nMid May\nUSA\nSCT\n\n\nPharmaSUG\nMid Jan\nMid May\nUSA\nPharmaSUG\n\n\nuseR\nEarly March\nEarly July\nEurope/Online\nuseR\n\n\nPSI\nNov-oral, Feb-Poster\nMid June\nEurope\nPSI\n\n\nDIA Global\nEnd Feb-poster\nMid June\nUSA\nDIA-USA\n\n\nDIA Europe\nNov\nMid March\nEurope\nDIA-Europe\n\n\nDIA China\nJan\nMid May\nChina\nDIA-China\n\n\nInternational Society for Clinical Biostatistics (ISCB)\nMid Feb\nMid August\nEurope\nISCB\n\n\nRoyal Statistical Society (RSS)\nEarly April\nEarly September\nEngland\nRSS\n\n\nSouthEast SAS User Group (SESUG)\nEnd Feb\nEnd Sept\nMaryland, USA\nSESUG\n\n\nPHUSE EU Connect\nMid March\nMid Nov\nEurope\nPHUSE EU Connect\n\n\nR/Pharma\nApril\nMid October\nVirtual\nR/pharma\n\n\nPOSIT conf.\nInvite only\nSeptember\nUSA\nPOSIT conf"
  },
  {
    "objectID": "blogs/posts/2025-03-13_tobit-regression/index.html",
    "href": "blogs/posts/2025-03-13_tobit-regression/index.html",
    "title": "Tobit Regression Comparison",
    "section": "",
    "text": "A recent CAMIS contribution explored the standard Tobit model for a virology endpoint (viral load) with a lower detection limit.\nTobit regression, a censored regression model, estimates linear relationships between independent variables and a dependent variable that is either left- or right-censored at a specific known value.\nThe implementations of Tobit regression in R and SAS were compared (link to full comparison on CAMIS website: R vs SAS Tobit Regression). In SAS, the LIFEREG procedure was used, which requires a specific structure in the MODEL statement, namely “(lower, upper)”. Here, if the lower value is missing, then the upper value is used as a left-censored value.\nIn R, the censReg, survival, and VGAM packages were explored. The censReg() and survreg() (from the survival package) functions provided matching results with SAS LIFEREG. In both cases estimation is being done by the maximum likelihood approach. The vglm() function in VGAM showed slight numerical differences due to a different estimation technique. The VGAM package uses vector generalized linear and additive models which are estimated using an iteratively reweighted least squares (IRLS) algorithm.\nTypically, the Tobit model assumes normally distributed data, and the standard Tobit regression results matched between R and SAS when a normally distributed endpoint was assumed. Additionally, this comparison also highlighted the flexibility of Tobit regression implementations across different software (as well as the importance of being aware of different default and available options), with SAS LIFEREG and R’s survival package offering multiple different distributional assumptions.\nCAMIS is a PHUSE working group in collaboration with PSI AIMS SIG. For more on CAMIS’s goals and repository, as well as how to contribute, visit the CAMIS website."
  },
  {
    "objectID": "blogs/posts/2024-03-29_phuse-conference/index.html",
    "href": "blogs/posts/2024-03-29_phuse-conference/index.html",
    "title": "2024 PHUSE US Connect Conference",
    "section": "",
    "text": "Congratulations, Soma Sekhar Sriadibhatla, on your poster presentation “CAMIS-An open source repository to document differences in statistical methodology software” at PHUSE US Connect 2024.\nA poster was presented on PHUSE DVOST-CAMIS effort to document discrepancies between programming languages such as SAS, R, and Python (due to software default choices) in order to conduct the same end-point analysis, a cheat sheet across multilingual languages, and the CAMIS-ONCO subgroup.\nWe are pleased to inform you that we have received positive feedback from the industry on our CAMIS repository, which helps them to eliminate the risk of doing end point analysis in a multilingual world."
  },
  {
    "objectID": "blogs/posts/2023-05-05_introduction-to-CAMIS/index.html",
    "href": "blogs/posts/2023-05-05_introduction-to-CAMIS/index.html",
    "title": "Introduction to CAMIS",
    "section": "",
    "text": "Are you trying to replicate results using different software/languages and struggling to find out why you can’t match the results? Check out the CAMIS repository!\n\n\n\n\n\n\n\n\n\n\nThe CAMIS repository stores documentation detailing the reasons for observed differences when performing statistical analysis in SAS and R. The repository is housed on github, and will be populated through open-source community contributions.\nDifferences between software could be due to different default and available options, including the methods being used. By documenting these known differences in a repository, we aim to reduce time-consuming efforts within the community, where multiple people are investigating the same issues. If you find an issue not already investigated, please log an Issue in github. If you have time to investigate and document the reason for the issue, then please submit a pull request with the new content in a quarto file. Details of how to contribute can be found on the website.\nCAMIS is a PHUSE working group in collaboration with PSI and the R consortium. Initially the repository contains R and SAS analysis result comparisons, however the team hope to extend to other software/languages in the near future. Our white paper will soon be available on the website. Please help us to build a high quality and comprehensive repository."
  },
  {
    "objectID": "non_website_content/Conferences 2023 archive.html",
    "href": "non_website_content/Conferences 2023 archive.html",
    "title": "Conferences",
    "section": "",
    "text": "Conference Programme\nWe plan to showcase the CAMIS project at a number of conferences throughout 2023 and 2024. See below the list of conferences the CAMIS team will be at and please come say hello to us !\n\n\n\n\n\n\n\n\n\n\n\nConference\n2023/2024 Planning dates\n2023 Date & Location\n2023 Main Contact\nAlso attending\nDetails\n\n\n\n\nJSM (ASA conference)\nAbstract Feb 2024\n\nLeon Shih\n\n\n\n\nPHUSE US Connect\nTBC for 2024\n5-8 March 2023 Orlando, Florida\nSoma Sekhar\n\nPresentation\n\n\nDISS (Duke industry statistics symposium)\nTBC for 2024\n29-31st March 2023 Virtual\nMolly MacDiarmid (2023)\n\nPoster\n\n\nPSDM(Pharmaceutical statistics and data management)\n\n19 Apr 2023 Netherlands\n\n\n\n\n\nIASCT (ConSPIC - conference for statistics and programming in clinical research)\nAbstract submission 14 Mar-3rd Apr\n4-6 May 2023 Bengaluru, India\nHarshal Khanolkar\n\nTalk. and/or poster\n\n\nSociety of Clinical Trials (SCT\n\n21-24 May 2023\nMichael Kane\n\n\n\n\nuse R\nTBC\nJune 2024?\n\n\n\n\n\nPSI 2023 Conference\nTalk submission Nov.\nPoster submission Feb.\n11-14 June 2023 Hammersmith London West, England\nMartin Brown\nChristina Fillmore\nLyn Taylor\nMolly Macdiarmid\nMartin Brown\nAiming Yang\nOral & poster submission completed\n\n\nDIA 2023 Global Annual Meeting\n\n25-29 June 2023 Boston MA, USA\n\n\n\n\n\nJoint statistical meeting (JSM)\nFeb 2024 submission for next year\n5-10 Aug 2023 Toronto, Ontario, Canada\n\n\n\n\n\nISCB Conference\n\n27-31 Aug 2023 Milan-Italy\n\n\n\n\n\nRSS conference\nAbstract by 6th April\n4-7 sept 2023 Harrogate, England\nLyn Taylor\n\nConfirmed oral presentation\n\n\nPHUSE/FDA Quarterly meeting\nSeptember 13 (10:00 EDT/15:00 BST)\nWG can present their work, share their progress, and request any FDA \nsupport\nLyn Taylor\n\n30 min presentation\n\n\nPHUSE CSS\n15th June Abstract open, register by 30th june\n(TBC 2024 DVOST breakout sessions)\nSept 18-20, Maryland USA\nSoma Sekhar\nVikash Jain\nAditee Dani\nPoster\n\n\nASA Bio pharmaceutical Section Regulatory-industry Statistics Workshop\n\n27-29 Sept 2023 Rockville, Maryland, USA\n\n\n\n\n\nEASD 2023 - European Association for study of diabetes\n\n02-06 Oct 2023 Hamberg Germany\n\n\n\n\n\nSESUG (South East SAS user group)\n\n17-19 Oct 2023\nBrian Varney\n\n\n\n\nPHUSE EU Connect 2023\n\n5-8 November 2023 ICC Birmingham, England\nJayashree vendanayagam\n\nPresenting on shiny App for regulatory submission (will include CAMIS advert)\n\n\nR in Pharma\n\n\nNov Virtual\nBrian Varney/ Christina Fillmore?\n\nForm open. Christina to speak to Brian.\n\n\nPOSIT conf.\nInvite only\nSeptember - Chicago\nJulianne Manitz & Doug Kelkhoff\n\nR Validation Hub team will include a slide for us. (Juliane Manitz/Doug Kelkhoff)\n\n\nPHUSE (Single day events) SDEs\n\nMississauga\nJune 8th\nJayashree vendanayagam\n\nPresenting on shiny App for regulatory submission (will include CAMIS advert)\n\n\nPHUSE (Single day events) SDEs\n\nNew York (Oct 16th)\nAiming Yang\n\nEmailed host to have poster/ talk/ advert"
  },
  {
    "objectID": "non_website_content/dissertations/202406_MMRM.html",
    "href": "non_website_content/dissertations/202406_MMRM.html",
    "title": "A comparison of MMRM methodology in SAS and R software",
    "section": "",
    "text": "NOTE: This project is no longer available for selection.\nAbstract:\nThe mixed model for repeated measures (MMRM) is commonly used in individual clinical trials due to its suitability to model longitudinal continuous data outcomes measured at set timepoints over time. However, there is much complexity in this methodology such that replication of analysis methods and results produced in SAS vs open source software such as R may not be straight forward.\nThe primary objective of this project is to build on the information already documented here CAMIS - A PHUSE DVOST Working Group (psiaims.github.io) under Repeated Measures (Linear Mixed Model (MMRM) section) and provide both PAREXEL and the wider pharmaceutical industry with a comprehensive guide for how to implement and replicate MMRMs analysis methods in SAS and R.\nIt is expected that the project will consist of performing a thorough comparison of MMRM analysis methods in SAS (using Proc Mixed and Proc GLIMMIX) versus in R (nlme::gls, lme4::lmer, and glmmTMB::glmmTMB and mmrm::mmrm). The project will discuss and document the options available in each, detailing similarities and differences in default options, available options and analysis results.\nThe project plan for this study is expected to consist of\n1 Self teaching in the MMRM methodology to understand how to apply the methods, the common options available when model fitting, their strengths and limitations in clinical research\n2 Literature search to investigate\n\nLatest advance in current methods and guidance\nR packages available for use to apply these methods\nSAS procedures available to apply these methods\nAny current research or evidence of researchers comparing methods in SAS vs R.\n\n3 Using one or more datasets (simulated or existing in open source, testing both small and large datasets), fit a selection of MMRM modelling methods using various software/package and options to see if SAS and R return the same results. Investigate and document the reasons for any differences. \nPossible extensions (if time permits):\n\nInvestigate Categorical MMRMs\nInvestigate the Bayesian MMRM options available in both software and document any differences.\nInvestigate pythons application of such methods with comparison to SAS and R"
  },
  {
    "objectID": "East/gsd-tte.html",
    "href": "East/gsd-tte.html",
    "title": "Group sequential design in East",
    "section": "",
    "text": "“Two Samples”, “Logrank Test Given Accrual Duration and Study Duration” in the Survival library will be used for sample size calculations.\nAfter selecting the design option, you will initially see tabs: “Test Parameters” and “Accrual/Dropouts”. Once the “Number of Looks” is updated to greater than 1, a “Boundary” tab will appear.\nBelow are screenshots of each of the tabs for a group sequential design (GSD) for a progression-free survival (PFS) endpoint, which has one interim analysis for both efficacy and non-binding futility:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe results are as follows:\n\n\n\n\n\n\n\n\n\nThe results are generated with East version 6.5.4.6."
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Apache License",
    "section": "",
    "text": "Apache License\nVersion 2.0, January 2004 &lt;http://www.apache.org/licenses/&gt;\n\nTerms and Conditions for use, reproduction, and distribution\n\n1. Definitions\n“License” shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.\n“Licensor” shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.\n“Legal Entity” shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, “control” means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.\n“You” (or “Your”) shall mean an individual or Legal Entity exercising permissions granted by this License.\n“Source” form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.\n“Object” form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.\n“Work” shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).\n“Derivative Works” shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.\n“Contribution” shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, “submitted” means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as “Not a Contribution.”\n“Contributor” shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.\n\n\n2. Grant of Copyright License\nSubject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.\n\n\n3. Grant of Patent License\nSubject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.\n\n\n4. Redistribution\nYou may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:\n\n(a) You must give any other recipients of the Work or Derivative Works a copy of this License; and\n(b) You must cause any modified files to carry prominent notices stating that You changed the files; and\n(c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and\n(d) If the Work includes a “NOTICE” text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.\n\nYou may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.\n\n\n5. Submission of Contributions\nUnless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.\n\n\n6. Trademarks\nThis License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.\n\n\n7. Disclaimer of Warranty\nUnless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.\n\n\n8. Limitation of Liability\nIn no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.\n\n\n9. Accepting Warranty or Additional Liability\nWhile redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.\nEND OF TERMS AND CONDITIONS\n\n\n\nAPPENDIX: How to apply the Apache License to your work\nTo apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets [] replaced with your own identifying information. (Don’t include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same “printed page” as the copyright notice for easier identification within third-party archives.\nCopyright 2024 PHUSE\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License."
  },
  {
    "objectID": "SAS/ci_for_prop.html",
    "href": "SAS/ci_for_prop.html",
    "title": "Confidence intervals for Proportions in SAS",
    "section": "",
    "text": "The methods to use for calculating a confidence interval (CI) for a proportion depend on the type of proportion you have.\n\n1 sample proportion (1 proportion calculated from 1 group of subjects)\n2 sample proportions and you want a CI for the difference in the 2 proportions.\n\nIf the 2 samples come from 2 independent samples (different subjects in each of the 2 groups)\nIf the 2 samples are matched (i.e. the same subject has 2 results, one on each group [paired data]).\n\n\nThe method selected is also dependent on whether your proportion is close to 0 or 1 (or near to the 0.5 midpoint), and your sample size.\nFor more information about these methods in R & SAS, including which performs better in different scenarios see Five Confidence Intervals for Proportions That You Should Know about1 and Confidence Intervals for Binomial Proportion Using SAS2"
  },
  {
    "objectID": "SAS/ci_for_prop.html#introduction",
    "href": "SAS/ci_for_prop.html#introduction",
    "title": "Confidence intervals for Proportions in SAS",
    "section": "",
    "text": "The methods to use for calculating a confidence interval (CI) for a proportion depend on the type of proportion you have.\n\n1 sample proportion (1 proportion calculated from 1 group of subjects)\n2 sample proportions and you want a CI for the difference in the 2 proportions.\n\nIf the 2 samples come from 2 independent samples (different subjects in each of the 2 groups)\nIf the 2 samples are matched (i.e. the same subject has 2 results, one on each group [paired data]).\n\n\nThe method selected is also dependent on whether your proportion is close to 0 or 1 (or near to the 0.5 midpoint), and your sample size.\nFor more information about these methods in R & SAS, including which performs better in different scenarios see Five Confidence Intervals for Proportions That You Should Know about1 and Confidence Intervals for Binomial Proportion Using SAS2"
  },
  {
    "objectID": "SAS/ci_for_prop.html#data-used",
    "href": "SAS/ci_for_prop.html#data-used",
    "title": "Confidence intervals for Proportions in SAS",
    "section": "Data used",
    "text": "Data used\nThe adcibc data stored here was used in this example, creating a binary treatment variable trt taking the values of Act or PBO and a binary response variable resp taking the values of Yes or No. For this example, a response is defined as a score greater than 4.\n\ndata adcibc2 (keep=trt resp) ;\n    set adcibc;     \n    if aval gt 4 then resp=\"Yes\";\n    else resp=\"No\";     \n    if trtp=\"Placebo\" then trt=\"PBO\";\n    else trt=\"Act\"; \nrun;\n\nThe below shows that for the Actual Treatment, there are 36 responders out of 154 subjects = 0.2338 (23.38% responders).\n\nproc freq data=adcibc;\n    table trt*resp/ nopct nocol;\nrun;"
  },
  {
    "objectID": "SAS/ci_for_prop.html#methods-for-calculating-confidence-intervals-for-a-single-proportion",
    "href": "SAS/ci_for_prop.html#methods-for-calculating-confidence-intervals-for-a-single-proportion",
    "title": "Confidence intervals for Proportions in SAS",
    "section": "Methods for Calculating Confidence Intervals for a single proportion",
    "text": "Methods for Calculating Confidence Intervals for a single proportion\nSAS PROC FREQ in Version 9.4 can compute 11 methods to calculate CIs for a single proportion, an explanation of these methods and the code is shown below. See BINOMIAL3 for more information on SAS parameterization. It is recommended to always sort your data prior to doing a PROC FREQ.\nHere we are calculating a 95% confidence interval for the proportion of responders in the active treatment group.\n\nClopper-Pearson (Exact or binomial CI) Method\nWith Binary endpoint data (response/non-response), we make the assumption that the proportion of responders, has been derived from a series of Bernoulli trials. Trials (Subjects) are independent and we have a fixed number of repeated trials with an outcome of respond or not respond. This type of data follows the discrete binomial probability distribution, and the Clopper-Pearson4 (Exact) method uses this distribution to calculate the CIs. However, for large numbers of trials (subjects), the probability distribution becomes difficult to calculate and hence a variety of approximations were developed all with their pros and cons (depending on your data distribution). This method can also be too conservative, implying that the interval returned is too wide an interval compared to the interval containing the true population proportion 95% of the time.\nClopper-Pearson method is output by SAS as the default method, but you can also specify it using BINOMIAL(LEVEL=\"Yes\" CL=CLOPPERPEARSON);\n\n\nNormal Approximation Method (Also known as the Wald or asymptotic CI Method)\nThe most commonly used alternative to the Clopper-Pearson (Exact) method is the asymptotic Normal Approximation (Wald) CI. In large random samples from independent trials, the sampling distribution of proportions approximately follows the normal distribution. The expectation of a sample proportion is the corresponding population proportion. Therefore, based on a sample of size \\(n\\), a \\((1-\\alpha)\\%\\) confidence interval for population proportion can be calculated using normal approximation as follows:\n\\(p\\approx \\hat p \\pm z_\\alpha \\sqrt{\\hat p(1-\\hat p)}/{n}\\), where \\(\\hat p\\) is the sample proportion, \\(z_\\alpha\\) is the \\(1-\\alpha/2\\) quantile of a standard normal distribution corresponding to level \\(\\alpha\\), and \\(\\sqrt{\\hat p(1-\\hat p)}/{n}\\) is the standard error.\nOne should note that the approximation can become unreliable as the proportion of responders gets close to 0 or 1 (e.g. 0 or 100% responding), and alternative methods may be more suitable. In this scenario, common issues consist of:\n\nit does not respect the 0 and 1 proportion boundary (so you can get a lower CI of -0.1 or an upper CI of 1.1%!)\nthe derived 95% CI may not cover the true proportion 95% of the time\n\nWald method can be derived with or without a Yate’s continuity correction. Applying the continuity correction is recommended when you have a small sample size or the estimated proportion is close to the tail ends (0 or 1). Applying Yate’s correction is considered more conservative but it’s not as conservative as Clopper-Pearson approach.\nNormal approximation method is output by SAS as the default method, but you can also specify it using BINOMIAL(LEVEL=\"Yes\" CL=WALD);\nSAS also produces a continuity correction version of the Wald method, you can specify it using BINOMIAL(LEVEL=\"Yes\" CL=WALD(CORRECT));\n\n\nWilson Method (Also known as the Score method or the Newcombe method)7\nThe Wilson (Score) method is an extension to the normal approximation, but commonly used where the proportion is close to 0 or 1 (i.e. 0% or 100% responding). This is because the normal approximation can be unreliable at the tail ends of the distribution, and as such the Wilson method can provide more reliable CIs. The method can be derived with or without a Yate’s continuity correction. Applying the continuity correction is recommended when you have a small sample size or the estimated proportion is close to the tail ends (0 or 1). Applying Yate’s correction is considered more conservative (sometimes too conservative), but it’s not as conservative as Clopper-Pearson approach. Not that the Wilson method is not boundary-respecting so you can get confidence interval &lt;0 or &gt;1.\nLet p=r/n, where r= number of responses, and n=number of subjects, q=1-p, and z= the appropriate value from standard normal distribution:\n\\[ z{_1-\\alpha/2} \\]For example, for 95% confidence intervals, alpha=0.05, using standard normal tables, z in the equations below will take the value =1.96. Calculate 3 quantities\n\\[ A= 2r+z^2\\]\n\\[ B=z\\sqrt(z^2 + 4rq) \\] \\[ C=2(n+z^2) \\]The method calculates the confidence interval (Low to High) as: (A-B)/C to (A+B)/C\nA = 2 * 36 + 1.96^2 = 75.8416\nB = 1.96 * sqrt (1.96^2 + 4 x 36 x 0.7662) = 20.9435\nC = 2* (154+1.96^2) = 315.6832\nLower interval = A-B/C = 75.8416 - 20.9435 / 315.6832 = 0.17390\nUpper interval = A+B/C = 75.8416 + 20.9435 / 315.6832 = 0.30659\nCI = 0.17390 to 0.30659\nWilson (score) method is output by SAS using BINOMIAL(LEVEL=\"Yes\" CL=Wilson);\nSAS also produces a continuity correction version of the Wilson method, you can specify it using BINOMIAL(LEVEL=\"Yes\" CL=WILSON(CORRECT));\nThe only differences in the equations to calculate the Wilson score with continuity correction is that the equations for A and B are changed as follows:\n\\[ A= 2r+z^2 -1\\]\n\\[ B=z\\sqrt(z^2 - 2 -\\frac{1}{n} + 4rq) \\]\n\n\nAgresti-Coull Method\nAgresti-Coull Method is a ‘simple solution’ designed to improve coverage compared to the Wald method and still perform better than Clopper-Pearson particularly when the probability isn’t in the mid-range (0.5). It is less conservative whilst still having good coverage. The only difference compared to the Wald method is that it adds two successes and two failures to the original observations (increasing the sample by 4 observations). In practice it is not often used.\nAgresti-Coull method is output by SAS using BINOMIAL(LEVEL=\"Yes\" CL=AGRESTICOULL);\n\n\nBinomial based MidP Method\nThe MidP method is similar to the Clopper-Pearson method, but aims to reduce the conservatism. It’s quite a complex method compared to the methods above and rarely used in practice.\nMidP method is output by SAS using BINOMIAL(LEVEL=\"Yes\" CL=MIDP);\n\n\nJeffreys Method\nJeffreys method is a particular type of Bayesian Highest Probability Density (HPD) Method. For proportions, the beta distribution is generally used for the prior, which consists of two parameters alpha and beta. Setting alpha=beta=0.5 is called Jeffrey’s prior. This is considered as non-informative for a binomial proportion.\n\\[\n(Beta (^k/_2 + ^1/_{2}, ^{(n-k)}/_2+^1/_2)_{\\alpha}, Beta (^k/_2 + ^1/_{2}, ^{(n-k)}/_2+^1/_2)_{1-\\alpha}\n\\] Jeffreys method is output by SAS using BINOMIAL(LEVEL=\"Yes\" CL=Jeffreys);\n\n\nBlaker Method6\nThe Blaker method is a less conservative alternative to the Clopper-pearson exact test. It is also an exact method, but derives the CI by inverting the p-value function of an exact test.\nThe Clopper-pearson CI’s are always wider and contain the Blaker CI limits. It’s adoption has been limited due to the numerical algorithm taking longer to compute compared to some of the other methods especially when the sample size is large. NOTE: Klaschka and Reiczigel5 is yet another adaptation of this method.\nBLAKER method is output by SAS using BINOMIAL(LEVEL=\"Yes\" CL=BLAKER);"
  },
  {
    "objectID": "SAS/ci_for_prop.html#example-code-using-proc-freq",
    "href": "SAS/ci_for_prop.html#example-code-using-proc-freq",
    "title": "Confidence intervals for Proportions in SAS",
    "section": "Example Code using PROC FREQ",
    "text": "Example Code using PROC FREQ\nBy adding the option BINOMIAL(LEVEL=\"Yes\") to your ‘PROC FREQ’, SAS outputs the Normal Approximation (Wald) and Clopper-Pearson (Exact) confidence intervals as two default methods, derived for the Responders = Yes. If you do not specify the LEVEL you want to model, then SAS assumes you want to model the first level that appears in the output (alphabetically).\nIt is very important to ensure you are calculating the CI for the correct level! Check your output to confirm, you will see below it states resp=Yes !\nThe output consists of the proportion of resp=Yes, the Asymptotic SE, 95% CIs using normal-approximation method, 95% CI using the Clopper-Pearson method (Exact), and then a Binomial test statistic and p-value for the null hypothesis of H0: Proportion = 0.5.\n\nproc sort data=adcibc;\n    by trt; \nrun; \n\nproc freq data=adcibc ; \n    table resp/ nopct nocol BINOMIAL(LEVEL=\"Yes\");\n    by trt;\nrun;\n\n\n\n\n\n\n\n\n\n\nBy adding the option BINOMIAL(LEVEL=\"Yes\" CL=&lt;name of CI method&gt;), the other CIs are output as shown below. You can list any number of the available methods within the BINOMIAL option CL=XXXX separated by a space. However, SAS will only calculate the WILSON and WALD or the WILSON(CORRECT) and WALD(CORRECT). SAS wont output them both from the same procedure.\n\nBINOMIAL(LEVEL=\"Yes\" CL=CLOPPERPEARSON WALD WILSON AGRESTICOULL JEFFREYS MIDP LIKELIHOODRATIO LOGIT BLAKER) will return Agresti-Coull, BLAKER, Clopper-pearson(Exact), WALD(without continuity correction) WILSON(without continuity correction), JEFFREYS, MIDP, LIKELIHOODRATIO, and LOGIT\nBINOMIAL(LEVEL=\"Yes\" CL=ALL); will return Agresti-Coull, Clopper-pearson (Exact), Jeffreys, Wald(without continuity correction), Wilson (without continuity correction)\nBINOMIALc(LEVEL=\"Yes\" CL=ALL);will return Agresti-Coull, Clopper-pearson (Exact), Jeffreys, Wald (with continuity correction), Wilson(with continuity correction)\nBINOMIALc(LEVEL=\"Yes\" CL=WILSON(CORRECT)  WALD(CORRECT));will return Wilson(with continuity correction) and Wald (with continuity correction)\n\n\nproc freq data=adcibc;\n    table resp/ nopct nocol \n    BINOMIAL(LEVEL=\"Yes\" \n            CL= CLOPPERPEARSON WALD WILSON \n            AGRESTICOULL JEFFREYS MIDP \n            LIKELIHOODRATIO LOGIT BLAKER);\n    by trt;\nrun;\n\n\n\n\n\n\n\n\n\n\n\nproc freq data=adcibc;\n    table resp/ nopct nocol \n        BINOMIAL(LEVEL=\"Yes\" \n        CL= WILSON(CORRECT)  WALD(CORRECT));\n    by trt; \nrun;\n\n\n\n\n\n\n\n\n\n\n\nSAS output often rounds to 3 or 4 decimal places in the output window, however the full values can be obtained using SAS ODS statements. ods output binomialcls=bcl; and then using the bcl dataset, in a data step to put the variable out to the number of decimal places we require.\n10 decimal places shown here ! lowercl2=put(lowercl,12.10);"
  },
  {
    "objectID": "SAS/ci_for_prop.html#methods-for-calculating-confidence-intervals-for-a-matched-pair-proportion",
    "href": "SAS/ci_for_prop.html#methods-for-calculating-confidence-intervals-for-a-matched-pair-proportion",
    "title": "Confidence intervals for Proportions in SAS",
    "section": "Methods for Calculating Confidence Intervals for a matched pair proportion",
    "text": "Methods for Calculating Confidence Intervals for a matched pair proportion\nYou may experience paired data in any of the following types of situation:\n\nTumour assesssments classified as Progressive Disease or Not Progressive Disease performed by an Investigator and separately by an independent panel.\nA paired case-control study (each subject taking active treatment is matched to a patient taking control)\nA cross-over trial where the same subjects take both medications\n\nIn all these cases, the calculated proportions for the 2 groups are not independent.\nUsing a cross over study as our example, a 2 x 2 table can be formed as follows:\n\n\n\n\n\n\n\n\n\n\nPlacebo\nResponse= Yes\nPlacebo\nResponse = No\nTotal\n\n\n\n\nActive Response = Yes\nr\ns\nr+s\n\n\nActive Response = No\nt\nu\nt+u\n\n\nTotal\nr+t\ns+u\nN = r+s+t+u\n\n\n\nThe proportions of subjects responding on each treatment are:\nActive: \\(\\hat p_1 = (r+s)/n\\) and Placebo: \\(\\hat p_2= (r+t)/n\\)\nDifference between the proportions for each treatment are: \\(D=p1-p2=(s-t)/n\\)\nSuppose :\n\n\n\n\n\n\n\n\n\n\nPlacebo\nResponse= Yes\nPlacebo\nResponse = No\nTotal\n\n\n\n\nActive Response = Yes\nr = 20\ns = 15\nr+s = 35\n\n\nActive Response = No\nt = 6\nu = 5\nt+u = 11\n\n\nTotal\nr+t = 26\ns+u = 20\nN = r+s+t+u = 46\n\n\n\n\nNormal Approximation Method (Also known as the Wald or asymptotic CI Method)\nIn large random samples from independent trials, the sampling distribution of the difference between two proportions approximately follows the normal distribution. Hence the SE for the difference and 95% confidence interval can be calculated using the following equations.\n\\(SE(D)=\\frac{1}{n} * sqrt(s+t-\\frac{(s-t)^2}{n})\\)\n\\(D-z_\\alpha * SE(D)\\) to \\(D+z_\\alpha * SE(D)\\)\nwhere \\(z_\\alpha\\) is the \\(1-\\alpha/2\\) quantile of a standard normal distribution corresponding to level \\(\\alpha\\),\nD=(15-6) /46 = 0.196\nSE(D) = 1/ 46 * sqrt (15+6- (((15+6)^2)/46) ) = 0.0956\nLower CI= 0.196 - 1.96 *0.0956 = 0.009108\nUpper CI = 0.196 + 1.96 * 0.0956 = 0.382892\n\n\nWilson Method (Also known as the Score method or the Altman, Newcombe method7 )\nDerive the confidence intervals using the Wilson Method equations above for each of the individual single samples 1 and 2.\nLet l1 = Lower CI for sample 1, and u1 be the upper CI for sample 1.\nLet l2 = Lower CI for sample 2, and u2 be the upper CI for sample 2.\nWe then define \\(\\phi\\) which is used to correct for \\(\\hat p_1\\) and \\(\\hat p_2\\) not being independent. As the samples are related, \\(\\phi\\) is usually positive and thus makes the confidence interval smaller (narrower).\nIf any of r+s, t+u, r+t, s+u are zero, then set \\(\\phi\\) to be 0.\nOtherwise we calculate A, B and C, and \\(\\phi=C / sqrt A\\)\nIn the above: \\(A=(r+s)(t+u)(r+t)(s+u)\\) and \\(B=(ru-st)\\)\nTo calculate C follow the table below. n=sample size.\n\n\n\nCondition of B\nSet C equal to\n\n\n\n\nIf B is greater than n/2\nB - n/2\n\n\nIf B is between 0 and n/2\n0\n\n\nIf B is less than 0\nB\n\n\n\nLet D = p1-p2 (the difference between the observed proportions of responders)\nThe Confidence interval for the difference between two population proportions is: \\(D - sqrt((p_1-l_1)^2-2\\phi(p_1-l_1)(u_2-p_2)+(u_2-p_2)^2 )\\) to\n\\(D + sqrt((p_2-l_2)^2-2\\phi(p_2-l_2)(u_1-p_1)+(u_1-p_1)^2 )\\)\nFirst using the Wilson Method equations for each of the individual single samples 1 and 2.\n\n\n\n\nActive\nPlacebo\n\n\n\n\na\n73.842\n55.842\n\n\nb\n13.728\n11.974\n\n\nc\n99.683\n99.683\n\n\nLower CI\n0.603 = L1\n0.440 = L2\n\n\nUpper CI\n0.878 = U1\n0.680 = U2\n\n\n\n\\(A=(r+s)(t+u)(r+t)(s+u)\\) = 9450000\nB=10\nC= 0 (as B is between 0 and n/2)\n\\(\\phi\\) = 0.\nHence the middle part of the equation simplies to 0, and becomes simply:\nLower CI = \\(D - sqrt((p_1-l_1)^2+(u_2-p_2)^2 )\\) = 0.196 - sqrt [ (0.761-0.603)^2 + (0.680-0.565) ^2 ]\nUpper CI = \\(D + sqrt((p_2-l_2)^2+(u_1-p_1)^2 )\\) = 0.196 + sqrt [ (0.565-0.440)^2 + (0.878-0.761) ^2 ]\nCI= 0.00032 to 0.367389"
  },
  {
    "objectID": "SAS/ci_for_prop.html#example-code-using-proc-freq-1",
    "href": "SAS/ci_for_prop.html#example-code-using-proc-freq-1",
    "title": "Confidence intervals for Proportions in SAS",
    "section": "Example Code using PROC FREQ",
    "text": "Example Code using PROC FREQ\nUnfortunately, SAS does not have a procedure which outputs the confidence intervals for matched proportions.\nInstead it calculates the risk difference = (r / (r+s) - t / (t+u) )\nWhich in the example above is: 20/ (20+15) - 6 / (6+5) = 0.0296\nThis is more applicable when you have exposed / non-exposed groups looking at who has experienced the outcome. SAS Proc Freq has 3 methods for analysis of paired data using a Common risk difference.\nThe default method is Mantel-Haenszel confidence limits. SAS can also Score (Miettinen-Nurminen) CIs and Stratified Newcombe CIs (constructed from stratified Wilson Score CIs). See here for equations.\nAs you can see below, this is not a CI for difference in proportions of 0.196, it is a CI for the risk difference of 0.0260. So must be interpreted with much consideration.\n\nproc freq data=adcibc; \n    table act*pbo/commonriskdiff(cl=MH); \nrun;"
  },
  {
    "objectID": "SAS/ci_for_prop.html#methods-for-calculating-confidence-intervals-for-2-independent-samples-proportion",
    "href": "SAS/ci_for_prop.html#methods-for-calculating-confidence-intervals-for-2-independent-samples-proportion",
    "title": "Confidence intervals for Proportions in SAS",
    "section": "Methods for Calculating Confidence Intervals for 2 independent samples proportion",
    "text": "Methods for Calculating Confidence Intervals for 2 independent samples proportion\nThis paper8 describes many methods for the calculation of confidence intervals for 2 independent proportions. The most commonly used are: Wald with continuity correction and Wilson with continuity correction. The Wilson method may be more applicable when sample sizes are smaller and/or the proportion is closer to 0 or 1, since reliance on a normal distribution may be inappropriate.\nSAS is able to calculate CIs using the following methods: Exact, Agresti/Caffo, Wald, Wald with Continuity correction, Wilson/Newcombe Score, Wilson/Newcombe score with continuity correction, Miettinen and Nurminen, and Hauck-Anderson. Example code is shown below, before provision of a much more detailed analysis using Wald and Wilson with and without continuity correction.\n\n# Wald, Wilson, Agresti/Caffo, Hauck-Anderson, and Miettinen and Nurminen methods\nproc freq data=adcibc order=data;\n    table trt*resp /riskdiff(CL=(wald wilson ac ha mn ));\nrun;\n\n# exact method\nproc freq data=adcibc order=data;\n    exact riskdiff (method=noscore);\n    table trt*resp/riskdiff(CL=(exact)); \nrun;\n\n\nNormal Approximation Method (Also known as the Wald or asymptotic CI Method)\nIn large random samples from independent trials, the sampling distribution of the difference between two proportions approximately follows the normal distribution.\nThe difference between two independent sample proportions is calculated as: \\(D= \\hat p_1-\\hat p_2\\)\nA confidence interval for the difference between two independent proportions \\(D\\) can be calculated using:\n\\(D\\approx \\hat D \\pm z_\\alpha * SE(\\hat p)\\),\nwhere \\(z_\\alpha\\) is the \\(1-\\alpha/2\\) quantile of a standard normal distribution corresponding to level \\(\\alpha\\), and\n\\(SE (\\hat p) = sqrt{( \\frac{\\hat p_1 (1-\\hat p_1)}{n_1} + \\frac{\\hat p_2 (1-\\hat p_2)}{n_2})}\\)\nWith continuity correction, the equation becomes\n\\(D\\approx \\hat D \\pm (CC + z_\\alpha * SE(\\hat p))\\),\nwhere \\(z_\\alpha\\) is the \\(1-\\alpha/2\\) quantile of a standard normal distribution corresponding to level \\(\\alpha\\),\nand \\(SE (\\hat p)\\) = \\(sqrt{( \\frac{\\hat p_1 (1-\\hat p_1)}{n_1} + \\frac{\\hat p_2 (1-\\hat p_2)}{n_2})}\\)\nand\n\\(CC = \\frac{1}{2} (\\frac{1}{n_1} + \\frac{1}{n_2})\\)\n\n\nWilson Method (Also known as the Score method or the Altman, Newcombe method7 )\nDerive the confidence intervals using the Wilson Method equations above for each of the individual single samples 1 and 2.\nLet l1 = Lower CI for sample 1, and u1 be the upper CI for sample 1.\nLet l2 = Lower CI for sample 2, and u2 be the upper CI for sample 2.\nLet D = p1-p2 (the difference between the observed proportions)\nThe Confidence interval for the difference between two population proportions is: \\[ D - sqrt((p_1-l_1)^2+(u_2-p_2)^2) \\quad to\\quad D + sqrt((p_2-l_2)^2+(u_1-p_1)^2 )   \\]"
  },
  {
    "objectID": "SAS/ci_for_prop.html#example-code-using-proc-freq-2",
    "href": "SAS/ci_for_prop.html#example-code-using-proc-freq-2",
    "title": "Confidence intervals for Proportions in SAS",
    "section": "Example Code using PROC FREQ",
    "text": "Example Code using PROC FREQ\nIt is important to check the output to ensure that you are modelling Active - Placebo, and response = Yes (not Response=No). By default SAS sorts alphabetically and calculates CI’s for the first column. You can change this by using the COLUMN= Option on riskdiff or by sorting the dataset (here by trt, then descending resp), and then using order=data in the proc freq. This tells SAS to use the order you have sorted the data by. SAS confirms this by saying “Difference is (Row 1 - Row 2)” and “Column 1 (resp=Yes)”. Note how in the SAS output, it calls the requested ‘wilson’ method ‘Newcombe’ in the output.\nOptions for riskdiff(CL=XXX) consist of AC:Agresti-Caffo, EXACT=exact, HA:Hauck-Anderson, MN or SCORE:Miettinen-Nurminen (another type of Score CI), WILSON or NEWCOMBE: Wilson method described above, and WALD: normal approximation wald method described above. Examples using Wald and Wilson are shown below with and without continuity correction.\n\nproc sort data=adcibc;\n    by  trt descending resp;\nrun;\n\n# without continuity correction\nproc freq data=adcibc order=data;\n    table trt*resp/riskdiff(CL=(wald wilson)); \nrun;\n\n# with continuity correction\nproc freq data=adcibc order=data;\n    table trt*resp/riskdiff(CORRECT CL=(wald wilson)); \nrun;"
  },
  {
    "objectID": "SAS/ci_for_prop.html#reference",
    "href": "SAS/ci_for_prop.html#reference",
    "title": "Confidence intervals for Proportions in SAS",
    "section": "Reference",
    "text": "Reference\n\nFive Confidence Intervals for Proportions That You Should Know about\nConfidence intervals for Binomial Proportion Using SAS\nSAS PROC FREQ here and here\nClopper,C.J.,and Pearson,E.S.(1934),“The Use of Confidence or Fiducial Limits Illustrated in the Case of the Binomial”, Biometrika 26, 404–413.\nKlaschka, J. and Reiczigel, J. (2021). “On matching confidence intervals and tests for some discrete distributions: Methodological and computational aspects,” Computational Statistics, 36, 1775–1790.\nBlaker, H. (2000). Confidence curves and improved exact confidence intervals for discrete distribu\u0002tions, Canadian Journal of Statistics 28 (4), 783–798\nD. Altman, D. Machin, T. Bryant, M. Gardner (eds). Statistics with Confidence: Confidence Intervals and Statistical Guidelines, 2nd edition. John Wiley and Sons 2000.\nhttps://www.lexjansen.com/wuss/2016/127_Final_Paper_PDF.pdf"
  },
  {
    "objectID": "SAS/rbmi_continuous_joint_SAS.html",
    "href": "SAS/rbmi_continuous_joint_SAS.html",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "",
    "text": "Reference-based multiple imputation methods have become popular for handling missing data, as well as for conducting sensitivity analyses, in randomized clinical trials. In the context of a repeatedly measured continuous endpoint assuming a multivariate normal model, Carpenter et al. (2013) proposed a framework to extend the usual MAR-based MI approach by postulating assumptions about the joint distribution of pre- and post-deviation data. Under this framework, one makes qualitative assumptions about how individuals’ missing outcomes relate to those observed in relevant groups in the trial, based on plausible clinical scenarios. Statistical analysis then proceeds using the method of multiple imputation (Rubin 1976, Rubin 1987).\nIn general, multiple imputation of a repeatedly measured continuous outcome can be done via 2 computational routes (Roger 2022):\n\nStepwise: split problem into separate imputations of data at each visit\n\nrequires monotone missingness, such as missingness due to withdrawal\nconditions on the imputed values at previous visit\nBayesian linear regression problem is much simpler with monotone missing, as one can sample directly using conjugate priors\n\nOne-step approach (joint modelling): Fit a Bayesian full multivariate normal repeated measures model using MCMC and then draw a sample.\n\nHere, we illustrate reference-based multiple imputation of a continuous outcome measured repeatedly via the so-called one-step approach.\n\n\n\nThe five macros (Roger 2022), available at LSHTM DIA Missing Data, fit a Bayesian Normal RM model and then impute post withdrawal data under a series of possible post-withdrawal profiles including J2R, CIR and CR as described by Carpenter et al. (2013). It then analyses the data using a univariate ANOVA at each visit and summarizes across imputations using Rubin’s rules.\nThe following standard and reference-based multiple imputation approaches will be illustrated here:\n\nMAR (Missing At Random)\nCIR (Copy Increment from Reference)\nJ2R (Jump to Reference)\nCR (Copy Reference)"
  },
  {
    "objectID": "SAS/rbmi_continuous_joint_SAS.html#reference-based-multiple-imputation-rbmi",
    "href": "SAS/rbmi_continuous_joint_SAS.html#reference-based-multiple-imputation-rbmi",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "",
    "text": "Reference-based multiple imputation methods have become popular for handling missing data, as well as for conducting sensitivity analyses, in randomized clinical trials. In the context of a repeatedly measured continuous endpoint assuming a multivariate normal model, Carpenter et al. (2013) proposed a framework to extend the usual MAR-based MI approach by postulating assumptions about the joint distribution of pre- and post-deviation data. Under this framework, one makes qualitative assumptions about how individuals’ missing outcomes relate to those observed in relevant groups in the trial, based on plausible clinical scenarios. Statistical analysis then proceeds using the method of multiple imputation (Rubin 1976, Rubin 1987).\nIn general, multiple imputation of a repeatedly measured continuous outcome can be done via 2 computational routes (Roger 2022):\n\nStepwise: split problem into separate imputations of data at each visit\n\nrequires monotone missingness, such as missingness due to withdrawal\nconditions on the imputed values at previous visit\nBayesian linear regression problem is much simpler with monotone missing, as one can sample directly using conjugate priors\n\nOne-step approach (joint modelling): Fit a Bayesian full multivariate normal repeated measures model using MCMC and then draw a sample.\n\nHere, we illustrate reference-based multiple imputation of a continuous outcome measured repeatedly via the so-called one-step approach.\n\n\n\nThe five macros (Roger 2022), available at LSHTM DIA Missing Data, fit a Bayesian Normal RM model and then impute post withdrawal data under a series of possible post-withdrawal profiles including J2R, CIR and CR as described by Carpenter et al. (2013). It then analyses the data using a univariate ANOVA at each visit and summarizes across imputations using Rubin’s rules.\nThe following standard and reference-based multiple imputation approaches will be illustrated here:\n\nMAR (Missing At Random)\nCIR (Copy Increment from Reference)\nJ2R (Jump to Reference)\nCR (Copy Reference)"
  },
  {
    "objectID": "SAS/rbmi_continuous_joint_SAS.html#data-used",
    "href": "SAS/rbmi_continuous_joint_SAS.html#data-used",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Data used",
    "text": "Data used\nA publicly available example dataset from an antidepressant clinical trial of an active drug versus placebo is used. Overall, data of 172 patients is available with 88 patients receiving placebo and 84 receiving active drug. The same data is used for the R part.\nThe relevant endpoint is the Hamilton 17-item depression rating scale (HAMD17) which was assessed at baseline and at weeks 1, 2, 4, and 6 (visits 4-7). Study drug discontinuation occurred in 24% (20/84) of subjects from the active drug and 26% (23/88) of subjects from placebo. All data after study drug discontinuation are missing.\n\nproc print data=dat (obs=10);\n      var PATIENT GENDER THERAPY RELDAYS VISIT BASVAL HAMDTL17 CHANGE;\nrun;\n\n\n\n\n\n\n\n\n\n\nThe number of patients per visit and arm are:\n\nproc freq data=dat;\n      table VISIT*THERAPY / norow nocol nopercent nocum;\nrun;\n\n\n\n\n\n\n\n\n\n\nThe mean change from baseline of the endpoint (Hamilton 17-item depression rating scale, HAMD17) per visit per treatment group using only the complete cases are:\n\nproc means data=dat n mean nonobs;\n      class VISIT THERAPY;\n      var CHANGE;\nrun;\n\n\n\n\n\n\n\n\n\n\nThe missingness pattern is show below. The incomplete data is primarily monotone in nature. 128 patients have complete data for all visits (all 1’s at each visit). 20, 10 and 13 patients have 1, 2 or 3 monotone missing data, respectively. Further, there is a single additional intermittent missing observation (patient 3618).\n\nproc transpose data=dat out=HAMD_wide(drop=_NAME_) prefix=CHG;\n      by PATIENT THERAPY BASVAL;\n      id VISIT;\n      var CHANGE;\nrun;\n\nproc mi data=HAMD_wide nimpute=0 displaypattern=NOMEANS;\n      var CHG4 CHG5 CHG6 CHG7;\nrun;"
  },
  {
    "objectID": "SAS/rbmi_continuous_joint_SAS.html#complete-case-analysis",
    "href": "SAS/rbmi_continuous_joint_SAS.html#complete-case-analysis",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Complete case analysis",
    "text": "Complete case analysis\nA complete case analysis is performed using mixed model for repeated measures (MMRM) with covariates: treatment [THERAPY], gender [GENDER], visit [VISIT] as factors; baseline score [BASVAL] as continuous; and visit-by-treatment [THERAPY * VISIT] interaction, and visit-by-baseline [BASVAL * VISIT] interaction. An unstructured covariance matrix is used. The MIXED procedure is used.\n\nproc mixed data=dat method=reml;\n      class THERAPY(ref=\"PLACEBO\") VISIT(ref=\"4\") PATIENT GENDER(ref=\"F\");\n      model CHANGE = THERAPY GENDER VISIT BASVAL THERAPY*VISIT BASVAL*VISIT /s ddfm=satterthwaite;\n      repeated VISIT / type=UN subject=PATIENT r;\n      lsmeans THERAPY*VISIT / diff=control(\"PLACEBO\" \"7\") cl;\nrun;\n\nThe parameter estimates of the fixed effects are:\n\n\n\n\n\n\n\n\n\nThe estimated unstructured covariance matrix parameters are:\n\n\n\n\n\n\n\n\n\nThe treatment difference at visit 7 is of interest, and is estimated to be -2.829 (se=1.117) with 95% CI of [-5.033 to -0.624] (p=0.0122)."
  },
  {
    "objectID": "SAS/rbmi_continuous_joint_SAS.html#five-macros-mar-approach",
    "href": "SAS/rbmi_continuous_joint_SAS.html#five-macros-mar-approach",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Five macros: MAR approach",
    "text": "Five macros: MAR approach\nAs described above, the so-called five macros will be used for the SAS implementation. The five macros are available at LSHTM DIA Missing Data under Reference-based MI via Multivariate Normal RM (the “five macros and MIWithD”). For the details, see the use guide available in the download of the five macros.\nApplying the five macros for reference-based multiple imputation entails the sequential run of the following:\n\nPart1A declares the parameter estimation model and checks consistency with the dataset. It builds a master dataset which holds details of the current job (run of the macros in sequence). It also builds indexes for the classification variables, which may be either numeric or character.\nPart1B fits the parameter estimation model using the MCMC procedure and draws a pseudo-independent sample from the joint posterior distribution for the linear predictor parameters and the covariance parameters.\nPart2A calculates the predicted mean under MAR, and under MNAR for each subject based on their withdrawal pattern once for each draw of the linear predictor parameter estimates. The choice of MNAR is controlled by the method used, which may vary from subject to subject.\nPart2B imputes the intermediate missing values using MAR and the trailing missing values using MNAR, by deriving the conditional distribution for the missing values conditional on the observed values and covariates, using the appropriate sampled covariance parameter estimates.\nPart3 carries out a univariate ANOVA analysis at selected time points usually based on the same covariates as the parameter estimation model. It then combines the least-squares means and their differences using the MIANALYZE procedure to provide final results. It is in this macro which handles the Delta methods.\n\nMost of the computation time is spent in the Part1B macro where the MCMC procedure is used to generate a sample from the posterior distribution of the full set of model parameters. These are stored away and can be used repeatedly by calling the later macros over and over again using different imputation methods.\nTo perform reference-based multiple imputation using MAR approach to following code is used\n\n%part1A(jobname = HAMD, \n        Data=dat,\n        Subject=PATIENT,\n        RESPONSE = CHANGE,\n        Time = VISIT,\n        Treat = THERAPY,\n        Covbytime = BASVAL,\n        Catcov = GENDER);\n\n%part1B(jobname = HAMD,\n        Ndraws = 500,\n        thin = 10,\n        seed = 12345);\n\n%part2A(jobname = HAMD_MAR,\n        inname = HAMD,\n        method = MAR);\n\n%part2B(jobname = HAMD_MAR,\n        seed = 12345);\n\n%part3(Jobname = HAMD_MAR,\n        anref = PLACEBO,\n        Label = MAR);\n\nTo print the results of the contrast at week 7\n\nproc print data=HAMD_MAR_OUT;\n    where VISIT = \"7\";\n    var VISIT THERAPY _THERAPY Diff SE_Diff df Probt LCL_Diff UCL_Diff;\nrun;"
  },
  {
    "objectID": "SAS/rbmi_continuous_joint_SAS.html#five-macros-mnar-cr-approach",
    "href": "SAS/rbmi_continuous_joint_SAS.html#five-macros-mnar-cr-approach",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Five macros: MNAR CR approach",
    "text": "Five macros: MNAR CR approach\nTo perform reference-based multiple imputation using Copy Reference (CR) approach the following changes are needed in part2A of the 5 macros\n\n%part2A(jobname = HAMD_CR,\n        inname = HAMD,\n        method = CR,\n        ref = PLACEBO);\n\nThe results for M=500 imputations are"
  },
  {
    "objectID": "SAS/rbmi_continuous_joint_SAS.html#five-macros-mnar-j2r-approach",
    "href": "SAS/rbmi_continuous_joint_SAS.html#five-macros-mnar-j2r-approach",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Five macros: MNAR J2R approach",
    "text": "Five macros: MNAR J2R approach\nTo perform reference-based multiple imputation using Jump to Reference (J2R) approach the following changes are needed in part2A of the 5 macros\n\n%part2A(jobname = HAMD_J2R,\n        inname = HAMD,\n        method = J2R,\n        ref = PLACEBO);\n\nThe results for M=500 imputations are"
  },
  {
    "objectID": "SAS/rbmi_continuous_joint_SAS.html#five-macros-mnar-cir-approach",
    "href": "SAS/rbmi_continuous_joint_SAS.html#five-macros-mnar-cir-approach",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Five macros: MNAR CIR approach",
    "text": "Five macros: MNAR CIR approach\nTo perform reference-based multiple imputation using Copy Increments in Reference (CIR) approach the following changes are needed in part2A of the 5 macros\n\n%part2A(jobname = HAMD_CIR,\n        inname = HAMD,\n        method = CIR,\n        ref = PLACEBO);\n\nThe results for M=500 imputations are"
  },
  {
    "objectID": "SAS/rbmi_continuous_joint_SAS.html#summary-of-results",
    "href": "SAS/rbmi_continuous_joint_SAS.html#summary-of-results",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Summary of results",
    "text": "Summary of results\nIn the table we present the results of the different imputation strategies (and with varying number, M, of multiple imputation draws). Note that some results can be slightly different from the results above due to a possible different seed. The table show the contrast at Visit 7 between DRUG and PLACEBO [DRUG - PLACEBO]:\n\n\n\n\n\n\n\n\n\n\nMethod\nEstimate\nSE\n95% CI\np-value\n\n\n\n\nComplete Case\n-2.829\n1.117\n-5.035 to -0.623\n0.0123\n\n\nMI - MAR (M=500)\n-2.810\n1.122\n-5.029 to -0.592\n0.0134\n\n\nMI - MAR (M=2000)\n-2.816\n1.128\n-5.047 to -0.586\n0.0137\n\n\nMI - MAR (M=5000)\n-2.825\n1.123\n-5.045 to -0.605\n0.0130\n\n\nMI - MNAR CR (M=500)\n-2.384\n1.120\n-4.598 to -0.170\n0.0350\n\n\nMI - MNAR CR (M=2000)\n-2.390\n1.118\n-4.599 to -0.180\n0.0342\n\n\nMI - MNAR CR (M=5000)\n-2.400\n1.115\n-4.604 to -0.196\n0.0330\n\n\nMI - MNAR J2R (M=500)\n-2.122\n1.141\n-4.377 to 0.133\n0.0650\n\n\nMI - MNAR J2R (M=2000)\n-2.135\n1.140\n-4.388 to 0.117\n0.0630\n\n\nMI - MNAR J2R (M=5000)\n-2.144\n1.136\n-4.389 to 0.101\n0.0611\n\n\nMI - MNAR CIR (M=500)\n-2.461\n1.120\n-4.674 to -0.248\n0.0296\n\n\nMI - MNAR CIR (M=2000)\n-2.469\n1.118\n-4.679 to -0.260\n0.0287\n\n\nMI - MNAR CIR (M=5000)\n-2.481\n1.115\n-4.684 to -0.278\n0.0276"
  },
  {
    "objectID": "SAS/rbmi_continuous_joint_SAS.html#discussion",
    "href": "SAS/rbmi_continuous_joint_SAS.html#discussion",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Discussion",
    "text": "Discussion\nA note on computational time. The total running time (including data loading, setting up data sets, MCMC run, imputing data and analysis MI data) for M=500 was about 23 seconds on a personal laptop. It increased to about 44 seconds for M=2000. Computational time was similar across difference imputation strategies.\nWith a small number of Ndraws in part1B a warning could pop-up “There is still significant autocorrelation after 5 lags, and the effective sample size for the parameter might not be estimated accurately.”. Increasing the number of Ndraws will mostly solve this warning. For example, for this data example, this message is received when setting Ndraws below 100."
  },
  {
    "objectID": "SAS/rbmi_continuous_joint_SAS.html#appendix-1-mmrm-as-analysis-model",
    "href": "SAS/rbmi_continuous_joint_SAS.html#appendix-1-mmrm-as-analysis-model",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Appendix 1: mmrm as analysis model",
    "text": "Appendix 1: mmrm as analysis model\nPart 3 of the 5 macros carries out a univariate ANOVA analysis at selected time points usually based on the same covariates as the parameter estimation model. It then combines the least-squares means and their differences using Rubin’s formula in a calculation similar to that in the MIANALYZE procedure to provide final results.\nSince, all imputed datasets are readily available (after part2B), another possibility is to analyse each imputed dataset using the analysis model of your choice, and combining the results using PROC MIANALYZE. For example, suppose an MMRM should be fit on each imputed dataset:\n\ndata HAMD_CR_DATAFULL;\n    set HAMD_CR_DATAFULL;\n    _Imputation_ = draw;\nrun;    \n\nproc mixed data=HAMD_CR_DATAFULL ;\n    by _Imputation_;\n  class THERAPY(ref=\"PLACEBO\") VISIT(ref=\"4\") PATIENT GENDER(ref=\"F\");\n  model CHANGE = THERAPY GENDER VISIT BASVAL THERAPY*VISIT BASVAL*VISIT /s ddfm=satterthwaite;\n  repeated VISIT /  type=UN subject=PATIENT r;\n  lsmeans THERAPY*VISIT / diff=control(\"PLACEBO\" \"7\") cl;\n  ods output Diffs=diff01;\nrun;    \n\nproc mianalyze parms=diff01(where=(VISIT=\"7\"));\n    class THERAPY VISIT;\n    modeleffects THERAPY*VISIT;\n    ods output ParameterEstimates=res01;\nrun;\n\nThe results for M=500 imputations are"
  },
  {
    "objectID": "SAS/rbmi_continuous_joint_SAS.html#reference",
    "href": "SAS/rbmi_continuous_joint_SAS.html#reference",
    "title": "Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "Reference",
    "text": "Reference\nCarpenter JR, Roger JH & Kenward MG (2013). Analysis of Longitudinal Trials with Protocol Deviation: A Framework for Relevant, Accessible Assumptions, and Inference via MI. Journal of Biopharmaceutical Statistics 23: 1352-1371.\nFive macros: Drug Information Association (DIA) Missing Data Working Group (2012). Reference-based MI via Multivariate Normal RM (the “five macros and MIWithD”). London School of Hygiene and Tropical Medicine DIA Missing Data.\nPROC MIANALYZE, SAS Institute Inc. (2017). SAS/STAT® 14.3 User’s Guide. Cary, NC: SAS Institute Inc.\nRoger J (2022, Dec 8). Other statistical software for continuous longitudinal endpoints: SAS macros for multiple imputation. Addressing intercurrent events: Treatment policy and hypothetical strategies. Joint EFSPI and BBS virtual event.\nRubin DB (1976). Inference and Missing Data. Biometrika 63: 581–592.\nRubin DB (1987). Multiple Imputation for Nonresponse in Surveys. New York: John Wiley & Sons."
  },
  {
    "objectID": "SAS/tobit regression SAS.html",
    "href": "SAS/tobit regression SAS.html",
    "title": "Tobit Regression",
    "section": "",
    "text": "Censoring occurs when data on the dependent variable is only partially known. For example, in virology, sample results could be below the lower limit of detection (eg, 100 copies/mL) and in such a case we only know that the sample result is &lt;100 copies/mL, but we don’t know the exact value.\nLet \\(y^{*}\\) be the the true underlying latent variable, and \\(y\\) the observed variable. We discuss here censoring on the left:\n\\[\ny =\n\\begin{cases}\ny^{*}, & y^{*} &gt; \\tau  \\\\\n\\tau, & y^{*} \\leq \\tau\n\\end{cases}       \n\\] We consider tobit regression with a censored normal distribution. The model equation is \\[\ny_{i}^{*} = X_{i}\\beta + \\epsilon_{i}\n\\] with \\(\\epsilon_{i} \\sim N(0,\\sigma^2)\\). But we only observe \\(y = max(\\tau, y^{*})\\). The tobit model uses maximum likelihood estimation (for details see for example Breen, 1996). It is important to note that \\(\\beta\\) estimates the effect of \\(x\\) on the latent variable \\(y^{*}\\), and not on the observed value \\(y\\).\n\n\n\nWe assume two equally sized groups (n=10 in each group). The data is censored on the left at a value of \\(\\tau=8.0\\). In group A 4/10 records are censored, and 1/10 in group B.\n\ndata dat_used;\n    input ID$ ARM$ Y CENS;\n    cards;\n  001 A 8.0 1 \n  002 A 8.0 1\n  003 A 8.0 1\n  004 A 8.0 1\n  005 A 8.9 0\n  006 A 9.5 0\n  007 A 9.9 0\n  008 A 10.3 0\n  009 A 11.0 0\n  010 A 11.2 0\n  011 B 8.0 1 \n  012 B 9.2 0\n  013 B 9.9 0\n  014 B 10.0 0\n  015 B 10.6 0\n  016 B 10.6 0\n  017 B 11.3 0\n  018 B 11.8 0\n  019 B 12.9 0\n  020 B 13.0 0\n    ;\nrun;\n\n\n\n\nThe analysis will be based on a Tobit analysis of variance with \\(Y\\), rounded to 1 decimal places, as dependent variable and study group as a fixed covariate. A normally distributed error term will be used. Values will be left censored at the value 8.0.\nFirst a data manipulation step needs to be performed in which the censored values are set to missing for a new variable called lower.\n\ndata dat_used;\n    set dat_used;\n    if Y &lt;= 8.0 then lower=.; else lower=Y;\nrun;\n\nThe data are sorted to make sure the intercept will correspond to the mean of ARM A.\n\nproc sort data=dat_used;\n    by descending ARM;\nrun;\n\nThe LIFEREG procedure is used for tobit regression. The following model syntax is used:\n  MODEL (lower,upper)= effects / options ;\nHere, if the lower value is missing, then the upper value is used as a left-censored value.\n\nproc lifereg data=dat_used order=data;\n    class ARM;\n    model (lower, Y) = ARM / d=normal;\n    lsmeans ARM /cl alpha=0.05;\n    estimate 'Contrast B-A' ARM 1 -1 / alpha=0.05;\nrun;\n\nThe fit statistics, type 3 analysis of effects and parameter estimated are shown here. The output provides an estimate of difference between groups A and B (B-A), namely 1.8225 (se=0.8061). The presented p-value is a two-sided p-value based on the Z-test. The scale parameter is an estimate for \\(\\sigma\\).\n\n\n\n\n\n\n\n\n\nThe p-value and confidence intervals of the contrast B-A are shown here. The p-value is the same as above.\n\n\n\n\n\n\n\n\n\n\n\n\nBreen, R. (1996). Regression models. SAGE Publications, Inc., https://doi.org/10.4135/9781412985611\nTobin, James (1958). “Estimation of Relationships for Limited Dependent Variables”. Econometrica. 26 (1): 24-36. doi:10.2307/1907382"
  },
  {
    "objectID": "SAS/tobit regression SAS.html#tobit-model",
    "href": "SAS/tobit regression SAS.html#tobit-model",
    "title": "Tobit Regression",
    "section": "",
    "text": "Censoring occurs when data on the dependent variable is only partially known. For example, in virology, sample results could be below the lower limit of detection (eg, 100 copies/mL) and in such a case we only know that the sample result is &lt;100 copies/mL, but we don’t know the exact value.\nLet \\(y^{*}\\) be the the true underlying latent variable, and \\(y\\) the observed variable. We discuss here censoring on the left:\n\\[\ny =\n\\begin{cases}\ny^{*}, & y^{*} &gt; \\tau  \\\\\n\\tau, & y^{*} \\leq \\tau\n\\end{cases}       \n\\] We consider tobit regression with a censored normal distribution. The model equation is \\[\ny_{i}^{*} = X_{i}\\beta + \\epsilon_{i}\n\\] with \\(\\epsilon_{i} \\sim N(0,\\sigma^2)\\). But we only observe \\(y = max(\\tau, y^{*})\\). The tobit model uses maximum likelihood estimation (for details see for example Breen, 1996). It is important to note that \\(\\beta\\) estimates the effect of \\(x\\) on the latent variable \\(y^{*}\\), and not on the observed value \\(y\\)."
  },
  {
    "objectID": "SAS/tobit regression SAS.html#data-used",
    "href": "SAS/tobit regression SAS.html#data-used",
    "title": "Tobit Regression",
    "section": "",
    "text": "We assume two equally sized groups (n=10 in each group). The data is censored on the left at a value of \\(\\tau=8.0\\). In group A 4/10 records are censored, and 1/10 in group B.\n\ndata dat_used;\n    input ID$ ARM$ Y CENS;\n    cards;\n  001 A 8.0 1 \n  002 A 8.0 1\n  003 A 8.0 1\n  004 A 8.0 1\n  005 A 8.9 0\n  006 A 9.5 0\n  007 A 9.9 0\n  008 A 10.3 0\n  009 A 11.0 0\n  010 A 11.2 0\n  011 B 8.0 1 \n  012 B 9.2 0\n  013 B 9.9 0\n  014 B 10.0 0\n  015 B 10.6 0\n  016 B 10.6 0\n  017 B 11.3 0\n  018 B 11.8 0\n  019 B 12.9 0\n  020 B 13.0 0\n    ;\nrun;"
  },
  {
    "objectID": "SAS/tobit regression SAS.html#example-code-using-sas",
    "href": "SAS/tobit regression SAS.html#example-code-using-sas",
    "title": "Tobit Regression",
    "section": "",
    "text": "The analysis will be based on a Tobit analysis of variance with \\(Y\\), rounded to 1 decimal places, as dependent variable and study group as a fixed covariate. A normally distributed error term will be used. Values will be left censored at the value 8.0.\nFirst a data manipulation step needs to be performed in which the censored values are set to missing for a new variable called lower.\n\ndata dat_used;\n    set dat_used;\n    if Y &lt;= 8.0 then lower=.; else lower=Y;\nrun;\n\nThe data are sorted to make sure the intercept will correspond to the mean of ARM A.\n\nproc sort data=dat_used;\n    by descending ARM;\nrun;\n\nThe LIFEREG procedure is used for tobit regression. The following model syntax is used:\n  MODEL (lower,upper)= effects / options ;\nHere, if the lower value is missing, then the upper value is used as a left-censored value.\n\nproc lifereg data=dat_used order=data;\n    class ARM;\n    model (lower, Y) = ARM / d=normal;\n    lsmeans ARM /cl alpha=0.05;\n    estimate 'Contrast B-A' ARM 1 -1 / alpha=0.05;\nrun;\n\nThe fit statistics, type 3 analysis of effects and parameter estimated are shown here. The output provides an estimate of difference between groups A and B (B-A), namely 1.8225 (se=0.8061). The presented p-value is a two-sided p-value based on the Z-test. The scale parameter is an estimate for \\(\\sigma\\).\n\n\n\n\n\n\n\n\n\nThe p-value and confidence intervals of the contrast B-A are shown here. The p-value is the same as above."
  },
  {
    "objectID": "SAS/tobit regression SAS.html#reference",
    "href": "SAS/tobit regression SAS.html#reference",
    "title": "Tobit Regression",
    "section": "",
    "text": "Breen, R. (1996). Regression models. SAGE Publications, Inc., https://doi.org/10.4135/9781412985611\nTobin, James (1958). “Estimation of Relationships for Limited Dependent Variables”. Econometrica. 26 (1): 24-36. doi:10.2307/1907382"
  },
  {
    "objectID": "SAS/survival_cif.html",
    "href": "SAS/survival_cif.html",
    "title": "Estimating Cumulative Incidence Functions Using SAS",
    "section": "",
    "text": "In this document we present how to estimate the cumulative incidence function (CIF) in SAS (version 9.4). We focus on the competing risks model where each subject experiences only one out of k possible events as depicted in the figure below.\n\n\n\n\n\n\n\n\n\n\n\nThe bone marrow transplant (BTM) dataset as presented by Guo & So (2018) is used. The dataset has the following variables:\n\nGroup has three levels, indicating three disease groups: ALL, AML-Low Risk, AML-High Risk.\nT is the disease-free survival time in days. A derived variable TYears = T/365.25 is used in the analysis.\nStatus has value 0 if T is censored; 1 if T is time to relapse; 2 if T is time to death.\nWaitTime is the waiting time to transplant in days. This variable is not used here.\nA new variable ID is created.\n\nSAS code to prepare the data:\n\nproc format;\n    value DiseaseGroup 1='ALL'\n                      2='AML-Low Risk'\n                      3='AML-High Risk';\n    value EventStatus  0='Censored'\n                      1='Relapse'\n                      2='Death';\nrun;\n\nlibname datalib \"..\\data\";\ndata bmt;\n    set datalib.bmt;\n    TYears = T / 365.25;\n    ID = _n_;\n    format Group DiseaseGroup.;\n    format Status EventStatus.;\nrun;"
  },
  {
    "objectID": "SAS/survival_cif.html#objective",
    "href": "SAS/survival_cif.html#objective",
    "title": "Estimating Cumulative Incidence Functions Using SAS",
    "section": "",
    "text": "In this document we present how to estimate the cumulative incidence function (CIF) in SAS (version 9.4). We focus on the competing risks model where each subject experiences only one out of k possible events as depicted in the figure below.\n\n\n\n\n\n\n\n\n\n\n\nThe bone marrow transplant (BTM) dataset as presented by Guo & So (2018) is used. The dataset has the following variables:\n\nGroup has three levels, indicating three disease groups: ALL, AML-Low Risk, AML-High Risk.\nT is the disease-free survival time in days. A derived variable TYears = T/365.25 is used in the analysis.\nStatus has value 0 if T is censored; 1 if T is time to relapse; 2 if T is time to death.\nWaitTime is the waiting time to transplant in days. This variable is not used here.\nA new variable ID is created.\n\nSAS code to prepare the data:\n\nproc format;\n    value DiseaseGroup 1='ALL'\n                      2='AML-Low Risk'\n                      3='AML-High Risk';\n    value EventStatus  0='Censored'\n                      1='Relapse'\n                      2='Death';\nrun;\n\nlibname datalib \"..\\data\";\ndata bmt;\n    set datalib.bmt;\n    TYears = T / 365.25;\n    ID = _n_;\n    format Group DiseaseGroup.;\n    format Status EventStatus.;\nrun;"
  },
  {
    "objectID": "SAS/survival_cif.html#estimating-cifs-in-sas",
    "href": "SAS/survival_cif.html#estimating-cifs-in-sas",
    "title": "Estimating Cumulative Incidence Functions Using SAS",
    "section": "Estimating CIFs in SAS",
    "text": "Estimating CIFs in SAS\nPROC LIFETEST is used to estimate the CIFs in SAS. For illustration, we model the time to relapse.\n\nods graphics on;\nproc lifetest data=bmt \n              plots=cif(test) \n              error=aalen\n              conftype=loglog\n              outcif=cif1 \n              timelist=0.5 1 1.5 2 3; \n    time Tyears * Status(0) / eventcode=1; \n    strata Group / order=internal; \n    format Group DiseaseGroup.;\nrun; \nods graphics off;\n\nBelow are selected outputs for comparison with the R outputs in the companion document.\nCIF estimates for time to relapse at selected timepoints for ‘AML-Low Risk’ patients:\n\n\n\n\n\n\n\n\n\nCIF estimates for time to relapses:\n\n\n\n\n\n\n\n\n\nTwo points to note:\n\nBy default the variance of the estimated CIF are estimated with Aalen’s asymptotic method. This can be changed to the delta method by setting error=delta in the PROC LIFETEST statement.\nBy default the log-log transformation is used to produce the pointwise confidence intervals (CIs) for the estimated CIFs. To select other methods, for instance log, set conftype=log."
  },
  {
    "objectID": "SAS/survival_cif.html#reference",
    "href": "SAS/survival_cif.html#reference",
    "title": "Estimating Cumulative Incidence Functions Using SAS",
    "section": "Reference",
    "text": "Reference\nAalen O. (1978). Nonparametric Estimation of Partial Transition Probabilities in Multiple Decrement Models, Annals of Statistics, 6:534-545.\nGray R. (1988). A Class of K-Sample Tests for Comparing the Cumulative Incidence of a Competing Risk, Annals of Statistics, 16:1141-1154.\nGray R. (2024). cmprsk: Subdistribution Analysis of Competing Risks. https://cran.r-project.org/web/packages/cmprsk/cmprsk.pdf\nGuo C and So Y. (2018). Cause-Specific Analysis of Competing Risks Using the PHREG Procedure. In Proceedings of the SAS Global Forum 2018 Conference. Cary, NC: SAS Institute Inc. https://support.sas.com/resources/papers/proceedings18/2159-2018.pdf.\nSAS (2019). Statistical Analysis Software. Users’ Guide Statistics Version 9.4. SAS Institute Inc., Cary."
  },
  {
    "objectID": "SAS/rmst.html",
    "href": "SAS/rmst.html",
    "title": "Restricted Mean Survival Time (RMST) in SAS",
    "section": "",
    "text": "Under the situation where you time to event outcome has non-proportional hazards over time, the commonly used Cox Proportional Hazards regression analysis and the log-rank test can be invalid - especially when the survival curves are crossing. One alternative is to analyse the Restricted Mean Survival Time (RMST).\nThere are a few ways in SAS to estimate the RMST. A parametric approach is to use general estimating equations(GEE) modelling using linear or log-linear link functions and the IPCW or pseudo-value approach as described in Methods 1 and 2 below. Alternatively you can use a non-parametric approach using an Area Under the Curve (AUC) calculated for the Kaplan-Meier curves.\nFor treatment comparisons, the RMST can be compared across treatments and it was recommended by the FDA in draft guidance in 2020 for analysis of Acute Myeloid Leukemia (AML) here. AML commonly has an initial higher rate of death following randomization, followed by a plateauing rate of death over time (Non-proportional hazards).\nThe main advantage of this method is its easy clinical interpretation (e.g. with an endpoint of time to death - we are measuring average time to death). The biggest disadvantage is you have to select a time at which to calculated the average over: this time is called tau. If data is not mature enough, you may get a unreliable result. In addition, one could accuse analysts of selecting tau such that you get the ‘most significant’ result in the direction you desire!\nReferences are found at the end of this page."
  },
  {
    "objectID": "SAS/rmst.html#data-used",
    "href": "SAS/rmst.html#data-used",
    "title": "Restricted Mean Survival Time (RMST) in SAS",
    "section": "Data used",
    "text": "Data used\nWe are using the lung_cancer.csv dataset found here. If you tabulate the censoring flag variable cnsr\n(1: censored, 0=event), we have 165 events, and 63 censored values.\nWe only need the variables listed below\n\ntime - Time(days) to event\ncnsr - 1=censored, 0=event\nage - Age of subject\nsex - 1=male, 2 = female\ntrt01pn - 1=Active, 2=Placebo\n\nFor example:\n\n\n\ntime\ncnsr\ntrt01pn\nage\nsex\n\n\n\n\n306\n0\n1\n74\n1\n\n\n455\n0\n1\n68\n1\n\n\n1010\n1\n1\n56\n1\n\n\n210\n0\n1\n57\n1"
  },
  {
    "objectID": "SAS/rmst.html#view-your-data---kaplan-meier-curves",
    "href": "SAS/rmst.html#view-your-data---kaplan-meier-curves",
    "title": "Restricted Mean Survival Time (RMST) in SAS",
    "section": "View your data - Kaplan-Meier Curves",
    "text": "View your data - Kaplan-Meier Curves\nIt is good practice to first view the shape of your Kaplan-Meier curves. As you can see our treatment curves are crossing at approximately 300 days.\nIt is very important to pre-specify your approach for selection of tau. As you can see from the curves, if we compared the period 0 to 6 months, vs 0 to 18 months, we would get very different results for the treatment comparison.\n\nproc lifetest data=adcibc  conftype=log;\n    time time*cnsr(1);\n    strata trt01pn;\nRun;"
  },
  {
    "objectID": "SAS/rmst.html#setting-tau",
    "href": "SAS/rmst.html#setting-tau",
    "title": "Restricted Mean Survival Time (RMST) in SAS",
    "section": "Setting tau",
    "text": "Setting tau\nThe code below calculates tau as the minimum time of the last event observed in each treatment group. This will be the period of time, our AUC will be calculated over. As cnsr=0 are events, we only select these observations. Below, the maximum event in treatment 1 = 883 days and in treatment 2 = 350 days. We therefore set tau = 350. This method avoids including in the AUC a period of time where events are no longer occurring in both treatments. You can see why setting tau is very important as we are likely to get very different AUCs calculating over the 350 day as opposed to the 883 day period!\n\nproc sort data=lung_cancer (where=(cnsr=0)) out=tau1;\n    by  trt01pn time;\nrun;\n\ndata tau1 (keep=studyid trt01pn time);\n    set tau1 ;\n    by trt01pn time;\n    if last.trt01pn then output;\nrun;\n\nproc sort data=tau1;\n    by descending time;\nrun;\n\ndata tau2;\n    set tau1 end=last;\n    by descending time;\n    if last then call symput(\"_tau\",put(time,best8.));\nrun;\n\n%put &_tau;\n350"
  },
  {
    "objectID": "SAS/rmst.html#method-1-inverse-probability-censoring-weighting-ipcw-estimation-proc-rmstreg",
    "href": "SAS/rmst.html#method-1-inverse-probability-censoring-weighting-ipcw-estimation-proc-rmstreg",
    "title": "Restricted Mean Survival Time (RMST) in SAS",
    "section": "Method 1: Inverse Probability Censoring Weighting (IPCW) Estimation (proc rmstreg)",
    "text": "Method 1: Inverse Probability Censoring Weighting (IPCW) Estimation (proc rmstreg)\nThe Inverse probability censoring weighting estimation as per Tian L, Zhao L, Wei LJ. Biostatistics 2014, 15, 222-233 is found in SAS using Proc rmstreg and method=ipcw. This is using a generalized linear model (linear or log-linear options are available) to model right censored data over time. The estimation method uses : Generalized estimating equations (GEE).\nThis method uses Kaplan-Meier estimation to obtain weights and it has been shown that weighting in this way provides an unbiased estimate for an adjusted survival curve Calkins 2018. See Royston & Parmar (2013) for more detail.\nTo calculate the stratified weights by treatment and use them in the iterative estimation process, you need to specify strata=trt01pn\nIn the output, its important to check that your event/censoring flag is the right was around and tau is set as expected. (165 events and tau=335)\n\nLinear link model - provides estimates of treatment differences\n\nproc rmstreg data=adcibc tau=&_tau;\n    class trt01pn sex;\n    model time*cnsr(1) =trt01pn sex age /link=linear method=ipcw (strata=trt01pn);\n    lsmeans trt01pn/pdiff=control('2') cl alpha=0.05;\n    ods output lsmeans=lsm diffs= diff;\nrun;\n\n\n\n\n\n\n\n\n\n\nThe above model results in a restricted mean survival time estimate of 257.16 days on treatment 1 vs 267.04 days on treatment 2. The difference (Active-Placebo) is -9.88 days (95% CI: -39.0 to 19.25, p=0.5061). Hence, there is no evidence of a difference between the treatments with respect to RMST when we look over the Kaplan-Meier plot from 0 to 350 days.\n\n\n\n\n\n\n\n\n\n\n\nLog link model - provides estimates of treatment ratios\nThe code is similar to above. We include the option exp on the lsmeans row, since this back transforms (exponentiates) the estimates of the RMST (and 95% CI) for each treatment and for the treatment difference back onto the days scale (rather than log(days) scale). NOTE: if you use the ilink option and link=log method, this does the same (given the link is log), however, does not back transform the treatment differences. It is currently believed that SAS is using the delta method from the treatment arm RMSTs, to estimate the standard error for the RMST ratio.\nSimilar to the linear model, we obtain results of a restricted mean survival time estimate of 255.21 days on treatment 1 vs 264.75 days on treatment 2. The difference (Active-Placebo) on the log scale is -0.03667 (95% CI: -0.1493 to 0.07596, p=0.5234) but this is hard to interpret. Hence, once back transformed, the treatment ratio (Active/Placebo) is 0.9640 (95% CI: 0.8613 to 1.0789, p=0.5234).\n\nproc rmstreg data=adcibc tau=&_tau;\n    class trt01pn sex;\n    model time*cnsr(1) =trt01pn sex age /link=log method=ipcw (strata=trt01pn);\n    lsmeans trt01pn/pdiff=control('2') cl alpha=0.05 exp;\n    ods output lsmeans=lsm diffs= diff;\nrun;"
  },
  {
    "objectID": "SAS/rmst.html#method-2-pseudo-value-estimation-proc-rmstreg",
    "href": "SAS/rmst.html#method-2-pseudo-value-estimation-proc-rmstreg",
    "title": "Restricted Mean Survival Time (RMST) in SAS",
    "section": "Method 2: Pseudo Value Estimation (proc rmstreg)",
    "text": "Method 2: Pseudo Value Estimation (proc rmstreg)\nThe pseudo-observations method Andersen, Hansen and Klein 2004, is available in SAS using the method=pv option. You use the link=linear or link=log options and output is similarly interpreted as described for Method 1 IPCW method.\n\nproc rmstreg data=adcibc tau=&_tau;\n    class trt01pn sex ;\n    model time*cnsr(1) =trt01pn sex age /link=linear  method=pv;\n    lsmeans trt01pn/pdiff=control('2') cl alpha=0.05;\n    ods output lsmeans=lsm diffs= diff;\nrun;"
  },
  {
    "objectID": "SAS/rmst.html#method-3-rmst-area-under-the-curve-method-proc-lifetest",
    "href": "SAS/rmst.html#method-3-rmst-area-under-the-curve-method-proc-lifetest",
    "title": "Restricted Mean Survival Time (RMST) in SAS",
    "section": "Method 3: RMST Area under the curve method (proc lifetest)",
    "text": "Method 3: RMST Area under the curve method (proc lifetest)\nA non-parametric method to calculate the RMST is available using the AUC Kaplan-Meier curves.\n\nproc lifetest data=adcibc plots=(rmst  s) rmst  (tau=&_tau);\n    time time*cnsr(1) ;\n    strata trt01pn / diff=control('2') ;\nrun;\n\nAs shown below, SAS only outputs the estimates and SEs. However, a 95% CI (assuming a normal distribution) can be calculated in an additional datastep using estimate +/- 1.96 * SE.\nThe AUC method results in a restricted mean survival time estimate of 248.2156 days on treatment 1 vs 272.9520 days on treatment 2. The difference (Active-Placebo) is -24.7364. Calculating 95% CIs, for this results in 95% CI: -54.3971 to 4.9243, p=0.1021). Hence, there is no evidence of a difference between the treatments with respect to RMST when we look over the Kaplan-Meier plot from 0 to 350 days.\nVarious multiple testing p-value adjustments are also available using this method.\n\n\n\n\n\n\n\n\n\n\nReferences\n\nOn Biostatistics and Clinical trials Monday April 19 2021\nRoyston & Parmar (2013)\nSAS User’s Guide for RMSTREG Procedure\nAnalyzing RMST using SAS/STAT, Changbin Guo and Yu LIang, SAS Institute, Paper SAS3013-2019\nHuang & Kuan (2017)\nTian L, Zhao L, Wei LJ. Biostatistics 2014, 15, 222-233\nFDA 2020 guidance and download\nAndersen, Hansen and Klein 2004\nCalkins KL, Canan CE, Moore RD, Lesko CR, Lau B. An application of restricted mean survival time in a competing risks setting: comparing time to ART initiation by injection drug use. BMC Med Res Methodol. 2018;18:27. doi: 10.1186/s12874-018-0484-z\n\n\n\nVersion\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package * version date (UTC) lib source\n R rmst      &lt;NA&gt;    &lt;NA&gt;       [?] &lt;NA&gt;\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n R ── Package was removed from disk.\n\n─ External software ──────────────────────────────────────────────────────────\n setting value\n SAS     9.04.01M7P08062020\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "SAS/linear-regression.html",
    "href": "SAS/linear-regression.html",
    "title": "Linear Regression",
    "section": "",
    "text": "To demonstrate the use of linear regression we examine a dataset that illustrates the relationship between Height and Weight in a group of 237 teen-aged boys and girls. The dataset is available at (../data/htwt.csv) and is imported to sas using proc import procedure.\n\nDescriptive Statistics\nThe first step is to obtain the simple descriptive statistics for the numeric variables of htwt data, and one-way frequencies for categorical variables. This is accomplished by employing proc means and proc freq procedures There are 237 participants who are from 13.9 to 25 years old. It is a cross-sectional study, with each participant having one observation. We can use this data set to examine the relationship of participants’ height to their age and sex.\n#| eval: false\nproc means data=htwt;\nrun;\n                    Descriptive Statistics for HTWT Data Set                  \n                             The MEANS Procedure\n\nVariable  Label     N          Mean       Std Dev       Minimum       Maximum\n-----------------------------------------------------------------------------\nAGE       AGE     237    16.4430380     1.8425767    13.9000000    25.0000000\nHEIGHT    HEIGHT  237    61.3645570     3.9454019    50.5000000    72.0000000\nWEIGHT    WEIGHT  237   101.3080169    19.4406980    50.5000000   171.5000000\n----------------------------------------------------------------------------\n#| eval: false\nproc freq data=htwt;\n    tables sex;\nrun;\n    Oneway Frequency Tabulation for Sex for HTWT Data Set                    \n                    The FREQ Procedure\n\n                                      Cumulative    Cumulative\nSEX         Frequency     Percent     Frequency      Percent\n-------------------------------------------------------------\nf           111           46.84           111        46.84\nm           126           53.16           237       100.00\nIn order to create a regression model to demonstrate the relationship between age and height for females, we first need to create a flag variable identifying females and an interaction variable between age and female gender flag.\n#| eval: false\ndata htwt2;\n  set htwt;\n  if sex=\"f\" then female=1;\n  if sex=\"m\" then female=0; \n\n  *model to demonstrate interaction between female gender and age;\n  fem_age = female * age;  \nrun;\n\n\nRegression Analysis\nNext, we fit a regression model, representing the relationships between gender, age, height and the interaction variable created in the datastep above. We again use a where statement to restrict the analysis to those who are less than or equal to 19 years old. We use the clb option to get a 95% confidence interval for each of the parameters in the model. The model that we are fitting is height = b0 + b1 x female + b2 x age + b3 x fem_age + e\n#| eval: false\nproc reg data=htwt2;\n    where age &lt;=19;\n    model height = female age fem_age / clb;\nrun; \nquit;\n                        Number of Observations Read         219\n                        Number of Observations Used         219\n\n                                 Analysis of Variance\n\n                                        Sum of           Mean\n    Source                   DF        Squares         Square    F Value    Pr &gt; F\n    Model                     3     1432.63813      477.54604      60.93    &lt;.0001\n    Error                   215     1684.95730        7.83701\n    Corrected Total         218     3117.59543\n\n\n                 Root MSE              2.79947    R-Square     0.4595\n                 Dependent Mean       61.00457    Adj R-Sq     0.4520\n                 Coeff Var             4.58895\nWe examine the parameter estimates in the output below.\n                            Parameter Estimates\n                            Parameter       Standard\n       Variable     DF       Estimate          Error    t Value    Pr &gt; |t|       95% Confidence Limits\n       Intercept     1       28.88281        2.87343      10.05      &lt;.0001       23.21911       34.54650\n       female        1       13.61231        4.01916       3.39      0.0008        5.69031       21.53432\n       AGE           1        2.03130        0.17764      11.44      &lt;.0001        1.68117        2.38144\n       fem_age       1       -0.92943        0.24782      -3.75      0.0002       -1.41791       -0.44096\nFrom the parameter estimates table the coefficients b0,b1,b2,b3 are estimated as b0=28.88 b1=13.61 b2=2.03 b3=-0.92942\nThe resulting regression model for height, age and gender based on the available data is height=28.88281 + 13.61231 x female + 2.03130 x age -0.92943 x fem_age"
  },
  {
    "objectID": "SAS/survival_csh.html",
    "href": "SAS/survival_csh.html",
    "title": "Estimating and Testing Cause Specific Hazard Ratio Using SAS",
    "section": "",
    "text": "In this document we present how to estimate and test cause specific hazard ratio for the probability of experiencing a certain event at a given time in a competing risks model in SAS (version 9.4). We focus on the basic model where each subject experiences only one out of k possible events as depicted in the figure below.\n\n\n\n\n\n\n\n\n\nAs this document aims to provide syntax for estimating and testing cause-specific hazard ratios using Cox’s PH model for competing risks, we assume that readers have working knowledge of a competing risks framework. The Reference below list a few literature for a quick refresher on this topic.\nThe syntax given here produce results match that by R package survival, in particular with function coxph() (see the companion R document). This is usually necessary if validating results from the two software is the objective."
  },
  {
    "objectID": "SAS/survival_csh.html#objective",
    "href": "SAS/survival_csh.html#objective",
    "title": "Estimating and Testing Cause Specific Hazard Ratio Using SAS",
    "section": "",
    "text": "In this document we present how to estimate and test cause specific hazard ratio for the probability of experiencing a certain event at a given time in a competing risks model in SAS (version 9.4). We focus on the basic model where each subject experiences only one out of k possible events as depicted in the figure below.\n\n\n\n\n\n\n\n\n\nAs this document aims to provide syntax for estimating and testing cause-specific hazard ratios using Cox’s PH model for competing risks, we assume that readers have working knowledge of a competing risks framework. The Reference below list a few literature for a quick refresher on this topic.\nThe syntax given here produce results match that by R package survival, in particular with function coxph() (see the companion R document). This is usually necessary if validating results from the two software is the objective."
  },
  {
    "objectID": "SAS/survival_csh.html#sas-procedure",
    "href": "SAS/survival_csh.html#sas-procedure",
    "title": "Estimating and Testing Cause Specific Hazard Ratio Using SAS",
    "section": "SAS procedure",
    "text": "SAS procedure\nWe use PROC PHREG in this document.\n\nData used\nThe bone marrow transplant (BTM) dataset as presented by Guo & So (2018) is used. The dataset has the following variables:\n\nGroup has three levels, indicating three disease groups.\nT is the disease-free survival time in days. A derived variable TYears = T/365.25 is used in the analysis.\nStatus has value 0 if T is censored; 1 if T is time to relapse; 2 if T is time to death.\nWaitTime is the waiting time to transplant in days.\nFor illustration, a categorical variable waitCat is created from waitTime as waitCat = TRUE if waitTime &gt; 200, and FALSE otherwise.\n\n\nproc format;\n    value DiseaseGroup 1='ALL'\n                      2='AML-Low Risk'\n                      3='AML-High Risk';\n    value EventStatus  0='Censored'\n                      1='Relapse'\n                      2='Death';\nrun;\n\nlibname datalib \"..\\data\";\ndata bmt;\n    set datalib.bmt;\n    TYears = T / 365.25;\n    waitCat = (waitTime&gt;200);\n    ID = _n_;\n    format Group DiseaseGroup.;\n    format Status EventStatus.;\nrun;"
  },
  {
    "objectID": "SAS/survival_csh.html#estimating-and-testing-the-cause-specific-hazard-ratio",
    "href": "SAS/survival_csh.html#estimating-and-testing-the-cause-specific-hazard-ratio",
    "title": "Estimating and Testing Cause Specific Hazard Ratio Using SAS",
    "section": "Estimating and testing the cause specific hazard ratio",
    "text": "Estimating and testing the cause specific hazard ratio\n\nSyntax 1: all events in one go\nStarting in SAS/STAT 14.3, all competing events can be estimated together. However, currently this syntax does not allow the strata statement.\n\nproc phreg data=Bmt;\n    title 'Cause-Specific Hazard Regression for Relapse and Death without strata';\n    class Group (order=internal ref=first);\n    model T*Status(0)=Group / eventcode(cox)=1;\nrun;\n\nThe results for both events are given below:\n\n\n\n\n\n\n\n\n\nThree points to note:\n\nThe option eventcode(cox)=1 tells PHREG that Relapse (event 1) is the event of interest, and Death (event 2) is the competing risk.\nThis results are essentially the same as modeling Relapse and Death separately: there are two global hypotheses, one for each event.\nThis is different from fitting all events in one model that is done in R coxph(). In other words, this is entirely a different model from what R does when modeling all competing events together. (See Syntax 1 in the Companion R document.)\nAdditionally, since strata statement cannot be incorporated, the results for each event are different from that produced by Syntax 1 in the R document.\n\nFor more information, please see Guo C and So Y. (2018).\n\n\nSyntax 2: Estimating one event at a time\nWe use Relapse as an example.\n\nods output ParameterEstimates=p1;\nproc phreg data=bmt; \n    title 'Cause-Specific Hazard Regression for Relapse with strata';\n    class Group (order=internal ref=first) waitCat;\n    strata waitCat;\n    model TYears*Status(0,2) = Group / risklimits alpha = 0.05;\nrun;\nquit;\n\nThe results for event Relapse are given below:\n\n\n\n\n\n\n\n\n\nNote that if there is no stratification, the results will be the same as from Syntax 1 above but for Relapse only."
  },
  {
    "objectID": "SAS/survival_csh.html#summary",
    "href": "SAS/survival_csh.html#summary",
    "title": "Estimating and Testing Cause Specific Hazard Ratio Using SAS",
    "section": "Summary",
    "text": "Summary\n\nIn PROC PHREG, by default Breslow’s method is used for handling ties. To match the default results with R survival::coxph() which uses Efron’s method, this needs to be requested via ties = efron option in the model statement.\nFor multi-state models such as a competing risk analysis, the R function survival::coxph() by default estimate the standard errors of parameter estimates with a robust sandwich estimator. To match results with R, the option covsandwich or covs for short, need to be added to the proc phreg statement.\nDue to the different internal numerical estimation methods of R and SAS, results only match up to the 4th decimal places. However, overall consistency can be established between the two for estimating and testing cause-specific hazard ratio using Cox’s PH model."
  },
  {
    "objectID": "SAS/survival_csh.html#reference",
    "href": "SAS/survival_csh.html#reference",
    "title": "Estimating and Testing Cause Specific Hazard Ratio Using SAS",
    "section": "Reference",
    "text": "Reference\nGuo C and So Y. (2018). “Cause-specific analysis of competing risks using the PHREG procedure.” In Proceedings of the SAS Global Forum 2018 Conference. Cary, NC: SAS Institute Inc. https://support.sas.com/resources/papers/proceedings18/2159-2018.pdf\nPintilie M. (2006). Competing Risks: A Practical Perspective. Wiley. http://dx.doi.org/10.1002/9780470870709\nTherneau T, Crowson C, and Atkinson E. (2024). “Multi-state models and competing risks.” https://cran.r-project.org/web/packages/survival/vignettes/compete.pdf"
  },
  {
    "objectID": "SAS/mi_mar_regression.html",
    "href": "SAS/mi_mar_regression.html",
    "title": "Multiple Imputaton: Linear Regression in SAS",
    "section": "",
    "text": "Prepare a subset of the analysis dummy dataset, details as below:\n\n\nUSUBJID (length 4): Subject ID.\nSEX1N: Sex A random integer between 0 and 1 representing a binary variable (perhaps gender).\nAVISITN: Visit number (1 to 5 for each subject).\nAVAL: A random value between 1 and 2, with a random 10% chance of being missing.\n\nAs PROC MI requires a horizontal, one record per subject data set. More often than not, the data we impute will come from a vertical ADaM BDS data set. So we need to first transpose the aval with the avisitn as ID (assuming avisitn = 1 to 5),creating transposed variable v1-v5.\n\ndata dummy;\n    length USUBJID $4;\n    do i=1 to 10;\n            sex1n=int(ranuni(0)*2);\n        do j=1 to 5;\n            USUBJID=strip(put(1000+i,best.));\n            AVISITN=j;\n            AVAL=round(1+ranuni(0),0.01);\n            if ranuni(0) &lt;0.1 then aval=.;\n            output;\n        end;\n    end;\n    drop i j;\nrun;\n\nproc sort data=dummy; \n    by usubjid sex1n;\nrun;\n\nproc transpose data=dummy out=dummyt(drop=_name_) prefix=v;\n    by USUBJID sex1n;\n    id avisitn;\n    var aval;\nrun;\n\nproc print data=dummyt(obs=5);\nrun;"
  },
  {
    "objectID": "SAS/mi_mar_regression.html#input-dataset-preparation-before-multiple-imputation",
    "href": "SAS/mi_mar_regression.html#input-dataset-preparation-before-multiple-imputation",
    "title": "Multiple Imputaton: Linear Regression in SAS",
    "section": "",
    "text": "Prepare a subset of the analysis dummy dataset, details as below:\n\n\nUSUBJID (length 4): Subject ID.\nSEX1N: Sex A random integer between 0 and 1 representing a binary variable (perhaps gender).\nAVISITN: Visit number (1 to 5 for each subject).\nAVAL: A random value between 1 and 2, with a random 10% chance of being missing.\n\nAs PROC MI requires a horizontal, one record per subject data set. More often than not, the data we impute will come from a vertical ADaM BDS data set. So we need to first transpose the aval with the avisitn as ID (assuming avisitn = 1 to 5),creating transposed variable v1-v5.\n\ndata dummy;\n    length USUBJID $4;\n    do i=1 to 10;\n            sex1n=int(ranuni(0)*2);\n        do j=1 to 5;\n            USUBJID=strip(put(1000+i,best.));\n            AVISITN=j;\n            AVAL=round(1+ranuni(0),0.01);\n            if ranuni(0) &lt;0.1 then aval=.;\n            output;\n        end;\n    end;\n    drop i j;\nrun;\n\nproc sort data=dummy; \n    by usubjid sex1n;\nrun;\n\nproc transpose data=dummy out=dummyt(drop=_name_) prefix=v;\n    by USUBJID sex1n;\n    id avisitn;\n    var aval;\nrun;\n\nproc print data=dummyt(obs=5);\nrun;"
  },
  {
    "objectID": "SAS/mi_mar_regression.html#check-missing-data-patterns",
    "href": "SAS/mi_mar_regression.html#check-missing-data-patterns",
    "title": "Multiple Imputaton: Linear Regression in SAS",
    "section": "Check missing data patterns",
    "text": "Check missing data patterns\nThe pattern can be checked using the following code, missing data pattern could be classified as “Monotone” or “Arbitrary”\n\n“Monotone” : The missingness of data follows a specific order such that if a certain variable is missing for a particular observation, all subsequent variables are also missing for that observation. If a dataset has columns X1,X2,…,Xk a monotone missing pattern appears when: If Xj is missing, then Xj+1, Xj+2,…,Xj+3 are missing.\n“Arbitrary” : The missingness of data does not follow any specific order or predictable sequence. Data can be missing at random points without a discernible pattern.\n\n\nods select MissPattern;\nproc mi data=dummyt nimpute=0;\n    var v1 - v5;\nrun;\n\nAs below figure shows the missingness dose not follow any specific order, obviously the missing pattern is arbitrary and non-monotone missing pattern."
  },
  {
    "objectID": "SAS/mi_mar_regression.html#fcs-regression-for-non-monotone-missing-pattern",
    "href": "SAS/mi_mar_regression.html#fcs-regression-for-non-monotone-missing-pattern",
    "title": "Multiple Imputaton: Linear Regression in SAS",
    "section": "FCS Regression for non-monotone missing pattern",
    "text": "FCS Regression for non-monotone missing pattern\n\nproc mi data=dummyt out=outdata nimpute=10 seed=123;\n    class sex1n;\n    var sex1n v1 - v5;\n    fcs reg (v1-v5 /details);\nrun;\n\n\nThe VAR statement above listing the variables to be analyzed, should match the statistical models for efficacy analysis per SAP, which may include TRTPN, necessary grouping variable (for eg AGEGR1/AGEGR1N), and all outcome variables coming from repeated assessments\nNIMPUTE : the number of imputations\nSEED : the seed to begin random number generator\nNote that depending on the SAS Proc MI algorithm, if there are more factors, the ordering of factors, for example SEX1N, RACE1N, may have an effect on the generation of the imputed values for the missing values, i.e., different orderings of these factors will generate different imputed values (e.g may happen in case of monotone missing pattern) from PROC MI procedure. The ordering of subjects in the dataset may also have an effect on the generation of the imputed values for the missing values.\nThe CLASS statement specifies the classification variables in the VAR statement.\nFCS is displayed as the method, if not specified then MCMC will be the default method.\nREG is the specified model which in this example is linear regression)\nThe DETAILS option displays the regression coefficients in the regression model used in each imputation."
  },
  {
    "objectID": "SAS/mi_mar_regression.html#monotone-regression-for-monotone-missing-pattern",
    "href": "SAS/mi_mar_regression.html#monotone-regression-for-monotone-missing-pattern",
    "title": "Multiple Imputaton: Linear Regression in SAS",
    "section": "Monotone Regression for monotone missing pattern",
    "text": "Monotone Regression for monotone missing pattern\nLet’s update above SAS code to generate a dummy dataset with monotone missing pattern\n\ndata dummy;\n    length USUBJID $4;\n    do i=1 to 10; \n        sex1n=int(ranuni(0)*2); \n        USUBJID = strip(put(1000+i, best.));\n        miss_start = ceil(ranuni(0) * 5); /* Randomly decide the start point for missing data (1 to 5) */\n        do j=1 to 5; \n            AVISITN = j;\n            if j &gt;= miss_start then AVAL = .; /* If the visit number is greater than or equal to miss_start, make AVAL missing */\n            else AVAL = round(1 + ranuni(0), 0.01);\n            output; \n        end;\n    end;\n    drop i miss_start j;\nrun;\n\nproc sort data=dummy; \n    by usubjid sex1n;\nrun;\n\nproc transpose data=dummy out=dummyt(drop=_name_) prefix=v;\n    by USUBJID sex1n;\n    id avisitn;\n    var aval;\nrun;\n\nproc print data=dummyt(obs=5);\nrun;\n\nods select MissPattern;\nproc mi data=dummyt nimpute=0;\n    var v1 - v5;\nrun;\n\n\n\n\n\n\n\n\n\n\nIn this case we will use monotone statement instead of FCS for the imputation, example code as below:\n\nproc mi data=dummyt out=outdata nimpute=10 seed=123;\n    class sex1n;\n    var sex1n v1 - v5;\n    monotone reg (v1-v5 /details);\nrun;"
  },
  {
    "objectID": "SAS/mi_mar_regression.html#reference",
    "href": "SAS/mi_mar_regression.html#reference",
    "title": "Multiple Imputaton: Linear Regression in SAS",
    "section": "Reference",
    "text": "Reference\n\nUser’s Guide The MI Procedure\nMultiple Imputation: A Statistical Programming Story\nExamine patterns of missing data in SAS"
  },
  {
    "objectID": "SAS/sample_s_noninferiority.html",
    "href": "SAS/sample_s_noninferiority.html",
    "title": "Sample Size for Non-Inferiority Trials in SAS",
    "section": "",
    "text": "PROC POWER1 can be used for sample size calculations for non-inferiority testing. See 2 for explanation of non-inferiority and how to perform Sample size in SAS (including comparing proportions). Below we give 2 sample size examples for the following types of studies:\n\ntwo-sample comparison of means for Non-inferiority (i.e. testing if one treatment mean is non-inferior to the another treatment mean).\nPaired-sample comparison of means (i.e. 2 treatment means recorded on 1 group of patients are equivalent within a set tolerance)"
  },
  {
    "objectID": "SAS/sample_s_noninferiority.html#estimating-the-within-patient-variance-and-correlation.",
    "href": "SAS/sample_s_noninferiority.html#estimating-the-within-patient-variance-and-correlation.",
    "title": "Sample Size for Non-Inferiority Trials in SAS",
    "section": "Estimating the within patient variance and correlation.",
    "text": "Estimating the within patient variance and correlation.\nLet’s consider a standard two-sequence, two period crossover design. Suppose that the sponsor is interested in showing non-inferiority of the test drug against the reference with the non-inferiority margin -20%. Assume power of 80%. Based on the results from previous trials, it is estimated that the variance (of the difference) is 0.2 (20%). Suppose that the true mean difference is -0.1 (-10%). What is the required sample size, assuming significance level of 5%?\nAlpha = 0.025 is used below, instead of 0.05 because you are doing non-inferiority (a one sided test). Note that this is still the sample size for alpha=0.05. The below shows a sample size of 13 patients is required.\n\npairedmeans \ntest=equiv_diff\n    lower = -0.3\n    upper = 0.1\n    meandiff = -0.1\n    stddev = 0.2\n    corr = 0.5\n    alpha = 0.025\n    npairs = .\n    power = 0.8;\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nPROC POWER SAS online help\nSample Size Calculation Using SAS® for non-inferiority\nSample Size for Cross over non-inferiority\n\n\n\nVersion\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package                 * version date (UTC) lib source\n R sample_s_noninferiority   &lt;NA&gt;    &lt;NA&gt;       [?] &lt;NA&gt;\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n R ── Package was removed from disk.\n\n─ External software ──────────────────────────────────────────────────────────\n setting value\n SAS     9.04.01M7P08062020\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "SAS/nparestimate.html",
    "href": "SAS/nparestimate.html",
    "title": "Non-parametric point estimation in SAS",
    "section": "",
    "text": "Introduction\nThe Hodges-Lehman estimator (Hodges and Lehmann 1962) provides a point estimate which is associated with the Wilcoxon rank sum statistics based on location shift. This is typically used for the 2-sample comparison with small sample size. Note: The Hodges-Lehman estimates the median of the difference and not the difference of the medians. The corresponding distribution-free confidence interval (CI) is also based on the Wilcoxon rank sum statistics (Moses). In addition, exact CIs can be constructed.\nPROC NPAR1WAY provides these estimates in a flexible manner.\nHodges, J. L. and Lehmann, E. L. (1962) Rank methods for combination of independent experiments in analysis of variance. Annals of Mathematical Statistics, 33, 482-4.\n\n\nCase study\n#| eval: false\n# Hollander-Wolfe-Chicken Example\ndata all;\ninput group $ value; \n  cards;\nA 1.83\nA 0.50\nA 1.62\nA 2.48\nA 1.68\nA 1.88\nA 1.55\nA 3.06\nA 1.30\nB 0.878\nB 0.647\nB 0.598\nB 2.050\nB 1.060\nB 1.290\nB 1.060\nB 3.140\nB 1.290\n; \nrun;\n\n\nHodges-Lehmann estimate and confidence interval\nHodges-Lehmann estimate and Moses confidence interval for the 2-sample case will be generated when putting HL as an option. The direction of the comparison can be controlled via refclass. If the exact confidence interval is required additionally then the exact statement together with the option HL needs to be defined. The Hodges-Lehmann point estimate and confidence interval can be addressed via the HodgesLehmann option under the ODS statement.\n#| eval: false\nproc npar1way hl (refclass = \"B\") data = all;\n    class group;\n    var value;\n    exact hl;\n    ods select HodgesLehmann;\nrun;\n\n\nResults\nThe NPAR1WAY Procedure\n                                           Hodges-Lehmann Estimation                                                \n\n                                        Location Shift (A - B)    0.5600                                            \n\n                                                                   Interval        Asymptotic                       \n                   Type                 95% Confidence Limits      Midpoint    Standard Error                       \n\n                   Asymptotic (Moses)     -0.3700      1.1830        0.4065            0.3962                       \n                   Exact                  -0.2200      1.0820        0.4310"
  },
  {
    "objectID": "SAS/ranksum.html",
    "href": "SAS/ranksum.html",
    "title": "Wilcoxon Rank Sum /Mann-Whitney U test",
    "section": "",
    "text": "The Wilcoxon rank-sum test, also known as the Mann-Whitney U test, is a nonparametric test used to compare differences between two independent samples. It’s particularly useful when the sample distributions are not normally distributed and the sample sizes are small (typically less than 30).\n\n\nTo perform a Wilcoxon rank-sum test in SAS, you can use the PROC NPAR1WAY procedure. Here’s a step-by-step guide:\n\nCreate the Dataset: If there are two groups (smoker and non-smoker) with their respective measurements birth weight, you can input the data as follows:\n\n#| eval: false\n/* Create dataset */\ndata bw;\n    input bw  grp $;\n    datalines;\n3.99    ns\n3.89    ns\n3.6     ns\n3.73    ns\n3.31    ns\n3.7     ns\n4.08    ns\n3.61    ns\n3.83    ns\n3.41    ns\n4.13    ns\n3.36    ns\n3.54    ns\n3.51    ns\n2.71    ns\n3.18    s\n2.74    s\n2.9     s\n3.27    s\n3.65    s\n3.42    s\n3.23    s\n2.86    s\n3.6     s\n3.65    s\n3.69    s\n3.53    s\n2.38    s\n2.34    s\n;\nrun;\n\nPerform the Wilcoxon rank-sum Test: Use the PROC NPAR1WAY procedure to perform the test. The wilcoxon option specifies that you want to perform the Wilcoxon rank-sum test. When computing the asymptotic Wilcoxon two-sample test, PROC NPAR1WAY uses a continuity correction by default. If specify the CORRECT=NO option in the PROC NPAR1WAY statement, the procedure does not use a continuity correction. Typically, we will also want the Hodges-Lehman confidence intervals. To get these you will need to add hl to the pro npar1way statement.\n\n#| eval: false\n/* Perform Wilcoxon rank-sum test - with continuity correction by default*/\nproc npar1way data=BW wilcoxon hl;\n    class grp;\n    var bw;\nrun;\n\n/* Perform Wilcoxon rank-sum test - without continuity correction*/\nproc npar1way data=BW wilcoxon CORRECT=NO hl;\n    class grp;\n    var bw;\nrun;\n\n\n\n\n\n\nAs seen above, SAS outputs a table of Wilcoxon Scores for birth weight by non-smoker and smoker: the number (N); the sum of scores; the expected sum of scores under the null hypothesis; the standard deviation under the null hypothesis, and the observed mean score. The table also includes a footnote to specify that ties were handled by using the average score.\nSAS also outputs a table of Wilcoxon Two-sample Test. This table includes a footnote to specify that a continuiity correction of 0.5 is used.\nStatistic: 150.5000\nZ: -2.5756 (This is the test statistic after applying a continuity correction of 0.5)\nPr &lt; Z: 0.0050 (This is the one-tailed p-value). The one-tailed p-value (Pr&lt; Z) of 0.0050 suggests that there is a 0.5% chance of observing a test statistic as extreme as 1.2498 under the null hypothesis.\nPr &gt; |Z|: 0.0100 (This is the two-tailed p-value). The two-tailed p-value (Pr &gt; |Z|) of 0.0100 suggests that there is a 1.00 % chance of observing a test statistic as extreme as 1.2498 in either direction under the null hypothesis.\nThe t-distribution approximations provide similar p-values, indicating the robustness of the results.\nt Approximation Pr &lt; Z: 0.0078 (This is the one-tailed p-value using a t-distribution approximation)\nt Approximation Pr &gt; |Z|: 0.0156 (This is the two-tailed p-value using a t-distribution approximation)\nSince the p-values (both one-tailed and two-tailed) are less than the common significance level (e.g., 0.05), we can reject the null hypothesis. This means there is a significant difference between the two groups (ns and s) for the variable BW.\n\n\n\n\nAs seen above, Wilcoxon Two-Sample Test results are changed because No continuity correction is used.\n\n\n\nThe correction does not effect the Hodges-Lehman CI. The Location shift is the Hodges-Lehmann estimator. By default the asymptotic (Moses) CI is shown.\n\n\n\n\nFor sufficiently small sample size, the large-sample normal approximation used by the asymptotic Wilcoxon might not be appropriate, so the exact statement is needed.\n#| eval: false\n/* Perform Wilcoxon rank-sum test - with continuity correction by default*/\nproc npar1way data=BW wilcoxon CORRECT=NO hl;\n    class grp;\n    var bw;\n    exact wilcoxon hl;\nrun;\n\nThe exact hl part of that statement makes the exact and asymptotic Hodges-Lehmann CI appear."
  },
  {
    "objectID": "SAS/ranksum.html#wilcoxon-rank-sum-mann-whitney-u-in-sas",
    "href": "SAS/ranksum.html#wilcoxon-rank-sum-mann-whitney-u-in-sas",
    "title": "Wilcoxon Rank Sum /Mann-Whitney U test",
    "section": "",
    "text": "To perform a Wilcoxon rank-sum test in SAS, you can use the PROC NPAR1WAY procedure. Here’s a step-by-step guide:\n\nCreate the Dataset: If there are two groups (smoker and non-smoker) with their respective measurements birth weight, you can input the data as follows:\n\n#| eval: false\n/* Create dataset */\ndata bw;\n    input bw  grp $;\n    datalines;\n3.99    ns\n3.89    ns\n3.6     ns\n3.73    ns\n3.31    ns\n3.7     ns\n4.08    ns\n3.61    ns\n3.83    ns\n3.41    ns\n4.13    ns\n3.36    ns\n3.54    ns\n3.51    ns\n2.71    ns\n3.18    s\n2.74    s\n2.9     s\n3.27    s\n3.65    s\n3.42    s\n3.23    s\n2.86    s\n3.6     s\n3.65    s\n3.69    s\n3.53    s\n2.38    s\n2.34    s\n;\nrun;\n\nPerform the Wilcoxon rank-sum Test: Use the PROC NPAR1WAY procedure to perform the test. The wilcoxon option specifies that you want to perform the Wilcoxon rank-sum test. When computing the asymptotic Wilcoxon two-sample test, PROC NPAR1WAY uses a continuity correction by default. If specify the CORRECT=NO option in the PROC NPAR1WAY statement, the procedure does not use a continuity correction. Typically, we will also want the Hodges-Lehman confidence intervals. To get these you will need to add hl to the pro npar1way statement.\n\n#| eval: false\n/* Perform Wilcoxon rank-sum test - with continuity correction by default*/\nproc npar1way data=BW wilcoxon hl;\n    class grp;\n    var bw;\nrun;\n\n/* Perform Wilcoxon rank-sum test - without continuity correction*/\nproc npar1way data=BW wilcoxon CORRECT=NO hl;\n    class grp;\n    var bw;\nrun;"
  },
  {
    "objectID": "SAS/ranksum.html#results",
    "href": "SAS/ranksum.html#results",
    "title": "Wilcoxon Rank Sum /Mann-Whitney U test",
    "section": "",
    "text": "As seen above, SAS outputs a table of Wilcoxon Scores for birth weight by non-smoker and smoker: the number (N); the sum of scores; the expected sum of scores under the null hypothesis; the standard deviation under the null hypothesis, and the observed mean score. The table also includes a footnote to specify that ties were handled by using the average score.\nSAS also outputs a table of Wilcoxon Two-sample Test. This table includes a footnote to specify that a continuiity correction of 0.5 is used.\nStatistic: 150.5000\nZ: -2.5756 (This is the test statistic after applying a continuity correction of 0.5)\nPr &lt; Z: 0.0050 (This is the one-tailed p-value). The one-tailed p-value (Pr&lt; Z) of 0.0050 suggests that there is a 0.5% chance of observing a test statistic as extreme as 1.2498 under the null hypothesis.\nPr &gt; |Z|: 0.0100 (This is the two-tailed p-value). The two-tailed p-value (Pr &gt; |Z|) of 0.0100 suggests that there is a 1.00 % chance of observing a test statistic as extreme as 1.2498 in either direction under the null hypothesis.\nThe t-distribution approximations provide similar p-values, indicating the robustness of the results.\nt Approximation Pr &lt; Z: 0.0078 (This is the one-tailed p-value using a t-distribution approximation)\nt Approximation Pr &gt; |Z|: 0.0156 (This is the two-tailed p-value using a t-distribution approximation)\nSince the p-values (both one-tailed and two-tailed) are less than the common significance level (e.g., 0.05), we can reject the null hypothesis. This means there is a significant difference between the two groups (ns and s) for the variable BW.\n\n\n\n\nAs seen above, Wilcoxon Two-Sample Test results are changed because No continuity correction is used.\n\n\n\nThe correction does not effect the Hodges-Lehman CI. The Location shift is the Hodges-Lehmann estimator. By default the asymptotic (Moses) CI is shown.\n\n\n\n\nFor sufficiently small sample size, the large-sample normal approximation used by the asymptotic Wilcoxon might not be appropriate, so the exact statement is needed.\n#| eval: false\n/* Perform Wilcoxon rank-sum test - with continuity correction by default*/\nproc npar1way data=BW wilcoxon CORRECT=NO hl;\n    class grp;\n    var bw;\n    exact wilcoxon hl;\nrun;\n\nThe exact hl part of that statement makes the exact and asymptotic Hodges-Lehmann CI appear."
  },
  {
    "objectID": "SAS/gsd-tte.html",
    "href": "SAS/gsd-tte.html",
    "title": "Group Sequential Design in Survival Endpoints Using SAS",
    "section": "",
    "text": "Introduction\nPROC SEQDESIGN1 can be used for sample size calculations for group sequential design (GSD). SAS provides a flowchart2 which summarizes the steps in a typical group sequential trial and the relevant SAS procedures. Here we focus on a GSD applied for time-to-event endpoints.\n\n\nLog-Rank Test for Two Survival Distributions\nThis example illustrates sample size computation for survival data with the same setting in another R example:\nA GSD will be utilized for progression-free survival (PFS). PFS will be tested at one interim analysis (IA) at 75% information fraction for both efficacy and non-binding futility. A Lan-DeMets O’Brien-Fleming-type (LD-OBF) spending function will be used for efficacy testing, and a Hwang-Shih-Decani (HSD) spending function (as known as gamma cumulative spending function) with \\(\\gamma = -10\\) will be used for futility. In the GSD, \\(\\alpha\\) is one-sided at 0.025, \\(\\beta\\) is 0.05, the accrual period is 24 months, and the follow-up period is 10 months. As described in the R example, the dropout rates are 0.2 by month 12 for the both group; that is, the dropout times follow the exponential distribution with the parameter \\(\\lambda = -\\ln(1-0.2)/12 = 0.0185953\\).\nThe SAS code is shown below:\n\nPROC SEQDESIGN;\n   DESIGN NSTAGES=2 \n      INFO=CUM(0.75 1.0) \n      ALT=UPPER \n      ALPHA=0.0125 \n      BETA=0.05\n      METHOD(ALPHA)=ERRFUNCOBF \n      METHOD(BETA)=ERRFUNCGAMMA(GAMMA=-10)  \n      STOP=BOTH(BETABOUNDARY=NONBINDING);\n   SAMPLESIZE MODEL=TWOSAMPLESURVIVAL(\n         NULLMEDSURVTIME=9.4\n         HAZARDRATIO=0.6\n         ACCTIME=24 \n         FOLTIME=10\n         LOSS=EXP(HAZARD=0.0185953)\n         WEIGHT=1);\nRUN;\n\nAs shown below, a total sample size of 398 is recommended, which equates to 199 in each group.\n\n\n\n\n\n\n\n\n\n\nReferences\n\nThe SEQDESIGN procedure: SAS® 9.4 and SAS® Viya® 3.5 Programming Documentation\nOverview: SEQDESIGN Procedure"
  },
  {
    "objectID": "SAS/survival.html",
    "href": "SAS/survival.html",
    "title": "Survival Analysis Using SAS",
    "section": "",
    "text": "The most commonly used survival analysis methods in clinical trials include:\nAdditionally, other methods for analyzing time-to-event data are available, such as:\nWhile these models may be explored in a separate document, this particular document focuses solely on the three most prevalent methods: KM estimators, log-rank test and Cox PH model."
  },
  {
    "objectID": "SAS/survival.html#example-data",
    "href": "SAS/survival.html#example-data",
    "title": "Survival Analysis Using SAS",
    "section": "Example Data",
    "text": "Example Data\nData source: https://stats.idre.ucla.edu/sas/seminars/sas-survival/\nThe data include 500 subjects from the Worcester Heart Attack Study. This study examined several factors, such as age, gender and BMI, that may influence survival time after heart attack. Follow up time for all participants begins at the time of hospital admission after heart attack and ends with death or loss to follow up (censoring). The variables used here are:\n\nlenfol: length of followup, terminated either by death or censoring - time variable\nfstat: loss to followup = 0, death = 1 - censoring variable\nafb: atrial fibrillation, no = 0, 1 = yes - explanatory variable\ngender: males = 0, females = 1 - stratification factor\n\n\nlibname mylib \"..\\data\";\n\ndata dat;\n    set mylib.whas500;\n    lenfoly = round(lenfol/365.25, 0.01);  /* change follow-up days to years for better visualization*/\nrun;"
  },
  {
    "objectID": "SAS/survival.html#the-non-stratified-model",
    "href": "SAS/survival.html#the-non-stratified-model",
    "title": "Survival Analysis Using SAS",
    "section": "The Non-stratified Model",
    "text": "The Non-stratified Model\nFirst we try a non-stratified analysis following the mock-up above to describe the association between survival time and afb (atrial fibrillation).\nThe KM estimators and log-rank test are from PROC LIFETEST, and Cox PH model is conducted using PROC PHREG.\n\nKM estimators and log-rank test\n\nproc lifetest data=dat outsurv=_SurvEst timelist= 1 3 5 reduceout stderr; \n    time lenfoly*fstat(0);\n    strata afb;\nrun;\n\nThe landmark estimates and quartile estimates for AFB = 0 group are as shown in below:\n\n\n\n\n\n\n\n\n\nThe logrank test result is in below:\n\n\n\n\n\n\n\n\n\n\n\nCox PH model\n\nproc phreg data = dat;\n    class afb;\n    model lenfol*fstat(0) = afb/rl;\nrun;\n\nThe hazard ratio and confidence intervals are shown as below:"
  },
  {
    "objectID": "SAS/survival.html#the-stratified-model",
    "href": "SAS/survival.html#the-stratified-model",
    "title": "Survival Analysis Using SAS",
    "section": "The Stratified Model",
    "text": "The Stratified Model\nIn a stratified model, the Kaplan-Meier estimators remain the same as those in the non-stratified model. To implement stratified log-rank tests and Cox proportional hazards models, simply add the STRATA option in both PROC LIFETEST and PROC PHREG.\n\n# KM estimators and log-rank test\nproc lifetest data=dat;\n    time lenfoly*fstat(0);\n    strata gender/group = afb;\nrun;\n\n# Cox PH model\nproc phreg data=dat;\n    class afb;\n    model lenfol*fstat(0) = afb/rl;\n    strata gender;\nrun;"
  },
  {
    "objectID": "SAS/mcnemar.html",
    "href": "SAS/mcnemar.html",
    "title": "McNemar’s test in SAS",
    "section": "",
    "text": "Performing McNemar’s test in SAS\nTo demonstrate McNemar’s test in SAS, data concerning the presence or absence of cold symptoms was used. The symptoms were recorded by the same children at the age of 12 and 14. A total of 2638 participants were involved.\n\nUsing PROC FREQ\nTesting for a significant difference in cold symptoms between ages, using McNemar’s test in SAS, can be performed as below. The AGREE option is stated within the FREQ procedure to produce agreement tests and measures, including McNemar’s test.\n\nproc freq data=colds;\n    tables age12*age14 / agree;\nrun;\n\n\n\nResults\n\n\n\n\n\n\n\n\n\nSAS outputs the tabulated data for proportions, the McNemar’s Chi-square statistic, and the Kappa coefficient with 95% confidence limits. There is no continuity correction used and no option to include this."
  },
  {
    "objectID": "SAS/wilcoxonsr_HL.html",
    "href": "SAS/wilcoxonsr_HL.html",
    "title": "Wilcoxon signed-rank test in SAS & StatXact®",
    "section": "",
    "text": "Similarily to what has been presented in R, we will explore the options of Wilcoxon Signed-Rank test that are avialable in SAS & StatXact.We will consider case with N&gt;=20 or N&lt;20 and without or with ties. For more information how to perform this analysis in R go here"
  },
  {
    "objectID": "SAS/wilcoxonsr_HL.html#analysis-in-sas",
    "href": "SAS/wilcoxonsr_HL.html#analysis-in-sas",
    "title": "Wilcoxon signed-rank test in SAS & StatXact®",
    "section": "Analysis in SAS",
    "text": "Analysis in SAS\n\nDataset without ties and N &gt; 20\nLet’s consider a case where the dataset has no ties and N (number of observations) = 240.\n\ndata TTR;\n    set TTR;\n    diff = TRT_B - TRT_A;\nrun;\n\n\n\n\n\n\n\n\n\n\nIn SAS Wilcoxon Signed-Rank test is available using PROC UNIVARIATE.\n\nproc univariate data=TTR\n    alpha=0.1;\n    var diff;\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\nDataset without ties and N≤20\nNow let’s consider a smaller dataset, created by selecting first 19 observations from our main data.\n\ndata TTR_19;\n    set TTR;\n    if _N_ &lt;= 19;\nrun;\n\n\nproc univariate data=TTR_19\n    alpha=0.1;\n    var diff;\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\nImportant notes on SAS\n\nOnly PROC UNIVARIATE can be used in SAS to perform Wilcoxon Signed-Rank test. SAS documentation details are here.\nIn regards to Wilcoxon S-R test, SAS provides only p value\nHodges-Lehmann estimator or CI are not available and have to be implemented manually\nProvided p value is based on Signed Rank (S) statistic (modification of a common T+). Details are here\nSAS computes exact p values only for N ≤ 20. For larger samples uses an asymptotic t-Student distribution of the test statistic. For more information how the p value is calculated go here\nPROC UNIVARIATE apart from performing Wilcoxon S-R test presents as well basic statistical measures of variability and location, e.g median. The given median is not a “pseudo-median” (median of the Walsh averages), it is a “normal” median of the considered variable.\nUsing CIQUANTNORMAL option we can get confidence limits for quantiles based on normal distribution. There are 5 different definitions for calculation quantiles available. See details from the SAS documentation here. It is important to note, those are not confidence intervals of estimator.\n\n\n\nApproach to 0s and ties in SAS\n\nIn SAS all the 0 differences are disregarded (Hollander and Wolfe, 1973). The sample size N is reduced to reflect the number of discarded zeros.\nTied differences are given an average of the ranks. Statistic S is updated accordingly following Sprent algorythm (Sprent, 1993)."
  },
  {
    "objectID": "SAS/wilcoxonsr_HL.html#analysis-in-statxact",
    "href": "SAS/wilcoxonsr_HL.html#analysis-in-statxact",
    "title": "Wilcoxon signed-rank test in SAS & StatXact®",
    "section": "Analysis in StatXact®",
    "text": "Analysis in StatXact®\nStatXact® PROCs for SAS users is a clinical trial analysis software from Cytel for exact statistics. Package includes more than 150 procedures for exact inference statistical data and power analysis.\n\nDataset without ties and N &gt; 20\n\n/* Wilxocon S-R test - p values */\nPROC PAIRED DATA=WilcoxonSignedRank_TTR\n    ALPHA=0.9;\n    WI/EX;\n    POPS TRT_B - TRT_A;\nRUN;\n\n\n\n\n\n\n\n\n\n\n\n/* Wilcoxon S-R - H-L estimator and CI */\nPROC PAIRED DATA=WilcoxonSignedRank_TTR \n    ALPHA=0.9;\n    HL/EX;\n    POPS TRT_B - TRT_A;\nRUN;\n\n\n\n\n\n\n\n\n\n\n\n\nImportant notes on StatXact®\n\nOnly PROC PAIRED can be used in StatXact to perform Wilcoxon Signed-Rank test\nFollows Sprent (1993) approach for Wilcoxon Signed-Rank test and Lehmann (1975) for H-L estimate and CI\nProvides exact/non-exact p values, (exact) H-L estimator and exact/non-exact CIs\np value is based on a common T+ statistic (sum of ranks of the positive differences)\n\n\n\nApproach to 0s and ties in StatXact®\n\nUsing ZEROS option we can compute H-L estimate including all differences, but by default 0s are excluded.\nTied differences are given an average of the ranks. Statistic S is updated accordingly following Sprent algorythm (Sprent, 1993)."
  },
  {
    "objectID": "SAS/association.html",
    "href": "SAS/association.html",
    "title": "Association Analysis for Count Data Using SAS",
    "section": "",
    "text": "In SAS, association analysis methods for count data/contingency tables is typically performed using the PROC FREQ procedure. This procedure has options for Chi-Square and Fisher’s Exact tests."
  },
  {
    "objectID": "SAS/association.html#tests-of-association",
    "href": "SAS/association.html#tests-of-association",
    "title": "Association Analysis for Count Data Using SAS",
    "section": "Tests of Association",
    "text": "Tests of Association\nThe following SAS code produces both the Chi-Square and Fisher’s Exact tests of association. Note that the results contain many statistics not produced by the corresponding R function. The relevant sections of the output have been outlined in red.\n\nproc freq data = test_case;\n    weight Count;\n    tables treatment * Weight / chisq fisher;\n    exact or;\nrun;\n\nOutput:"
  },
  {
    "objectID": "SAS/mmrm.html",
    "href": "SAS/mmrm.html",
    "title": "MMRM in SAS",
    "section": "",
    "text": "Mixed Models\n\nFitting the MMRM in SAS\nIn SAS the following code was used (assessments at avisitn=0 should also be removed from the response variable):\n#| eval: false\nproc mixed data=adlbh;\n    where base ne . and avisitn not in (., 99);\n    class usubjid trtpn(ref=\"0\") avisitn;\n    by paramcd param;\n    model chg=base trtpn avisitn  trtpn*avisitn / solution cl alpha=0.05 ddfm=KR;\n    repeated avisitn/subject=usubjid type=&covar;\n    lsmeans trtpn * avisitn / diff cl slice=avisitn;\n    lsmeans trtpn / diff cl;\nrun;\nwhere the macro variable covar could be UN, CS or AR(1). The results were stored in .csv files that were post-processed in R and compared with the results from R."
  },
  {
    "objectID": "SAS/sample_s_superiority.html",
    "href": "SAS/sample_s_superiority.html",
    "title": "Sample Size for Superiority Trials in SAS",
    "section": "",
    "text": "SAS has 2 procedures for doing Sample size. A basic summary is provided here based on Jenny Cody’s paper1 , but see the paper itself for more details. There are also many available options to best to consult SAS online support for PROC POWER2 and PROC GLMPOWER3.\nPROC POWER is used for sample size calculations for tests such as:\n\nt tests, equivalence tests, and confidence intervals for means,\ntests, equivalence tests, and confidence intervals for binomial proportions,\nmultiple regression,\ntests of correlation and partial correlation,\none-way analysis of variance,\nrank tests for comparing two survival curves,\nlogistic regression with binary response,\nWilcoxon-Mann-Whitney (rank-sum) test (SAS, 2010).\n\nPROC GLMPOWER is used for sample size calculations for more complex linear models, and cover Type III tests and contrasts of fixed effects in univariate linear models with or without covariates. (SAS, 2011).\n\nComparing means for parallel design (unpaired)\nIn the most common scenario SDs are assumed known and the same in both treatment groups. Otherwise Student t distribution is used instead of the normal distribution. SAS follows the Satterthwaite method.\n\nExample: Sample size for comparison of 2 independant treatment group means with same known SDs\nA client is interested in conducting a clinical trial to compare two cholesterol lowering agents for treatment of hypercholesterolemic patients. The primary efficacy parameter is a low-density lipidprotein cholesterol (LDL-C). Suppose that a difference of 8% in the percent change of LDL-C is considered a clinically meaningful difference and that the standard deviation is assumed to be 15%. What sample size is required for a two-sided false positive rate of 5% and a power of 80%?\nThe code below estimates the sample size in SAS. NOTE: you can either specify the MEANDIFF=8 or if you know the separate group means X and Y, you can use GROUPMEANS =X|Y code instead. SAS also assume a default alpha level of 0.05, a 1:1 balanced randomization and a Normal distribution.\n\nPROC POWER  ;\n    TWOSAMPLEMEANS TEST=DIFF\n    MEANDIFF=8\n    STDDEV=15\n    NTOTAL=.\n    POWER=0.8\n    ;\nRUN;\n\nAs shown below, a total sample size of 114 is recommended, which equates to 57 in each group.\n\n\n\n\n\n\n\n\n\n\n\n\nComparing means for crossover design (paired)\nIt is important to differentiate here between the within patient SD and the SD of the difference. We may need to recalculate one to the other, depending on the case.\nVariance of the difference = 2x Variance within patient. Vardiff=2∗Varpatient\n\nExample\nWe wish to run an AB/BA single dose crossover to compare two brochodilators. The primary outcome is peak expiratory flow, and a clinically relevant difference of 30 l/min is sought with 80% power, the significance level is 5% and the best estimate of the within patient standard deviation is 32 l/min. What size of trial do we require? (After recalculating: 32∗2=45 and assuming no period effect and assuming between each pair of measurements on the same subject that we have a 0.5 correlation)\n\nPROC POWER  ;\n    PAIREDMEANS TEST=DIFF\n    NPAIRS=.\n    corr=0.5\n    MEANDIFF=30\n    STDDEV=45\n    POWER=0.8\n    ;\nRUN;\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nSample Size Calculation Using SAS®, R, and nQuery Software, 2020 Jenna Cody, Paper 4675-2020\nPROC POWER SAS online help https://support.sas.com/documentation/cdl/en/statug/63347/HTML/default/viewer.htm#statug_power_sect010.htm\nPROC GLMPOWER SAS online helphttps://support.sas.com/documentation/cdl/en/statug/63347/HTML/default/viewer.htm#statug_glmpower_a0000000154.htm\n\n\n\nVersion\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package              * version date (UTC) lib source\n R sample_s_superiority   &lt;NA&gt;    &lt;NA&gt;       [?] &lt;NA&gt;\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n R ── Package was removed from disk.\n\n─ External software ──────────────────────────────────────────────────────────\n setting value\n SAS     9.04.01M7P08062020\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "SAS/cmh.html",
    "href": "SAS/cmh.html",
    "title": "CMH Test",
    "section": "",
    "text": "The CMH procedure tests for conditional independence in partial contingency tables for a 2 x 2 x K design. However, it can be generalized to tables of X x Y x K dimensions. This page also details derivation of risk differences and their confidence intervals which often accompnay a CMH test.\n\n\nThe cmh test is calculated in SAS using the PROC FREQ procedure. By default, it outputs the chi square statistic, degrees of freedom and p-value for each of the three alternative hypothesis: general association, row means differ, and nonzero correlation. It is up to the statistical analyst or statistician to know which result is appropriate for their analysis.\nWhen the design of the contingency table is 2 x 2 x K (i.e, X == 2 levels, Y == 2 levels, K &gt;= 2 levels), the Mantel-Haenszel Common Odds Ratio (odds ratio estimate, 95% CI, P-value) and the Breslow-Day Test for Homogeneity of the Odds Ratios (chi-square statistic, degrees of freedom, P-value) are also output.\nBelow is the syntax to conduct a CMH analysis in SAS:\n\nproc freq data = filtered_data; \n    tables K * X * Y / cmh; \n    * the order of K, X, and Y appearing on the line is important!;\nrun; \n\n\n\n\nThe adcibc data described here is used for this example.\n\n\n\nThe code used is always the same, however, we can limit the number of levels in each example to show a 2x2x2 case, 2x3xK case etc.\n\nproc freq data = adcibc; \n    tables agegr1 * trtp *  sex / cmh;  \nrun;\n\n\n\n\nLet’s test if there is a difference between 2 treatments (Placebo, and high dose), in the number of males and females, whilst adjusting for 2 levels of Age group (&lt;65 and 65-&lt;80). NOTE: prior to the proc freq, we have removed data in the low dose and &gt;80 categories.\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s test if there is a difference between 3 treatments (Placebo, Xanomeline low dose and high dose), in the number of males and females, whilst adjusting for 3 levels of Age group (&lt;65, 65-&lt;80 and &gt;=80). Here K=Agegrp1 the variable we are controlling for, X=Treatment -what we want to compare, and Y=Sex the variable we want to see if it’s different between treatments (often this would be response/ non-response!).\n\n\n\n\n\n\n\n\n\n\n\n\nThe above examples are a test for general association or if the row means scores differ across the strata controlling for another factor, however we may want to get an estimate of the direction and size of treatment effect (with CI), either within each strata or combined across strata.\n\n\nRisk differences within each strata can be obtained by adding the riskdiff option in SAS. The exact same output is obtained as per example 1 above, with the addition of 2 tables (1 for each age strata), showing the proportion of Female patients within each treatment (including 95% CIs), and the difference between the treatment proportions (including 95% CIs). By default, the CI’s are calculated using Wald asymptotic confidence limits and in addition, the exact Clopper-Pearson confidence intervals for the risks. See SAS userguide here and here for more detail on the range of CI’s SAS can calculate for the risk differences such as: Agresti-Caffo, exact unconditional, Hauck-Anderson, Miettinen-Nurminen (score), Newcombe (hybrid-score), Wald confidence limits, continuity-corrected Newcombe and continuity corrected Wald CIs.\nThe individual treatment comparisons within strata can be useful to explore if the treatment effect is in the same direction and size for each strata, such as to determine if pooling them is in fact sensible.\n\n# Default method is: Wald asymptotic confidence limits \nproc freq data = adcibc (where=(trtpn ne 54 and agegr1 ne \"&gt;80\")); \n    tables  agegr1 * trtp *  sex / cmh riskdiff; \nrun; \n\n\n\n\n\n\n\n\n\n\nNote above that exact CI’s are not output for the difference betweeen the treatments. You can request SAS output other CI methods as shown below. This outputs the risk difference between the treatments and 95% CI, calculated for each age group strata separately using the Miettinen-Nurminen (score) (MN) method.\n\n# You can change the confidence limits derivation using (cl=xxx) option\nproc freq data = adcibc (where=(trtpn ne 54 and agegr1 ne \"\\&gt;80\")); \n    tables agegr1 * trtp * sex / cmh riskdiff(cl=mn);\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: you may think by running the following code, that you would be creating a common risk difference using the stratified Miettinen-Nurminen method. However, this is actually performing an unstratified Miettinen-Nurminen (Score) method. The output contains the same risk differences calculated for each strata separately and then a common risk difference (however this is NOT a stratified approach !!). See SAS guide for more detail.\nSee the next section on Common risk differences available in SAS.\n\n# Specifying the Miettinen-Nurminen (score) method \nproc freq data = adcibc (where=(trtpn ne 54 and agegr1 ne \"&gt;80\")); \n    tables  agegr1 * trtp *  sex / cmh riskdiff (common cl=mn); \nrun; \n\n\n\n\n\n\n\n\n\n\n\n\n\nIncluding either column=1 or column=2 tells SAS which is your outcome of interest (ie, often that you want to compare treatment responders and not treatment non-responders!) My default it takes the 1st column sorted alphabetically but you can change this as shown below.\n\nproc freq data = adcibc (where=(trtpn ne 54 and agegr1 ne \"\\&gt;80\")); \n    tables agegr1 * trtp * sex / cmh riskdiff(common column=2);\nrun;\n\n\n\n\n\nProc freq can calculate estimates of the common risk difference with 95% CIs, calculated using the Mantel-Haenszel and summary score (Miettinen-Nurminen) methods for multiway 2x2 tables. It can also provide stratified Newcombe confidence intervals using the method by Yan and Su (2010). The stratified Newcombe CIs are constructed from stratified Wilson CIs for the common (overall) row proportions. See SAS help for more detail.\nNote that SAS (since v9.3M2 / STAT 12.1) PROC FREQ will produce the Miettinen-Nurminen (‘MN’) score interval for unstratified datasets only. Using ‘commonriskdiff’ requests risks (binomial proportions) and risk differences for 2x2 tables. But doesn’t extend to stratified analysis.\nThe only known way to have SAS produce stratified Miettinen-Nurminen CIs is to use this publicly available macro: https://github.com/petelaud/ratesci-sas/tree/main\n\nproc freq data = adcibc (where=(trtpn ne 54 and agegr1 ne \"&gt;80\")); \n    tables  agegr1 * trtp *  sex / cmh commonriskdiff(CL=SCORE TEST=SCORE); \nrun; \n\n\n\n\n\n\n\n\n\n\n\n\nproc freq data = adcibc (where=(trtpn ne 54 and agegr1 ne \"&gt;80\")); \n    tables  agegr1 * trtp *  sex / cmh commonriskdiff(CL= newcombe); \nrun;"
  },
  {
    "objectID": "SAS/cmh.html#cmh-in-sas",
    "href": "SAS/cmh.html#cmh-in-sas",
    "title": "CMH Test",
    "section": "",
    "text": "The cmh test is calculated in SAS using the PROC FREQ procedure. By default, it outputs the chi square statistic, degrees of freedom and p-value for each of the three alternative hypothesis: general association, row means differ, and nonzero correlation. It is up to the statistical analyst or statistician to know which result is appropriate for their analysis.\nWhen the design of the contingency table is 2 x 2 x K (i.e, X == 2 levels, Y == 2 levels, K &gt;= 2 levels), the Mantel-Haenszel Common Odds Ratio (odds ratio estimate, 95% CI, P-value) and the Breslow-Day Test for Homogeneity of the Odds Ratios (chi-square statistic, degrees of freedom, P-value) are also output.\nBelow is the syntax to conduct a CMH analysis in SAS:\n\nproc freq data = filtered_data; \n    tables K * X * Y / cmh; \n    * the order of K, X, and Y appearing on the line is important!;\nrun;"
  },
  {
    "objectID": "SAS/cmh.html#data-used",
    "href": "SAS/cmh.html#data-used",
    "title": "CMH Test",
    "section": "",
    "text": "The adcibc data described here is used for this example."
  },
  {
    "objectID": "SAS/cmh.html#code-used",
    "href": "SAS/cmh.html#code-used",
    "title": "CMH Test",
    "section": "",
    "text": "The code used is always the same, however, we can limit the number of levels in each example to show a 2x2x2 case, 2x3xK case etc.\n\nproc freq data = adcibc; \n    tables agegr1 * trtp *  sex / cmh;  \nrun;"
  },
  {
    "objectID": "SAS/cmh.html#example-1-2-x-2-x-2-i.e-x-2-trt-levels-y-2-sex-levels-k-2-age-levels",
    "href": "SAS/cmh.html#example-1-2-x-2-x-2-i.e-x-2-trt-levels-y-2-sex-levels-k-2-age-levels",
    "title": "CMH Test",
    "section": "",
    "text": "Let’s test if there is a difference between 2 treatments (Placebo, and high dose), in the number of males and females, whilst adjusting for 2 levels of Age group (&lt;65 and 65-&lt;80). NOTE: prior to the proc freq, we have removed data in the low dose and &gt;80 categories."
  },
  {
    "objectID": "SAS/cmh.html#example-2-2-x-3-x-k-i.e-x-2-levels-y-3-levels-k-2-levels",
    "href": "SAS/cmh.html#example-2-2-x-3-x-k-i.e-x-2-levels-y-3-levels-k-2-levels",
    "title": "CMH Test",
    "section": "",
    "text": "Let’s test if there is a difference between 3 treatments (Placebo, Xanomeline low dose and high dose), in the number of males and females, whilst adjusting for 3 levels of Age group (&lt;65, 65-&lt;80 and &gt;=80). Here K=Agegrp1 the variable we are controlling for, X=Treatment -what we want to compare, and Y=Sex the variable we want to see if it’s different between treatments (often this would be response/ non-response!)."
  },
  {
    "objectID": "SAS/cmh.html#example-3-risk-differences---comparing-treatment-differences-within-strata-and-combined-across-strata",
    "href": "SAS/cmh.html#example-3-risk-differences---comparing-treatment-differences-within-strata-and-combined-across-strata",
    "title": "CMH Test",
    "section": "",
    "text": "The above examples are a test for general association or if the row means scores differ across the strata controlling for another factor, however we may want to get an estimate of the direction and size of treatment effect (with CI), either within each strata or combined across strata.\n\n\nRisk differences within each strata can be obtained by adding the riskdiff option in SAS. The exact same output is obtained as per example 1 above, with the addition of 2 tables (1 for each age strata), showing the proportion of Female patients within each treatment (including 95% CIs), and the difference between the treatment proportions (including 95% CIs). By default, the CI’s are calculated using Wald asymptotic confidence limits and in addition, the exact Clopper-Pearson confidence intervals for the risks. See SAS userguide here and here for more detail on the range of CI’s SAS can calculate for the risk differences such as: Agresti-Caffo, exact unconditional, Hauck-Anderson, Miettinen-Nurminen (score), Newcombe (hybrid-score), Wald confidence limits, continuity-corrected Newcombe and continuity corrected Wald CIs.\nThe individual treatment comparisons within strata can be useful to explore if the treatment effect is in the same direction and size for each strata, such as to determine if pooling them is in fact sensible.\n\n# Default method is: Wald asymptotic confidence limits \nproc freq data = adcibc (where=(trtpn ne 54 and agegr1 ne \"&gt;80\")); \n    tables  agegr1 * trtp *  sex / cmh riskdiff; \nrun; \n\n\n\n\n\n\n\n\n\n\nNote above that exact CI’s are not output for the difference betweeen the treatments. You can request SAS output other CI methods as shown below. This outputs the risk difference between the treatments and 95% CI, calculated for each age group strata separately using the Miettinen-Nurminen (score) (MN) method.\n\n# You can change the confidence limits derivation using (cl=xxx) option\nproc freq data = adcibc (where=(trtpn ne 54 and agegr1 ne \"\\&gt;80\")); \n    tables agegr1 * trtp * sex / cmh riskdiff(cl=mn);\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: you may think by running the following code, that you would be creating a common risk difference using the stratified Miettinen-Nurminen method. However, this is actually performing an unstratified Miettinen-Nurminen (Score) method. The output contains the same risk differences calculated for each strata separately and then a common risk difference (however this is NOT a stratified approach !!). See SAS guide for more detail.\nSee the next section on Common risk differences available in SAS.\n\n# Specifying the Miettinen-Nurminen (score) method \nproc freq data = adcibc (where=(trtpn ne 54 and agegr1 ne \"&gt;80\")); \n    tables  agegr1 * trtp *  sex / cmh riskdiff (common cl=mn); \nrun; \n\n\n\n\n\n\n\n\n\n\n\n\n\nIncluding either column=1 or column=2 tells SAS which is your outcome of interest (ie, often that you want to compare treatment responders and not treatment non-responders!) My default it takes the 1st column sorted alphabetically but you can change this as shown below.\n\nproc freq data = adcibc (where=(trtpn ne 54 and agegr1 ne \"\\&gt;80\")); \n    tables agegr1 * trtp * sex / cmh riskdiff(common column=2);\nrun;\n\n\n\n\n\nProc freq can calculate estimates of the common risk difference with 95% CIs, calculated using the Mantel-Haenszel and summary score (Miettinen-Nurminen) methods for multiway 2x2 tables. It can also provide stratified Newcombe confidence intervals using the method by Yan and Su (2010). The stratified Newcombe CIs are constructed from stratified Wilson CIs for the common (overall) row proportions. See SAS help for more detail.\nNote that SAS (since v9.3M2 / STAT 12.1) PROC FREQ will produce the Miettinen-Nurminen (‘MN’) score interval for unstratified datasets only. Using ‘commonriskdiff’ requests risks (binomial proportions) and risk differences for 2x2 tables. But doesn’t extend to stratified analysis.\nThe only known way to have SAS produce stratified Miettinen-Nurminen CIs is to use this publicly available macro: https://github.com/petelaud/ratesci-sas/tree/main\n\nproc freq data = adcibc (where=(trtpn ne 54 and agegr1 ne \"&gt;80\")); \n    tables  agegr1 * trtp *  sex / cmh commonriskdiff(CL=SCORE TEST=SCORE); \nrun; \n\n\n\n\n\n\n\n\n\n\n\n\nproc freq data = adcibc (where=(trtpn ne 54 and agegr1 ne \"&gt;80\")); \n    tables  agegr1 * trtp *  sex / cmh commonriskdiff(CL= newcombe); \nrun;"
  },
  {
    "objectID": "SAS/summary-stats.html",
    "href": "SAS/summary-stats.html",
    "title": "Calculating Quantiles (percentiles) in SAS",
    "section": "",
    "text": "Percentiles can be calculated in SAS using the UNIVARIATE procedure. The procedure has the option PCTLDEF which allows for five different percentile definitions to be used. The default is PCTLDEF=5, which uses the empirical distribution function to find percentiles.\nThis is how the 25th and 40th percentiles of aval in the dataset adlb could be calculated, using the default option for PCTLDEF. For quantiles, Q1= 25%, Q2=50%, Q3 = 75%, Q4=100%.\n#| eval: false\nproc univariate data=adlb;\n    var aval;\n    output out=stats pctlpts=25 40 pctlpre=p;\nrun;\nThe pctlpre=p option tells SAS the prefix to use in the output dataset for the percentile results. In the above example, SAS will create a dataset called stats, containing variables p25 and p40."
  },
  {
    "objectID": "contribution/hackathon/contribution_guide_ssh.html",
    "href": "contribution/hackathon/contribution_guide_ssh.html",
    "title": "Contribution Guide: connect RStudio with GitHub",
    "section": "",
    "text": "Do you have RStudio locally? If so, this should be straight forward. If on a remote server it may be more complex!\nHave you connected your RStudio to GitHub? If not, complete Steps 1 to 3 below. \nNOTE: You will need the following to proceed:\n\nR Studio\nGit software and\na GitHub account\n\n\nStep 1: Ensure that your RStudio has a SSH Key\nGo to:  Tools – Global Options – Git/SVN.\n\n\n\n\n\nClick to Create SSH Key - This allows communication between Github & R.\n\n\n\n\n\nWhere is asks if you want to add a password, you do not need any password adding.\nClick to View Public Key & Copy it to the clipboard.\n\n\nStep 2: Add the R Studio SSH key to your github account.\nNOTE: you may need to come off your Company VPN in order for the connection to be accepted\nLog into your GitHub account.\nIf you don’t know your github ID, then you could check to see if you contributed to the CSRMLW project and find it from there, then reset your account. Otherwise, set up a new github account. https://github.com/phuse-org/CSRMLW\nOnce logged in, Within Github - go to settings (the blue widget below)\n\n\n\n\n\nGo to the SSH and GPG keys tab.\n\n\n\n\n\nSelect “New SSH Key”\nGive it a title (Company X account) and “Add SSH Key”.\nPaste in the SSH Code that you copied in step 1 and click “Add SSH Key”.\n\n\nStep 3: Tell R Studio the project you want to work on: the CAMIS github repo\nNavigate to the Git hub repo you want to work in: https://github.com/PSIAIMS/CAMIS\nClick on the Green “Code” button and select the tab: Local – SSH as shown below Copy the SSH key.\n\n\n\n\n\nGo into R Studio. Select: File New Project - Version Control - Git : In the repository URL paste the SSH key from Github. Click Ok.\nThis will set up the link between Github & your R studio.\nThe console will show you where files will be stored locally, before/after doing pull requests to the repo\n\n\n\n\n\nNow you can create new RMD files - edit them locally and save them back to github using the Git tab as shown below (on the right Environment, History, Connections, Git, Tutorial)\n\n\n\n\n\nWhen you save a file, It will appear in the GIT tab.\nCommit - will push it back to the repo.\nMake sure you pull down (Blue down arrow) before starting changes so you are editing the latest version of things from the repo. After you commit, click the Green up arrow to do a pull request back to the repo.\n If you have problems with the new project and what packages it has available. It is a good idea go into: Tools - Project Options - Environments - and select “Use RENV with this project”. This then saves the packages more locally & they should be there when you go back in.\nIf you get the following message, then run “renv::restore()” in the console."
  },
  {
    "objectID": "contribution/package_review.html",
    "href": "contribution/package_review.html",
    "title": "How to Choose an R Stats Package",
    "section": "",
    "text": "When you want to implement statistical methodology in R and you don’t already know the package that does the method, it can be difficult to figure out the “best” package. Sometimes when you google a method, the top result is the package with wording that matches closest to what you typed into google, rather than the package that is “best” for the method. You don’t want to waste time looking deeply into a package only to find there is a more common and robust R package out there for the same method. So before you go down a rabbit hole on one package, it is worth checking a few packages. But, how do you “check” a package. This blog post will go through a worked example of comparing packages and a checklist of things to look at when comparing packages in the future."
  },
  {
    "objectID": "contribution/package_review.html#package-checklist",
    "href": "contribution/package_review.html#package-checklist",
    "title": "How to Choose an R Stats Package",
    "section": "Package Checklist",
    "text": "Package Checklist\nWhen looking at a package the first place to start is the CRAN index page. You can find this by googling CRAN and name of the package. From there you want to ask yourself the following questions:\n\nIs this package being actively maintained?\nIs the author known in the field?\n\nIs there more than one author?\n\nDoes the package have adequate documentation?\n\nAre there references to external peer reviewed papers?\nIs there a website / vignettes?\n\nIs there a way to report bugs?\nCan the packages handle different edge cases?\nDoes the package have a lot of dependencies / unusual dependencies?\nLook at community adoption?\n\nUsing this checklist can help you quickly and consistently get a sense of a package before spending time looking into the code directly. Let’s see how this works in practice."
  },
  {
    "objectID": "contribution/package_review.html#worked-example-wilcoxon-rank-sum-test",
    "href": "contribution/package_review.html#worked-example-wilcoxon-rank-sum-test",
    "title": "How to Choose an R Stats Package",
    "section": "Worked Example: Wilcoxon Rank-Sum Test",
    "text": "Worked Example: Wilcoxon Rank-Sum Test\nFor this, we are going to look at the Wilcoxon Rank-Sum test and the associated Hodges-Lehmann confidence interval. After googling a bit, I found three different packages that do a Wilcoxon Rank-Sum p-value and Hodges-Lehmann CI:\n\n{stats} (part of base R)\n{pairwiseCI}\n{coin}\n\nGreat! I might be kind of done, because I tend to favor base R stats functions, but as I start looking into this, I found the {stats} function can’t handle ties if I want the exact methods. So I need to look into and compare the {pairwiseCI} and {coin} packages.\n\n\n\n\n\n\nTip\n\n\n\nYou often find that differences between packages and software show up when there are ties, missing data, and/or extreme values, so it is good to try to include these in the dataset you are using to compare.\n\n\nNow I need to choose between {pairwaiseCI} and {coin}. I could just run the model in both and see if the results match, but that will be a lot of work. So before I get started I want to go through our checklist.\nLet’s pull up the CRAN index pages for each of these packages and see if we can figure out which package we should use for this analysis.\n\n{pairwiseCI}\nStarting with {pairwiseCI}, the index page looks like this:\n\nNow let’s go down the checklist to see if there are any red flags for this package.\n\nIs this package being actively maintained?\n\nThe last update to this package was 2019-03-11, so over 6 years at the writing of this post. That indicates this probably isn’t being actively maintained.\n\nIs the author known in the field?\n\nPersonally, I don’t know this author, but it looks like he does work in a biostatistics department at a university, so that is a really good sign. When you are looking at the author you don’t need to go super in-depth, but if you don’t know who they are it can be good to check their qualifications.\n\n\nIs there more than one author?\n\nYes, it looks like there are two authors here. This can be good to check because it can mean the burden of maintaining the package is shared and the documentation has potentially been peer reviewed.\n\n\nDoes the package have adequate documentation?\n\nThis can be hard to determine from just this index page, but the sub-questions can help here.\n\n\nAre there references to external peer reviewed papers?\n\nOn the index there are no references, but there might be some references on the function level. Really it just means they haven’t published a paper about this package.\n\nIs there a website / Vignettes?\n\nThere isn’t a website or vingettes. This means all the documenation will be limited to just the functions, which can be harder to understand.\n\n\nIs there a way to report bugs?\n\nThere doesn’t appear to be a standard way to report bugs. If this package was on github or something similar, I would be able to check any issues there to see if others had similar problems or if the issue was caused by user error and has a quick fix.\n\nCan the packages handle different edge cases?\n\nThe description doesn’t say anything about handling special cases. But, I did find this package because it can handle ties in the exact case.\n\nDoes the package have a lot of dependencies / unusual dependencies?\n\nIt looks like this package only has two dependencies, {MCPAN} and, interestingly, {coin}, the other package we are looking at.\n\n\nOkay, having gone through all but the final question, I would say I feel not amazing about the package, but if it was my only option I would still try to use it. The author gives me confidence in the package, but other things like documentation and last update date, make me a bit nervous about this package.\n\n\n{coin}\nNow on to {coin} with the same questions. The index page is as follows:\n\n\nIs this package being actively maintained?\n\nThe last update to this package was 2023-09-27, so more recently than {pairwiseCI}.\n\nIs the author known in the field?\n\nAgain, I don’t know the author, but he has an R-project.org email, which indicates he is very involved in the R ecosystem and is a very good sign.\n\n\nIs there more than one author?\n\nYes, there are 5 different authors, so lots of eyes on bugs and documentation.\n\n\nDoes the package have adequate documentation?\n\nAgain, this can be hard to determine from just this index page, but the sub-questions can help here.\n\n\nAre there references to external peer reviewed papers?\n\nYes, there is a peer reviewed paper in the description of this package.\n\nIs there a website / Vignettes?\n\nWhile there isn’t a website here, there are four different vignettes.\n\n\nIs there a way to report bugs?\n\nLike with the other package, there doesn’t appear to be a standard way to report bugs.\n\nCan the packages handle different edge cases?\n\nSame as above. It doesn’t directly said it can handle our edge case, but I know it can.\n\nDoes the package have a lot of dependencies / unusual dependencies?\n\nWhile this package has more dependencies, all the dependencies are very standard and do not raise any red flags for me\n\n\nHaving gone through most the questions, I am fairly confident in saying I want to use {coin} to investigate this method rather than {pairwiseCI}. For almost all the questions {coin} looks slightly better than {pairwiseCI} and really just has a larger accumulation of evidence of quality. But, I haven’t answered the last question in my checklist for either these packages. What about community adoption? It can be a bit hard to look at directly, but I tend to use a few different ways.\nFirst, staying on the CRAN index page for the package, I look at the Reverse Dependencies. This section gets split into three parts, “Reverse depends”, “Reverse imports”, and “Reverse suggests” which explains how the other packages are using the package. In terms of community adoption, it doesn’t matter if other packages are depending, importing or suggesting the package, all that matters is they are using it. Note: This section only appears if other packages on CRAN use the package.\nFor these two packages, only {coin} has this section and we can see there are many other packages that use {coin}.\n\nThe next thing I will check is the number of downloads. This can easily be done with the following bit of code:\n\ncranlogs::cran_downloads(package = c(\"coin\", \"pairwiseCI\"))\n\n\nAnd you can see {coin} is much more popular than {pairwiseCI}.\nSo with all of this information, I think starting with {coin} is going to be the best use of my time.\nWhen looking at the number of downloads, you can look over a longer period like over the last month (by using the when parameter) or you can look between specific dates (by using the from and to parameters). But, it will give you the download numbers for each day, which you will need to summaries. These day-by-day numbers can be very helpful to look at trends, especially when there is a new package that is getting rapidly adopted.\nThe checklist isn’t intended to replace a full review of the package for an GxP workflows. But, when just trying to decide which package to look into for a particular stats method it can be helpful.\nIn summary, selecting the appropriate R package for statistical analyses is hard. Google, isn’t perfect and so it worth finding a few packages and going through this checklist. By taking a few minutes to consider factors like maintenance, documentation, and community adoption can save you time in the long run."
  },
  {
    "objectID": "python/correlation.html",
    "href": "python/correlation.html",
    "title": "Correlation Analysis in Python",
    "section": "",
    "text": "Correlation analyses measures the strength of the relationship between two variables. Correlation analyses can be used to test for associations in hypothesis testing. If the null hypothesis states there is correlation between the variables considered under the study. Then, the purpose is to investigate the possible association in the underlying variables.\nThe Scipy library in Python encompasees Stats module with pearsonr(), kendalltau(), spearsmanr() function to evaluate Pearson, Kendall and Spearsman Correlation co-efficient respectively.\n\nPearson’s Correlation\nIt is a parametric correlation test because it depends on the distribution of data. It measures the linear dependence between two variables x and y. It is the ratio between the covariance of two variables and the product of their standard deviation. The result always have a value between 1 and -1.\n\nimport pandas as pd\nfrom scipy.stats import pearsonr\n\n# Read the sample data\ndf = pd.read_csv(\"../data/NCCTG_Lung_Cancer_Data_535_29.csv\")\n\n# Convert dataframe into series\nx = df['age']\ny = df['meal.cal']\n\n# Apply the pearsonr()\ncorr, _ = pearsonr(x, y)\nprint('Pearsons correlation: %.3f' % corr)\n\nPearsons correlation: -0.240\n\n\n\n\nKendall’s Rank\nA τ test is a non-parametric hypothesis test for statistical dependence based on the τ coefficient. It is a measure of rank correlation: the similarity of the orderings of the data when ranked by each of the quantities. The Kendall correlation between two variables will be high when observations have a similar (or identical for a correlation of 1) rank (i.e. relative position label of the observations within the variable: 1st, 2nd, 3rd, etc.) between the two variables, and low when observations have a dissimilar (or fully different for a correlation of −1) rank between the two variables.\n\nimport pandas as pd\nfrom scipy.stats import kendalltau \n\n# Read the sample data\ndf = pd.read_csv(\"../data/NCCTG_Lung_Cancer_Data_535_29.csv\")\n  \n# Convert dataframe into series\nx=df['age']\ny = df['meal.cal']\n\n\n# Calculating Kendall Rank correlation \ncorr, _ = kendalltau(x, y) \nprint('Kendall Rank correlation: %.5f' % corr) \n\nKendall Rank correlation: -0.14581\n\n\n\n\nSpearman’s Rank\nSpearman’s Rank Correlation is a statistical measure of the strength and direction of the monotonic relationship between two continuous variables. Therefore, these attributes are ranked or put in the order of their preference. It is denoted by the symbol “rho” (ρ) and can take values between -1 to +1. A positive value of rho indicates that there exists a positive relationship between the two variables, while a negative value of rho indicates a negative relationship. A rho value of 0 indicates no association between the two variables.\n\nimport pandas as pd\nfrom scipy.stats import spearmanr\n \n# Read the sample data\ndf= pd.read_csv(\"../data/NCCTG_Lung_Cancer_Data_535_29.csv\")\n\n# Convert dataframe into series\nx = df['age']\ny = df['meal.cal']\n \n# calculate Spearman's correlation coefficient and p-value\ncorr, pval = spearmanr(x, y)\n \n# print the result\nprint(\"Spearman's correlation coefficient:\", corr)\nprint(\"p-value:\", pval)\n\nSpearman's correlation coefficient: -0.21159256066613205\np-value: 0.006051240282927171"
  },
  {
    "objectID": "python/skewness_kurtosis.html",
    "href": "python/skewness_kurtosis.html",
    "title": "Skewness/Kurtosis",
    "section": "",
    "text": "Skewness measures the the amount of asymmetry in a distribution, while Kurtosis describes the “tailedness” of the curve. These measures are frequently used to assess the normality of the data. There are several methods to calculate these measures. In Python, the packages pandas, scipy.stats.skew and scipy.stats.kurtosis can be used.\n\n\n\nimport pandas as pd\nfrom scipy.stats import skew, kurtosis\n\n# Create sample data\ndata = {\n    'team': [\"A\"]*5 + [\"B\"]*5 + [\"C\"]*5,\n    'points': [10, 17, 17, 18, 15, 10, 14, 13, 29, 25, 12, 30, 34, 12, 11],\n    'assists': [2, 5, 6, 3, 0, 2, 5, 4, 0, 2, 1, 1, 3, 4, 7]\n}\ndf = pd.DataFrame(data)\n\n\n\nJoanes and Gill (1998) discusses three methods for estimating skewness:\n\nType 1: This is the typical definition used in many older textbooks\n\n\\[g_1 = m_1/m_2^{3/2}\\]\n\nType 2: Used in SAS and SPSS\n\\[\nG_1 = g_1\\sqrt{n(n-1)}/(n-2)\n\\]\nType 3: Used in MINITAB and BMDP\n\\[\nb_1 = m_3/s^3 = g_1((n-1)/n)^{3/2}\n\\]\n\nAll three skewness measures are unbiased under normality. The three methods are illustrated in the following code:\n\n# Skewness\ntype1_skew = skew(df['points'])\ntype2_skew = df['points'].skew()\ntype3_skew = skew(df['points']) * ((len(df['points']) - 1) / len(df['points'])) ** (3/2)\n\nprint(f\"Skewness - Type 1: {type1_skew}\")\nprint(f\"Skewness - Type 2: {type2_skew}\")\nprint(f\"Skewness - Type 3: {type3_skew}\")\n\nSkewness - Type 1: 0.9054442043798532\nSkewness - Type 2: 1.0093179298709385\nSkewness - Type 3: 0.816426058828937\n\n\nThe default for the scipy.stats.skew function is type 1.\n\n\n\nJoanes and Gill (1998) discuss three methods for estimating kurtosis:\n\nType 1: This is the typical definition used in many older textbooks\n\n\\[g_2 = m_4/m_2^{2}-3\\]\n\nType 2: Used in SAS and SPSS\n\\[G_2 = ((n+1)g_2+6)*\\frac{(n-1)}{(n-2)(n-3)}\\]\nType 3: Used in MINITAB and BMDP\n\\[b_2 = m_4/s^4-3 = (g_2 + 3)(1-1/n)^2-3\\]\n\nOnly \\(G_2\\) (corresponding to type 2) is unbiased under normality. The three methods are illustrated in the following code:\n\n# Kurtosis\ntype1_kurt = kurtosis(df['points'])\n\nn = len(df['points'])\ng2 = kurtosis(df['points'], fisher=True)  # Fisher's kurtosis\n\n# Calculate the kurtosis type using the formula G2\ntype2_kurt = ((n + 1) * g2 + 6) * ((n - 1) / ((n - 2) * (n - 3)))\n\n# Calculate the kurtosis type using the formula b2\nn = len(df['points'])\ng2 = kurtosis(df['points'], fisher=True)  # Fisher's kurtosis\n\ntype3_kurt = (g2 + 3) * ((1 - 1/n) ** 2) - 3\n\nprint(f\"Kurtosis - Type 1: {type1_kurt}\")\nprint(f\"Kurtosis - Type 2: {type2_kurt}\")\nprint(f\"Kurtosis - Type 3: {type3_kurt}\")\n\nKurtosis - Type 1: -0.5833410771247833\nKurtosis - Type 2: -0.2991564184355863\nKurtosis - Type 3: -0.8948215605175891\n\n\nThe default for the scipy.stats.kurtosis function is type 1."
  },
  {
    "objectID": "python/skewness_kurtosis.html#data-used",
    "href": "python/skewness_kurtosis.html#data-used",
    "title": "Skewness/Kurtosis",
    "section": "",
    "text": "import pandas as pd\nfrom scipy.stats import skew, kurtosis\n\n# Create sample data\ndata = {\n    'team': [\"A\"]*5 + [\"B\"]*5 + [\"C\"]*5,\n    'points': [10, 17, 17, 18, 15, 10, 14, 13, 29, 25, 12, 30, 34, 12, 11],\n    'assists': [2, 5, 6, 3, 0, 2, 5, 4, 0, 2, 1, 1, 3, 4, 7]\n}\ndf = pd.DataFrame(data)\n\n\n\nJoanes and Gill (1998) discusses three methods for estimating skewness:\n\nType 1: This is the typical definition used in many older textbooks\n\n\\[g_1 = m_1/m_2^{3/2}\\]\n\nType 2: Used in SAS and SPSS\n\\[\nG_1 = g_1\\sqrt{n(n-1)}/(n-2)\n\\]\nType 3: Used in MINITAB and BMDP\n\\[\nb_1 = m_3/s^3 = g_1((n-1)/n)^{3/2}\n\\]\n\nAll three skewness measures are unbiased under normality. The three methods are illustrated in the following code:\n\n# Skewness\ntype1_skew = skew(df['points'])\ntype2_skew = df['points'].skew()\ntype3_skew = skew(df['points']) * ((len(df['points']) - 1) / len(df['points'])) ** (3/2)\n\nprint(f\"Skewness - Type 1: {type1_skew}\")\nprint(f\"Skewness - Type 2: {type2_skew}\")\nprint(f\"Skewness - Type 3: {type3_skew}\")\n\nSkewness - Type 1: 0.9054442043798532\nSkewness - Type 2: 1.0093179298709385\nSkewness - Type 3: 0.816426058828937\n\n\nThe default for the scipy.stats.skew function is type 1.\n\n\n\nJoanes and Gill (1998) discuss three methods for estimating kurtosis:\n\nType 1: This is the typical definition used in many older textbooks\n\n\\[g_2 = m_4/m_2^{2}-3\\]\n\nType 2: Used in SAS and SPSS\n\\[G_2 = ((n+1)g_2+6)*\\frac{(n-1)}{(n-2)(n-3)}\\]\nType 3: Used in MINITAB and BMDP\n\\[b_2 = m_4/s^4-3 = (g_2 + 3)(1-1/n)^2-3\\]\n\nOnly \\(G_2\\) (corresponding to type 2) is unbiased under normality. The three methods are illustrated in the following code:\n\n# Kurtosis\ntype1_kurt = kurtosis(df['points'])\n\nn = len(df['points'])\ng2 = kurtosis(df['points'], fisher=True)  # Fisher's kurtosis\n\n# Calculate the kurtosis type using the formula G2\ntype2_kurt = ((n + 1) * g2 + 6) * ((n - 1) / ((n - 2) * (n - 3)))\n\n# Calculate the kurtosis type using the formula b2\nn = len(df['points'])\ng2 = kurtosis(df['points'], fisher=True)  # Fisher's kurtosis\n\ntype3_kurt = (g2 + 3) * ((1 - 1/n) ** 2) - 3\n\nprint(f\"Kurtosis - Type 1: {type1_kurt}\")\nprint(f\"Kurtosis - Type 2: {type2_kurt}\")\nprint(f\"Kurtosis - Type 3: {type3_kurt}\")\n\nKurtosis - Type 1: -0.5833410771247833\nKurtosis - Type 2: -0.2991564184355863\nKurtosis - Type 3: -0.8948215605175891\n\n\nThe default for the scipy.stats.kurtosis function is type 1."
  },
  {
    "objectID": "python/binomial_test.html",
    "href": "python/binomial_test.html",
    "title": "Binomial Test",
    "section": "",
    "text": "The statistical test used to determine whether the proportion in a binary outcome experiment is equal to a specific value. It is appropriate when we have a small sample size and want to test the success probability \\(p\\) against a hypothesized value \\(p_0\\)."
  },
  {
    "objectID": "python/binomial_test.html#creating-a-sample-dataset",
    "href": "python/binomial_test.html#creating-a-sample-dataset",
    "title": "Binomial Test",
    "section": "Creating a sample dataset",
    "text": "Creating a sample dataset\n\nWe will generate a dataset where we record the outcomes of 1000 coin flips.\nWe will use the binom.test function to test if the proportion of heads is significantly different from 0.5.\n\n\nimport numpy as np\nfrom scipy.stats import binomtest\n\n# Set seed for reproducibility\nnp.random.seed(19)\ncoin_flips = np.random.choice(['H', 'T'], size=1000, replace=True, p=[0.5, 0.5])\n\nNow, we will count the heads and tails and summarize the data.\n\n# Count heads and tails\nheads_count = np.sum(coin_flips == 'H')\ntails_count = np.sum(coin_flips == 'T')\ntotal_flips = len(coin_flips)\n\nheads_count, tails_count, total_flips\n\n(np.int64(523), np.int64(477), 1000)"
  },
  {
    "objectID": "python/binomial_test.html#conducting-binomial-test",
    "href": "python/binomial_test.html#conducting-binomial-test",
    "title": "Binomial Test",
    "section": "Conducting Binomial Test",
    "text": "Conducting Binomial Test\n\n# Perform the binomial test\nbinom_test_result = binomtest(heads_count, total_flips, p=0.5)\nbinom_test_result\n\nBinomTestResult(k=523, n=1000, alternative='two-sided', statistic=0.523, pvalue=0.15469370647995673)\n\n\n\nResults:\nThe output has a p-value py binom_test_result \\(&gt; 0.05\\) (chosen level of significance). Hence, we fail to reject the null hypothesis and conclude that the coin is fair."
  },
  {
    "objectID": "python/binomial_test.html#conduct-the-binomial-test",
    "href": "python/binomial_test.html#conduct-the-binomial-test",
    "title": "Binomial Test",
    "section": "Conduct the Binomial Test",
    "text": "Conduct the Binomial Test\nWe will conduct the Binomial test and hypothesize that the proportion of death should be 19%.\n\n# Perform the binomial test\nbinom_test_clinical = binomtest(num_deaths, total_pat, p=0.19)\nbinom_test_clinical\n\nBinomTestResult(k=63, n=228, alternative='two-sided', statistic=0.27631578947368424, pvalue=0.0016828878642599632)"
  },
  {
    "objectID": "python/binomial_test.html#results-1",
    "href": "python/binomial_test.html#results-1",
    "title": "Binomial Test",
    "section": "Results:",
    "text": "Results:\nThe output has a p-value py binom_test_clinical \\(&lt; 0.05\\) (chosen level of significance). Hence, we reject the null hypothesis and conclude that the propotion of death is significantly different from 19%."
  },
  {
    "objectID": "python/anova.html",
    "href": "python/anova.html",
    "title": "ANOVA",
    "section": "",
    "text": "Analysis of VAriance (ANOVA) is a statistical test to measure the difference between means of more than two groups.It is best suited when the data is normally distributed. By partitioning total variance into components, ANOVA unravels relationship between variables and identifies the true source of variation. It can handle multiple factors and their interactions, providing a robust way to better understand intricate relationships."
  },
  {
    "objectID": "python/anova.html#introduction",
    "href": "python/anova.html#introduction",
    "title": "ANOVA",
    "section": "",
    "text": "Analysis of VAriance (ANOVA) is a statistical test to measure the difference between means of more than two groups.It is best suited when the data is normally distributed. By partitioning total variance into components, ANOVA unravels relationship between variables and identifies the true source of variation. It can handle multiple factors and their interactions, providing a robust way to better understand intricate relationships."
  },
  {
    "objectID": "python/anova.html#anova-test-in-python",
    "href": "python/anova.html#anova-test-in-python",
    "title": "ANOVA",
    "section": "Anova Test in Python",
    "text": "Anova Test in Python\nTo perform a one-way ANOVA test in Python we can use the f_oneway() function from SciPy library. Similarly, to perform two-way ANOVA test anova_lm() function from the statsmodel library is frequently used.\nFor this test, we’ll create a data frame called df_disease taken from the SAS documentation. The corresponding data can be found here. In this experiment, we are trying to find the impact of different drug and disease group on the stem-length\n\nimport pandas as pd\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\n# Read the sample data\ndf = pd.read_csv(\"../data/sas_disease.csv\")\n\n\n#perform two-way ANOVA\nmodel = ols('y ~ C(drug) + C(disease) + C(drug):C(disease)', data=df).fit()\nsm.stats.anova_lm(model, typ=2)\n\n\n\n\n\n\n\n\nsum_sq\ndf\nF\nPR(&gt;F)\n\n\n\n\nC(drug)\n3063.432863\n3.0\n9.245096\n0.000067\n\n\nC(disease)\n418.833741\n2.0\n1.895990\n0.161720\n\n\nC(drug):C(disease)\n707.266259\n6.0\n1.067225\n0.395846\n\n\nResidual\n5080.816667\n46.0\nNaN\nNaN"
  },
  {
    "objectID": "python/anova.html#sum-of-squares-tables",
    "href": "python/anova.html#sum-of-squares-tables",
    "title": "ANOVA",
    "section": "Sum of Squares Tables",
    "text": "Sum of Squares Tables\n\nType I\n\nmodel = ols('y ~ C(drug) + C(disease) + C(drug):C(disease)', data=df).fit()\nsm.stats.anova_lm(model)\n\n\n\n\n\n\n\n\ndf\nsum_sq\nmean_sq\nF\nPR(&gt;F)\n\n\n\n\nC(drug)\n3.0\n3133.238506\n1044.412835\n9.455761\n0.000056\n\n\nC(disease)\n2.0\n418.833741\n209.416870\n1.895990\n0.161720\n\n\nC(drug):C(disease)\n6.0\n707.266259\n117.877710\n1.067225\n0.395846\n\n\nResidual\n46.0\n5080.816667\n110.452536\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nType II\n\nmodel = ols('y ~ C(drug) + C(disease) + C(drug):C(disease)', data=df).fit()\nsm.stats.anova_lm(model, typ=2)\n\n\n\n\n\n\n\n\nsum_sq\ndf\nF\nPR(&gt;F)\n\n\n\n\nC(drug)\n3063.432863\n3.0\n9.245096\n0.000067\n\n\nC(disease)\n418.833741\n2.0\n1.895990\n0.161720\n\n\nC(drug):C(disease)\n707.266259\n6.0\n1.067225\n0.395846\n\n\nResidual\n5080.816667\n46.0\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nType III\n\nmodel = ols('y ~ C(drug,Sum) + C(disease,Sum) + C(drug,Sum):C(disease,Sum)', data=df).fit()\nsm.stats.anova_lm(model, typ=3)\n\n\n\n\n\n\n\n\nsum_sq\ndf\nF\nPR(&gt;F)\n\n\n\n\nIntercept\n20037.613011\n1.0\n181.413788\n1.417921e-17\n\n\nC(drug, Sum)\n2997.471860\n3.0\n9.046033\n8.086388e-05\n\n\nC(disease, Sum)\n415.873046\n2.0\n1.882587\n1.637355e-01\n\n\nC(drug, Sum):C(disease, Sum)\n707.266259\n6.0\n1.067225\n3.958458e-01\n\n\nResidual\n5080.816667\n46.0\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nType IV\nThere is no Type IV sum of squares calculation in Python similiar to SAS."
  },
  {
    "objectID": "python/logistic_regression.html",
    "href": "python/logistic_regression.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "#data manipulation\nimport pandas as pd\nimport numpy as np\n\n#modelling\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LogisticRegression"
  },
  {
    "objectID": "python/logistic_regression.html#statsmodels-package",
    "href": "python/logistic_regression.html#statsmodels-package",
    "title": "Logistic Regression",
    "section": "Statsmodels package",
    "text": "Statsmodels package\nWe will use the sm.Logit() method to fit our logistic regression model.\n\n#intercept column\nx_sm = sm.add_constant(x)\n\n#fit model\nlr_sm = sm.Logit(y, x_sm).fit() \nprint(lr_sm.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.568825\n         Iterations 5\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                 wt_grp   No. Observations:                  167\nModel:                          Logit   Df Residuals:                      162\nMethod:                           MLE   Df Model:                            4\nDate:                Thu, 13 Mar 2025   Pseudo R-squ.:                 0.05169\nTime:                        16:21:34   Log-Likelihood:                -94.994\nconverged:                       True   LL-Null:                       -100.17\nCovariance Type:            nonrobust   LLR p-value:                   0.03484\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          3.3576      1.654      2.029      0.042       0.115       6.600\nage           -0.0126      0.021     -0.598      0.550      -0.054       0.029\nsex           -0.8645      0.371     -2.328      0.020      -1.592      -0.137\nph.ecog        0.4182      0.263      1.592      0.111      -0.097       0.933\nmeal.cal      -0.0009      0.000     -1.932      0.053      -0.002    1.27e-05\n==============================================================================\n\n\n\nModel fitting\nIn addition to the information contained in the summary, we can display the model coefficients as odds ratios:\n\nprint(\"Odds ratios for statsmodels logistic regression:\")\nprint(np.exp(lr_sm.params))\n\nOdds ratios for statsmodels logistic regression:\nconst       28.719651\nage          0.987467\nsex          0.421266\nph.ecog      1.519198\nmeal.cal     0.999140\ndtype: float64\n\n\nWe can also provide the 5% confidence intervals for the odds ratios:\n\nprint(\"CI at 5% for statsmodels logistic regression:\")\nprint(np.exp(lr_sm.conf_int(alpha = 0.05)))\n\nCI at 5% for statsmodels logistic regression:\n                 0           1\nconst     1.121742  735.301118\nage       0.947449    1.029175\nsex       0.203432    0.872354\nph.ecog   0.907984    2.541852\nmeal.cal  0.998269    1.000013\n\n\n\n\nPrediction\nLet’s use our trained model to make a weight loss prediction about a new patient.\n\n# new female, symptomatic but completely ambulatory patient consuming 2500 calories\nnew_pt = pd.DataFrame({\n    \"age\": [56],\n    \"sex\": [2],\n    \"ph.ecog\": [1.00], \n    \"meal.cal\": [2500]\n})\n\n# Add intercept term to the new data; for a single row this should be \n# forced using the `add_constant` command\nnew_pt_sm = sm.add_constant(new_pt, has_constant=\"add\")\nprint(\"Probability of weight loss using the statsmodels package:\")\nprint(lr_sm.predict(new_pt_sm))\n\nProbability of weight loss using the statsmodels package:\n0    0.308057\ndtype: float64"
  },
  {
    "objectID": "python/logistic_regression.html#scikit-learn-package",
    "href": "python/logistic_regression.html#scikit-learn-package",
    "title": "Logistic Regression",
    "section": "Scikit-learn Package",
    "text": "Scikit-learn Package\nThe scikit-learn package is a popular package for machine learning and predictive modelling.\n\n\n\n\n\n\nWarning\n\n\n\nIt’s important to note that l2 regularisation is applied by default in the scikit-learn implementation of logistic regression. More recent releases of this package include an option to have no regularisation penalty.\n\n\n\nlr_sk = LogisticRegression(penalty=None).fit(x, y)\n\nUnlike the statsmodels approach scikit-learn doesn’t have a summary method for the model but you can extract some of the model parameters as follows:\n\nprint(\"Intercept for scikit learn logistic regression:\")\nprint(lr_sk.intercept_)\nprint(\"Odds ratios for scikit learn logistic regression:\")\nprint(np.exp(lr_sk.coef_))\n\nIntercept for scikit learn logistic regression:\n[3.35756405]\nOdds ratios for scikit learn logistic regression:\n[[0.98746739 0.42126736 1.51919379 0.99914048]]\n\n\nHowever, obtaining the confidence intervals and other metrics is not directly supported in scikit-learn.\n\nPrediction\nUsing the same new patient example we can use our logistic regression model to make a prediction. The predict_proba method is used to return the probability for each class. If you are interested in viewing the prediction for y = 1, i.e. the probability of weight loss then you can select the second probability as shown:\n\nprint(\"Probability of weight loss using the scikit-learn package:\")\nprint(lr_sk.predict_proba(new_pt)[:,1])\n\nProbability of weight loss using the scikit-learn package:\n[0.30805813]"
  },
  {
    "objectID": "python/logistic_regression.html#conclusions",
    "href": "python/logistic_regression.html#conclusions",
    "title": "Logistic Regression",
    "section": "Conclusions",
    "text": "Conclusions\nThere are two main ways to fit a logistic regression using python. Each of these packages have their advantages with statsmodel geared more towards model and coefficient interpretation in low dimensional data settings and in contrast the scikit-learn implementation more appropriate for use cases focused on prediction with more complex, higher dimensional data."
  },
  {
    "objectID": "python/linear_regression.html",
    "href": "python/linear_regression.html",
    "title": "Linear Regression",
    "section": "",
    "text": "To demonstrate the use of linear regression we examine a dataset that illustrates the relationship between Height and Weight in a group of 237 teen-aged boys and girls. The dataset is available here and is imported to the workspace.\n\nDescriptive Statistics\nThe first step is to obtain the simple descriptive statistics for the numeric variables of htwt data, and one-way frequencies for categorical variables. This is accomplished by employing summary function. There are 237 participants who are from 13.9 to 25 years old. It is a cross-sectional study, with each participant having one observation. We can use this data set to examine the relationship of participants’ height to their age and sex.\n\nimport pandas as pd\nimport statsmodels.api as sm\n\n# Importing CSV\nhtwt = pd.read_csv(\"../data/htwt.csv\")\n\nIn order to create a regression model to demonstrate the relationship between age and height for females, we first need to create a flag variable identifying females and an interaction variable between age and female gender flag.\n\nhtwt['female'] = (htwt['SEX'] == 'f').astype(int)\nhtwt['fem_age'] = htwt['AGE'] * htwt['female']\nhtwt.head()\n\n\n\n\n\n\n\n\nROW\nSEX\nAGE\nHEIGHT\nWEIGHT\nfemale\nfem_age\n\n\n\n\n0\n1\nf\n14.3\n56.3\n85.0\n1\n14.3\n\n\n1\n2\nf\n15.5\n62.3\n105.0\n1\n15.5\n\n\n2\n3\nf\n15.3\n63.3\n108.0\n1\n15.3\n\n\n3\n4\nf\n16.1\n59.0\n92.0\n1\n16.1\n\n\n4\n5\nf\n19.1\n62.5\n112.5\n1\n19.1\n\n\n\n\n\n\n\n\n\nRegression Analysis\nNext, we fit a regression model, representing the relationships between gender, age, height and the interaction variable created in the datastep above. We again use a where statement to restrict the analysis to those who are less than or equal to 19 years old. We use the clb option to get a 95% confidence interval for each of the parameters in the model. The model that we are fitting is height = b0 + b1 x female + b2 x age + b3 x fem_age + e\n\nX = htwt[['female', 'AGE', 'fem_age']][htwt['AGE'] &lt;= 19]\nX = sm.add_constant(X)\nY = htwt['HEIGHT'][htwt['AGE'] &lt;= 19]\n\nmodel = sm.OLS(Y, X).fit()\n\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nHEIGHT\nR-squared:\n0.460\n\n\nModel:\nOLS\nAdj. R-squared:\n0.452\n\n\nMethod:\nLeast Squares\nF-statistic:\n60.93\n\n\nDate:\nWed, 20 Aug 2025\nProb (F-statistic):\n1.50e-28\n\n\nTime:\n14:01:28\nLog-Likelihood:\n-534.17\n\n\nNo. Observations:\n219\nAIC:\n1076.\n\n\nDf Residuals:\n215\nBIC:\n1090.\n\n\nDf Model:\n3\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nconst\n28.8828\n2.873\n10.052\n0.000\n23.219\n34.547\n\n\nfemale\n13.6123\n4.019\n3.387\n0.001\n5.690\n21.534\n\n\nAGE\n2.0313\n0.178\n11.435\n0.000\n1.681\n2.381\n\n\nfem_age\n-0.9294\n0.248\n-3.750\n0.000\n-1.418\n-0.441\n\n\n\n\n\n\n\n\nOmnibus:\n1.300\nDurbin-Watson:\n2.284\n\n\nProb(Omnibus):\n0.522\nJarque-Bera (JB):\n0.981\n\n\nSkew:\n-0.133\nProb(JB):\n0.612\n\n\nKurtosis:\n3.191\nCond. No.\n450.\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nFrom the coefficients table b0,b1,b2,b3 are estimated as b0=28.88 b1=13.61 b2=2.03 b3=-0.92942\nThe resulting regression model for height, age and gender based on the available data is height=28.8828 + 13.6123 x female + 2.0313 x age -0.9294 x fem_age"
  },
  {
    "objectID": "python/ancova.html",
    "href": "python/ancova.html",
    "title": "Ancova",
    "section": "",
    "text": "In this example, we’re looking at Analysis of Covariance. ANCOVA is typically used to analyse treatment differences, to see examples of prediction models go to the simple linear regression page."
  },
  {
    "objectID": "python/ancova.html#introduction",
    "href": "python/ancova.html#introduction",
    "title": "Ancova",
    "section": "",
    "text": "In this example, we’re looking at Analysis of Covariance. ANCOVA is typically used to analyse treatment differences, to see examples of prediction models go to the simple linear regression page."
  },
  {
    "objectID": "python/ancova.html#data-summary",
    "href": "python/ancova.html#data-summary",
    "title": "Ancova",
    "section": "Data Summary",
    "text": "Data Summary\n\nimport pandas as pd\n\n# Input data\ndata = {\n    'drug': [\"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\",\n             \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\",\n             \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\"],\n    'pre': [11, 8, 5, 14, 19, 6, 10, 6, 11, 3,\n            6, 6, 7, 8, 18, 8, 19, 8, 5, 15,\n            16, 13, 11, 9, 21, 16, 12, 12, 7, 12],\n    'post': [6, 0, 2, 8, 11, 4, 13, 1, 8, 0,\n             0, 2, 3, 1, 18, 4, 14, 9, 1, 9,\n             13, 10, 18, 5, 23, 12, 5, 16, 1, 20]\n}\n\ndf = pd.DataFrame(data)\n\n\n# Descriptive statistics\nsummary_stats = df.describe()\n\n# Calculate median\nmedian_pre = df['pre'].median()\nmedian_post = df['post'].median()\n\n# Add median to the summary statistics\nsummary_stats.loc['median'] = [median_pre, median_post]\n\nprint(summary_stats)\n\n              pre       post\ncount   30.000000  30.000000\nmean    10.733333   7.900000\nstd      4.791755   6.666178\nmin      3.000000   0.000000\n25%      7.000000   2.000000\n50%     10.500000   7.000000\n75%     13.750000  12.750000\nmax     21.000000  23.000000\nmedian  10.500000   7.000000"
  },
  {
    "objectID": "python/ancova.html#ancova-in-python",
    "href": "python/ancova.html#ancova-in-python",
    "title": "Ancova",
    "section": "Ancova in Python",
    "text": "Ancova in Python\nIn Python, Ancova can be performed using the statsmodels library from the scipy package.\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom tabulate import tabulate\n\n# Fit the ANCOVA model\nmodel_ancova = smf.ols('post ~ drug + pre', data=df).fit()\n\n# Summary of the model\nmodel_summary = model_ancova.summary()\nprint(model_summary)\n\n# Extracting glance (summary) information\nmodel_glance = {\n    'r_squared': model_ancova.rsquared,\n    'adj_r_squared': model_ancova.rsquared_adj,\n    'f_statistic': model_ancova.fvalue,\n    'f_pvalue': model_ancova.f_pvalue,\n    'aic': model_ancova.aic,\n    'bic': model_ancova.bic\n}\nmodel_glance_df = pd.DataFrame([model_glance])\nprint(tabulate(model_glance_df, headers='keys', tablefmt='grid'))\n\n# Extracting tidy (coefficients) information\nmodel_tidy = model_ancova.summary2().tables[1]\nprint(tabulate(model_tidy, headers='keys', tablefmt='grid'))\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   post   R-squared:                       0.676\nModel:                            OLS   Adj. R-squared:                  0.639\nMethod:                 Least Squares   F-statistic:                     18.10\nDate:                Wed, 20 Aug 2025   Prob (F-statistic):           1.50e-06\nTime:                        14:01:49   Log-Likelihood:                -82.054\nNo. Observations:                  30   AIC:                             172.1\nDf Residuals:                      26   BIC:                             177.7\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -3.8808      1.986     -1.954      0.062      -7.964       0.202\ndrug[T.D]      0.1090      1.795      0.061      0.952      -3.581       3.799\ndrug[T.F]      3.4461      1.887      1.826      0.079      -0.432       7.324\npre            0.9872      0.164      6.001      0.000       0.649       1.325\n==============================================================================\nOmnibus:                        2.609   Durbin-Watson:                   2.526\nProb(Omnibus):                  0.271   Jarque-Bera (JB):                2.148\nSkew:                           0.645   Prob(JB):                        0.342\nKurtosis:                       2.765   Cond. No.                         39.8\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n+----+-------------+-----------------+---------------+-------------+---------+---------+\n|    |   r_squared |   adj_r_squared |   f_statistic |    f_pvalue |     aic |     bic |\n+====+=============+=================+===============+=============+=========+=========+\n|  0 |    0.676261 |        0.638906 |       18.1039 | 1.50137e-06 | 172.108 | 177.712 |\n+----+-------------+-----------------+---------------+-------------+---------+---------+\n+-----------+-----------+------------+------------+-------------+-----------+----------+\n|           |     Coef. |   Std.Err. |          t |       P&gt;|t| |    [0.025 |   0.975] |\n+===========+===========+============+============+=============+===========+==========+\n| Intercept | -3.88081  |   1.9862   | -1.95388   | 0.0615519   | -7.96351  | 0.201887 |\n+-----------+-----------+------------+------------+-------------+-----------+----------+\n| drug[T.D] |  0.108971 |   1.79514  |  0.0607037 | 0.952059    | -3.58098  | 3.79892  |\n+-----------+-----------+------------+------------+-------------+-----------+----------+\n| drug[T.F] |  3.44614  |   1.88678  |  1.82646   | 0.0792846   | -0.432195 | 7.32447  |\n+-----------+-----------+------------+------------+-------------+-----------+----------+\n| pre       |  0.987184 |   0.164498 |  6.00121   | 2.45433e-06 |  0.649054 | 1.32531  |\n+-----------+-----------+------------+------------+-------------+-----------+----------+\n\n\nPlease note that all values match with the corresponding R version, except for the AIC and BIC values, which differ slightly. This should be acceptable for most practical purposes in statistical analysis. Currently, there are ongoing discussions in the statsmodels community regarding the computational details of AIC and BIC.\nThe following code can be used to enforce complete consistency of AIC and BIC values with R outputs by adding 1 to the number of parameters:\n\nimport numpy as np\n\n# Manual calculation of AIC and BIC to ensure consistency with R\nn = df.shape[0]  # number of observations\nk = model_ancova.df_model + 1  # number of parameters (including intercept)\nlog_lik = model_ancova.llf  # log-likelihood\n\n# Adjusted number of parameters (including scale parameter)\nk_adjusted = k + 1\n\n# Manually calculate AIC and BIC to match R's behavior\naic_adjusted = 2 * k_adjusted - 2 * log_lik\nbic_adjusted = np.log(n) * k_adjusted - 2 * log_lik\n\nprint(f\"Number of observations (n): {n}\")\nprint(f\"Number of parameters (k_adjusted): {k_adjusted}\")\nprint(f\"Log-likelihood: {log_lik}\")\nprint(f\"AIC (adjusted): {aic_adjusted}\")\nprint(f\"BIC (adjusted): {bic_adjusted}\")\n\nNumber of observations (n): 30\nNumber of parameters (k_adjusted): 5.0\nLog-likelihood: -82.0537744890265\nAIC (adjusted): 174.107548978053\nBIC (adjusted): 181.11353588636376\n\n\nThere are different types of anova computations. The statsmodels.stats.anova.anova_lm function allows the types 1, 2 and 3. The code to compute these types is depicted below:\n\nimport statsmodels.formula.api as smf\nimport statsmodels.stats.anova as ssa\n\n# Center the predictor for Type III anova\n#df['pre_centered'] = df['pre'] - df['pre'].mean()\n\n# Fit the model for types I and II anova\nmodel = smf.ols('post ~ C(drug) + pre', data=df).fit()\n\n# Perform anova for types I and II\nancova_table_type_1 = ssa.anova_lm(model, typ=1)\nancova_table_type_2 = ssa.anova_lm(model, typ=2)\n\n# Fit the model for Type III anova with centered predictors\nmodel_type_3 = smf.ols('post ~ C(drug) + pre', data=df).fit()\nancova_table_type_3 = ssa.anova_lm(model_type_3, typ=3)\n\n# Calculate SSd (sum of squares for residuals)\nssd_type1 = ancova_table_type_1['sum_sq'].loc['Residual']\nssd_type2 = ancova_table_type_2['sum_sq'].loc['Residual']\nssd_type3 = ancova_table_type_3['sum_sq'].loc['Residual']\n\n# Calculate ges\nancova_table_type_1['ges'] = ancova_table_type_1['sum_sq'] / (ancova_table_type_1['sum_sq'] + ssd_type1)\nancova_table_type_2['ges'] = ancova_table_type_2['sum_sq'] / (ancova_table_type_2['sum_sq'] + ssd_type2)\nancova_table_type_3['ges'] = ancova_table_type_3['sum_sq'] / (ancova_table_type_3['sum_sq'] + ssd_type3)\n\n# Add SSd column\nancova_table_type_1['SSd'] = ssd_type1\nancova_table_type_2['SSd'] = ssd_type2\nancova_table_type_3['SSd'] = ssd_type3\n\n# Add significance column\nancova_table_type_1['p&lt;0.05'] = ancova_table_type_1['PR(&gt;F)'] &lt; 0.05\nancova_table_type_2['p&lt;0.05'] = ancova_table_type_2['PR(&gt;F)'] &lt; 0.05\nancova_table_type_3['p&lt;0.05'] = ancova_table_type_3['PR(&gt;F)'] &lt; 0.05\n\n# Rename columns to match the R output\nancova_table_type_1.rename(columns={'sum_sq': 'SSn', 'df': 'DFn', 'F': 'F', 'PR(&gt;F)': 'p'}, inplace=True)\nancova_table_type_1.reset_index(inplace=True)\nancova_table_type_1.rename(columns={'index': 'Effect'}, inplace=True)\n\nancova_table_type_2.rename(columns={'sum_sq': 'SSn', 'df': 'DFn', 'F': 'F', 'PR(&gt;F)': 'p'}, inplace=True)\nancova_table_type_2.reset_index(inplace=True)\nancova_table_type_2.rename(columns={'index': 'Effect'}, inplace=True)\n\nancova_table_type_3.rename(columns={'sum_sq': 'SSn', 'df': 'DFn', 'F': 'F', 'PR(&gt;F)': 'p'}, inplace=True)\nancova_table_type_3.reset_index(inplace=True)\nancova_table_type_3.rename(columns={'index': 'Effect'}, inplace=True)\n\n# Calculate DFd (degrees of freedom for residuals)\ndfd_type1 = ancova_table_type_1.loc[ancova_table_type_1['Effect'] == 'Residual', 'DFn'].values[0]\ndfd_type2 = ancova_table_type_2.loc[ancova_table_type_2['Effect'] == 'Residual', 'DFn'].values[0]\ndfd_type3 = ancova_table_type_3.loc[ancova_table_type_3['Effect'] == 'Residual', 'DFn'].values[0]\nancova_table_type_1['DFd'] = dfd_type1\nancova_table_type_2['DFd'] = dfd_type2\nancova_table_type_3['DFd'] = dfd_type3\n\n# Filter out the Residual row\nancova_table_type_1 = ancova_table_type_1[ancova_table_type_1['Effect'] != 'Residual']\nancova_table_type_2 = ancova_table_type_2[ancova_table_type_2['Effect'] != 'Residual']\nancova_table_type_3 = ancova_table_type_3[ancova_table_type_3['Effect'] != 'Residual']\n\n# Select and reorder columns to match the R output\nancova_table_type_1 = ancova_table_type_1[['Effect', 'DFn', 'DFd', 'SSn', 'SSd', 'F', 'p', 'p&lt;0.05', 'ges']]\nancova_table_type_2 = ancova_table_type_2[['Effect', 'DFn', 'DFd', 'SSn', 'SSd', 'F', 'p', 'p&lt;0.05', 'ges']]\nancova_table_type_3 = ancova_table_type_3[['Effect', 'DFn', 'DFd', 'SSn', 'SSd', 'F', 'p', 'p&lt;0.05', 'ges']]"
  },
  {
    "objectID": "python/ancova.html#type-1-ancova-in-python",
    "href": "python/ancova.html#type-1-ancova-in-python",
    "title": "Ancova",
    "section": "Type 1 Ancova in Python",
    "text": "Type 1 Ancova in Python\n\nprint(tabulate(ancova_table_type_1, headers='keys', tablefmt='grid'))\n\n+----+----------+-------+-------+---------+---------+----------+-------------+----------+----------+\n|    | Effect   |   DFn |   DFd |     SSn |     SSd |        F |           p | p&lt;0.05   |      ges |\n+====+==========+=======+=======+=========+=========+==========+=============+==========+==========+\n|  0 | C(drug)  |     2 |    26 | 293.6   | 417.203 |  9.14855 | 0.000981237 | True     | 0.413054 |\n+----+----------+-------+-------+---------+---------+----------+-------------+----------+----------+\n|  1 | pre      |     1 |    26 | 577.897 | 417.203 | 36.0145  | 2.45433e-06 | True     | 0.580743 |\n+----+----------+-------+-------+---------+---------+----------+-------------+----------+----------+"
  },
  {
    "objectID": "python/ancova.html#type-2-ancova-in-python",
    "href": "python/ancova.html#type-2-ancova-in-python",
    "title": "Ancova",
    "section": "Type 2 Ancova in Python",
    "text": "Type 2 Ancova in Python\n\nprint(tabulate(ancova_table_type_2, headers='keys', tablefmt='grid'))\n\n+----+----------+-------+-------+----------+---------+----------+-------------+----------+----------+\n|    | Effect   |   DFn |   DFd |      SSn |     SSd |        F |           p | p&lt;0.05   |      ges |\n+====+==========+=======+=======+==========+=========+==========+=============+==========+==========+\n|  0 | C(drug)  |     2 |    26 |  68.5537 | 417.203 |  2.13613 | 0.138379    | False    | 0.141128 |\n+----+----------+-------+-------+----------+---------+----------+-------------+----------+----------+\n|  1 | pre      |     1 |    26 | 577.897  | 417.203 | 36.0145  | 2.45433e-06 | True     | 0.580743 |\n+----+----------+-------+-------+----------+---------+----------+-------------+----------+----------+"
  },
  {
    "objectID": "python/ancova.html#type-3-ancova-in-python",
    "href": "python/ancova.html#type-3-ancova-in-python",
    "title": "Ancova",
    "section": "Type 3 Ancova in Python",
    "text": "Type 3 Ancova in Python\n\nprint(tabulate(ancova_table_type_3, headers='keys', tablefmt='grid'))\n\n+----+-----------+-------+-------+----------+---------+----------+-------------+----------+----------+\n|    | Effect    |   DFn |   DFd |      SSn |     SSd |        F |           p | p&lt;0.05   |      ges |\n+====+===========+=======+=======+==========+=========+==========+=============+==========+==========+\n|  0 | Intercept |     1 |    26 |  61.2592 | 417.203 |  3.81767 | 0.0615519   | False    | 0.128034 |\n+----+-----------+-------+-------+----------+---------+----------+-------------+----------+----------+\n|  1 | C(drug)   |     2 |    26 |  68.5537 | 417.203 |  2.13613 | 0.138379    | False    | 0.141128 |\n+----+-----------+-------+-------+----------+---------+----------+-------------+----------+----------+\n|  2 | pre       |     1 |    26 | 577.897  | 417.203 | 36.0145  | 2.45433e-06 | True     | 0.580743 |\n+----+-----------+-------+-------+----------+---------+----------+-------------+----------+----------+\n\n\nPlease note that the results are consistent with the results achieved with R, except for the first row of the type 3 table featuring the intercept."
  },
  {
    "objectID": "python/Rounding.html",
    "href": "python/Rounding.html",
    "title": "Rounding in Python",
    "section": "",
    "text": "Python has a built-in round() function that takes two numeric arguments, number and ndigits, and returns a floating point number that is a rounded version of the number up to the specified number of decimals.\nThe default number of decimal is 0, meaning that the function will return the nearest integer.\nThe round() function in Python will round to the nearest whole number and ‘rounding to the even number’ when equidistant, meaning that exactly 12.5 rounds to the integer 12.\n\n# For integers\nx= 12\nprint(round(x))\n \n# For floating point\nx= 12.3\nprint(round(22.7))  \n \n# if the second parameter is present\n \n# when the (ndigit+1)th digit is =5 \nx=4.465\nprint(round(x, 2)) \n   \n# when the (ndigit+1)th digit is &gt;=5 \nx=4.476\nprint(round(x, 2))   \n   \n# when the (ndigit+1)th digit is &lt;5 \nx=4.473\nprint(round(x, 2))\n\n12\n23\n4.46\n4.48\n4.47"
  },
  {
    "objectID": "python/chi-square.html",
    "href": "python/chi-square.html",
    "title": "Chi-Square Association/Fisher’s exact",
    "section": "",
    "text": "The chi-square test is a non-parametric statistical test used to determine whether there is a significant association within the categorical variables. It compares the observed frequencies in a contingency table with the frequency we would expect if the variables were independent. The chi-square test calculates a test statistic, often denoted as χ² (chi-square), which follows chi-square distribution, we can determine whether the association between the variables are statistically significant.\nThe chi-squared test and Fisher’s exact test can assess for independence between two variables when the comparing groups are independent and not correlated. The chi-squared test applies an approximation assuming the sample is large, while the Fisher’s exact test runs an exact procedure especially for small-sized samples."
  },
  {
    "objectID": "python/chi-square.html#introduction",
    "href": "python/chi-square.html#introduction",
    "title": "Chi-Square Association/Fisher’s exact",
    "section": "",
    "text": "The chi-square test is a non-parametric statistical test used to determine whether there is a significant association within the categorical variables. It compares the observed frequencies in a contingency table with the frequency we would expect if the variables were independent. The chi-square test calculates a test statistic, often denoted as χ² (chi-square), which follows chi-square distribution, we can determine whether the association between the variables are statistically significant.\nThe chi-squared test and Fisher’s exact test can assess for independence between two variables when the comparing groups are independent and not correlated. The chi-squared test applies an approximation assuming the sample is large, while the Fisher’s exact test runs an exact procedure especially for small-sized samples."
  },
  {
    "objectID": "python/chi-square.html#data-used",
    "href": "python/chi-square.html#data-used",
    "title": "Chi-Square Association/Fisher’s exact",
    "section": "Data used",
    "text": "Data used\nTo perform the analysis the data used is: Loprinzi CL. Laurie JA. Wieand HS. Krook JE. Novotny PJ. Kugler JW. Bartel J. Law M. Bateman M. Klatt NE. et al. Prospective evaluation of prognostic variables from patient-completed questionnaires. North Central Cancer Treatment Group. Journal of Clinical Oncology. 12(3):601-7, 1994."
  },
  {
    "objectID": "python/chi-square.html#implementing-chi-square-test-in-python",
    "href": "python/chi-square.html#implementing-chi-square-test-in-python",
    "title": "Chi-Square Association/Fisher’s exact",
    "section": "Implementing Chi-Square test in Python",
    "text": "Implementing Chi-Square test in Python\nWe can use crosstab() function to create contingency table of two selected variables.\n\nimport pandas as pd \nimport numpy as np\nimport scipy.stats as stats \n\n# Read the sample data\ndata = pd.read_csv(\"../data/lung_cancer.csv\") \n\n# Removing undesired rows\ndf= data.dropna(subset=['ph.ecog','wt.loss']) \n\n# Converting numerical variable into categorical variable\n\ndf['ecog_grp']= np.where(df['ph.ecog']&gt;0, \"fully active\",\"symptomatic\")\nprint(df['ecog_grp'])\ndf['wt_grp'] = np.where(df['wt.loss']&gt;0, \"weight loss\", \"weight gain\")\n\ncontingency_table= pd.crosstab(df['ecog_grp'],df['wt_grp'])\ncontingency_table\n\n1       symptomatic\n2       symptomatic\n3      fully active\n4       symptomatic\n5      fully active\n           ...     \n223    fully active\n224     symptomatic\n225    fully active\n226    fully active\n227    fully active\nName: ecog_grp, Length: 213, dtype: object\n\n\n/var/folders/wv/j23_bm7d0mn77bx35v5mgl_00000gn/T/ipykernel_56901/2909872460.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['ecog_grp']= np.where(df['ph.ecog']&gt;0, \"fully active\",\"symptomatic\")\n/var/folders/wv/j23_bm7d0mn77bx35v5mgl_00000gn/T/ipykernel_56901/2909872460.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['wt_grp'] = np.where(df['wt.loss']&gt;0, \"weight loss\", \"weight gain\")\n\n\n\n\n\n\n\n\nwt_grp\nweight gain\nweight loss\n\n\necog_grp\n\n\n\n\n\n\nfully active\n39\n113\n\n\nsymptomatic\n22\n39\n\n\n\n\n\n\n\nFurthermore, the chi2_contingency() function in scipy.stats library in Python can be used to implement Chi-square test.\n\n# Parsing the values from the contingency table\nvalue = np.array([contingency_table.iloc[0][0:5].values,\n                  contingency_table.iloc[1][0:5].values])\n\nstatistic, p, dof, expected = stats.chi2_contingency(value)\n\nprint(\"The chi2 value is:\", statistic)\nprint(\"The p value is:\", p)\nprint(\"The degree of freedom is:\", dof)\nprint(\"The expected values are:\", expected)\n\nThe chi2 value is: 1.8260529076055192\nThe p value is: 0.17659446865934617\nThe degree of freedom is: 1\nThe expected values are: [[ 43.53051643 108.46948357]\n [ 17.46948357  43.53051643]]"
  },
  {
    "objectID": "python/chi-square.html#implementing-fisher-exact-test-in-python",
    "href": "python/chi-square.html#implementing-fisher-exact-test-in-python",
    "title": "Chi-Square Association/Fisher’s exact",
    "section": "Implementing Fisher exact test in Python",
    "text": "Implementing Fisher exact test in Python\nTo implement Fischer’s exact test in Python, we can use the fischer_exact() function from the stats module in SciPy library. It returns SignificanceResult object with statistic and pvalue as it’s attributes.\n\nstats.fisher_exact(value, alternative=\"two-sided\")\n\nSignificanceResult(statistic=np.float64(0.6118262268704746), pvalue=np.float64(0.13500579984749855))"
  },
  {
    "objectID": "python/kruskal_wallis.html",
    "href": "python/kruskal_wallis.html",
    "title": "Kruskal Wallis in Python",
    "section": "",
    "text": "The Kruskal-Wallis test is a non-parametric equivalent to the one-way ANOVA. For this example, the data used is a subset of the iris dataset, testing for difference in sepal width between species of flower.\n\nimport pandas as pd\n\n# Define the data\ndata = {\n    'Species': ['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica'],\n    'Sepal_Width': [3.4, 3.0, 3.4, 3.2, 3.5, 3.1, 2.7, 2.9, 2.7, 2.6, 2.5, 2.5, 3.0, 3.0, 3.1, 3.8, 2.7, 3.3]\n}\n\n# Create the DataFrame\niris_sub = pd.DataFrame(data)\n\n# Print the DataFrame\nprint(iris_sub)\n\n       Species  Sepal_Width\n0       setosa          3.4\n1       setosa          3.0\n2       setosa          3.4\n3       setosa          3.2\n4       setosa          3.5\n5       setosa          3.1\n6   versicolor          2.7\n7   versicolor          2.9\n8   versicolor          2.7\n9   versicolor          2.6\n10  versicolor          2.5\n11  versicolor          2.5\n12   virginica          3.0\n13   virginica          3.0\n14   virginica          3.1\n15   virginica          3.8\n16   virginica          2.7\n17   virginica          3.3"
  },
  {
    "objectID": "python/kruskal_wallis.html#introduction",
    "href": "python/kruskal_wallis.html#introduction",
    "title": "Kruskal Wallis in Python",
    "section": "",
    "text": "The Kruskal-Wallis test is a non-parametric equivalent to the one-way ANOVA. For this example, the data used is a subset of the iris dataset, testing for difference in sepal width between species of flower.\n\nimport pandas as pd\n\n# Define the data\ndata = {\n    'Species': ['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica'],\n    'Sepal_Width': [3.4, 3.0, 3.4, 3.2, 3.5, 3.1, 2.7, 2.9, 2.7, 2.6, 2.5, 2.5, 3.0, 3.0, 3.1, 3.8, 2.7, 3.3]\n}\n\n# Create the DataFrame\niris_sub = pd.DataFrame(data)\n\n# Print the DataFrame\nprint(iris_sub)\n\n       Species  Sepal_Width\n0       setosa          3.4\n1       setosa          3.0\n2       setosa          3.4\n3       setosa          3.2\n4       setosa          3.5\n5       setosa          3.1\n6   versicolor          2.7\n7   versicolor          2.9\n8   versicolor          2.7\n9   versicolor          2.6\n10  versicolor          2.5\n11  versicolor          2.5\n12   virginica          3.0\n13   virginica          3.0\n14   virginica          3.1\n15   virginica          3.8\n16   virginica          2.7\n17   virginica          3.3"
  },
  {
    "objectID": "python/kruskal_wallis.html#implementing-kruskal-wallis-in-python",
    "href": "python/kruskal_wallis.html#implementing-kruskal-wallis-in-python",
    "title": "Kruskal Wallis in Python",
    "section": "Implementing Kruskal-Wallis in Python",
    "text": "Implementing Kruskal-Wallis in Python\nThe Kruskal-Wallis test can be implemented in Python using the kruskal function from scipy.stats. The null hypothesis is that the samples are from identical populations.\n\nfrom scipy.stats import kruskal\n\n# Separate the data for each species\nsetosa_data = iris_sub[iris_sub['Species'] == 'setosa']['Sepal_Width']\nversicolor_data = iris_sub[iris_sub['Species'] == 'versicolor']['Sepal_Width']\nvirginica_data = iris_sub[iris_sub['Species'] == 'virginica']['Sepal_Width']\n\n# Perform the Kruskal-Wallis H-test\nh_statistic, p_value = kruskal(setosa_data, versicolor_data, virginica_data)\n\n# Calculate the degrees of freedom\nk = len(iris_sub['Species'].unique())\ndf = k - 1\n\nprint(\"H-statistic:\", h_statistic)\nprint(\"p-value:\", p_value)\nprint(\"Degrees of freedom:\", df)\n\nH-statistic: 10.922233820459285\np-value: 0.0042488075570347485\nDegrees of freedom: 2"
  },
  {
    "objectID": "python/kruskal_wallis.html#results",
    "href": "python/kruskal_wallis.html#results",
    "title": "Kruskal Wallis in Python",
    "section": "Results",
    "text": "Results\nAs seen above, Python outputs the Kruskal-Wallis rank sum statistic (10.922), the degrees of freedom (2), and the p-value of the test (0.004249). Therefore, the difference in population medians is statistically significant at the 5% level."
  },
  {
    "objectID": "python/Summary_statistics.html",
    "href": "python/Summary_statistics.html",
    "title": "Summary statistics",
    "section": "",
    "text": "The numpy.percentile() function is useful to determine the nth-percentile for the given array of data. It returns an array with percentile values or a scalar along the specified axis. The function accepts the following parameters:\n1.array: The array of data whose percentile needs to be calculated.\n2.percentile: Denotes the percentile that needs to be computed.\n3.axis (optional): Denotes the axis along which the percentile is calculated. By default, a flattened array is used.\n4.out (optional): An alternate output array where we can place the result.\n5.overwrite_input (optional): Used to modify the input array.\n6.keepdims (optional): Creates reduced axes with dimensions of one size.\n\nimport numpy as np\n\nsample_data=[12, 25, 16, 50, 34, 29, 60, 86, 52, 39, 41]\n\npercentile = np.percentile(sample_data,75)\n\nprint(percentile)\n\n51.0"
  },
  {
    "objectID": "python/one_sample_t_test.html",
    "href": "python/one_sample_t_test.html",
    "title": "One Sample t-test in Python",
    "section": "",
    "text": "The One Sample t-test is used to compare a single sample against an expected hypothesis value. In the One Sample t-test, the mean of the sample is compared against the hypothesis value. In Python, a One Sample t-test can be performed using the scipy.stats.ttest_1samp(…) function from the scipy package, which accepts the following parameters:\n1.a: Sample observations.\n2.popmean: Expected value in null hypothesis. If array_like, then its length along axis must equal 1, and it must otherwise be broadcastable with a.\n3.nan_policy: Defines how to handle input NaNs.\n4.alternative (optional): Defines the alternative hypothesis.\n5.keepdims: If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array."
  },
  {
    "objectID": "python/one_sample_t_test.html#data-used",
    "href": "python/one_sample_t_test.html#data-used",
    "title": "One Sample t-test in Python",
    "section": "Data Used",
    "text": "Data Used\n\nimport pandas as pd\n\n# Create sample data\ndata = {\n    'score': [40, 47, 52, 26, 19, 25, 35, 39, 26, 48, 14, 22, 42, 34, 33, 18, 15, 29, 41, 44, 51, 43, 27, 46, 28, 49, 31, 28, 54, 45],\n    'count': [2, 2, 2, 1, 2, 2, 4, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1]\n}\n\ndf = pd.DataFrame(data)\n\nThe following code was used to test the comparison in Python. Note that the baseline null hypothesis goes in the “popmean” parameter.\n\nimport pandas as pd\nfrom scipy import stats\n\n# Perform one-sample t-test\nsample_mean = df['score'].mean()\nnull_mean = 30  # Hypothetical null hypothesis mean for comparison\nalpha = 0.05  # Significance level\n\nt_statistic, p_value = stats.ttest_1samp(df['score'], null_mean)\n\nprint(f\"t: {t_statistic}\")\nprint(f\"p-value: {p_value}\")\nprint(f\"mean of x: {sample_mean}\")\n\nif p_value &lt; alpha:\n    print(\"Reject null hypothesis: There is a significant difference.\")\nelse:\n    print(\"Fail to reject null hypothesis: There is no significant difference.\")\n\nt: 2.364306444879101\np-value: 0.02497410401836272\nmean of x: 35.03333333333333\nReject null hypothesis: There is a significant difference."
  },
  {
    "objectID": "python/MANOVA.html",
    "href": "python/MANOVA.html",
    "title": "MANOVA",
    "section": "",
    "text": "MANOVA in Python\nMultivariate analysis of variance (MANOVA) is a statistical technique used to examine group mean difference of several dependent variables at once while accounting for correlations between the variables.By considering multiple dependent variables simultaneously, MANOVA provides a more comprehensive understanding of group differences and patterns. In context of python, statsmodels library can be used to implement MANOVA.\nThe from_formula() function is the recommended method to specify a model and simplifies testing without needing to manually configure the contrast matrices.\nExample 39.6 Multivariate Analysis of Variance from SAS MANOVA User Guide\nThis example employs multivariate analysis of variance (MANOVA) to measure differences in the chemical characteristics of ancient pottery found at four kiln sites in Great Britain. The data are from Tubb, Parker, and Nickless (1980), as reported in Hand et al. (1994).\nFor each of 26 samples of pottery, the percentages of oxides of five metals are measured. The following statements create the data set and invoke the GLM procedure to perform a one-way MANOVA. Additionally, it is of interest to know whether the pottery from one site in Wales (Llanederyn) differs from the samples from other sites; a CONTRAST statement is used to test this hypothesis.\n\nimport pandas as pd\nfrom statsmodels.multivariate.manova import MANOVA\n\ndf= pd.read_csv(\"../data/manova1.csv\")\ndf.rename(columns={'al':'Al','fe':'Fe','mg':'Mg','ca ':'Ca','na':'Na'},inplace=True)\n\nmanova = MANOVA.from_formula('Al + Fe + Mg + Ca + Na ~ site', data=df)\nresult = manova.mv_test()\nprint(result)\n\n                   Multivariate linear model\n===============================================================\n                                                               \n---------------------------------------------------------------\n        Intercept         Value  Num DF  Den DF F Value  Pr &gt; F\n---------------------------------------------------------------\n           Wilks' lambda  0.0300 5.0000 18.0000 116.5838 0.0000\n          Pillai's trace  0.9700 5.0000 18.0000 116.5838 0.0000\n  Hotelling-Lawley trace 32.3844 5.0000 18.0000 116.5838 0.0000\n     Roy's greatest root 32.3844 5.0000 18.0000 116.5838 0.0000\n---------------------------------------------------------------\n                                                               \n---------------------------------------------------------------\n          site           Value   Num DF  Den DF F Value  Pr &gt; F\n---------------------------------------------------------------\n          Wilks' lambda  0.0123 15.0000 50.0915  13.0885 0.0000\n         Pillai's trace  1.5539 15.0000 60.0000   4.2984 0.0000\n Hotelling-Lawley trace 35.4388 15.0000 29.1304  40.5880 0.0000\n    Roy's greatest root 34.1611  5.0000 20.0000 136.6445 0.0000\n===============================================================\n\n\n\nThe Wilki’s lambda test evaluates the significance of group difference across several dependent variables. A lower Wilk’s Lambda value suggest more evidence of group difference.\nThe Pillai’s Trace test statistics is statistically significant [Pillai’s Trace = 1.55, F(6, 72) = 4.29, p &lt; 0.001] and indicates that sites has a statistically significant association with all the listed elements.\nNOTE: if you feel you can help with the above discrepancy please contribute to the CAMIS repo by following the instructions on the contributions page."
  },
  {
    "objectID": "python/survey-stats-summary.html",
    "href": "python/survey-stats-summary.html",
    "title": "Survey Summary Statistics using Python",
    "section": "",
    "text": "When conducting large-scale trials on samples of the population, it can be necessary to use a more complex sampling design than a simple random sample.\nAll of these designs need to be taken into account when calculating statistics, and when producing models. Only summary statistics are discussed in this document, and variances are calculated using Taylor series linearisation methods. For a more detailed introduction to calculating survey statistics using statistical software, see (Lohr 2022).\nThe ecosystem of survey statistics packages is less mature in Python than in R or SAS, however there is a package that provides a subset of the functionality: samplics."
  },
  {
    "objectID": "python/survey-stats-summary.html#mean",
    "href": "python/survey-stats-summary.html#mean",
    "title": "Survey Summary Statistics using Python",
    "section": "Mean",
    "text": "Mean\nIf we want to calculate a mean of a variable in a dataset using samplics, we need to create an estimator object using the estimation method we will use - here Taylor Series estimation - and the parameter we are estimating. Then, we can specify the survey design by passing columns which define our strata and PSUs, and a column to estimate:\n\nimport numpy as np\nimport pandas as pd\n\nfrom samplics import TaylorEstimator\nfrom samplics.utils.types import PopParam\n\nnhanes = pd.read_csv(\"../data/nhanes.csv\")\n\nmean_estimator = TaylorEstimator(PopParam.mean)\n\nmean_estimator.estimate(\n    y=nhanes[\"HI_CHOL\"],\n    samp_weight=nhanes[\"WTMEC2YR\"],\n    psu=nhanes[\"SDMVPSU\"],\n    stratum=nhanes[\"SDMVSTRA\"],\n    remove_nan=True,\n)\nprint(mean_estimator.to_dataframe())\n\n          _param  _estimate  _stderror      _lci      _uci       _cv\n0  PopParam.mean   0.112143   0.005446  0.100598  0.123688  0.048562"
  },
  {
    "objectID": "python/survey-stats-summary.html#total",
    "href": "python/survey-stats-summary.html#total",
    "title": "Survey Summary Statistics using Python",
    "section": "Total",
    "text": "Total\nCalculating population totals can be done by changing the TaylorEstimator parameter to PopParam.total:\n\ntotal_estimator = TaylorEstimator(PopParam.total)\n\ntotal_estimator.estimate(\n    y=nhanes[\"HI_CHOL\"],\n    samp_weight=nhanes[\"WTMEC2YR\"],\n    psu=nhanes[\"SDMVPSU\"],\n    stratum=nhanes[\"SDMVSTRA\"],\n    remove_nan=True,\n)\nprint(total_estimator.to_dataframe())\n\n           _param     _estimate  ...          _uci       _cv\n0  PopParam.total  2.863525e+07  ...  3.291896e+07  0.070567\n\n[1 rows x 6 columns]"
  },
  {
    "objectID": "python/survey-stats-summary.html#ratios",
    "href": "python/survey-stats-summary.html#ratios",
    "title": "Survey Summary Statistics using Python",
    "section": "Ratios",
    "text": "Ratios\nCalculating population ratios can be done by changing the TaylorEstimator parameter to PopParam.ratio, and additionally specifying an x parameter in the estimate method:\n\nratio_estimator = TaylorEstimator(PopParam.ratio)\n\nratio_estimator.estimate(\n    y=nhanes[\"HI_CHOL\"],\n    x=nhanes[\"RIAGENDR\"],\n    samp_weight=nhanes[\"WTMEC2YR\"],\n    psu=nhanes[\"SDMVPSU\"],\n    stratum=nhanes[\"SDMVSTRA\"],\n    remove_nan=True,\n)\nprint(ratio_estimator.to_dataframe())\n\n           _param  _estimate  _stderror      _lci      _uci       _cv\n0  PopParam.ratio   0.074222   0.003715  0.066347  0.082097  0.050049"
  },
  {
    "objectID": "python/survey-stats-summary.html#proportions",
    "href": "python/survey-stats-summary.html#proportions",
    "title": "Survey Summary Statistics using Python",
    "section": "Proportions",
    "text": "Proportions\nCalculating proportions can be done by changing the TaylorEstimator parameter to PopParam.prop:\n\nprop_estimator = TaylorEstimator(PopParam.prop)\n\nprop_estimator.estimate(\n    y=nhanes[\"agecat\"],\n    samp_weight=nhanes[\"WTMEC2YR\"],\n    psu=nhanes[\"SDMVPSU\"],\n    stratum=nhanes[\"SDMVSTRA\"],\n    remove_nan=True,\n)\nprop_estimator.to_dataframe()\n\n          _param    _level  _estimate  _stderror      _lci      _uci       _cv\n0  PopParam.prop    (0,19]   0.207749   0.006130  0.195054  0.221044  0.029506\n1  PopParam.prop   (19,39]   0.293408   0.009561  0.273557  0.314077  0.032585\n2  PopParam.prop   (39,59]   0.303290   0.004519  0.293795  0.312955  0.014901\n3  PopParam.prop  (59,Inf]   0.195553   0.008093  0.178965  0.213280  0.041383"
  },
  {
    "objectID": "python/survey-stats-summary.html#quantiles",
    "href": "python/survey-stats-summary.html#quantiles",
    "title": "Survey Summary Statistics using Python",
    "section": "Quantiles",
    "text": "Quantiles\nsamplics currently does not have a method to calculate quantiles."
  },
  {
    "objectID": "python/survey-stats-summary.html#domain-estimations",
    "href": "python/survey-stats-summary.html#domain-estimations",
    "title": "Survey Summary Statistics using Python",
    "section": "Domain Estimations",
    "text": "Domain Estimations\nWe can perform domain estimations of different sub-populations by passing our domain column as a parameter to the estimate method:\n\nmean_estimator = TaylorEstimator(PopParam.mean)\n\nmean_estimator.estimate(\n    y=nhanes[\"HI_CHOL\"],\n    samp_weight=nhanes[\"WTMEC2YR\"],\n    psu=nhanes[\"SDMVPSU\"],\n    stratum=nhanes[\"SDMVSTRA\"],\n    domain=nhanes[\"race\"],\n    remove_nan=True,\n)\nmean_estimator.to_dataframe()\n\n          _param  _domain  _estimate  _stderror      _lci      _uci       _cv\n0  PopParam.mean        1   0.101492   0.006246  0.088251  0.114732  0.061540\n1  PopParam.mean        2   0.121649   0.006604  0.107649  0.135649  0.054288\n2  PopParam.mean        3   0.078640   0.010385  0.056626  0.100655  0.132053\n3  PopParam.mean        4   0.099679   0.024666  0.047389  0.151969  0.247458\n\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       Ubuntu 24.04.3 LTS\n system   x86_64, linux-gnu\n ui       X11\n language (EN)\n collate  C.UTF-8\n ctype    C.UTF-8\n tz       UTC\n date     2025-10-17\n pandoc   3.6.3 @ /opt/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package * version date (UTC) lib source\n P survey  * 4.4-2   2024-03-20 [?] RSPM (R 4.4.0)\n\n [1] /home/runner/work/CAMIS/CAMIS/renv/library/linux-ubuntu-noble/R-4.4/x86_64-pc-linux-gnu\n [2] /opt/R/4.4.2/lib/R/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n─ Python configuration ────────────────────────────────────────────────────────\n Python    3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0]\n samplics  0.4.22"
  },
  {
    "objectID": "python/two_samples_t_test.html",
    "href": "python/two_samples_t_test.html",
    "title": "Two Sample t-test in Python",
    "section": "",
    "text": "The Two Sample t-test is used to compare two independent samples against each other. In the Two Sample t-test, the mean of the first sample is compared against the mean of the second sample. In Python, a Two Sample t-test can be performed using the stats package from scipy.\n\nData Used\nThe following data was used in this example.\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\n\n# Create sample data\ndata = {\n    'trt_grp': ['placebo', 'placebo', 'placebo', 'placebo', 'placebo', 'placebo', 'placebo', 'placebo', 'placebo', 'placebo', 'placebo', 'placebo', 'placebo', 'placebo', 'placebo', 'placebo', 'treatment', 'treatment', 'treatment', 'treatment', 'treatment', 'treatment', 'treatment', 'treatment', 'treatment', 'treatment', 'treatment', 'treatment', 'treatment', 'treatment', 'treatment', 'treatment'],\n    'WtGain': [94, 12, 26, 89, 88, 96, 85, 130, 75, 54, 112, 69, 104, 95, 53, 21, 45, 62, 96, 128, 120, 99, 28, 50, 109, 115, 39, 96, 87, 100, 76, 80]\n}\n\ndf = pd.DataFrame(data)\n\nIf we have normalized data, we can use the classic Student’s t-test. For a Two sample test where the variances are not equal, we should use the Welch’s t-test. Both of those options are available in the scipy stats package.\n\n\nStudent’s T-Test\n\nCode\nThe following code was used to test the comparison in Python. Note that we must separate the single variable into two variables to satisfy the scipy stats package syntax.\n\n# Separate data into two groups\ngroup1 = df[df['trt_grp'] == 'placebo']['WtGain']\ngroup2 = df[df['trt_grp'] == 'treatment']['WtGain']\n\n# Perform Student's t-test assuming equal variances\nt_stat, p_value_equal_var = stats.ttest_ind(group1, group2, equal_var=True)\n\nprint(\"Student's T-Test assuming equal variances:\")\nprint(f\"T-statistic: {t_stat}\")\nprint(f\"P-value: {p_value_equal_var}\")\n\nStudent's T-Test assuming equal variances:\nT-statistic: -0.6969002027708538\nP-value: 0.4912306166204561\n\n\n\n\n\nWelch’s T-Test\n\nCode\nThe following code was used to test the comparison in Python using Welch’s t-test.\n\n# Perform Welch's t-test assuming unequal variances\nt_stat_welch, p_value_unequal_var = stats.ttest_ind(group1, group2, equal_var=False)\n\nprint(\"\\nWelch's T-Test assuming unequal variances:\")\nprint(f\"T-statistic: {t_stat_welch}\")\nprint(f\"P-value: {p_value_unequal_var}\")\n\n\nWelch's T-Test assuming unequal variances:\nT-statistic: -0.6969002027708538\nP-value: 0.4912856152047901"
  },
  {
    "objectID": "python/paired_t_test.html",
    "href": "python/paired_t_test.html",
    "title": "Paired t-test",
    "section": "",
    "text": "Paired t-tests are used to test the difference of means for two dependant variables. In the Paired t-test, the difference of the means between the two samples is compared to a given number that represents the null hypothesis. For a Paired t-test, the number of observations in each sample must be equal.\nIn Python, a Paired t-test can be performed using the scipy.stats.ttest_rel(…) function from the scipy package, which accepts the following parameters:\n1.a, b: Sample observations. The arrays must have the same shape.\n2.axis: If an int, the axis of the input along which to compute the statistic. The statistic of each axis-slice (e.g. row) of the input will appear in a corresponding element of the output. If None, the input will be raveled before computing the statistic.\n3.nan_policy: Defines how to handle input NaNs.\n4.alternative (optional): Defines the alternative hypothesis.\n5.keepdims: If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array."
  },
  {
    "objectID": "python/paired_t_test.html#data-used",
    "href": "python/paired_t_test.html#data-used",
    "title": "Paired t-test",
    "section": "Data Used",
    "text": "Data Used\n\nimport pandas as pd\n\n# Create sample data\ndata = {\n    'SBPbefore': [120, 124, 130, 118, 140, 128, 140, 135, 126, 130, 126, 127],\n    'SBPafter': [128, 131, 131, 127, 132, 125, 141, 137, 118, 132, 129, 135]\n}\n\ndf_pressure = pd.DataFrame(data)\n\nThe following code was used to test the comparison in Python. Note that the baseline null hypothesis goes in the “popmean” parameter.\n\nimport pandas as pd\nfrom scipy import stats\n\n# Perform paired t-test\nt_stat, p_value = stats.ttest_rel(df_pressure['SBPbefore'], df_pressure['SBPafter'])\n\n# Print results\nprint(\"Paired t-test:\")\nprint(f\"t = {t_stat}\")\nprint(f\"p-value = {p_value}\")\n\nPaired t-test:\nt = -1.0896479884009451\np-value = 0.299163498777129"
  },
  {
    "objectID": "contribution/get_started.html",
    "href": "contribution/get_started.html",
    "title": "Get Started with Your Environment",
    "section": "",
    "text": "The following instructions provide a step-by-step workflow to set up your work space. In general, you will need:\nRequired/Necessary\n\nA GitHub Account\nGit\nR version 4.4.2 (2024-10-31)\n\nIf possible, utilize R 4.4.2, as this is the version utilized in the repository.\nOtherwise, R ≥ 4.1 should be compatible, so long as your version of R is compatible with the R package versions in the environment.\n\nRStudio (recommended) or Positron\n\nThese are suggested IDEs for writing and running code. We recommend RStudio.\nBoth come bundled with Quarto, which is used for writing the reports and comparisons, so no additional setup is needed on your part.\n\n\nOptional\n\nSAS\n\nRequires a paid license.\n\nPython version 3.12.6\n\nYou will not need to separately download Python. In the configuration of this project through subsequent steps, a virtual environment of Python is activated and installed.\n\n\n\nSet up Git, GitHub, RStudio\nYou will need to download and setup GitHub, Git, R, and RStudio in order to contribute to CAMIS. Please see the above links to download and configure these for your system.\nIn setting up and connecting your RStudio and GitHub accounts, Jenny Bryan has a great book, Happy Git with R, where she talks in much greater depth on connecting RStudio and GitHub.\nSpecifically, Happy Git with R covers:\n\nRegistering for a GitHub Account\nInstalling Git and An Introduction to Git\nConfiguring Personal Access Tokens and\nConnecting Git, GitHub, and RStudio\n\nAt this point, we assume you have the necessary configurations setup and have RStudio connected to GitHub (not necessarily to the CAMIS project yet).\n\n\nFork the CAMIS Repository\nNext, navigate to the CAMIS Repository and fork the repository. Forking the repository will make a copy of the CAMIS repository within your GitHub repository list. This will allow you to make changes and contribute Pull Requests to CAMIS.\n\n\n\n\n\nNow you will have a copy of the CAMIS repository in your list of repositories on GitHub.\nIt is really important to understand the next steps in forking and cloning repositories. Before moving on to the next steps, please read the Happy Git with R Chapter on Fork and Clone. If you are looking to make changes, add a document or comparison, or some other feature through a pull request, you must take some steps in order to properly set up your forked repository. Jenny does a great job walking through the details and differences of upstream, origin, and describes some handy functions to help get your fork properly configured.\n\n\nClone to Your Own Computer\nIf you follow the instructions in Happy Git with R Chapter on Fork and Clone, you can jump to this section.\nOnce you’ve created a copy of this repository, you’ll need to clone it from GitHub to your computer. Click the “Code” button to do this.\nThe method you’ll use, either “HTTPS” or “SSH”, depends on how you’ve connected your computer to GitHub. If you’ve set up using a PAT, select the “HTTPS” tab. If you’ve used “SSH”, then choose that tab. Either way, you will need to copy the location in the box.\n\n\n\n\n\n\n\nCreate an RStudio Project with Version Control\nIn RStudio, you will need to create a new project and select “Version Control” in the project wizard. Then you will select “Git” and finally paste the location copied from GitHub into the URL box. Finally hit “Create Project” and you should be good to go!\n\n\n\n\n\n\n\nSetting up CAMIS with renv\nThe CAMIS repository utilizes renv, which is an R package that helps create reproducible environments. Assuming you downloaded R 4.4.2, which is the version of R associated with this renv project, everything should be relatively straightforward.\nIf you have R ≥ 4.1, you generally shouldn’t have issues, but renv will alert you that R 4.4.2 was used to install the packages and that R 4.4.2 is different than the R version you are using. As more R packages are added/updated in CAMIS renv, there may arise issues if your R version differs greatly from R 4.4.2. This may require you to install a version of R closer to R 4.4.2, so please work with your appropriate technology professional to upgrade R.\nIf you do not have the renv package, you can install it using:\ninstall.packages(\"renv@1.0.10\") \nThis will install the same version of renv as the CAMIS Repository utilizes. Next, you will need to install the specific R and Python packages associated with CAMIS. This can take some time if you do not have some of these already downloaded. Again, because this is a reproducible environment with specific versions of packages (these are listed in a renv.lock file), specific versions of these packages will be downloaded and install into this environment. To install these, run the following code:\n\nrenv::restore()\n\nAgain, this may take some time to install these packages and requirements. There can be some systems that are not as compatible or may require the installation of other systems outside of R packages. Often, these are related to systems or software for installing the binary packages of R. Please refer to those user manuals and other online resources for their installation. Make sure you have the necessary permissions for installing them.\nAs you make contributions to CAMIS, you may also need to add new packages to the renv.lock file. You must use renv to manage and install these packages like:\n\nrenv::install(\"package_name\")\n\nIt is also recommended after installation to snapshot these changes using:\n\nrenv::snapshot()\nrenv::restore()\n\nThese function calls help to record and update the renv.lock file with the package and associated dependencies in a reproducible manner.\nAt this point, it is assumed that your system in RStudio is connected to Git and GitHub, and that the renv environment is successfully activated. Now every time you close RStudio and reopen the CAMIS project on your computer, you should see the option:\n- Project '(path/to/CAMIS/project)' loaded. [renv 1.0.10] \n\n\nCreate a Branch in RStudio\nNow you should have an RStudio Project that contains all of the CAMIS Repository files. A highly recommended step is to create a new branch. A branch separates any changes you make in the forked repository from the Main branch. This allows you to more easily keep up with changes from the CAMIS Repository on the upstream branch.\nTo create a new branch, find the “Git” tab (top right corner) in RStudio. Select the icon to create a new branch. You can name the branch anything, but its helpful to match it with the changes you intend to make. Within the box that comes up, ensure the drop down for Remote is set to “origin” and the option “Sync branch with remote” is checked.\n\n\nContribute Your Changes\nNow you can add and edit various files within the CAMIS project. If you are looking for templates to get you started in comparing R packages or comparing specific methods between coding languages, see the templates for only a Single Language or for comparing Multiple Languages. These templates are good starting points to model off of, and we recommend you keep the structure similar. Also see How to Review an R Package for some other guidance.\nIf you are adding SAS-related examples, add those to the SAS/ folder. R-related examples should be added to the R/ folder. Similarly, Python-related examples should be added to the Python/ folder. For examples that compare two or more languages (i.e. SAS vs R), add these examples in the Comp/ folder Follow the naming convention of the files already stored in those folders.\n\n\nCommit Changes and Push to Remote\nWithin Rstudio, commit each change or new file added, and push these changes to your forked repository. Once you have completed all of the change you want to make, it is time to create a pull request. Before you start creating a pull request, check that your branch on GitHub contains all the changes you want. If your branch on GitHub doesn’t contain all your changes, commit and push those from RStudio.\n\n\n\nThis is what it will look like if you still need to push\n\n\n\n\nCreate a Pull Request\nBack on your fork on GitHub, you will see that your repo is now ahead of the main CAMIS repository. The first thing you want to do is make sure that your forked repository is in sync with the main CAMIS Repository. Sync your own main branch first and then sync your the branch with your desired changes. Click ‘Sync fork’:\n\n\n\n\n\nIf you are having issues on syncing with upstream, Happy Git with R has some guidance. If you have merge conflicts or other issues, Happy Git with R has some recommendations for how to start resolving these.\nNow that you are all synced with main, you can create a pull request by clicking on ‘Contribute’ and then ‘Open pull request’. This brings you to a page where you can explain your pull request. It is often helpful to describe the changes you made to make reviewing the pull request easier and the reviewers can better understand your intended changes. If there are any relevant issues that your pull request is related to, also include and link those issues.\nFor more details about making pull requests see create a pull request.\nOnce your change is approved, and merged into main, you will be able to see your changes on the main CAMIS GitHub repository. You can then delete your branch in your forked repository and sync any other branches with the upstream CAMIS repository."
  },
  {
    "objectID": "contribution/contribution.html",
    "href": "contribution/contribution.html",
    "title": "Get Started with CAMIS",
    "section": "",
    "text": "CAMIS is a community effort. Although this project does have a core team, the endeavor of tracking all these comparisons will fail without community contributions. We appreciate all contributions, big or small!\nYou can get involved in the following ways:\n\njoin our monthly online meetings by completing the new members form\nreport a difference or request a new method by filing an issue\ncontribute to our documentation"
  },
  {
    "objectID": "contribution/contribution.html#how-to-get-involved",
    "href": "contribution/contribution.html#how-to-get-involved",
    "title": "Get Started with CAMIS",
    "section": "",
    "text": "CAMIS is a community effort. Although this project does have a core team, the endeavor of tracking all these comparisons will fail without community contributions. We appreciate all contributions, big or small!\nYou can get involved in the following ways:\n\njoin our monthly online meetings by completing the new members form\nreport a difference or request a new method by filing an issue\ncontribute to our documentation"
  },
  {
    "objectID": "contribution/contribution.html#first-time-contributors",
    "href": "contribution/contribution.html#first-time-contributors",
    "title": "Get Started with CAMIS",
    "section": "First-time contributors",
    "text": "First-time contributors\nWelcome to CAMIS! Please read this article: Get started, which contains some useful information to help you navigate your first PR submission."
  },
  {
    "objectID": "contribution/contribution.html#how-to-contribute-to-the-documentation",
    "href": "contribution/contribution.html#how-to-contribute-to-the-documentation",
    "title": "Get Started with CAMIS",
    "section": "How to contribute to the documentation",
    "text": "How to contribute to the documentation\nPlease contribute by submitting a pull request (PR) and our team will review it.\n\nAdding a new page\nIf you are adding a new page, please follow our template guidelines:\n\nSingle Language Template\nComparing Languages Template\n\nGood documentation on data, methods are very much appreciated!\n\n\nAsking for help\nIf you need any assistance with setting up your workspace, do not hesitate to contact @DrLynTaylor, @statasaurus, @chizapoth or @yannickvandendijck! For more information about how to choose an R package read this short guidance"
  },
  {
    "objectID": "contribution/contribution.html#dissertation-projects",
    "href": "contribution/contribution.html#dissertation-projects",
    "title": "Get Started with CAMIS",
    "section": "Dissertation projects",
    "text": "Dissertation projects\nAre you:\n\na student looking for a dissertation project?\nan academic looking for projects for your students?\na researcher who wants to partner with a university and student to help progress your research?\n\nIf so, check out this page, and contact @DrLynTaylor for more information."
  },
  {
    "objectID": "SAS/rounding.html",
    "href": "SAS/rounding.html",
    "title": "Rounding in SAS",
    "section": "",
    "text": "SAS provides two distinct rounding functions that handle tie-breaking (values exactly halfway between two numbers) differently:\n\nround: Uses “round half away from zero” - 12.5 becomes 13, -12.5 becomes -13\nrounde: Uses “round half to even” (banker’s rounding) - 12.5 becomes 12, 13.5 becomes 14\n\nThe key difference appears when rounding values that are exactly halfway between two possible results.\n\ndata XXX;\n    input my_number;\n    datalines;\n    2.2\n    3.99\n    1.2345\n    7.876\n    13.8739\n    ;\n\ndata xxx2;\n    set xxx;\n    do decimal_places = 1, 2, 3;\n        round_result = round(my_number, 10**(-decimal_places));\n        rounde_result = rounde(my_number, decimal_places);\n        output;\n    end;\nrun;\n\nproc print data=xxx2;\nrun;\n\n\n\n\n\n\nThe round function can produce unexpected results due to floating-point precision limitations. This typically occurs with: - Very large numbers (beyond 15-16 significant digits) - Results of arithmetic operations that introduce small rounding errors - Numbers near the machine epsilon precision threshold\nThese precision issues are inherent to how computers store decimal numbers, not specific flaws in SAS.\n\ndata floating_point_precision;\n    /* Example 1: Large number precision loss */\n    input_val = 32768.0156255;\n    expected =  32768.015626;\n    actual = round(input_val, 1e-6);\n    difference = actual - expected;\n    example = 'Large number';\n    output;\n    \n    /* Example 2: Subtraction then rounding */\n    input_val = 2048.1375 - 2048;  /* = 0.1375 */\n    expected = 0.138;\n    actual = round(input_val, 1e-3);\n    difference = actual - expected;\n    example = 'After subtraction';\n    output;\nrun;\n\nproc print data=floating_point_precision;\n    format input_val expected actual difference 13.8;\n    var example input_val expected actual difference;\nrun;\n\n\n\n\n\n\nThe following analysis systematically identifies cases where round fails by testing combinations of large integers and decimal fractions. Numbers with trailing digits near machine precision limits are most susceptible to incorrect rounding.\n\ndata dum1;\n    int1=0; output;\n    do i=1 to 25;\n      int1=2**i; output;\n    end;\n    keep int1;\nrun;\n\ndata dum2;\n    do round_digits=1 to 7;\n      *x.xxx5 should be rounded up, or replace 5 to 4.99 which should be rounded down;\n      dec1=2**(-round_digits)+10**(-round_digits-1)*5;\n      output;\n    end;\n    keep dec1 round_digits;\nrun;\n\nproc sql;\n    create table incorrect_round2(where=(rounded&lt;num1)) as\n    select dum1.*,dum2.*,int1+dec1 as num1,round(calculated num1,10**(-round_digits)) as rounded\n    from dum1, dum2;\nproc print;\nquit;\n\n\n\n\n\n\nThis example demonstrates rounding behavior with results from common arithmetic operations (addition, subtraction, multiplication, division) across different precision levels, showing how accumulated floating-point errors can affect rounding accuracy.\n\ndata simple;\n    input num1 num2;\n    datalines;\n    3.14159 2.71828\n    1.99999 0.33333\n    5.55555 4.44444\n    7.87654 1.23456\n    0.12345 9.87654\n    6.66666 3.33333\n    ;\nrun;\n\ndata results;\n    set simple;\n    operator='+'; num3=num1+num2; output;\n    operator='-'; num3=num1-num2; output;\n    operator='*'; num3=num1*num2; output;\n    operator='/'; num3=num1/num2; output;\nrun;\n\ndata final;\n    set results;\n    rounded_001 = round(num3, 0.001);  /* Round to nearest 0.001 */\n    rounded_01  = round(num3, 0.01);   /* Round to nearest 0.01 */\n    rounded_1   = round(num3, 0.1);    /* Round to nearest 0.1 */\n    rounded_int = round(num3, 1);      /* Round to nearest integer */\nrun;\n\nproc print data=final;\n    format num1 num2 num3 rounded_001 rounded_01 rounded_1 rounded_int 12.6;\nrun;\n\n\n\n\n\n\nDespite these floating-point precision issues with very large numbers, the round function remains reliable for most practical statistical applications. Users should be aware of potential precision limitations when working with numbers beyond 15-16 significant digits or results from complex arithmetic operations.\nReferences\nSAS Documentation: ROUND Function\nSAS Documentation: ROUNDE Function\nHow to Round Numbers in SAS - SAS Example Code"
  },
  {
    "objectID": "SAS/sample_s_equivalence.html",
    "href": "SAS/sample_s_equivalence.html",
    "title": "Sample Size for Equivalence Trials in SAS",
    "section": "",
    "text": "PROC POWER1 can be used for sample size calculations for equivalence testing2. Note that equivalence testing is different to bioequivalence testing. For bioequivalence see TOST page. SAS can calculate equivalence testing sample size for:\n\nOne sample test: Is a mean equivalent to a target value, within a set tolerance\nTwo independent sample test: Comparison of means for equivalence, when the true mean difference is zero, but within a set tolerance.\nOne sample test: Is a proportion equivalent to a target value, within a set tolerance\nPaired-sample test: Comparison of means for equivalence, within a set tolerance\n\nPROC POWER CANNOT CALCULATE SAMPLE SIZE FOR:\n\nTwo independent sample test: Comparison of means for equivalence, when the true mean difference is non-zero, and within a set tolerance. (It will give you a result, but this doesn’t align to other software/books calculations)\nTwo independent sample test: Comparison of proportions for equivalence, when the true mean difference is zero or non-zero, and within a set tolerance"
  },
  {
    "objectID": "SAS/sample_s_equivalence.html#comparing-two-independent-sample-means-for-parallel-design-unpaired-samples-where-true-difference-between-treatments-is-believed-to-be-zero-and-within-a-tolerance",
    "href": "SAS/sample_s_equivalence.html#comparing-two-independent-sample-means-for-parallel-design-unpaired-samples-where-true-difference-between-treatments-is-believed-to-be-zero-and-within-a-tolerance",
    "title": "Sample Size for Equivalence Trials in SAS",
    "section": "Comparing two independent sample means for parallel design (unpaired samples) where true difference between treatments is believed to be zero and within a tolerance",
    "text": "Comparing two independent sample means for parallel design (unpaired samples) where true difference between treatments is believed to be zero and within a tolerance\nIn the most common scenario, SDs are assumed known and the same in both treatment groups.\nFor a mean in group 1 of \\(\\mu_1\\), and a mean in group 2 of \\(\\mu_2\\), we are testing if the absolute difference between the treatments, \\(|\\mu_2-\\mu_1|\\) is equivalent to some value \\(\\theta\\), within a tolerance of \\(\\delta\\). In this example \\(\\theta =0\\), in other words:\n\\(H_0:|\\mu_2-\\mu_1| \\le \\theta+\\delta\\) versus \\(H_1: |\\mu_2-\\mu_1|\\gt \\theta+\\delta\\) (where \\(\\theta=0\\) ) or\n\\(H_0:|\\mu_2-\\mu_1| \\le \\delta\\) versus \\(H_1: |\\mu_2-\\mu_1|\\gt \\delta\\)\n\nExample where \\(\\theta = 0\\)\nIt is anticipated that patients will have the same mean diastolic BP of 96 mmHg on both the new drug and the active comparator, hence \\(\\theta=0\\). It is also anticipated that the SD (\\(\\sigma\\)) of the diastolic BP is approximately 8 mmHg. The decision is made by clinical to accept equivalence if the difference found between the treatments is less than 5 mmHg, hence \\(\\delta\\)=5. How many patients are required for an 80% power and an overall significance level of 5%?\nA total sample size of 90 is recommended, which equates to a sample size of 45 patients per treatment group. Notice how SAS asks for the lower and upper bounds, these are derived by using the meandiff \\(\\theta\\)+/- the acceptable equivalence limit \\(\\delta\\) (which is stated as 5 mmHg above).\n\nPROC POWER  ;\n    twosamplemeans test=equiv_diff   \n    lower  = -5          \n    upper  = 5   \n    meandiff=0 \n    stddev = 8      \n    ntotal = .       \n    power  = 0.8      \n    alpha  = 0.05;    \nRUN;"
  },
  {
    "objectID": "SAS/sample_s_equivalence.html#comparing-two-independent-sample-means-for-parallel-design-unpaired-samples-where-true-difference-between-treatments-is-believed-not-to-be-zero-and-within-a-tolerance",
    "href": "SAS/sample_s_equivalence.html#comparing-two-independent-sample-means-for-parallel-design-unpaired-samples-where-true-difference-between-treatments-is-believed-not-to-be-zero-and-within-a-tolerance",
    "title": "Sample Size for Equivalence Trials in SAS",
    "section": "Comparing two independent sample means for parallel design (unpaired samples) where true difference between treatments is believed NOT to be zero and within a tolerance",
    "text": "Comparing two independent sample means for parallel design (unpaired samples) where true difference between treatments is believed NOT to be zero and within a tolerance\nIn the most common scenario, SDs are assumed known and the same in both treatment groups.\nFor a mean in group 1 of \\(\\mu_1\\), and a mean in group 2 of \\(\\mu_2\\), we are testing if the absolute difference between the treatments, \\(|\\mu_2-\\mu_1|\\) is equivalent to some value \\(\\theta\\) within a tolerance of \\(\\delta\\), in other words:\n\\(H_0:|\\mu_2-\\mu_1| \\le \\theta+\\delta\\) versus \\(H_1: |\\mu_2-\\mu_1|\\gt \\theta+\\delta\\).\n\nExample where \\(\\theta \\neq 0\\)\nIn this example, you would expect that you could apply similar code to above, but with lower & upper not equidistant from the mean difference, however, doing so does not give the right answer. If you consult SAS literature, it states that the below code is doing Two One-Sided Tests (TOST) Bioequivalence testing. To date, we have not been able to program equivalence with \\(\\theta \\neq 0\\) in SAS and get a sample size that matches the literature.\nInstead of the hypothesis: \\(H_0:|\\mu_2-\\mu_1| \\le \\theta+\\delta\\) versus \\(H_1: |\\mu_2-\\mu_1|\\gt \\theta+\\delta\\).\nThe sample size calculation in this example is aligned to TOST hypotheses:\n\\(H_01: \\mu_2 - \\mu_1 \\ge -\\theta\\) vs \\(H_11:\\mu_2-\\mu_1 \\lt -\\theta\\)\nAND \\(H_02: \\mu_2 - \\mu_1 \\le \\theta\\) vs \\(H_12:\\mu_2-\\mu_1 \\gt \\theta\\)\nSee TOST page for more detail.\nA client is interested in conducting a clinical trial to compare two cholesterol lowering agents for treatment of hypercholesterolemic patients through a parallel design. The primary efficacy parameter is a low-density lipidprotein cholesterol (LDL-C). For establishing equivalence, suppose the true mean difference is 0.01 (1%) and the equivalence limit is 0.05 (5%). Assuming SD = 0.1 (10%), how many patients are required for an 80% power and an overall significance level of 5%?\nBelow shows a sample size of 140 patients in Total (70 per treatment group).\n\nPROC POWER  ;\n    twosamplemeans test=equiv_diff  \n    lower  = -0.04         \n    upper  = 0.06  \n    meandiff = 0.01 \n    stddev = 0.1     \n    ntotal = .       \n    power  = 0.8      \n    alpha  = 0.05;    \nRUN;"
  },
  {
    "objectID": "SAS/sample_s_equivalence.html#estimating-the-within-patient-variance-and-correlation.",
    "href": "SAS/sample_s_equivalence.html#estimating-the-within-patient-variance-and-correlation.",
    "title": "Sample Size for Equivalence Trials in SAS",
    "section": "Estimating the within patient variance and correlation.",
    "text": "Estimating the within patient variance and correlation.\nIt is important to differentiate here between the within patient SD and the SD of the difference. We may need to recalculate one to the other, depending on the case.\nWith no carry-over, then an approximation could be: Variance of the difference = 2x Within Patient Variance. The variance within a patient can be estimated from the within subject residual mean square after fitting the model including visit, period and treatment. For example, using Proc mixed repeated visit / r  sub=usubjid, and ods select r, gives you blocks of the estimate R matrix (covariances between residuals).\nSAS cannot do sample size in this scenario without also having the within subject correlation. It’s common in this scenario to set this equivalent to 0.5. More investigation is required to determine why this is also need to be specified as in this scenario, the correlation should not be required.\n\nExample\nLet’s consider a standard standard two-sequence, two period crossover design for trials to establish therapeutic equivalence between a test drug and a standard therapy. The sponsor is interested in having an 80% power for establishing equivalence. Based on the results from previous trials, it is estimated that the variance (of the difference) is 0.2 (20%). Suppose that the true mean difference is -0.1 (-10%) and the equivalence limit is 0.25 (25%). What is the required sample size, assuming significance level of 5%?\nThe below shows a sample size of 8 patients is required.\n\nPROC POWER;\n    pairedmeans test=equiv_diff   \n    lower  = -35          \n    upper  = 15   \n    meandiff=-10 \n    stddev = 20      \n    npairs = .  \n    corr=0.5\n    power  = 0.8      \n    alpha  = 0.05; \nRUN;\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nPROC POWER SAS online help\nSample Size Calculation Using SAS® for equivalence\n\n\n\nVersion\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package              * version date (UTC) lib source\n R sample_s_equivalence   &lt;NA&gt;    &lt;NA&gt;       [?] &lt;NA&gt;\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n R ── Package was removed from disk.\n\n─ External software ──────────────────────────────────────────────────────────\n setting value\n SAS     9.04.01M7P08062020\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "SAS/count_data_regression.html",
    "href": "SAS/count_data_regression.html",
    "title": "Poisson and Negative Binomial Regression in SAS",
    "section": "",
    "text": "This page serves as an introduction to performing Poisson and Negative Binomial regression in SAS. For detail on how results compare between R and SAS see RvsSAS."
  },
  {
    "objectID": "SAS/count_data_regression.html#example-data",
    "href": "SAS/count_data_regression.html#example-data",
    "title": "Poisson and Negative Binomial Regression in SAS",
    "section": "Example Data",
    "text": "Example Data\nTo demonstrate the use of poisson and negative binomial regression we examine the same polyps dataset as used in the R example for poisson and negative binomial regression here."
  },
  {
    "objectID": "SAS/count_data_regression.html#example-poisson-model-in-sas",
    "href": "SAS/count_data_regression.html#example-poisson-model-in-sas",
    "title": "Poisson and Negative Binomial Regression in SAS",
    "section": "Example: Poisson Model in SAS",
    "text": "Example: Poisson Model in SAS\nIn SAS, we can use proc genmod to perform poisson regression.\nThe OM (obsmargins) option\nIt is generally good practice to apply the OM option on the lsmeans statement. The standard (default) LS-means have equal coefficients across classification effects; however, the OM option changes these coefficients to be proportional to those found in OM-data-set. This adjustment is reasonable when you want your inferences to apply to a population that is not necessarily balanced but has the margins observed in OM-data-set. See here for more details.\nOdds Ratios and 95% CIs\nYou can use exponential of the maximum likelihood parameter estimate (for treat and age in this example), and the exponential of the Wald 95% Confidence Limits to obtain the odds ratios and 95% CIs. Estimates of the least squares means and CI’s for each treatment are output using the lsmeans option. These estimates also have to be back transformed using exponential distribution to get the mean count back onto the original scale. Proc Genmod uses GLM parameterization.\n\nods output ParameterEstimates=ORs lsmeans=lsm;\nproc genmod data=polyps;       \n    class treat (ref=\"placebo\");    \n    model  number = treat age  /  dist=poisson;\n    lsmeans treat/ cl OM;\nrun; \nods output close;\n\n# read in ORs and back transform the estimates (lsm can be done same way)\ndata bt_or;\n    set ors;\n    OR=exp(estimate);\n    OR_low=exp(lowerwaldcl);\n    OR_high=exp(upperwaldcl);\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBack transformation of the parameter estimates and 95% CIs produces the following results\nLsmean number of polyps (95% CI) on Drug: 9.02 (7.30 - 11.13)\nLsmean number of polyps (95% CI) on Placebo: 35.10 (31.72-38.84)\nOdds ratio (95% CI)= 0.2569 (0.2040 - 0.3235)\nHence, patients on Drug have significantly less polyps than those on placebo."
  },
  {
    "objectID": "SAS/count_data_regression.html#example-negative-binomial-in-sas",
    "href": "SAS/count_data_regression.html#example-negative-binomial-in-sas",
    "title": "Poisson and Negative Binomial Regression in SAS",
    "section": "Example: negative binomial in SAS",
    "text": "Example: negative binomial in SAS\nIn SAS, we can use proc genmod to perform negative binomial regression. The below example assumes all patients are followed for the same duration, however if patients are followed for different durations, you should use offset=logtime on the model row as an option to offset the model by the log of the patients duration on the study.\nModel parameterization is very similar to poisson\n\nods output ParameterEstimates=ORs lsmeans=lsm;\nproc genmod data=polyps; \n    class treat (ref=\"placebo\"); \n    model  number = treat age  /  dist=negbin link=log;\n    lsmeans treat/ cl OM;\nrun;\n\nods output close;\n\n# read in lsmeans and back transform the estimates (ORs can be done same way)\ndata bt_lsm;\n    set lsm;\n    lsmean_count=exp(estimate);\n    mean_low=exp(lower);\n    mean_high=exp(upper);\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBack transformation of the parameter estimates and 95% CIs produces the following results\nLsmean number of polyps (95% CI) on Drug: 8.97 (5.18 - 15.53)\nLsmean number of polyps (95% CI) on Placebo: 35.24 (22.12-56.13)\nOdds ratio Drug/Placebo (95% CI)= 0.2546 (0.1232 - 0.5259)\nHence, patients on Drug have significantly less polyps than those on placebo."
  },
  {
    "objectID": "SAS/manova.html",
    "href": "SAS/manova.html",
    "title": "Multivariate Analysis of Variance in SAS",
    "section": "",
    "text": "Example 39.6 Multivariate Analysis of Variance from SAS MANOVA User Guide\nThis example employs multivariate analysis of variance (MANOVA) to measure differences in the chemical characteristics of ancient pottery found at four kiln sites in Great Britain. The data are from Tubb, Parker, and Nickless (1980), as reported in Hand et al. (1994).\nFor each of 26 samples of pottery, the percentages of oxides of five metals are measured. The following statements create the data set and invoke the GLM procedure to perform a one-way MANOVA. Additionally, it is of interest to know whether the pottery from one site in Wales (Llanederyn) differs from the samples from other sites; a CONTRAST statement is used to test this hypothesis.\n\n# Example code\ntitle \"Romano-British Pottery\";\ndata pottery;\n  input Site $12. Al Fe Mg Ca Na;\n  datalines;\n    Llanederyn   14.4 7.00 4.30 0.15 0.51\n    Llanederyn   13.8 7.08 3.43 0.12 0.17\n    Llanederyn   14.6 7.09 3.88 0.13 0.20\n    Llanederyn   11.5 6.37 5.64 0.16 0.14\n    Llanederyn   13.8 7.06 5.34 0.20 0.20\n    Llanederyn   10.9 6.26 3.47 0.17 0.22\n    Llanederyn   10.1 4.26 4.26 0.20 0.18\n    Llanederyn   11.6 5.78 5.91 0.18 0.16\n    Llanederyn   11.1 5.49 4.52 0.29 0.30\n    Llanederyn   13.4 6.92 7.23 0.28 0.20\n    Llanederyn   12.4 6.13 5.69 0.22 0.54\n    Llanederyn   13.1 6.64 5.51 0.31 0.24\n    Llanederyn   12.7 6.69 4.45 0.20 0.22\n    Llanederyn   12.5 6.44 3.94 0.22 0.23\n    Caldicot     11.8 5.44 3.94 0.30 0.04\n    Caldicot     11.6 5.39 3.77 0.29 0.06\n    IslandThorns 18.3 1.28 0.67 0.03 0.03\n    IslandThorns 15.8 2.39 0.63 0.01 0.04\n    IslandThorns 18.0 1.50 0.67 0.01 0.06\n    IslandThorns 18.0 1.88 0.68 0.01 0.04\n    IslandThorns 20.8 1.51 0.72 0.07 0.10\n    AshleyRails  17.7 1.12 0.56 0.06 0.06\n    AshleyRails  18.3 1.14 0.67 0.06 0.05\n    AshleyRails  16.7 0.92 0.53 0.01 0.05\n    AshleyRails  14.8 2.74 0.67 0.03 0.05\n    AshleyRails  19.1 1.64 0.60 0.10 0.03\n;\nrun;\n\nproc glm data=pottery;\n    class Site;\n    model Al Fe Mg Ca Na = Site;\n    contrast 'Llanederyn vs. the rest' Site 1 1 1 -3;\n    manova h=_all_ / printe printh;\nrun;\n\nAfter the summary information (1), PROC GLM produces the univariate analyses for each of the dependent variables (2-6). These analyses show that sites are significantly different for all oxides individually. You can suppress these univariate analyses by specifying the NOUNI option in the MODEL statement.\n1 Summary Information about Groups\n\n\n\n\n\n\n\n\n\n2 Univariate Analysis of Variance for Aluminum Oxide (AI)\n\n\n\n\n\n\n\n\n\n3 Univariate Analysis of Variance for Iron Oxide (Fe)\n\n\n\n\n\n\n\n\n\n4 Univariate Analysis of Variance for Calcium Oxide (Ca)\n\n\n\n\n\n\n\n\n\n5 Univariate Analysis of Variance for Magnesium Oxide (Mg)\n\n\n\n\n\n\n\n\n\n6 Analysis of Variance for Sodium Oxide (Na)\n\n\n\n\n\n\n\n\n\nThe PRINTE option in the MANOVA statement displays the elements of the error matrix (7), also called the Error Sums of Squares and Crossproducts matrix. The diagonal elements of this matrix are the error sums of squares from the corresponding univariate analyses.\nThe PRINTE option also displays the partial correlation matrix (7) associated with the E matrix. In this example, none of the oxides are very strongly correlated; the strongest correlation (r=0.488) is between magnesium oxide and calcium oxide.\n7 Error SSCP Matrix and Partial Correlations\n\n\n\n\n\n\n\n\n\nThe PRINTH option produces the SSCP matrix for the hypotheses being tested (Site and the contrast); (8 and 9). Since the Type III SS are the highest-level SS produced by PROC GLM by default, and since the HTYPE= option is not specified, the SSCP matrix for Site gives the Type III H matrix. The diagonal elements of this matrix are the model sums of squares from the corresponding univariate analyses.\nFour multivariate tests are computed, all based on the characteristic roots and vectors of \\(E^{-1}H\\). These roots and vectors are displayed along with the tests. All four tests can be transformed to variates that have distributions under the null hypothesis. Note that the four tests all give the same results for the contrast, since it has only one degree of freedom. In this case, the multivariate analysis matches the univariate results: there is an overall difference between the chemical composition of samples from different sites, and the samples from Llanederyn are different from the average of the other sites.\n8 Hypothesis SSCP Matrix and Multivariate Tests for Overall Site Effect\n\n\n\n\n\n\n\n\n\n9 Hypothesis SSCP Matrix and Multivariate Tests for Differences between Llanederyn and the Other Sites\n\n\n\n\n\n\n\n\n\nReferences\nSAS MANOVA User Guide"
  },
  {
    "objectID": "SAS/ancova.html",
    "href": "SAS/ancova.html",
    "title": "Ancova",
    "section": "",
    "text": "ANCOVA in SAS\nIn SAS, there are several ways to perform ANCOVA analysis. One common way is to use PROC GLM with the LSMEANS option. The below example will use this method.\n\nData Used\nThe following data was used in this example.\n\ndata DrugTest;\n    input Drug $ PreTreatment PostTreatment @@;\n    datalines;\n  A 11  6   A  8  0   A  5  2   A 14  8   A 19 11\n  A  6  4   A 10 13   A  6  1   A 11  8   A  3  0\n  D  6  0   D  6  2   D  7  3   D  8  1   D 18 18\n  D  8  4   D 19 14   D  8  9   D  5  1   D 15  9\n  F 16 13   F 13 10   F 11 18   F  9  5   F 21 23\n  F 16 12   F 12  5   F 12 16   F  7  1   F 12 20\n  ;\n\n\n\nCode\nThe following code was used to test the effects of a drug pre and post treatment:\n\nproc glm data=DrugTest;\n    class Drug;\n    model PostTreatment = Drug PreTreatment / solution;\n    lsmeans Drug / stderr pdiff cov out=adjmeans;\nrun;\nproc print data=adjmeans;\nrun;\n\nOutput:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs can be seen in the images above, the GLM procedure provides multiple types of analysis to determine the relationship between the dependent and independent variables. The last step produces a table of LSMEANS and coefficient of variation values for each of the three different drugs in the dataset."
  },
  {
    "objectID": "SAS/kruskal_wallis.html",
    "href": "SAS/kruskal_wallis.html",
    "title": "Kruskal Wallis SAS",
    "section": "",
    "text": "The Kruskal-Wallis test is a non-parametric equivalent to the one-way ANOVA. For this example, the data used is a subset of R’s datasets::iris, testing for difference in sepal width between species of flower. This data was subset in R and input manually to SAS with a data step.\n\ndata iris_sub;\n      input Species $ Sepal_Width;\n      datalines;\nsetosa 3.4\nsetosa 3.0\nsetosa 3.4\nsetosa 3.2\nsetosa 3.5\nsetosa 3.1\nversicolor 2.7\nversicolor 2.9\nversicolor 2.7\nversicolor 2.6\nversicolor 2.5\nversicolor 2.5\nvirginica 3.0\nvirginica 3.0\nvirginica 3.1\nvirginica 3.8\nvirginica 2.7\nvirginica 3.3\n;\nrun;"
  },
  {
    "objectID": "SAS/kruskal_wallis.html#introduction",
    "href": "SAS/kruskal_wallis.html#introduction",
    "title": "Kruskal Wallis SAS",
    "section": "",
    "text": "The Kruskal-Wallis test is a non-parametric equivalent to the one-way ANOVA. For this example, the data used is a subset of R’s datasets::iris, testing for difference in sepal width between species of flower. This data was subset in R and input manually to SAS with a data step.\n\ndata iris_sub;\n      input Species $ Sepal_Width;\n      datalines;\nsetosa 3.4\nsetosa 3.0\nsetosa 3.4\nsetosa 3.2\nsetosa 3.5\nsetosa 3.1\nversicolor 2.7\nversicolor 2.9\nversicolor 2.7\nversicolor 2.6\nversicolor 2.5\nversicolor 2.5\nvirginica 3.0\nvirginica 3.0\nvirginica 3.1\nvirginica 3.8\nvirginica 2.7\nvirginica 3.3\n;\nrun;"
  },
  {
    "objectID": "SAS/kruskal_wallis.html#implementing-kruskal-wallis-in-sas",
    "href": "SAS/kruskal_wallis.html#implementing-kruskal-wallis-in-sas",
    "title": "Kruskal Wallis SAS",
    "section": "Implementing Kruskal-Wallis in SAS",
    "text": "Implementing Kruskal-Wallis in SAS\nThe Kruskal-Wallis test can be implemented in SAS using the NPAR1WAY procedure with WILCOXON option. Below, the test is defined with the indicator variable (Species) by the CLASS statement, and the response variable (Sepal_Width) by the VAR statement. Adding the EXACT statement outputs the exact p-value in addition to the asymptotic result. The null hypothesis is that the samples are from identical populations.\n\nproc npar1way data=iris_sub wilcoxon;\n    class Species;\n    var Sepal_Width;\n    exact;\nrun;"
  },
  {
    "objectID": "SAS/kruskal_wallis.html#results",
    "href": "SAS/kruskal_wallis.html#results",
    "title": "Kruskal Wallis SAS",
    "section": "Results",
    "text": "Results\n\n\n\n\n\n\n\n\n\nAs seen above, SAS outputs a table of Wilcoxon Scores for Sepal_Width by each Species including (per group): the number (N); the sum of scores; the expected sum of scores under the null hypothesis; the standard deviation under the null hypothesis, and the observed mean score. The table also includes a footnote to specify that ties were handled by using the average score.\nA table of the test results gives the Kruskal-Wallis rank sum statistic (10.922), the degrees of freedom (2), and the asymptotic p-value of the test (0.0042), and the exact p-value (0.0008). Therefore, the difference in population medians is statistically significant at the 5% level."
  },
  {
    "objectID": "SAS/recurrent_events.html",
    "href": "SAS/recurrent_events.html",
    "title": "SAS Recurrent Events",
    "section": "",
    "text": "Traditionally, survival analysis focuses on the time to a single first event. While there are many applications for such time-to-event analysis in clinical trials, this approach falls short when events of interest can occur multiple times within the same subject. Recurrent event models extend the traditional Cox proportional hazards framework to account for multiple events per subject (Ozga et al. 2018, Amorim et al. 2015).\nIn this tutorial, we will demonstrate how to implement different recurrent event models in SAS, specifically the Andersen-Gill, proportional means/rates (Lin-Wei-Yang-Ying,) Prentice-Williams-Peterson, and Wei-Lin-Weissfeld models. The SAS code follows the layout of Amor 2023, with additional insights taken from Lu et al. 2018.\nRecurrent event models can roughly be divided in three categories: counting process models, conditional models and marginal models. In the section below, we will explore the difference between each of these approaches. In addition, important aspects of data structure will be discussed by means of two fictional subjects, one with 4 events and 0 censored observations (events at time 6, 9, 56 and 88), and another with 2 events and 1 censored observation (events at time 42, 57, and censored at time 91).\nDefine the following:\n\n\n\n\n\n\nNote\n\n\n\n\\(\\lambda_i(t)\\): hazard function for the \\(i\\)th subject at time \\(t\\)\n\\(\\lambda_{ij}(t)\\): hazard function for the \\(j\\)th event of the \\(i\\)th subject at time \\(t\\)\n\\(\\lambda_0(t)\\): common baseline hazard for all events\n\\(\\lambda_{0j}(t)\\): event-specific baseline hazard for the \\(j\\)th event at time \\(t\\)\n\\(\\beta\\): common parameter vector\n\\(\\beta_j\\): event-specific parameter vector for the \\(j\\)th event\n\\(X_{ij}\\): covariate vector for the \\(j\\)th event of the \\(i\\)th subject\n\n\n\n\n\n\n\n\\[\n\\lambda_i(t) = \\lambda_0(t) \\exp \\left( \\beta X_{ij}(t) \\right) \\\n\\]\n\nCounting process approach: treats each subject as a multiple events counting process\nCommon baseline hazard \\(\\lambda_0(t)\\)\nCommon regression coefficients \\(\\beta\\)\nUnrestricted risk set: a subject contributes to the risk set for an event as long as the subject is under observation, i.e. it can be at risk for a subsequent event even though the previous event did not yet occur\nOrder of events is not important\n\nAn essential assumption of the Andersen-Gill model is that of independent events within subjects. This, however, is often not realistic in clinical trial data. For example, let’s say that we are modelling myocardial infarction (MI). If a patient has already experienced one MI, their risk of subsequent events may increase due to underlying cardiovascular damage or presence of other risk factors. Thus, the more events a patient has, the more likely they are to experience future events, indicating dependence rather than independence. To accurately model this within-subject correlation, extensions like time-varying covariates, a robust sandwich covariance estimator or frailty terms may be needed. In this tutorial, we will discuss the sandwich correction.\nLin-Wei-Yang-Ying (LWYY) model or proportional means/rates model (Lei, Wei, Yang & Ying 2000)\nLin, Wei, Yang & Ying introduced an improved version of the Andersen-Gill model in 2000 (often referred to as proportional means/rates model), featuring a robust sandwich estimator that explicitly accounts for individual subject clusters. These robust standard errors yield wider confidence intervals and provide asymptotically valid inference even when the independence assumption does not hold (Lee et al. 2025). The original and improved Andersen-Gill model often appear interchangeable in the literature, and while they produce identical estimates, their robust standard errors can differ substantially, which may impact the conclusions drawn from statistical inference.\nFor both versions of the Andersen-Gill model, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(6, 9]\n1\n1\n\n\n1\n(9, 56]\n1\n1\n\n\n1\n(56, 88]\n1\n1\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(42, 87]\n1\n1\n\n\n2\n(87, 91]\n0\n1\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nIn both versions of the Andersen-Gill model, each new time interval starts where the previous one ends.\n\n\n\n\n\n\n\nConditional approach: incorporates conditional strata to account for ordering/dependence of events\nStratified baseline hazard \\(\\lambda_{0j}(t)\\)\nStratified regression coefficients \\(\\beta_j\\): can be pooled (\\(\\beta\\)) or kept as event-specific (\\(\\beta_j\\)) in the output\nRestricted risk set: contributions to the risk set for a subsequent event are restricted to only consider subjects that already experienced the previous event\nOrder of events is important\n\nThe Prentice-Williams-Peterson model can incorporate both overall and event-specific effects \\(\\beta_j\\) for each covariate. An often made assumption is to set \\(\\beta_1 = \\beta_2 = ... = \\beta_k = \\beta\\) to estimate a common parameter \\(\\beta\\).\nDepending on the outcome of interest, Prentice, Williams and Peterson suggested two distinct models:\n\nTotal time model\n\n\\[\n\\lambda_{ij}(t) = \\lambda_{0j}(t) \\exp \\left( \\beta_j X_{ij}(t) \\right) \\\n\\]\nThe total time variant of the Prentice-Williams-Peterson model uses the same time intervals as the counting process approach (Andersen-Gill model), which is useful for modelling the full time course (\\(t\\)) of the recurrent event process, i.e. the hazard of any recurrence.\nFor the total time model, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(6, 9]\n1\n2\n\n\n1\n(9, 56]\n1\n3\n\n\n1\n(56, 88]\n1\n4\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(42, 87]\n1\n2\n\n\n2\n(87, 91]\n0\n3\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nAgain, in the total time model, each new time intervals starts where the previous one ends.\n\nGap time model\n\n\\[\n\\lambda_{ij}(t) = \\lambda_{0j}(t - t_{j-1}) \\exp \\left( \\beta_j X_{ij}(t) \\right) \\\n\\]\nThe gap time variant of the Prentice-Williams-Peterson model uses time intervals that start at zero and end at the length of time until the next event, which is useful for modelling the time between each of the recurring events (\\(t - t_{j-1}\\)), i.e. the hazard of recurrence after the previous event.\nFor the gap time model, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(0, 3]\n1\n2\n\n\n1\n(0, 47]\n1\n3\n\n\n1\n(0, 32]\n1\n4\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(0, 45]\n1\n2\n\n\n2\n(0, 3]\n0\n3\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nIn the gap time model, each time interval starts at zero and has a length equal to the gap time between two neighboring events.\n\n\n\n\n\n\n\\[\n\\lambda_{ij}(t) = \\lambda_{0j}(t) \\exp \\left( \\beta_j X_{ij}(t) \\right) \\\n\\]\n\nMarginal approach: treats each (recurrent) event as having a separate, marginal process\nStratified baseline hazard \\(\\lambda_{0j}(t)\\)\nSemi-restricted risk set: all subjects contribute follow-up times to all potential events, i.e. each subject is at risk for all potential events, regardless of how many events that subject actually experiences\nOrder of events is not important\n\nAlthough the Wei-Lin-Weissfeld model has it roots in competing risks analysis, it conveniently lends itself to model recurrent events as well. Like the Andersen-Gill model, the Wei-Lin-Weissfeld model also assumes independence of events, which is often not feasible in practice. In addition, it is assumed there is no specific order among the events or that the events are different types of events, and not necessarily recurrent events.\nLike the Prentice-Williams-Peterson models, the Wei-Lin-Weissfeld model can incorporate both overall and event-specific effects \\(\\beta_j\\) for each covariate. An often made assumption is to set \\(\\beta_1 = \\beta_2 = ... = \\beta_k = \\beta\\) to estimate a common parameter \\(\\beta\\). Another approach is to combine event-specific effects \\(\\beta_j\\) to get an estimator of the average treatment effect, as described in Wei, Lin & Weissfeld 1989 (this is not discussed further here).\nFor Wei-Lin-Weissfeld models, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(0, 9]\n1\n2\n\n\n1\n(0, 56]\n1\n3\n\n\n1\n(0, 88]\n1\n4\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(0, 87]\n1\n2\n\n\n2\n(0, 91]\n0\n3\n\n\n2\n(0, 91]\n0\n4\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nIn the Wei-Lin-Weissfeld model, each time intervals starts at zero and ends at its respective event time.\n\n\n\n\nIn summary, the selection of the model to use would depend on the type of events, the importance of the order of the events and the time intervals to be analyzed. We made an effort to summarize the similarities and differences between the models in the table below.\n\n\n\n\n\n\n\n\n\n\n\nAG\nPWPtt\nPWPgt\nWLW\n\n\n\n\nApproach\ncounting process\nconditional\nconditional\nmarginal\n\n\nBaseline hazard\ncommon\nstratified\nstratified\nstratified\n\n\nRegression coefficients\ncommon\nstratified possible\nstratified possible\nstratified possible\n\n\nRisk set\nunrestricted\nrestricted\nrestricted\nsemi-restricted\n\n\nTime interval\ntotal time\ntotal time\ngap time\ntotal time\n\n\nOrder of events\nnot important\nimportant\nimportant\nnot important\n\n\nHazard ratio (HR)\nrisk of any recurrence\nrisk of any recurrence\nrisk of recurrence after previous event\nrisk of event of any type, not necessarily recurrent event\n\n\n\nNote that, because the ordering of events is not important in the Andersen-Gill and Wei-Lin-Weissfeld model, these models come with the assumption of independence of events. In contrast, the Prentice-Williams-Peterson models overcome the need for this assumption by capturing the dependence structure between recurrent events in conditional strata. Consequently, events are assumed to be conditionally independent in the Prentice-Williams-Peterson models.\nA nice visual representation of the stratification and time interval structure of each model is given below. The correct data structure is pivotal when modelling recurrent events and depends on the methodology you want to use, as illustrated in the figure.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor this tutorial we will use the bladder data from the survival R package, which captures recurrences of bladder cancer from a clinical trial for an oncolytic called thiotepa. The bladder data is regularly used by many statisticians to demonstrate methodology for recurrent event modelling. Somewhat confusingly, there are three versions of this data available:\n\nbladder1: original data from the study on all subjects (294 records)\nbladder2: data in Andersen-Gill format on subset of subjects with nonzero follow-up time (178 records)\nbladder: data in Wei-Lin-Weissfeld format on subset of subjects with nonzero follow-up time (340 records)\n\nFor this tutorial, we will use bladder2 to illustrate Andersen-Gill and Prentice-Williams-Peterson models, and bladder to illustrate the Wei-Lin-Weissfeld model.\nThe variables included in both datasets are:\n\nid: patient id\nrx: treatment group (1 = placebo, 2 = thiotepa)\nnumber: initial number of tumors (8 = 8 or more)\nsize: size in cm of largest initial tumor\nstart: start of time interval; this variable is not present in bladder\nstop: (recurrent) event or censoring time\nevent: event indicator (1 = event, 0 = censored)\nenum: order of recurrence\n\nImportantly, both datasets collect the data in a counting process structure. This means that there is one record for each subject and time interval, where a time interval is defined as the time to its respective event (event = 1), or the time to follow-up if the event did not occur (event = 0).\nLet’s look more closely at the bladder2 and bladder data:\n\nbladder2 &lt;- survival::bladder2\ngt(head(bladder2, 6))\n\n\n\n\n\n\n\nid\nrx\nnumber\nsize\nstart\nstop\nevent\nenum\n\n\n\n\n1\n1\n1\n3\n0\n1\n0\n1\n\n\n2\n1\n2\n1\n0\n4\n0\n1\n\n\n3\n1\n1\n1\n0\n7\n0\n1\n\n\n4\n1\n5\n1\n0\n10\n0\n1\n\n\n5\n1\n4\n1\n0\n6\n1\n1\n\n\n5\n1\n4\n1\n6\n10\n0\n2\n\n\n\n\n\n\n\n\nbladder2 %&gt;%\n  group_by(enum) %&gt;% summarise(n = n()) %&gt;% gt()\n\n\n\n\n\n\n\nenum\nn\n\n\n\n\n1\n85\n\n\n2\n46\n\n\n3\n27\n\n\n4\n20\n\n\n\n\n\n\n\nIn bladder2, in the Andersen-Gill format, each subject has a variable amount of records, depending on the amount of events that subject experienced.\n\nbladder &lt;- survival::bladder\ngt(head(bladder, 20))\n\n\n\n\n\n\n\nid\nrx\nnumber\nsize\nstop\nevent\nenum\n\n\n\n\n1\n1\n1\n3\n1\n0\n1\n\n\n1\n1\n1\n3\n1\n0\n2\n\n\n1\n1\n1\n3\n1\n0\n3\n\n\n1\n1\n1\n3\n1\n0\n4\n\n\n2\n1\n2\n1\n4\n0\n1\n\n\n2\n1\n2\n1\n4\n0\n2\n\n\n2\n1\n2\n1\n4\n0\n3\n\n\n2\n1\n2\n1\n4\n0\n4\n\n\n3\n1\n1\n1\n7\n0\n1\n\n\n3\n1\n1\n1\n7\n0\n2\n\n\n3\n1\n1\n1\n7\n0\n3\n\n\n3\n1\n1\n1\n7\n0\n4\n\n\n4\n1\n5\n1\n10\n0\n1\n\n\n4\n1\n5\n1\n10\n0\n2\n\n\n4\n1\n5\n1\n10\n0\n3\n\n\n4\n1\n5\n1\n10\n0\n4\n\n\n5\n1\n4\n1\n6\n1\n1\n\n\n5\n1\n4\n1\n10\n0\n2\n\n\n5\n1\n4\n1\n10\n0\n3\n\n\n5\n1\n4\n1\n10\n0\n4\n\n\n\n\n\n\n\n\nbladder %&gt;%\n  group_by(enum) %&gt;% summarise(n = n()) %&gt;% gt()\n\n\n\n\n\n\n\nenum\nn\n\n\n\n\n1\n85\n\n\n2\n85\n\n\n3\n85\n\n\n4\n85\n\n\n\n\n\n\n\nIn bladder, in the Wei-Lin-Weissfeld format, each subject has four records, regardless of how many events that subject actually experienced. In addition, there is no start variable, as all time intervals start at zero.\nNote: The variables id, start and stop were renamed to subjid, tstart and tstop to avoid using SAS key words as variable names.\n\n\n\nIn SAS, any survival analysis based on the Cox proportional hazard model can be conducted using the phreg procedure. Hence, conveniently, when modelling time-to-event data with recurrent events, the same procedure can be used. The caveat here is that an adequate data structure is required, which must be in correspondence with the model you want to use.\nIn this section of the tutorial, we will explain how the arguments of the phreg procedure and data structure must be defined to fit every type of recurrent event model correctly.\n\n\n\nImproved Andersen-Gill model (LWYY model or proportional means/rates model)\n\nFor the improved version of the Andersen-Gill model you must include:\n\nproc phreg data=bladder2 covs(aggregate)\nmodel (tstart, tstop) * event(0) = 'predictors';\nid subjid;\n\nAnd the data structure must be:\n\n\n\nSubjid\nTime interval\nTstart\nTstop\nEvent\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n\n\n2\n(0, 4]\n0\n4\n0\n\n\n3\n(0, 7]\n0\n7\n0\n\n\n4\n(0, 10]\n0\n10\n0\n\n\n5\n(0, 6]\n0\n6\n1\n\n\n5\n(6, 10]\n6\n10\n0\n\n\n\nWe will use the bladder2 data for this.\n\nproc phreg data=bladder2 covs(aggregate);\n    class rx (ref='1');\n    model (tstart, tstop) * event(0) = rx size number /rl;\n    id subjid;\nrun;\n\n\n\n\n\n\n\n\n\n\nBy including the covs(aggregate) option and setting id subjid;, SAS will compute a robust sandwich covariance and display robust standard error estimates in the output. Under the hood, the robust standard errors will consider all subjid clusters separately and ultimately sum up the score residuals for each distinct cluster.\n\nOriginal Andersen-Gill model\n\nThe original Andersen-Gill model of 1989 can be fitted by changing covs(aggregate) to covs in the procedure, while excluding id subjid;.\n\nproc phreg data=bladder2 covs;\n    class rx (ref='1');\n    model (tstart, tstop) * event(0) = rx size number /rl;\nrun;\n\n\n\n\n\n\n\n\n\n\nAlthough the original Andersen-Gill model does not consider separate subjid clusters, it still computes robust standard errors using the sandwich estimator. The resulting robust standard errors differ from those provided for the improved Andersen-Gill model, while the estimated coefficients remain perfectly unchanged.\n\n\n\nTotal time model\nFor the Prentice-Williams-Peterson total time model you must include:\n\nproc phreg data=bladder2 covs(aggregate);\nmodel (tstart, tstop) * event(0) = 'predictors';\nid subjid;\nstrata enum;\n\nAnd the data structure must be:\n\n\n\nSubjid\nTime interval\nTstart\nTstop\nEvent\nEnum\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n1\n\n\n2\n(0, 4]\n0\n4\n0\n1\n\n\n3\n(0, 7]\n0\n7\n0\n1\n\n\n4\n(0, 10]\n0\n10\n0\n1\n\n\n5\n(0, 6]\n0\n6\n1\n1\n\n\n5\n(6, 10]\n6\n10\n0\n2\n\n\n\nWe will use the bladder2 data for this.\n\nproc phreg data=bladder2 covs(aggregate);\n    class rx (ref='1');\n    model (tstart, tstop) * event(0) = rx size number /rl; \n    id subjid;\n    strata enum;\nrun;\n\n\n\n\n\n\n\n\n\n\nThe conditional strata of the Prentice-Williams-Peterson model are set by strata enum; in the formula, where enum captures the ordering of recurrent events.\nGap time model\nFor the Prentice-Williams-Peterson gap time model you must include:\n\nproc phreg data=bladder2 covs(aggregate);\nmodel gtime * event(0) = 'predictors';\nid subjid;\nstrata enum;\n\nAnd the data structure must be:\n\n\n\nSubjid\nTime interval\nTstart\nTstop\nEvent\nEnum\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n1\n\n\n2\n(0, 4]\n0\n4\n0\n1\n\n\n3\n(0, 7]\n0\n7\n0\n1\n\n\n4\n(0, 10]\n0\n10\n0\n1\n\n\n5\n(0, 6]\n0\n6\n1\n1\n\n\n5\n(0, 4]\n0\n4\n0\n2\n\n\n\nThis data structure can be achieved in bladder2 by adding a gtime variable.\n\ndata bladder2;\n    set bladder2;\n    gtime = tstop - tstart;\nrun;\n\nWe artificially set start = 0 for each gap time interval by including gtime instead of (start, stop) in the model statement.\n\nproc phreg data=bladder2 covs(aggregate);\n    class rx (ref='1');\n    model gtime * event(0) = rx size number/rl; \n    id subjid;\n    strata enum;\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor the Wei-Lin-Weissfeld model you must include:\n\nproc phreg data=bladder covs(aggregate);\nmodel tstop * event(0) = 'predictors';\nid subjid;\nstrata enum;\n\nAnd the data structure must be:\n\n\n\nSubjid\nTime interval\nTstart\nTstop\nEvent\nEnum\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n1\n\n\n1\n(0, 1]\n0\n1\n0\n2\n\n\n1\n(0, 1]\n0\n1\n0\n3\n\n\n1\n(0, 1]\n0\n1\n0\n4\n\n\n2\n(0, 4]\n0\n4\n0\n1\n\n\n2\n(0, 4]\n0\n4\n0\n2\n\n\n2\n(0, 4]\n0\n4\n0\n3\n\n\n2\n(0, 4]\n0\n4\n0\n4\n\n\n3\n(0, 7]\n0\n7\n0\n1\n\n\n3\n(0, 7]\n0\n7\n0\n2\n\n\n3\n(0, 7]\n0\n7\n0\n3\n\n\n3\n(0, 7]\n0\n7\n0\n4\n\n\n4\n(0, 10]\n0\n10\n0\n1\n\n\n4\n(0, 10]\n0\n10\n0\n2\n\n\n4\n(0, 10]\n0\n10\n0\n3\n\n\n4\n(0, 10]\n0\n10\n0\n4\n\n\n5\n(0, 6]\n0\n6\n1\n1\n\n\n5\n(0, 10]\n0\n10\n0\n2\n\n\n5\n(0, 10]\n0\n10\n0\n3\n\n\n5\n(0, 10]\n0\n10\n0\n4\n\n\n\nWe will use the bladder data for this.\n\nproc phreg data=bladder covs(aggregate);\n    class rx (ref='1');\n    model tstop * event(0) = rx size number /rl;\n    id subjid;\n  strata enum;\nrun;\n\n\n\n\n\n\n\n\n\n\nImportantly, the strata of the Wei-Lin-Weissfeld model as set by strata enum; are substantially different from the conditional strata of the Prentice-Williams-Peterson model. The enum variable is now no longer assumed to be an ordinal variable.\n\n\n\nNote: The rl option ensures the 95% confidence interval for the hazard ratio is displayed.\nNote: If you want to display non-robust, model-based standard errors (like the ones given by default in R), you can do this by adding covm to the procedure statement.\nNote: It may be useful to look at the Summary of the Number of Event and Censored Values to check whether the data stratification was rightly specified for your model. Examples for the Prentice-Williams-Peterson and Wei-Lin-Weissfeld models are given below.\nSummary for Prentice-Williams-Peterson models:\n\n\n\n\n\n\n\n\n\nSummary for Wei-Lin-Weissfeld model:\n\n\n\n\n\n\n\n\n\nNote: R uses ties = \"efron\" by default, while SAS uses ties = breslow by default. If this argument remains unchanged in both software, it can cause differences in outcome. For more information, be sure to check the CAMIS webpage on the comparison of Cox proportional hazards models in R and SAS.\n\n\n\n\nIn terms of interpretation, hazard ratios (\\(\\exp(\\beta_j)\\)) are often used when making inferences based on Cox proportional hazards models. Now, as you may remember from the overview presented earlier, it is important to recognize that each of the recurrent event models comes with a slightly different interpretation of the hazard ratio, as defined by the assumptions around the model.\n\n\n\n\n\n\n\n\n\n\n\nAG\nPWPtt\nPWPgt\nWLW\n\n\n\n\nHazard ratio (HR)\nrisk of any recurrence\nrisk of any recurrence\nrisk of recurrence after previous event\nrisk of event of any type, not necessarily recurrent event\n\n\n\nThis means that, for the bladder data, we can draw slightly different conclusions on the hazard ratio of the group treated with thiotepa (rx = 2) versus the placebo group (rx = 1).\n\n\n\nModel\nHR: rx2 vs rx1\n95% CI\nP-value\n\n\n\n\nAG\n0.631\n0.381 to 1.047\n0.0747\n\n\nOriginal AG\n0.631\n0.403 to 0.989\n0.0447\n\n\nPWPtt\n0.716\n0.486 to 1.053\n0.0898\n\n\nPWPgt\n0.764\n0.508 to 1.148\n0.1952\n\n\nWLW\n0.560\n0.309 to 1.015\n0.0560\n\n\n\nThese conclusions are:\n\nAndersen-Gill: the risk of having any new tumor recurrence in the treatment group is 0.631 (0.381 - 1.047) times that of the placebo group\nPrentice-Williams-Peterson: total time: the risk of having any new tumor recurrence in the treatment group is 0.716 (0.486 - 1.053) times that of the placebo group\nPrentice-Williams-Peterson: gap time: the risk of having a new tumor recurrence after a previous event in the treatment group is 0.764 (0.508 - 1.148) times that of the placebo group\nWei-Lin-Weissfeld: the risk of having any type of event in the treatment group is 0.560 (0.309 - 1.015) times that of the placebo group\n\nNote: The improved Andersen-Gill model (LWYY model or proportional means/rates model) is preferred over the original Andersen-Gill model.\n\n\n\nFor the Prentice-Williams-Peterson and Wei-Lin-Weissfeld models we can incorporate both overall (\\(\\beta\\)) and event-specific (\\(\\beta_j\\)) effects for each covariate. To arrive at pooled model parameters these models assume that \\(\\beta_1 = \\beta_2 = ... = \\beta_k = \\beta\\). Until now, we have only considered pooled model parameters, but given the underlying stratification of these two models in particular, it may be valuable to look into the event-specific estimates as well (Amorim & Cai 2015).\nTo get event-specific estimates for the treatment effect (rx), we first need to introduce four new rx variables to the bladder2 and bladder datasets, one for each stratum.\n\ndata bladder2;\n    set bladder2;\n    rx_enum1 = rx*(enum=1);\n    rx_enum2 = rx*(enum=2);\n    rx_enum3 = rx*(enum=3);\n    rx_enum4 = rx*(enum=4);\nrun;\n\n\ndata bladder;\n    set bladder;\n    rx_enum1 = rx*(enum=1);\n    rx_enum2 = rx*(enum=2);\n    rx_enum3 = rx*(enum=3);\n    rx_enum4 = rx*(enum=4);\nrun;\n\nWith these four interaction variables, we need to specify rx_enum1-rx_enum4 in the formula and set class enum / param=glm; to output the event-specific estimates.\n\n\nTotal time model\n\nproc phreg data=bladder2 covs(aggregate);\n    class enum / param=glm;\n    model (tstart, tstop) * event(0) = rx_enum1-rx_enum4 size number /rl; \n    id subjid;\n    strata enum;\nrun;\n\n\n\n\n\n\n\n\n\n\nGap time model\n\nproc phreg data=bladder2 covs(aggregate);\n    class enum / param=glm;\n    model gtime * event(0) = rx_enum1-rx_enum4 size number/rl; \n    id subjid;\n    strata enum;\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nproc phreg data=bladder covs(aggregate);\n    class enum / param=glm;\n    model tstop * event(0) = rx_enum1-rx_enum4 size number /rl;\n    id subjid;\n  strata enum;\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAmor 2023. Eat, Sleep, R, Repeat.\nAmorim & Cai 2015. Modelling recurrent events: a tutorial for analysis in epidemiology. International Journal of Epidemiology. 2015 Feb;44(1):324-33.\nAndersen & Gill 1982. Cox’s Regression Model for Counting Processes: A Large Sample Study. The Annals of Statistics. 10(4):1100–1120.\nbladder data\nLu & Shen 2018. Application of Survival Analysis in Multiple Events Using SAS. PharmaSUG 2018.\nOzga et al. 2018. A systematic comparison of recurrent event models for application to composite endpoints. BMC Medical Research Methodoly. 2018 Jan 4;18(1):2.\nPrentice, Williams & Peterson 1981. On the Regression Analysis of Multivariate Failure Time Data. Biometrika. 68(2):373–379.\nsurvival package\nWei, Lin & Weissfeld 1989. Regression Analysis of Multivariate Incomplete Failure Time Data by Modeling Marginal Distributions. Journal of the American Statistical Association. 84(408):1065–1073."
  },
  {
    "objectID": "SAS/recurrent_events.html#modelling-recurrent-events",
    "href": "SAS/recurrent_events.html#modelling-recurrent-events",
    "title": "SAS Recurrent Events",
    "section": "",
    "text": "Traditionally, survival analysis focuses on the time to a single first event. While there are many applications for such time-to-event analysis in clinical trials, this approach falls short when events of interest can occur multiple times within the same subject. Recurrent event models extend the traditional Cox proportional hazards framework to account for multiple events per subject (Ozga et al. 2018, Amorim et al. 2015).\nIn this tutorial, we will demonstrate how to implement different recurrent event models in SAS, specifically the Andersen-Gill, proportional means/rates (Lin-Wei-Yang-Ying,) Prentice-Williams-Peterson, and Wei-Lin-Weissfeld models. The SAS code follows the layout of Amor 2023, with additional insights taken from Lu et al. 2018.\nRecurrent event models can roughly be divided in three categories: counting process models, conditional models and marginal models. In the section below, we will explore the difference between each of these approaches. In addition, important aspects of data structure will be discussed by means of two fictional subjects, one with 4 events and 0 censored observations (events at time 6, 9, 56 and 88), and another with 2 events and 1 censored observation (events at time 42, 57, and censored at time 91).\nDefine the following:\n\n\n\n\n\n\nNote\n\n\n\n\\(\\lambda_i(t)\\): hazard function for the \\(i\\)th subject at time \\(t\\)\n\\(\\lambda_{ij}(t)\\): hazard function for the \\(j\\)th event of the \\(i\\)th subject at time \\(t\\)\n\\(\\lambda_0(t)\\): common baseline hazard for all events\n\\(\\lambda_{0j}(t)\\): event-specific baseline hazard for the \\(j\\)th event at time \\(t\\)\n\\(\\beta\\): common parameter vector\n\\(\\beta_j\\): event-specific parameter vector for the \\(j\\)th event\n\\(X_{ij}\\): covariate vector for the \\(j\\)th event of the \\(i\\)th subject\n\n\n\n\n\n\n\n\\[\n\\lambda_i(t) = \\lambda_0(t) \\exp \\left( \\beta X_{ij}(t) \\right) \\\n\\]\n\nCounting process approach: treats each subject as a multiple events counting process\nCommon baseline hazard \\(\\lambda_0(t)\\)\nCommon regression coefficients \\(\\beta\\)\nUnrestricted risk set: a subject contributes to the risk set for an event as long as the subject is under observation, i.e. it can be at risk for a subsequent event even though the previous event did not yet occur\nOrder of events is not important\n\nAn essential assumption of the Andersen-Gill model is that of independent events within subjects. This, however, is often not realistic in clinical trial data. For example, let’s say that we are modelling myocardial infarction (MI). If a patient has already experienced one MI, their risk of subsequent events may increase due to underlying cardiovascular damage or presence of other risk factors. Thus, the more events a patient has, the more likely they are to experience future events, indicating dependence rather than independence. To accurately model this within-subject correlation, extensions like time-varying covariates, a robust sandwich covariance estimator or frailty terms may be needed. In this tutorial, we will discuss the sandwich correction.\nLin-Wei-Yang-Ying (LWYY) model or proportional means/rates model (Lei, Wei, Yang & Ying 2000)\nLin, Wei, Yang & Ying introduced an improved version of the Andersen-Gill model in 2000 (often referred to as proportional means/rates model), featuring a robust sandwich estimator that explicitly accounts for individual subject clusters. These robust standard errors yield wider confidence intervals and provide asymptotically valid inference even when the independence assumption does not hold (Lee et al. 2025). The original and improved Andersen-Gill model often appear interchangeable in the literature, and while they produce identical estimates, their robust standard errors can differ substantially, which may impact the conclusions drawn from statistical inference.\nFor both versions of the Andersen-Gill model, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(6, 9]\n1\n1\n\n\n1\n(9, 56]\n1\n1\n\n\n1\n(56, 88]\n1\n1\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(42, 87]\n1\n1\n\n\n2\n(87, 91]\n0\n1\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nIn both versions of the Andersen-Gill model, each new time interval starts where the previous one ends.\n\n\n\n\n\n\n\nConditional approach: incorporates conditional strata to account for ordering/dependence of events\nStratified baseline hazard \\(\\lambda_{0j}(t)\\)\nStratified regression coefficients \\(\\beta_j\\): can be pooled (\\(\\beta\\)) or kept as event-specific (\\(\\beta_j\\)) in the output\nRestricted risk set: contributions to the risk set for a subsequent event are restricted to only consider subjects that already experienced the previous event\nOrder of events is important\n\nThe Prentice-Williams-Peterson model can incorporate both overall and event-specific effects \\(\\beta_j\\) for each covariate. An often made assumption is to set \\(\\beta_1 = \\beta_2 = ... = \\beta_k = \\beta\\) to estimate a common parameter \\(\\beta\\).\nDepending on the outcome of interest, Prentice, Williams and Peterson suggested two distinct models:\n\nTotal time model\n\n\\[\n\\lambda_{ij}(t) = \\lambda_{0j}(t) \\exp \\left( \\beta_j X_{ij}(t) \\right) \\\n\\]\nThe total time variant of the Prentice-Williams-Peterson model uses the same time intervals as the counting process approach (Andersen-Gill model), which is useful for modelling the full time course (\\(t\\)) of the recurrent event process, i.e. the hazard of any recurrence.\nFor the total time model, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(6, 9]\n1\n2\n\n\n1\n(9, 56]\n1\n3\n\n\n1\n(56, 88]\n1\n4\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(42, 87]\n1\n2\n\n\n2\n(87, 91]\n0\n3\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nAgain, in the total time model, each new time intervals starts where the previous one ends.\n\nGap time model\n\n\\[\n\\lambda_{ij}(t) = \\lambda_{0j}(t - t_{j-1}) \\exp \\left( \\beta_j X_{ij}(t) \\right) \\\n\\]\nThe gap time variant of the Prentice-Williams-Peterson model uses time intervals that start at zero and end at the length of time until the next event, which is useful for modelling the time between each of the recurring events (\\(t - t_{j-1}\\)), i.e. the hazard of recurrence after the previous event.\nFor the gap time model, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(0, 3]\n1\n2\n\n\n1\n(0, 47]\n1\n3\n\n\n1\n(0, 32]\n1\n4\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(0, 45]\n1\n2\n\n\n2\n(0, 3]\n0\n3\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nIn the gap time model, each time interval starts at zero and has a length equal to the gap time between two neighboring events.\n\n\n\n\n\n\n\\[\n\\lambda_{ij}(t) = \\lambda_{0j}(t) \\exp \\left( \\beta_j X_{ij}(t) \\right) \\\n\\]\n\nMarginal approach: treats each (recurrent) event as having a separate, marginal process\nStratified baseline hazard \\(\\lambda_{0j}(t)\\)\nSemi-restricted risk set: all subjects contribute follow-up times to all potential events, i.e. each subject is at risk for all potential events, regardless of how many events that subject actually experiences\nOrder of events is not important\n\nAlthough the Wei-Lin-Weissfeld model has it roots in competing risks analysis, it conveniently lends itself to model recurrent events as well. Like the Andersen-Gill model, the Wei-Lin-Weissfeld model also assumes independence of events, which is often not feasible in practice. In addition, it is assumed there is no specific order among the events or that the events are different types of events, and not necessarily recurrent events.\nLike the Prentice-Williams-Peterson models, the Wei-Lin-Weissfeld model can incorporate both overall and event-specific effects \\(\\beta_j\\) for each covariate. An often made assumption is to set \\(\\beta_1 = \\beta_2 = ... = \\beta_k = \\beta\\) to estimate a common parameter \\(\\beta\\). Another approach is to combine event-specific effects \\(\\beta_j\\) to get an estimator of the average treatment effect, as described in Wei, Lin & Weissfeld 1989 (this is not discussed further here).\nFor Wei-Lin-Weissfeld models, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(0, 9]\n1\n2\n\n\n1\n(0, 56]\n1\n3\n\n\n1\n(0, 88]\n1\n4\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(0, 87]\n1\n2\n\n\n2\n(0, 91]\n0\n3\n\n\n2\n(0, 91]\n0\n4\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nIn the Wei-Lin-Weissfeld model, each time intervals starts at zero and ends at its respective event time.\n\n\n\n\nIn summary, the selection of the model to use would depend on the type of events, the importance of the order of the events and the time intervals to be analyzed. We made an effort to summarize the similarities and differences between the models in the table below.\n\n\n\n\n\n\n\n\n\n\n\nAG\nPWPtt\nPWPgt\nWLW\n\n\n\n\nApproach\ncounting process\nconditional\nconditional\nmarginal\n\n\nBaseline hazard\ncommon\nstratified\nstratified\nstratified\n\n\nRegression coefficients\ncommon\nstratified possible\nstratified possible\nstratified possible\n\n\nRisk set\nunrestricted\nrestricted\nrestricted\nsemi-restricted\n\n\nTime interval\ntotal time\ntotal time\ngap time\ntotal time\n\n\nOrder of events\nnot important\nimportant\nimportant\nnot important\n\n\nHazard ratio (HR)\nrisk of any recurrence\nrisk of any recurrence\nrisk of recurrence after previous event\nrisk of event of any type, not necessarily recurrent event\n\n\n\nNote that, because the ordering of events is not important in the Andersen-Gill and Wei-Lin-Weissfeld model, these models come with the assumption of independence of events. In contrast, the Prentice-Williams-Peterson models overcome the need for this assumption by capturing the dependence structure between recurrent events in conditional strata. Consequently, events are assumed to be conditionally independent in the Prentice-Williams-Peterson models.\nA nice visual representation of the stratification and time interval structure of each model is given below. The correct data structure is pivotal when modelling recurrent events and depends on the methodology you want to use, as illustrated in the figure."
  },
  {
    "objectID": "SAS/recurrent_events.html#modelling-recurrent-events-using-the-survival-package",
    "href": "SAS/recurrent_events.html#modelling-recurrent-events-using-the-survival-package",
    "title": "SAS Recurrent Events",
    "section": "",
    "text": "For this tutorial we will use the bladder data from the survival R package, which captures recurrences of bladder cancer from a clinical trial for an oncolytic called thiotepa. The bladder data is regularly used by many statisticians to demonstrate methodology for recurrent event modelling. Somewhat confusingly, there are three versions of this data available:\n\nbladder1: original data from the study on all subjects (294 records)\nbladder2: data in Andersen-Gill format on subset of subjects with nonzero follow-up time (178 records)\nbladder: data in Wei-Lin-Weissfeld format on subset of subjects with nonzero follow-up time (340 records)\n\nFor this tutorial, we will use bladder2 to illustrate Andersen-Gill and Prentice-Williams-Peterson models, and bladder to illustrate the Wei-Lin-Weissfeld model.\nThe variables included in both datasets are:\n\nid: patient id\nrx: treatment group (1 = placebo, 2 = thiotepa)\nnumber: initial number of tumors (8 = 8 or more)\nsize: size in cm of largest initial tumor\nstart: start of time interval; this variable is not present in bladder\nstop: (recurrent) event or censoring time\nevent: event indicator (1 = event, 0 = censored)\nenum: order of recurrence\n\nImportantly, both datasets collect the data in a counting process structure. This means that there is one record for each subject and time interval, where a time interval is defined as the time to its respective event (event = 1), or the time to follow-up if the event did not occur (event = 0).\nLet’s look more closely at the bladder2 and bladder data:\n\nbladder2 &lt;- survival::bladder2\ngt(head(bladder2, 6))\n\n\n\n\n\n\n\nid\nrx\nnumber\nsize\nstart\nstop\nevent\nenum\n\n\n\n\n1\n1\n1\n3\n0\n1\n0\n1\n\n\n2\n1\n2\n1\n0\n4\n0\n1\n\n\n3\n1\n1\n1\n0\n7\n0\n1\n\n\n4\n1\n5\n1\n0\n10\n0\n1\n\n\n5\n1\n4\n1\n0\n6\n1\n1\n\n\n5\n1\n4\n1\n6\n10\n0\n2\n\n\n\n\n\n\n\n\nbladder2 %&gt;%\n  group_by(enum) %&gt;% summarise(n = n()) %&gt;% gt()\n\n\n\n\n\n\n\nenum\nn\n\n\n\n\n1\n85\n\n\n2\n46\n\n\n3\n27\n\n\n4\n20\n\n\n\n\n\n\n\nIn bladder2, in the Andersen-Gill format, each subject has a variable amount of records, depending on the amount of events that subject experienced.\n\nbladder &lt;- survival::bladder\ngt(head(bladder, 20))\n\n\n\n\n\n\n\nid\nrx\nnumber\nsize\nstop\nevent\nenum\n\n\n\n\n1\n1\n1\n3\n1\n0\n1\n\n\n1\n1\n1\n3\n1\n0\n2\n\n\n1\n1\n1\n3\n1\n0\n3\n\n\n1\n1\n1\n3\n1\n0\n4\n\n\n2\n1\n2\n1\n4\n0\n1\n\n\n2\n1\n2\n1\n4\n0\n2\n\n\n2\n1\n2\n1\n4\n0\n3\n\n\n2\n1\n2\n1\n4\n0\n4\n\n\n3\n1\n1\n1\n7\n0\n1\n\n\n3\n1\n1\n1\n7\n0\n2\n\n\n3\n1\n1\n1\n7\n0\n3\n\n\n3\n1\n1\n1\n7\n0\n4\n\n\n4\n1\n5\n1\n10\n0\n1\n\n\n4\n1\n5\n1\n10\n0\n2\n\n\n4\n1\n5\n1\n10\n0\n3\n\n\n4\n1\n5\n1\n10\n0\n4\n\n\n5\n1\n4\n1\n6\n1\n1\n\n\n5\n1\n4\n1\n10\n0\n2\n\n\n5\n1\n4\n1\n10\n0\n3\n\n\n5\n1\n4\n1\n10\n0\n4\n\n\n\n\n\n\n\n\nbladder %&gt;%\n  group_by(enum) %&gt;% summarise(n = n()) %&gt;% gt()\n\n\n\n\n\n\n\nenum\nn\n\n\n\n\n1\n85\n\n\n2\n85\n\n\n3\n85\n\n\n4\n85\n\n\n\n\n\n\n\nIn bladder, in the Wei-Lin-Weissfeld format, each subject has four records, regardless of how many events that subject actually experienced. In addition, there is no start variable, as all time intervals start at zero.\nNote: The variables id, start and stop were renamed to subjid, tstart and tstop to avoid using SAS key words as variable names.\n\n\n\nIn SAS, any survival analysis based on the Cox proportional hazard model can be conducted using the phreg procedure. Hence, conveniently, when modelling time-to-event data with recurrent events, the same procedure can be used. The caveat here is that an adequate data structure is required, which must be in correspondence with the model you want to use.\nIn this section of the tutorial, we will explain how the arguments of the phreg procedure and data structure must be defined to fit every type of recurrent event model correctly.\n\n\n\nImproved Andersen-Gill model (LWYY model or proportional means/rates model)\n\nFor the improved version of the Andersen-Gill model you must include:\n\nproc phreg data=bladder2 covs(aggregate)\nmodel (tstart, tstop) * event(0) = 'predictors';\nid subjid;\n\nAnd the data structure must be:\n\n\n\nSubjid\nTime interval\nTstart\nTstop\nEvent\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n\n\n2\n(0, 4]\n0\n4\n0\n\n\n3\n(0, 7]\n0\n7\n0\n\n\n4\n(0, 10]\n0\n10\n0\n\n\n5\n(0, 6]\n0\n6\n1\n\n\n5\n(6, 10]\n6\n10\n0\n\n\n\nWe will use the bladder2 data for this.\n\nproc phreg data=bladder2 covs(aggregate);\n    class rx (ref='1');\n    model (tstart, tstop) * event(0) = rx size number /rl;\n    id subjid;\nrun;\n\n\n\n\n\n\n\n\n\n\nBy including the covs(aggregate) option and setting id subjid;, SAS will compute a robust sandwich covariance and display robust standard error estimates in the output. Under the hood, the robust standard errors will consider all subjid clusters separately and ultimately sum up the score residuals for each distinct cluster.\n\nOriginal Andersen-Gill model\n\nThe original Andersen-Gill model of 1989 can be fitted by changing covs(aggregate) to covs in the procedure, while excluding id subjid;.\n\nproc phreg data=bladder2 covs;\n    class rx (ref='1');\n    model (tstart, tstop) * event(0) = rx size number /rl;\nrun;\n\n\n\n\n\n\n\n\n\n\nAlthough the original Andersen-Gill model does not consider separate subjid clusters, it still computes robust standard errors using the sandwich estimator. The resulting robust standard errors differ from those provided for the improved Andersen-Gill model, while the estimated coefficients remain perfectly unchanged.\n\n\n\nTotal time model\nFor the Prentice-Williams-Peterson total time model you must include:\n\nproc phreg data=bladder2 covs(aggregate);\nmodel (tstart, tstop) * event(0) = 'predictors';\nid subjid;\nstrata enum;\n\nAnd the data structure must be:\n\n\n\nSubjid\nTime interval\nTstart\nTstop\nEvent\nEnum\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n1\n\n\n2\n(0, 4]\n0\n4\n0\n1\n\n\n3\n(0, 7]\n0\n7\n0\n1\n\n\n4\n(0, 10]\n0\n10\n0\n1\n\n\n5\n(0, 6]\n0\n6\n1\n1\n\n\n5\n(6, 10]\n6\n10\n0\n2\n\n\n\nWe will use the bladder2 data for this.\n\nproc phreg data=bladder2 covs(aggregate);\n    class rx (ref='1');\n    model (tstart, tstop) * event(0) = rx size number /rl; \n    id subjid;\n    strata enum;\nrun;\n\n\n\n\n\n\n\n\n\n\nThe conditional strata of the Prentice-Williams-Peterson model are set by strata enum; in the formula, where enum captures the ordering of recurrent events.\nGap time model\nFor the Prentice-Williams-Peterson gap time model you must include:\n\nproc phreg data=bladder2 covs(aggregate);\nmodel gtime * event(0) = 'predictors';\nid subjid;\nstrata enum;\n\nAnd the data structure must be:\n\n\n\nSubjid\nTime interval\nTstart\nTstop\nEvent\nEnum\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n1\n\n\n2\n(0, 4]\n0\n4\n0\n1\n\n\n3\n(0, 7]\n0\n7\n0\n1\n\n\n4\n(0, 10]\n0\n10\n0\n1\n\n\n5\n(0, 6]\n0\n6\n1\n1\n\n\n5\n(0, 4]\n0\n4\n0\n2\n\n\n\nThis data structure can be achieved in bladder2 by adding a gtime variable.\n\ndata bladder2;\n    set bladder2;\n    gtime = tstop - tstart;\nrun;\n\nWe artificially set start = 0 for each gap time interval by including gtime instead of (start, stop) in the model statement.\n\nproc phreg data=bladder2 covs(aggregate);\n    class rx (ref='1');\n    model gtime * event(0) = rx size number/rl; \n    id subjid;\n    strata enum;\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor the Wei-Lin-Weissfeld model you must include:\n\nproc phreg data=bladder covs(aggregate);\nmodel tstop * event(0) = 'predictors';\nid subjid;\nstrata enum;\n\nAnd the data structure must be:\n\n\n\nSubjid\nTime interval\nTstart\nTstop\nEvent\nEnum\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n1\n\n\n1\n(0, 1]\n0\n1\n0\n2\n\n\n1\n(0, 1]\n0\n1\n0\n3\n\n\n1\n(0, 1]\n0\n1\n0\n4\n\n\n2\n(0, 4]\n0\n4\n0\n1\n\n\n2\n(0, 4]\n0\n4\n0\n2\n\n\n2\n(0, 4]\n0\n4\n0\n3\n\n\n2\n(0, 4]\n0\n4\n0\n4\n\n\n3\n(0, 7]\n0\n7\n0\n1\n\n\n3\n(0, 7]\n0\n7\n0\n2\n\n\n3\n(0, 7]\n0\n7\n0\n3\n\n\n3\n(0, 7]\n0\n7\n0\n4\n\n\n4\n(0, 10]\n0\n10\n0\n1\n\n\n4\n(0, 10]\n0\n10\n0\n2\n\n\n4\n(0, 10]\n0\n10\n0\n3\n\n\n4\n(0, 10]\n0\n10\n0\n4\n\n\n5\n(0, 6]\n0\n6\n1\n1\n\n\n5\n(0, 10]\n0\n10\n0\n2\n\n\n5\n(0, 10]\n0\n10\n0\n3\n\n\n5\n(0, 10]\n0\n10\n0\n4\n\n\n\nWe will use the bladder data for this.\n\nproc phreg data=bladder covs(aggregate);\n    class rx (ref='1');\n    model tstop * event(0) = rx size number /rl;\n    id subjid;\n  strata enum;\nrun;\n\n\n\n\n\n\n\n\n\n\nImportantly, the strata of the Wei-Lin-Weissfeld model as set by strata enum; are substantially different from the conditional strata of the Prentice-Williams-Peterson model. The enum variable is now no longer assumed to be an ordinal variable.\n\n\n\nNote: The rl option ensures the 95% confidence interval for the hazard ratio is displayed.\nNote: If you want to display non-robust, model-based standard errors (like the ones given by default in R), you can do this by adding covm to the procedure statement.\nNote: It may be useful to look at the Summary of the Number of Event and Censored Values to check whether the data stratification was rightly specified for your model. Examples for the Prentice-Williams-Peterson and Wei-Lin-Weissfeld models are given below.\nSummary for Prentice-Williams-Peterson models:\n\n\n\n\n\n\n\n\n\nSummary for Wei-Lin-Weissfeld model:\n\n\n\n\n\n\n\n\n\nNote: R uses ties = \"efron\" by default, while SAS uses ties = breslow by default. If this argument remains unchanged in both software, it can cause differences in outcome. For more information, be sure to check the CAMIS webpage on the comparison of Cox proportional hazards models in R and SAS.\n\n\n\n\nIn terms of interpretation, hazard ratios (\\(\\exp(\\beta_j)\\)) are often used when making inferences based on Cox proportional hazards models. Now, as you may remember from the overview presented earlier, it is important to recognize that each of the recurrent event models comes with a slightly different interpretation of the hazard ratio, as defined by the assumptions around the model.\n\n\n\n\n\n\n\n\n\n\n\nAG\nPWPtt\nPWPgt\nWLW\n\n\n\n\nHazard ratio (HR)\nrisk of any recurrence\nrisk of any recurrence\nrisk of recurrence after previous event\nrisk of event of any type, not necessarily recurrent event\n\n\n\nThis means that, for the bladder data, we can draw slightly different conclusions on the hazard ratio of the group treated with thiotepa (rx = 2) versus the placebo group (rx = 1).\n\n\n\nModel\nHR: rx2 vs rx1\n95% CI\nP-value\n\n\n\n\nAG\n0.631\n0.381 to 1.047\n0.0747\n\n\nOriginal AG\n0.631\n0.403 to 0.989\n0.0447\n\n\nPWPtt\n0.716\n0.486 to 1.053\n0.0898\n\n\nPWPgt\n0.764\n0.508 to 1.148\n0.1952\n\n\nWLW\n0.560\n0.309 to 1.015\n0.0560\n\n\n\nThese conclusions are:\n\nAndersen-Gill: the risk of having any new tumor recurrence in the treatment group is 0.631 (0.381 - 1.047) times that of the placebo group\nPrentice-Williams-Peterson: total time: the risk of having any new tumor recurrence in the treatment group is 0.716 (0.486 - 1.053) times that of the placebo group\nPrentice-Williams-Peterson: gap time: the risk of having a new tumor recurrence after a previous event in the treatment group is 0.764 (0.508 - 1.148) times that of the placebo group\nWei-Lin-Weissfeld: the risk of having any type of event in the treatment group is 0.560 (0.309 - 1.015) times that of the placebo group\n\nNote: The improved Andersen-Gill model (LWYY model or proportional means/rates model) is preferred over the original Andersen-Gill model.\n\n\n\nFor the Prentice-Williams-Peterson and Wei-Lin-Weissfeld models we can incorporate both overall (\\(\\beta\\)) and event-specific (\\(\\beta_j\\)) effects for each covariate. To arrive at pooled model parameters these models assume that \\(\\beta_1 = \\beta_2 = ... = \\beta_k = \\beta\\). Until now, we have only considered pooled model parameters, but given the underlying stratification of these two models in particular, it may be valuable to look into the event-specific estimates as well (Amorim & Cai 2015).\nTo get event-specific estimates for the treatment effect (rx), we first need to introduce four new rx variables to the bladder2 and bladder datasets, one for each stratum.\n\ndata bladder2;\n    set bladder2;\n    rx_enum1 = rx*(enum=1);\n    rx_enum2 = rx*(enum=2);\n    rx_enum3 = rx*(enum=3);\n    rx_enum4 = rx*(enum=4);\nrun;\n\n\ndata bladder;\n    set bladder;\n    rx_enum1 = rx*(enum=1);\n    rx_enum2 = rx*(enum=2);\n    rx_enum3 = rx*(enum=3);\n    rx_enum4 = rx*(enum=4);\nrun;\n\nWith these four interaction variables, we need to specify rx_enum1-rx_enum4 in the formula and set class enum / param=glm; to output the event-specific estimates.\n\n\nTotal time model\n\nproc phreg data=bladder2 covs(aggregate);\n    class enum / param=glm;\n    model (tstart, tstop) * event(0) = rx_enum1-rx_enum4 size number /rl; \n    id subjid;\n    strata enum;\nrun;\n\n\n\n\n\n\n\n\n\n\nGap time model\n\nproc phreg data=bladder2 covs(aggregate);\n    class enum / param=glm;\n    model gtime * event(0) = rx_enum1-rx_enum4 size number/rl; \n    id subjid;\n    strata enum;\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nproc phreg data=bladder covs(aggregate);\n    class enum / param=glm;\n    model tstop * event(0) = rx_enum1-rx_enum4 size number /rl;\n    id subjid;\n  strata enum;\nrun;"
  },
  {
    "objectID": "SAS/recurrent_events.html#references",
    "href": "SAS/recurrent_events.html#references",
    "title": "SAS Recurrent Events",
    "section": "",
    "text": "Amor 2023. Eat, Sleep, R, Repeat.\nAmorim & Cai 2015. Modelling recurrent events: a tutorial for analysis in epidemiology. International Journal of Epidemiology. 2015 Feb;44(1):324-33.\nAndersen & Gill 1982. Cox’s Regression Model for Counting Processes: A Large Sample Study. The Annals of Statistics. 10(4):1100–1120.\nbladder data\nLu & Shen 2018. Application of Survival Analysis in Multiple Events Using SAS. PharmaSUG 2018.\nOzga et al. 2018. A systematic comparison of recurrent event models for application to composite endpoints. BMC Medical Research Methodoly. 2018 Jan 4;18(1):2.\nPrentice, Williams & Peterson 1981. On the Regression Analysis of Multivariate Failure Time Data. Biometrika. 68(2):373–379.\nsurvival package\nWei, Lin & Weissfeld 1989. Regression Analysis of Multivariate Incomplete Failure Time Data by Modeling Marginal Distributions. Journal of the American Statistical Association. 84(408):1065–1073."
  },
  {
    "objectID": "SAS/ttest_2Sample.html",
    "href": "SAS/ttest_2Sample.html",
    "title": "Independant Two-Sample t-test",
    "section": "",
    "text": "Data Used\nThe following data was used in this example.\n\ndata d1;\n    length trt_grp $ 9;\n    input trt_grp $ WtGain @@;\n    datalines;\nplacebo    94 placebo    12 placebo    26 placebo    89 \nplacebo    88 placebo    96 placebo    85 placebo   130 \nplacebo    75 placebo    54 placebo   112 placebo    69 \nplacebo   104 placebo    95 placebo    53 placebo    21 \ntreatment  45 treatment  62 treatment  96 treatment 128 \ntreatment 120 treatment  99 treatment  28 treatment  50 \ntreatment 109 treatment 115 treatment  39 treatment  96 \ntreatment  87 treatment 100 treatment  76 treatment  80 \n;\nrun;\n\n\n\nIndependent Two-Sample t-test in SAS\nThe null hypothesis of the Independent Samples t-test is, the means for the two populations are equal.\nIn SAS the following code was used to test the mean comparison (mean of Weight Gain) of two independent treatment groups (Treatment and Placebo).\nFor this example, we’re testing the significant difference in mean of Weight gain (WtGain) between treatment and placebo (trt_grp) using PROC TTEST procedure in SAS.\n\nproc ttest data=d1; \n    class trt_grp; \n    var WtGain; \nrun; \n\nOutput:\n             Figure 1: Test results for independent t-test using PROC TTEST in SAS\n\n\n\n\n\n\n\n\n\nHere the t-value is –0.70, degrees of freedom is 30 and P value is 0.4912 which is greater than 0.05, so we accept the null hypothesis that there is no evidence of a significant difference between the means of treatment groups. The mean in placebo group is 75.1875 and mean in Treatment group is 83.1250. The mean difference the treatment groups (Treatment-Placebo) is –7.9375 and the 95% CI for the mean difference is [–31.1984, 15.3234]. The 95% confidence interval includes a treatment difference of 0, which supports the conclusion that the data fail to provide any evidence of a difference between the treatment groups.\n\n\nModel Checking\nNote: Before entering straight into the t-test we need to check whether the assumptions (like the equality of variance, the observations should be independent, observations should be normally distributed) are met or not. If normality is not satisfied, we may consider using a suitable non-parametric test.\n\nNormality: You can check for data to be normally distributed by plotting a histogram of the data by treatment. Alternatively, you can use the Shapiro-Wilk test or the Kolmogorov-Smirnov test. If the test is &lt;0.05 and your sample is quite small then this suggests you should not use the t-test. However, if your sample in each treatment group is large (say &gt;30 in each group), then you do not need to rely so heavily on the assumption that the data have an underlying normal distribution in order to apply the two-sample t-test. This is where plotting the data using histograms can help to support investigation into the normality assumption. We have checked the normality of the observations using the code below. Here for both the treatment groups we have P value greater than 0.05 (Shapiro-Wilk test is used), therefore the normality assumption is there for our data.\n\n\nproc univariate data=d1 normal;  \n    qqplot WtGain; \n    by trt_grp; \nrun; \n\nOutput:\n        Figure 2: The results of normality test for Treatment group\n\n\n\n\n\n\n\n\n\n       Figure 3: The results of normality test for Placebo group\n\n\n\n\n\n\n\n\n\n\nHomogeneity of variance (or Equality of variance): Homogeniety of variance will be tested by default in PROC TTEST itself by Folded F-test. In our case the P values is 0.6981 which is greater than 0.05. So we accept the null hypothesis of F-test, i.e. variances are same. Then we will consider the pooled method for t-test. If the F test is statistically significant (p&lt;0.05), then the pooled t-test may give erroneous results. In this instance, if it is believed that the population variances may truly differ, then the Satterthwaite (unequal variances) analysis results should be used. These are provided in the SAS output alongside the Pooled results as default.\n\nOutput:\n                    Figure 4: Folded F-test result in PROC TTEST"
  },
  {
    "objectID": "SAS/sample_s_StatXact_test_of_trends.html",
    "href": "SAS/sample_s_StatXact_test_of_trends.html",
    "title": "Sample size for K ordered binomial populations - Cochran-Armitage trend test",
    "section": "",
    "text": "Cochran-Armitage trend test\nCochran-Armitage trend test (Cochran-Armitage Z-test) is used to check if there is a trend in proportions across levels of a categorical, ordered variable. It’s mostly used to analyse data where one variable is a binomial and the other is an ordinal variable. Basically, the test checks if the proportions vary in a specific direction (increasing or decreasing) when the ordered variable changes.\nIn the examples below we will calculate the extract and asymptotic powers and sample size of the Cochran-Armitage trend test. Analysis is not available in SAS and need to be run in StatXact PROC (module to SAS from Cytel).\nThe below parameters are need for the calculations:\n\nω_i - dose level/exposure for he i-th group\nn_i - number of subjects in i-th group\nπ_1 - baseline response probability\nπ_i - response (binomial) probability for i-th group\nλ (lambda) - slope for the logit model, can be interpreted as change in the log-odds of response per unit increase in dose\nα - significance level for one-sided trend test\nβ - required power\n\nIn StatXact we can directly specify all of the response probabilities, or we can specify the baseline probability and use the below logit model with prespecified slope lambda to derive the rest:\n\n\n\n\n\n\n\n\n\n\nExample 1 - Power for dose finding pilot study\nLet’s consider an example of a dose-finding phase I clinical trial of patients with advanced chronic disease. At the lowest dose level the response probability is known to be 0.001. The drug will be considered useful if the log odds of response increase by 0.5 per unit increase in dose (that defines the lambda). The study design assumes doubling the dose up to maximum of 16 units. Sample sizes of 10, 10, 10, 5 and 2, are proposed for the five dose levels, to restrict the total number of subjects at the two highest dose levels due to possible side effects. A one-sided Cochran-Armitage trend test at the 2.5% significance level will performed at the end of the study. What is the power?\nDesign parameter are as below:\n\n\n\n\n\n\n\n\n\nSAS code:\n\nproc sxpowerbin;\n    tr/ex;\n    palpha 0.025;\n    k 5;\n    H0 0.001;\n    H1 logodds /val=0.5;\n    scores 1 2 4 8 16;\n    size1 10;\n    size2 10;\n    size3 10;\n    size4 5;\n    size5 2;\nrun;\n\nOutput from StatXact and results:\n\n\n\n\n\n\n\n\n\nThe exact power is 48%, whilst the asymptotic power is 84%. Here, using the asymptotic power would have led to a false sense of security concerning the adequacy of the proposed sample sizes for carrying out this pilot study.\n\n\nExample 2 - Power for cohort study of effects of low dose radiation\nLet’s consider an example of a long-term follow-up study of subjects exposed to low-dose radiation in Japan (adapted from Landis, Heyman and Koch, 1978). The cohort was partitioned into four groups based on average radiation exposures of 0, 5, 30 and 75 rads. There were 2500, 3600, 1450 and 410 subjects, respectively, in the four dose groups. Subjects were classified as responders if they died from leukemia and non-responders if they died from other causes. We want detect a trend parameter of 0.049 on the logit scale, given a background response rate of 1 in 10,000. A one-sided Cochran-Armitage trend test at the 5% significance level was performed at the end of the study. What was the power?\nDesign parameter are as below:\n\n\n\n\n\n\n\n\n\nSAS code:\n\nproc sxpowerbin;\n    tr/ex dist_file=tr;\n    palpha 0.05;\n    k 4;\n    H0 0.0001;\n    H1 logodds /val=0.049;\n    scores 0 5 30 75;\n    size1 2500;\n    size2 3600;\n    size3 1450;\n    size4 410;\nrun;\n\nOutput from StatXact and results:\n\n\n\n\n\n\n\n\n\nAsymptotic power of the test is 77%, a considerable overestimate of the actual power, 60%.\n\n\nExample 3 - Sample size calculation for trend test\nLet’s consider an example of the study where the design parameters are as below:\n\n\n\n\n\n\n\n\n\nWhat is the required sample size to achieve the power of 80% with the significance level 5%?\nSAS code:\n\nproc sxpowerbin ti =15;\n    tr/ex;\n    palpha 0.05;\n    beta 0.8;\n    k 5;\n    H0 0.10;\n    H1 user/val=0.13 0.16 0.19 0.22;\n    scores 0 1 2 4 8;\nrun;\n\n(option ti = 15 limits the maximum time of computation to 15 min)\nOutput from StatXact and results:\n\n\n\n\n\n\n\n\n\nSample size of 108 is needed to obtain the required power.\n\n\nReferences\nAll of the examples are adapted from StatXact 12 PROCs Manual."
  },
  {
    "objectID": "SAS/ttest_Paired.html",
    "href": "SAS/ttest_Paired.html",
    "title": "Paired t-test",
    "section": "",
    "text": "The Paired t-test is used when two samples are naturally correlated. In the Paired t-test, the difference of the means between the two samples is compared to a given number that represents the null hypothesis. For a Paired t-test, the number of observations in each sample must be equal.\nIn SAS, a Paired t-test is typically performed using PROC TTEST.\n\n\nBy default, SAS PROC TTEST t-test assumes normality in the data and uses a classic Student’s t-test.\n\n\nThe following data was used in this example.\n\ndata pressure;\n    input SBPbefore SBPafter @@;\n    datalines;\n  120 128   124 131   130 131   118 127\n  140 132   128 125   140 141   135 137\n  126 118   130 132   126 129   127 135\n  ;\n\n\n\n\nThe following code was used to test the comparison of two paired samples of Systolic Blood Pressure before and after a procedure.\n\nproc ttest data=pressure;\n    paired SBPbefore*SBPafter;\nrun;\n\nOutput:\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe SAS paired t-test also supports analysis of lognormal data. Here is the data used for the lognormal analysis.\n\n\n\ndata auc;\n    input TestAUC RefAUC @@;\n    datalines;\n  103.4 90.11  59.92 77.71  68.17 77.71  94.54 97.51\n  69.48 58.21  72.17 101.3  74.37 79.84  84.44 96.06\n  96.74 89.30  94.26 97.22  48.52 61.62  95.68 85.80\n  ;\n\n\n\n\nFor cases when the data is lognormal, SAS offers the “DIST” option to chose between a normal and lognormal distribution. The procedure also offers the TOST option to specify the equivalence bounds.\n\nproc ttest data=auc dist=lognormal tost(0.8, 1.25);\n    paired TestAUC*RefAUC;\nrun;\n\nOutput:\n\n\n\n\n\n\n\n\n\nAs can be seen in the figure above, the lognormal variation of the TTEST procedure offers additional results for geometric mean, coefficient of variation, and TOST equivalence analysis. The output also includes multiple p-values."
  },
  {
    "objectID": "SAS/ttest_Paired.html#normal",
    "href": "SAS/ttest_Paired.html#normal",
    "title": "Paired t-test",
    "section": "",
    "text": "By default, SAS PROC TTEST t-test assumes normality in the data and uses a classic Student’s t-test.\n\n\nThe following data was used in this example.\n\ndata pressure;\n    input SBPbefore SBPafter @@;\n    datalines;\n  120 128   124 131   130 131   118 127\n  140 132   128 125   140 141   135 137\n  126 118   130 132   126 129   127 135\n  ;\n\n\n\n\nThe following code was used to test the comparison of two paired samples of Systolic Blood Pressure before and after a procedure.\n\nproc ttest data=pressure;\n    paired SBPbefore*SBPafter;\nrun;\n\nOutput:"
  },
  {
    "objectID": "SAS/ttest_Paired.html#lognormal",
    "href": "SAS/ttest_Paired.html#lognormal",
    "title": "Paired t-test",
    "section": "",
    "text": "The SAS paired t-test also supports analysis of lognormal data. Here is the data used for the lognormal analysis.\n\n\n\ndata auc;\n    input TestAUC RefAUC @@;\n    datalines;\n  103.4 90.11  59.92 77.71  68.17 77.71  94.54 97.51\n  69.48 58.21  72.17 101.3  74.37 79.84  84.44 96.06\n  96.74 89.30  94.26 97.22  48.52 61.62  95.68 85.80\n  ;\n\n\n\n\nFor cases when the data is lognormal, SAS offers the “DIST” option to chose between a normal and lognormal distribution. The procedure also offers the TOST option to specify the equivalence bounds.\n\nproc ttest data=auc dist=lognormal tost(0.8, 1.25);\n    paired TestAUC*RefAUC;\nrun;\n\nOutput:\n\n\n\n\n\n\n\n\n\nAs can be seen in the figure above, the lognormal variation of the TTEST procedure offers additional results for geometric mean, coefficient of variation, and TOST equivalence analysis. The output also includes multiple p-values."
  },
  {
    "objectID": "SAS/anova.html",
    "href": "SAS/anova.html",
    "title": "ANOVA",
    "section": "",
    "text": "Getting Started\nTo demonstrate the various types of sums of squares, we’ll create a data frame called df_disease taken from the SAS documentation.\n\n\nThe Model\nFor this example, we’re testing for a significant difference in stem_length using ANOVA.\n\nproc glm data = disease;\n    class drug disease;\n    model y=drug disease drug*disease;\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\nSums of Squares Tables\nSAS has four types of sums of squares calculations. To get these calculations, the sum of squares option needs to be added (/ ss1 ss2 ss3 ss4) to the model statement.\n\nproc glm;\n    class drug disease;\n    model y=drug disease drug*disease / ss1 ss2 ss3 ss4;\nrun;\n\n\nType I\n\n\n\n\n\n\n\n\n\n\n\nType II\n\n\n\n\n\n\n\n\n\n\n\nType III\n\n\n\n\n\n\n\n\n\n\n\nType IV\n\n\n\n\n\n\n\n\n\n\n\n\nContrasts\nTo get contrasts in SAS, we use the estimate statement. For looking at contrast we are going to fit a different model on new data, that doesn’t include an interaction term as it is easier to calculate contrasts without an interaction term. For this dataset we have three different drugs A, C, and E.\n\nproc glm data=testdata;\n    class drug;\n    model post = drug pre / solution;\n    estimate 'C vs A'  drug -1  1 0;\n    estimate 'E vs CA' drug -1 -1 2;\nrun;\n\n\n\n\n\n\n\n\n\n\nReference: Sum of squares type I, II, and III"
  },
  {
    "objectID": "SAS/jonchkheere_terpstra.html",
    "href": "SAS/jonchkheere_terpstra.html",
    "title": "SAS Jonckheere-Terpstra Test",
    "section": "",
    "text": "The Jonckheere-Terpstra (JT) test is a nonparametric method designed to detect ordered differences across categories. It offers an advantageous alternative to more general tests for class differences, such as the Kruskal-Wallis test, particularly when the analysis is conducted using the WILCOXON option within the NPAR1WAY procedure. \\(^{[1]}\\)\nThe JT test is particularly well-suited for dose-response or trend analysis with ordered categorical data, where the objective is to ascertain whether an increment in dosage leads to a corresponding escalation or reduction in the response variable.\\(^{[2]}\\)\\(^{[5]}\\) Unlike other statistical evaluations that might focus on identifying isolated differences between groups, this test is specifically tailored to uncover an overarching trend within the data."
  },
  {
    "objectID": "SAS/jonchkheere_terpstra.html#background",
    "href": "SAS/jonchkheere_terpstra.html#background",
    "title": "SAS Jonckheere-Terpstra Test",
    "section": "",
    "text": "The Jonckheere-Terpstra (JT) test is a nonparametric method designed to detect ordered differences across categories. It offers an advantageous alternative to more general tests for class differences, such as the Kruskal-Wallis test, particularly when the analysis is conducted using the WILCOXON option within the NPAR1WAY procedure. \\(^{[1]}\\)\nThe JT test is particularly well-suited for dose-response or trend analysis with ordered categorical data, where the objective is to ascertain whether an increment in dosage leads to a corresponding escalation or reduction in the response variable.\\(^{[2]}\\)\\(^{[5]}\\) Unlike other statistical evaluations that might focus on identifying isolated differences between groups, this test is specifically tailored to uncover an overarching trend within the data."
  },
  {
    "objectID": "SAS/jonchkheere_terpstra.html#sas-procedure",
    "href": "SAS/jonchkheere_terpstra.html#sas-procedure",
    "title": "SAS Jonckheere-Terpstra Test",
    "section": "SAS Procedure",
    "text": "SAS Procedure\nTo request Jonckheere-Terpstra test, specify the JT option in the Table statement like below:\n#| eval: false\nproc freq; \n    table Var1 * Var2 / JT; \nQuit;\nThe JT option in the TABLES statement provides the Jonckheere-Terpstra test.\nPROC FREQ also provides exact p-values for the Jonckheere-Terpstra test. You can request the exact test by specifying the JT option in the EXACT statement.\\(^{[3]}\\)"
  },
  {
    "objectID": "SAS/jonchkheere_terpstra.html#data-used-1",
    "href": "SAS/jonchkheere_terpstra.html#data-used-1",
    "title": "SAS Jonckheere-Terpstra Test",
    "section": "Data used 1",
    "text": "Data used 1\nThis dataset has been generated using example data which aligned with the specifications outlined in the section on the Jonckheere–Terpstra test from reference [5]. It represents the duration of hospital stays for a randomly selected group of patients across three distinct ICU departments: cardiothoracic, medical, and neurosurgical.\n#| eval: false\ndata ICU_Stay;\n    input ICU $ Stay;\n    label Stay = 'Length of Stay in Days';\n    datalines;\nCardiothoracic 7\nMedical 4\nCardiothoracic 1\nMedical 7\nCardiothoracic 2\nMedical 16\nCardiothoracic 6\nMedical 11\nCardiothoracic 11\nMedical 21\nCardiothoracic 8\nNeurosurgical 20\nNeurosurgical 25\nNeurosurgical 13\nNeurosurgical 9\nNeurosurgical 14\nNeurosurgical 11\n;\nrun;\n\nproc sort data=ICU_Stay;\n    by ICU Stay;\nrun;"
  },
  {
    "objectID": "SAS/jonchkheere_terpstra.html#example-code-using-1",
    "href": "SAS/jonchkheere_terpstra.html#example-code-using-1",
    "title": "SAS Jonckheere-Terpstra Test",
    "section": "Example Code using 1",
    "text": "Example Code using 1\nThe code performs a frequency analysis on the ‘ICU_Stay’ dataset, examining the relationship between ‘ICU’ and ‘Stay’ variables. It applies the Jonckheere-Terpstra test using JT option to identify trends in the ordered categorical ‘Stay’ variable. The output is streamlined by omitting percentages and totals for columns and rows with the ‘nopercent nocol norow’ options, emphasizing the Jonckheere-Terpstra test outcomes.\n#| eval: false\nproc freq data=ICU_Stay; \n    table ICU * Stay / JT nopercent nocol norow; \nrun;"
  },
  {
    "objectID": "SAS/jonchkheere_terpstra.html#test-result-1",
    "href": "SAS/jonchkheere_terpstra.html#test-result-1",
    "title": "SAS Jonckheere-Terpstra Test",
    "section": "Test Result 1",
    "text": "Test Result 1\n\n\n\nTest Result 1\n\n\nComparing this with a standard Normal distribution gives a P value of 0.005, indicating that the increase in length of stay with ICU is significant, in the order cardiothoracic, medical and neurosurgical."
  },
  {
    "objectID": "SAS/jonchkheere_terpstra.html#data-used-2",
    "href": "SAS/jonchkheere_terpstra.html#data-used-2",
    "title": "SAS Jonckheere-Terpstra Test",
    "section": "Data used 2",
    "text": "Data used 2\nThis dataset incorporates illustrative data extracted from reference [3]. It encapsulates the responses of subjects randomly assigned to one of four treatment arms: placebo, low dosage(20mg), medium dosage(60mg), and high dosage(180mg). The variable of interest is a continuous measure. The variable ‘groupn’ is used to provide an order of ‘group’.\n#| eval: false\ndata contin;\n    input groupn group $  subject response;\n    cards;\n0 Placebo 01 27\n0 Placebo 02 28\n0 Placebo 03 27\n0 Placebo 04 31\n0 Placebo 05 34\n0 Placebo 06 32\n1 20mg 01 31\n1 20mg 02 35\n1 20mg 03 34\n1 20mg 04 32\n1 20mg 05 31\n1 20mg 06 33\n2 60mg 01 32\n2 60mg 02 33\n2 60mg 03 30\n2 60mg 04 34\n2 60mg 05 37\n2 60mg 06 36\n3 180mg 01 40\n3 180mg 02 39\n3 180mg 03 41\n3 180mg 04 38\n3 180mg 05 42\n3 180mg 06 43\n;\nrun;"
  },
  {
    "objectID": "SAS/jonchkheere_terpstra.html#example-code-using-2",
    "href": "SAS/jonchkheere_terpstra.html#example-code-using-2",
    "title": "SAS Jonckheere-Terpstra Test",
    "section": "Example Code using 2",
    "text": "Example Code using 2\nThe code is performing a Jonckheere-Terpstra trend test on a continuous ‘response’ variable, categorized by a ‘group’ variable, using the ‘proc freq’ procedure. The analysis is applied to the dataset named ‘contin’. The result is presented with a title “Jonckheere-Terpstra Trend Test for Continuous Data”, indicating the specific nature of the test being conducted. The ‘JT’ option is used to specify the Jonckheere-Terpstra test.\n#| eval: false\nproc freq data=contin; \n    tables group * response/JT; \n    title \"Jonckheere-Terpstra Trend Test for Continuous Data\"; \nrun;"
  },
  {
    "objectID": "SAS/jonchkheere_terpstra.html#test-result-2",
    "href": "SAS/jonchkheere_terpstra.html#test-result-2",
    "title": "SAS Jonckheere-Terpstra Test",
    "section": "Test Result 2",
    "text": "Test Result 2\n\n\n\nTest Result 2\n\n\nThere is a significant trend across different groups in the response gives a P value of &lt;.0001."
  },
  {
    "objectID": "SAS/jonchkheere_terpstra.html#exact-options",
    "href": "SAS/jonchkheere_terpstra.html#exact-options",
    "title": "SAS Jonckheere-Terpstra Test",
    "section": "EXACT Options",
    "text": "EXACT Options\nWith EXACT statement, the exact version and it Monte Carlo approximation can be also conducted. However, it should be noted that the exact test, i.e., a permuation test takes a long time to compelete the task even for a small dataset.\n#| eval: false\nproc freq data = inds;\n    title \"Asymptotic p-value calculation\";\n    table ICU * Stay / jt;\n    ods output JTTest = o_jt;\nrun;\n\nproc freq data = inds;\n  title \"Approximation of exact test by resampling\";\n  table ICU * Stay / jt;\n  exact jt / mc seed = 4989 n = 10000 alpha = 0.05;\n  ods output JTTestMC = o_jt_sim;\nrun;"
  },
  {
    "objectID": "SAS/jonchkheere_terpstra.html#conclusion",
    "href": "SAS/jonchkheere_terpstra.html#conclusion",
    "title": "SAS Jonckheere-Terpstra Test",
    "section": "Conclusion",
    "text": "Conclusion\nThe JT test is particularly useful in scenarios such as dose-response studies in pharmacology, where the interest lies in whether increasing doses of a drug lead to a monotonic increase in the response."
  },
  {
    "objectID": "SAS/jonchkheere_terpstra.html#reference",
    "href": "SAS/jonchkheere_terpstra.html#reference",
    "title": "SAS Jonckheere-Terpstra Test",
    "section": "Reference",
    "text": "Reference\n[1] SAS Institute Inc. (n.d.). SAS Help Center. Retrieved August 7, 2024, from https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.5/statug/statug_freq_details77.htm\n[2] Pennsylvania State University. (n.d.). 11.4 - Safety and Efficacy (Phase II) Studies: Trend Analysis. In STAT 509: Advanced Statistics for the Health Sciences. Retrieved August 7, 2024, from https://online.stat.psu.edu/stat509/lesson/11/11.4\n[3] SAS Institute Inc. (n.d.). FREQ Procedure: Syntax. In SAS/STAT 14.2 User’s Guide. Retrieved August 7, 2024, from https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.5/statug/statug_freq_syntax08.htm\n[4] Park, C., Hsiung, J.-T., Soohoo, M., & Streja, E. (2019). Choosing Wisely: Using the Appropriate Statistical Test for Trend in SAS\n[5] Bewick V, Cheek L, Ball J. Statistics review 10: Further nonparametric methods. Crit Care. 2004;8(4):R131-R139. doi:10.1186/cc468904. PMCID: PMC468904.PubMed Central."
  },
  {
    "objectID": "SAS/binomial_test.html",
    "href": "SAS/binomial_test.html",
    "title": "Binomial Test on Coin Flips and Clinical Data",
    "section": "",
    "text": "Set the seed for reproducibility and simulate 1000 coin flips using a Bernoulli distribution.\n#| eval: false\n/* Set the seed for reproducibility */\n%let seed = 19;\n\ndata coin_flips;\n    call streaminit(&seed);\n    do i = 1 to 1000;\n        /* Simulate coin flips: 1 for Heads (H), 0 for Tails (T) */\n        flip = rand(\"Bernoulli\", 0.5);\n/*         flip = rand(\"BINOMIAL\", 0.5,1); */\n        if flip = 1 then result = \"H\";\n        else result = \"T\";\n        output;\n    end;\nrun;"
  },
  {
    "objectID": "SAS/binomial_test.html#simulating-coin-flips",
    "href": "SAS/binomial_test.html#simulating-coin-flips",
    "title": "Binomial Test on Coin Flips and Clinical Data",
    "section": "",
    "text": "Set the seed for reproducibility and simulate 1000 coin flips using a Bernoulli distribution.\n#| eval: false\n/* Set the seed for reproducibility */\n%let seed = 19;\n\ndata coin_flips;\n    call streaminit(&seed);\n    do i = 1 to 1000;\n        /* Simulate coin flips: 1 for Heads (H), 0 for Tails (T) */\n        flip = rand(\"Bernoulli\", 0.5);\n/*         flip = rand(\"BINOMIAL\", 0.5,1); */\n        if flip = 1 then result = \"H\";\n        else result = \"T\";\n        output;\n    end;\nrun;"
  },
  {
    "objectID": "SAS/binomial_test.html#counting-heads-and-tails",
    "href": "SAS/binomial_test.html#counting-heads-and-tails",
    "title": "Binomial Test on Coin Flips and Clinical Data",
    "section": "Counting Heads and Tails",
    "text": "Counting Heads and Tails\nUse SQL to count how many heads and tails were observed in the simulation.\n#| eval: false\nproc sql;\n    select \n        sum(result = \"H\") as heads_count,\n        sum(result = \"T\") as tails_count,\n        count(*) as total_flips\n    into :heads_count, :tails_count, :total_flips\n    from coin_flips;\nquit;"
  },
  {
    "objectID": "SAS/binomial_test.html#display-the-results",
    "href": "SAS/binomial_test.html#display-the-results",
    "title": "Binomial Test on Coin Flips and Clinical Data",
    "section": "Display the Results",
    "text": "Display the Results\nPrint the counts using %put statements.\n#| eval: false\n%put Heads Count: &heads_count;\n%put Tails Count: &tails_count;\n%put Total Flips: &total_flips;"
  },
  {
    "objectID": "SAS/binomial_test.html#perform-binomial-test-on-coin-flip-results",
    "href": "SAS/binomial_test.html#perform-binomial-test-on-coin-flip-results",
    "title": "Binomial Test on Coin Flips and Clinical Data",
    "section": "Perform Binomial Test on Coin Flip Results",
    "text": "Perform Binomial Test on Coin Flip Results\nUse proc freq to check if the observed results differ significantly from the expected probability of 0.5.\nproc freq data=coin_flips;\n    tables result / binomial(p=0.5);\nrun;"
  },
  {
    "objectID": "SAS/binomial_test.html#example-binomial-test-in-clinical-trial-data",
    "href": "SAS/binomial_test.html#example-binomial-test-in-clinical-trial-data",
    "title": "Binomial Test on Coin Flips and Clinical Data",
    "section": "Example: Binomial Test in Clinical Trial Data",
    "text": "Example: Binomial Test in Clinical Trial Data\nWe load a clinical dataset and test if the observed death proportion is significantly different from a hypothesized value (e.g., 19%).\n\nImport Dataset\n#| eval: false\nproc import datafile='/home/u63532805/CAMIS/lung_cancer.csv'\n    out=lung_cancer\n    dbms=csv\n    replace;\n    getnames=yes;\nrun;\n\n\nCreate Binary Flag for Deaths\n#| eval: false\ndata lung_cancer;\n    set lung_cancer;\n    death_flag = (status = 1);\nrun;\n\n\nPerform Exact Binomial Test\n#| eval: false\nproc freq data=lung_cancer;\n    tables death_flag / binomial(p=0.19 level='1');\n    title \"Exact Binomial Test for Death Proportion\";\nrun;"
  },
  {
    "objectID": "SAS/binomial_test.html#sas-output",
    "href": "SAS/binomial_test.html#sas-output",
    "title": "Binomial Test on Coin Flips and Clinical Data",
    "section": "SAS Output",
    "text": "SAS Output\n\nCoin Flip Summary\n\n\n\nheads_count\ntails_count\ntotal_flips\n\n\n\n\n520\n480\n1000\n\n\n\n\n\nBinomial Test on Coin Flips\nThe FREQ Procedure\n\n\n\n\n\n\n\n\n\n\nresult\nFrequency\nPercent\nCumulative Frequency\nCumulative Percent\n\n\n\n\nH\n520\n52.00\n520\n52.00\n\n\nT\n480\n48.00\n1000\n100.00\n\n\n\nBinomial Proportion for result = H\n\nProportion: 0.5200\n\nASE: 0.0158\n\n95% Lower Conf Limit: 0.4890\n\n95% Upper Conf Limit: 0.5510\n\nExact Confidence Limits\n\n95% Lower Conf Limit: 0.4885\n\n95% Upper Conf Limit: 0.5514\n\nTest of H0: Proportion = 0.5\n\nASE under H0: 0.0158\n\nZ: 1.2649\n\nOne-sided Pr &gt; Z: 0.1030\n\nTwo-sided Pr &gt; |Z|: 0.2059\n\nSample Size: 1000\n\n\n\nExact Binomial Test for Death Proportion\nThe FREQ Procedure\n\n\n\n\n\n\n\n\n\n\ndeath_flag\nFrequency\nPercent\nCumulative Frequency\nCumulative Percent\n\n\n\n\n0\n165\n72.37\n165\n72.37\n\n\n1\n63\n27.63\n228\n100.00\n\n\n\nBinomial Proportion for death_flag = 1\n\nProportion: 0.2763\n\nASE: 0.0296\n\n95% Lower Conf Limit: 0.2183\n\n95% Upper Conf Limit: 0.3344\n\nExact Confidence Limits\n\n95% Lower Conf Limit: 0.2193\n\n95% Upper Conf Limit: 0.3392\n\nTest of H0: Proportion = 0.19\n\nASE under H0: 0.0260\n\nZ: 3.3223\n\nOne-sided Pr &gt; Z: 0.0004\n\nTwo-sided Pr &gt; |Z|: 0.0009\n\nSample Size: 228"
  },
  {
    "objectID": "SAS/survey-stats-summary.html",
    "href": "SAS/survey-stats-summary.html",
    "title": "Survey Summary Statistics using SAS",
    "section": "",
    "text": "When conducting large-scale trials on samples of the population, it can be necessary to use a more complex sampling design than a simple random sample.\nAll of these designs need to be taken into account when calculating statistics, and when producing models. Only summary statistics are discussed in this document, and variances are calculated using the default Taylor series linearisation methods. For a more detailed introduction to survey statistics in SAS, see (Lohr 2022) or (SAS/STAT® 15.1 User’s Guide 2018).\nFor survey summary statistics in SAS, we can use the SURVEYMEANS and SURVEYFREQ procedures."
  },
  {
    "objectID": "SAS/survey-stats-summary.html#mean",
    "href": "SAS/survey-stats-summary.html#mean",
    "title": "Survey Summary Statistics using SAS",
    "section": "Mean",
    "text": "Mean\nIf we want to calculate a mean of a variable in a dataset which has been obtained from a simple random sample such as apisrs, in SAS we can do the following (nb. here total=6194 is obtained from the constant fpc column, and provides the finite population correction):\n\nproc surveymeans data=apisrs total=6194 mean;\n    var growth;\nrun;\n\n                             The SURVEYMEANS Procedure\n\n                                    Data Summary\n\n                        Number of Observations           200\n\n\n                                    Statistics\n\n                                                Std Error\n Variable               N            Mean         of Mean       95% CL for Mean\n ---------------------------------------------------------------------------------\n growth               200       31.900000        2.090493    27.7776382 36.0223618\n ---------------------------------------------------------------------------------"
  },
  {
    "objectID": "SAS/survey-stats-summary.html#total",
    "href": "SAS/survey-stats-summary.html#total",
    "title": "Survey Summary Statistics using SAS",
    "section": "Total",
    "text": "Total\nTo calculate population totals, we can request the sum. However SAS requires the user to specify the weights, otherwise the totals will be incorrect. These weights in this case are equivalent to the total population size divided by the sample size:\n\ndata apisrs;\n    set apisrs nobs=n;\n    weight = fpc / n;\nrun;\n\nproc surveymeans data=apisrs total=6194 sum;\n    var growth;\n    weight weight;\nrun;\n\n       The SURVEYMEANS Procedure\n\n              Data Summary\n\n  Number of Observations           200\n  Sum of Weights                  6194\n\n\n               Statistics\n\n                               Std Error\nVariable             Sum          of Sum\n----------------------------------------\ngrowth            197589           12949\n----------------------------------------"
  },
  {
    "objectID": "SAS/survey-stats-summary.html#ratios",
    "href": "SAS/survey-stats-summary.html#ratios",
    "title": "Survey Summary Statistics using SAS",
    "section": "Ratios",
    "text": "Ratios\nTo perform ratio analysis for means or proportions of analysis variables in SAS, we can use the following:\n\nproc surveymeans data=apisrs total=6194;\n    ratio api00 / api99;\nrun;\n\n                             The SURVEYMEANS Procedure\n\n                                    Data Summary\n\n                        Number of Observations           200\n\n\n                                    Statistics\n\n                                                Std Error\n Variable               N            Mean         of Mean       95% CL for Mean\n ---------------------------------------------------------------------------------\n api00                200      656.585000        9.249722    638.344950 674.825050\n api99                200      624.685000        9.500304    605.950813 643.419187\n ---------------------------------------------------------------------------------\n\n\n                                   Ratio Analysis\n\n                                                          Std\nNumerator Denominator            N           Ratio           Error        95% CL for Ratio\n----------------------------------------------------------------------------------------------\napi00     api99                200        1.051066        0.003604    1.04395882    1.05817265\n----------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "SAS/survey-stats-summary.html#proportions",
    "href": "SAS/survey-stats-summary.html#proportions",
    "title": "Survey Summary Statistics using SAS",
    "section": "Proportions",
    "text": "Proportions\nTo calculate a proportion in SAS, we use the PROC SURVEYFREQ, in the simplest case below:\n\nproc surveyfreq data=apisrs total=6194;\n    table 'sch.wide'n / cl;\nrun;\n\n                          The SURVEYFREQ Procedure\n\n                                Data Summary\n\n                    Number of Observations           200\n\n\n                             Table of sch.wide\n\n                                       Std Err of    95% Confidence Limits\n sch.wide     Frequency     Percent       Percent         for Percent\n -------------------------------------------------------------------------\n No                  37     18.5000        2.7078     13.1604      23.8396\n Yes                163     81.5000        2.7078     76.1604      86.8396\n\n Total              200    100.0000"
  },
  {
    "objectID": "SAS/survey-stats-summary.html#quantiles",
    "href": "SAS/survey-stats-summary.html#quantiles",
    "title": "Survey Summary Statistics using SAS",
    "section": "Quantiles",
    "text": "Quantiles\nTo calculate quantiles in SAS, we can use the quantile option to request specific quantiles, or can use keywords to request common quantiles (e.g. quartiles or the median). This will use Woodruff’s method for confidence intervals, and a custom quantile method (SAS/STAT® 15.1 User’s Guide 2018, 9834).\n\nproc surveymeans data=apisrs total=6194 quantile=(0.025 0.5 0.975);\n    var growth;\nrun;\n\n                             The SURVEYMEANS Procedure\n\n                                    Data Summary\n\n                        Number of Observations           200\n\n\n\n\n                                     Quantiles\n\n                                                      Std\n Variable       Percentile       Estimate           Error    95% Confidence Limits\n ---------------------------------------------------------------------------------\n growth           2.5          -16.500000        1.755916    -19.962591 -13.037409\n                   50 Median    26.500000        1.924351     22.705263  30.294737\n                 97.5           99.000000       16.133827     67.184794 130.815206\n ---------------------------------------------------------------------------------"
  },
  {
    "objectID": "SAS/tipping_point.html",
    "href": "SAS/tipping_point.html",
    "title": "SAS Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "The concept of delta adjustment and tipping point analysis builds on the framework of reference-based multiple imputation (rbmi) as seen on its respective CAMIS webpage. The use of the five macros (Roger 2022) in SAS for the following standard and reference-based multiple imputation approaches are introduced there:\n\nMissing At Random (MAR)\nJump to Reference (J2R)\nCopy Reference (CR)\nCopy Increment from Reference (CIR)\n\nEssentially, the workflow comes down to sequentially running the five macro’s:\n\nPart1A() declares the parameter estimation model and checks consistency with the dataset. It builds a master dataset which holds details of the current job (run of the macros in sequence). It also builds indexes for the classification variables, which may be either numeric or character.\nPart1B() fits the parameter estimation model using the MCMC procedure and draws a pseudo-independent sample from the joint posterior distribution for the linear predictor parameters and the covariance parameters.\nPart2A() calculates the predicted mean under MAR, and under MNAR for each subject based on their withdrawal pattern once for each draw of the linear predictor parameter estimates. The choice of MNAR is controlled by the method used, which may vary from subject to subject.\nPart2B() imputes the intermediate missing values using MAR and the trailing missing values using MNAR, by deriving the conditional distribution for the missing values conditional on the observed values and covariates, using the appropriate sampled covariance parameter estimates.\nPart3() carries out a univariate ANOVA analysis at selected time points usually based on the same covariates as the parameter estimation model. It then combines the least-squares means and their differences using the MIANALYZE procedure to provide final results. It is in this macro which handles the Delta methods.\n\nThe five macros are available at LSHTM DIA Missing Data under Imputation based approaches &gt; Reference-based MI via Multivariate Normal RM (the “five macros” and MIWithD) &gt; Downloads. Please make sure to familiarize yourself with its functionalities before checking this tutorial. For more details, see the user guide available upon download (Roger 2017).\n\n\n\nThe same publicly available dataset from an antidepressant clinical trial that was used to illustrate rbmi is again used for this tutorial. This dataset is also used in the R version of this CAMIS webpage and the quickstart vignette of the rbmi R package.\nThe relevant endpoint for the antidepressant trial was assessed using the Hamilton 17-item depression rating scale (HAMD17), which was measured at baseline and subsequently at weeks 1, 2, 3, 4 and 6 (visits 4-7). Study drug discontinuation occurred in 24% (20/84) of subjects in the active drug group, compared to 26% (23/88) of subjects in the placebo group. Importantly, all data after study drug discontinuation are missing and there is a single intermittent missing observation.\n\nproc print data=dat (obs=10);\n    var PATIENT GENDER THERAPY RELDAYS VISIT BASVAL HAMDTL17 CHANGE;\nrun;\n\n\n\n\n\n\n\n\n\n\nThe number of patients per visit and treatment group are:\n\nproc freq data=dat;\n    table VISIT*THERAPY / norow nocol nopercent nocum;\nrun;\n\n\n\n\n\n\n\n\n\n\nThe mean change from baseline of the HAMD17 endpoint per visit and treatment group using only the complete cases are:\n\nproc means data=dat n mean nonobs;\n    class VISIT THERAPY;\n    var CHANGE;\nrun;\n\n\n\n\n\n\n\n\n\n\nThe missingness pattern is:\n\nproc transpose data=dat out=HAMD_wide(drop=_NAME_) prefix=CHG;\n    by PATIENT THERAPY BASVAL;\n    id VISIT;\n    var CHANGE;\nrun;\n\nproc mi data=HAMD_wide nimpute=0 displaypattern=NOMEANS;\n    var CHG4 CHG5 CHG6 CHG7;\nrun;\n\n\n\n\n\n\n\n\n\n\nThere is a single patient with an intermittent missing observation at visit 5, which is patient 3618. Special considerations need to be taken when applying delta adjustments to intermittent missing observations like this one (more on this below).\n\n\n\n\n\n\nWhen analyses for endpoints are performed under MAR or MNAR assumptions for missing data, it is important to perform sensitivity analyses to assess the impact of deviations from these assumptions. Tipping point analysis (or delta adjustment method) is an example of a sensitivity analysis that can be used to assess the robustness of a clinical trial when its result is based on imputed missing data.\nGenerally, tipping point analysis explores the influence of missingness on the overall conclusion of the treatment difference by shifting imputed missing values in the treatment group towards the reference group until the result becomes non-significant. The tipping point is the minimum shift needed to make the result non-significant. If the minimum shift needed to make the result non-significant is implausible, then greater confidence in the primary results can be inferred.\nTipping point analysis generally happens by adjusting imputing values by a so-called delta values. The observed tipping point is the minimum delta needed to make the result non-significant. Mostly a range of delta values is explored and only imputed values from the active treatment group are adjusted by the delta value. However, delta adjustments to the control group are possible as well. Naturally, the range of acceptable values for delta should be agreed a priori, before taking this approach.\nFor an extensive discussion on delta adjustment methods, we refer to Cro et al. 2020.\n\n\n\n\nAs mentioned, we will illustrate the use of the so-called five macros in SAS for delta adjustment and tipping point analysis. These are available at LSHTM DIA Missing Data under Imputation based approaches &gt; Reference-based MI via Multivariate Normal RM (the “five macros” and MIWithD) &gt; Downloads.\n\n\nTo conduct a tipping point analysis under the MAR assumption, we simply specify method = MAR under Part2A() of the five macros. Generally, the rest of Part1 and Part2 are the same as in the scenario without any delta adjustment.\n\n%part1A(jobname = HAMD, \n        Data=dat,\n        Subject=PATIENT,\n        RESPONSE = CHANGE,\n        Time = VISIT,\n        Treat = THERAPY,\n        Covbytime = BASVAL,\n        Catcov = GENDER);\n\n%part1B(jobname = HAMD,\n        Ndraws = 500,\n        thin = 10,\n        seed = 12345);\n\n%part2A(jobname = HAMD_MAR,\n        inname = HAMD,\n        method = MAR);\n\n%part2B(jobname = HAMD_MAR,\n        seed = 12345);\n\nThen, in Part3(), we create a series of delta values that increases sequentially for the intervention group by changing the Delta argument within a do loop, and setting Dgroups = DRUG and Dlag = 1 0 0 0 (more on this below).\nA clear description of these arguments is given in the documentation:\n\nDelta: A vector of Delta values from visit 1 up to the final visit (default is not applying a delta adjustment)\nDlag: A vector of multipliers for each Lag after withdrawal for the Delta values (default is all values of 1)\nDgroups: The treatment groups to which Delta should be applied (default is all treatment groups)\n\nTo automate the tipping point analysis, you can create a new macro like shown below. The first part of this macro prints all results, while the second part prints the non-significant and significant results separately by filtering on Probt.\n\ndata all_results;\n    length DELTA 8 VISIT $10 THERAPY $20 _THERAPY $20 Diff SE_Diff df Probt LCL_Diff UCL_Diff 8;\n    stop;\nrun;\n\n%macro part3_TP;\n\n%do delta = -5 %to 10 %by 1;\n%part3(Jobname = HAMD_MAR, anref=PLACEBO, Delta = &delta &delta &delta &delta, DLag = 1 0 0 0, DGroups = DRUG, Label=MAR);\n\ndata current_result;\n    set HAMD_MAR_OUT(keep = VISIT THERAPY _THERAPY Diff SE_Diff df Probt LCL_Diff UCL_Diff);\n    DELTA = &delta;\nrun;\n\nproc append base=all_results data=current_result force nowarn;\nrun;\n\n%end;\nproc print data = all_results noobs label;\n    where VISIT = \"7\";\n    var DELTA VISIT THERAPY _THERAPY Diff SE_Diff df Probt LCL_Diff UCL_Diff;\n    title \"MAR: all results\";\nrun;\n\n\n\n\n\n\n\n\n\n\n\nproc sql noprint;\n    create table delta_ge_05 as\n    select distinct DELTA\n    from all_results\n    where Probt &gt;= 0.05 and not missing(Probt) and VISIT = \"7\";\n\n    select DELTA into :non_sig_delta separated by ' '\n    from delta_ge_05;\n\n    create table delta_lt_05 as\n    select distinct DELTA\n    from all_results\n    where Probt &lt; 0.05 and not missing(Probt) and VISIT = \"7\";\n\n    select DELTA into :sig_delta separated by ' '\n    from delta_lt_05;\nquit;\n\nproc print data = all_results noobs label;\n    where DELTA in (&non_sig_delta.) and VISIT = \"7\";\n    var DELTA VISIT THERAPY _THERAPY Diff SE_Diff df Probt LCL_Diff UCL_Diff;\n    title \"MAR: non-significant results\";\nrun;\n\nproc print data = all_results noobs label;\n    where DELTA in (&sig_delta.) and VISIT = \"7\";\n    var DELTA VISIT THERAPY _THERAPY Diff SE_Diff df Probt LCL_Diff UCL_Diff;\n    title \"MAR: significant results\";\nrun;\n\n%mend;\n\n%part3_TP;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo determine the exact tipping point between the last “significant” delta and the first “non-significant” delta, you may manually perform linear interpolation for DELTA, Diff, LCL_Diff and UCL_Diff at Probt = 0.05.\n\n\n\n\n\n\n\n\n\nNote: In the five macros, delta adjustments happen right after data imputation under MAR or MNAR (using reference-based imputation approaches) in Part2, but before implementing the analysis model in Part3. Sensitivity analyses can therefore be performed without having to refit the imputation model, which is computationally efficient. This approach is considered a marginal delta adjustment approach, because the delta is simply added to the mean of the conditional multivariate normal distribution (conditional on the observed values and the covariates) for the imputation model (Roger 2017).\n\n\n\nA nice visualization of this tipping point analysis for the MAR approach is shown below. The dashed horizontal line indicates a p-value of 0.05 in the left plot and no treatment effect in the right plot.\n\n\n\n\n\n\n\n\n\nWe clearly see that the p-value under MAR reaches a tipping point from 3 onward in the range of delta’s considered.\n\n\n\n\n\n\nIn the table below we present the results of the different imputation strategies with varying number of multiple imputation draws, M = 500 and M = 5000. Note that the results can be slightly different from the results above due to a possible different seed. The estimates show the contrast at visit 7 between DRUG and PLACEBO (DRUG - PLACEBO). Delta adjustments were applied to all imputed missing data, except intermittent missing data, in the intervention group only.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\nDelta control\nDelta intervention at TP\nEstimate at TP\n95% CI\nP-value\nOriginal estimate\nOriginal p-value\n\n\n\n\nMI - MAR (M=500)\n0\n3\n-2.081\n-4.337 to 0.175\n0.0703\n-2.810\n0.0134\n\n\nMI - MAR (M=5000)\n0\n3\n-2.096\n-4.353 to 0.161\n0.0684\n-2.825\n0.0130\n\n\nMI - MNAR J2R (M=500)\n0\n-1\n-2.365\n-4.604 to -0.125\n0.0386\n-2.122\n0.0650\n\n\nMI - MNAR J2R (M=5000)\n0\n-1\n-2.387\n-4.617 to -0.157\n0.0361\n-2.144\n0.0611\n\n\nMI - MNAR CR (M=500)\n0\n1\n-2.141\n-4.370 to 0.089\n0.0597\n-2.384\n0.0350\n\n\nMI - MNAR CR (M=5000)\n0\n1\n-2.157\n-4.377 to 0.062\n0.0566\n-2.400\n0.0330\n\n\nMI - MNAR CIR (M=500)\n0\n1\n-2.218\n-4.446 to 0.010\n0.0510\n-2.461\n0.0296\n\n\nMI - MNAR CIR (M=5000)\n0\n2\n-1.995\n-4.229 to 0.240\n0.0798\n-2.481\n0.0276\n\n\n\nOf all considered approaches, the MAR approach yields the largest delta adjustment at its tipping point, with a delta intervention of 3 at both M = 500 and M = 5000. This indicates that the MAR assumption is the most robust against slight deviations of its conditions. Notice that for the MNAR JR approach we included, for completeness, tipping point analyses to know when the results switch from non-significant to significant. Correspondingly, two negative delta’s (-1) are found at the tipping point. This is expected, given that the original analyses are non-significant (p ~ 0.0650 and p ~ 0.0611) and a tipping point analysis here aims to find the point at which the analysis turns to be significant, instead of non-significant.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSo far, we have only considered simple delta adjustments that add the same value to all imputed missing data. However, you may want to implement more flexible delta adjustments for missing data following an intercurrent event (ICE), where the magnitude of the delta varies depending on the distance of the visit from the ICE visit.\nTo enable flexible delta adjustments, Part3() includes three delta arguments: Delta, DLag and DGroups. Although these arguments were introduced earlier in the tutorial, we will now elaborate on how exactly these arguments allow for flexible delta adjustments with a few examples taken from the advanced functionality vignette of the rbmi R package.\n\n\nAssume a setting with 4 visits and the user specified Delta = 5 6 7 8 and DLag = 1 2 3 4. For a subject for whom the first visit affected by the ICE is visit 2, these values of Delta and DLag would imply the following delta adjustments:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n5\n6\n7\n8\n\n\nDLag\n0\n1\n2\n3\n\n\nDelta * DLag\n0\n6\n14\n24\n\n\nCumulative sum\n0\n6\n20\n44\n\n\n\nThat is, the subject would have a delta adjustment of 0 applied to visit 1, 6 for visit 2, 20 for visit 3 and 44 for visit 4.\nAssume instead, that the subject’s first visit affected by the ICE was visit 3. Then, the above values of Delta and DLag would imply the following delta adjustment:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n5\n6\n7\n8\n\n\nDLag\n0\n0\n1\n2\n\n\nDelta * DLag\n0\n0\n7\n16\n\n\nCumulative sum\n0\n0\n7\n23\n\n\n\nAnd thus the subject would have a delta adjustment of 0 applied to visits 1 and 2, 7 for visit 3 and 23 for visit 4.\nAnother way of using these arguments is to set Delta to the difference in time between visits and DLag to be the amount of delta per unit of time. For example, let’s say that visits occur on weeks 1, 5, 6 and 9 and that we want a delta of 3 to be applied for each week after an ICE. For simplicity, we assume that the ICE occurs immediately after the subject’s last visit which is not affected by the ICE. This this could be achieved by setting Delta = 1 4 1 3, i.e. the difference in weeks between each visit, and DLag = 3 3 3 3.\nAssume a subject’s first visit affected by the ICE was visit 2, then these values of Delta and DLag would imply the following delta offset:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n1\n4\n1\n3\n\n\nDLag\n0\n3\n3\n3\n\n\nDelta * DLag\n0\n12\n3\n9\n\n\nCumulative sum\n0\n12\n15\n24\n\n\n\nLet’s now consider the antidepressant data again. Suppose we apply a delta adjustment of 2 for each week following an ICE in the intervention group only. For example, if the ICE took place immediately after visit 4, then the cumulative delta applied to a missing value from visit 5 would be 2, from visit 6 would be 4, and from visit 7 would be 6.\nTo program this, we would define Delta, DLag and DGroups in Part3() of the five macros as follows:\n\n%part3(Jobname = HAMD_MAR, \n        anref=PLACEBO, \n        Delta = 2 2 2 2, \n        DLag = 1 1 1 1, \n        DGroups = DRUG, \n        Label=MAR);\n\nNotice that DLag = 1 1 1 1 is the default for this argument in SAS, you may also leave it unspecified in this case.\n\n\n\nAs already illustrated in the tipping point analysis assuming MAR above, you may also add a simple, fixed delta using the Delta and DLag arguments. To do this, Delta should be the same value repeated for each visit, e.g. 5 5 5 5, while DLag should be 1 0 0 0. This ensures a delta of 5 is added to each imputed missing value following an ICE, which we here assume to occur at the visit 2:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n5\n5\n5\n5\n\n\nDlag\n0\n1\n0\n0\n\n\nDelta * dlag\n0\n0\n0\n0\n\n\nCumulative sum\n0\n5\n5\n5\n\n\n\nTo apply this delta = 5 to both groups we leave DGroups unspecified.\n\n%part3(Jobname = HAMD_MAR, \n        anref=PLACEBO, \n        Delta = 5 5 5 5, \n        DLag = 1 0 0 0, \n        Label=MAR);\n\nIn the five macros, delta adjustments are not applied to intermittent missing observations, but only to missing observations after withdrawal. From the documentation, it seems like this cannot be altered. In contrast, the choice of which missing data to apply delta adjustments to can be more freely managed using the rbmi R package. This may lead to discrepancies between tipping point analyses conducted in SAS and R, and may have important implications for datasets with high proportions of intermittent missing values in particular.\nNote: By making use of the DGroupsV argument in Part3 (see five macros documentation) one can specify a variable in the dataset that indicates whether a delta adjustment should be applied to any imputed value for the record after withdrawal. The five macros documentation states that “As an alternative to DGroups=, this option specifies a numeric variable with a logical value indicating whether Delta should be applied to any imputed value for the record. This variable should be Numeric holding a logical value.”. However, from our experience the intermittent missing values are not delta adjusted using this argument, only the missing values after withdrawal.\nNote: By making use of the DeltaV argument in Part3 (see five macros documentation) one can set specific delta adjustments by records.\n\n\n\n\nCro et al. 2020. Sensitivity analysis for clinical trials with missing continuous outcome data using controlled multiple imputation: A practical guide. Statistics in Medicine. 2020;39(21):2815-2842.\nrbmi: Advanced Functionality\nrbmi: Quickstart\nRoger 2022. Other statistical software for continuous longitudinal endpoints: SAS macros for multiple imputation. Addressing intercurrent events: Treatment policy and hypothetical strategies. Joint EFSPI and BBS virtual event.\nRoger 2017. Fitting reference-based models for missing data to longitudinal repeated-measures Normal data. User guide five macros."
  },
  {
    "objectID": "SAS/tipping_point.html#reference-based-multiple-imputation-rbmi",
    "href": "SAS/tipping_point.html#reference-based-multiple-imputation-rbmi",
    "title": "SAS Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "The concept of delta adjustment and tipping point analysis builds on the framework of reference-based multiple imputation (rbmi) as seen on its respective CAMIS webpage. The use of the five macros (Roger 2022) in SAS for the following standard and reference-based multiple imputation approaches are introduced there:\n\nMissing At Random (MAR)\nJump to Reference (J2R)\nCopy Reference (CR)\nCopy Increment from Reference (CIR)\n\nEssentially, the workflow comes down to sequentially running the five macro’s:\n\nPart1A() declares the parameter estimation model and checks consistency with the dataset. It builds a master dataset which holds details of the current job (run of the macros in sequence). It also builds indexes for the classification variables, which may be either numeric or character.\nPart1B() fits the parameter estimation model using the MCMC procedure and draws a pseudo-independent sample from the joint posterior distribution for the linear predictor parameters and the covariance parameters.\nPart2A() calculates the predicted mean under MAR, and under MNAR for each subject based on their withdrawal pattern once for each draw of the linear predictor parameter estimates. The choice of MNAR is controlled by the method used, which may vary from subject to subject.\nPart2B() imputes the intermediate missing values using MAR and the trailing missing values using MNAR, by deriving the conditional distribution for the missing values conditional on the observed values and covariates, using the appropriate sampled covariance parameter estimates.\nPart3() carries out a univariate ANOVA analysis at selected time points usually based on the same covariates as the parameter estimation model. It then combines the least-squares means and their differences using the MIANALYZE procedure to provide final results. It is in this macro which handles the Delta methods.\n\nThe five macros are available at LSHTM DIA Missing Data under Imputation based approaches &gt; Reference-based MI via Multivariate Normal RM (the “five macros” and MIWithD) &gt; Downloads. Please make sure to familiarize yourself with its functionalities before checking this tutorial. For more details, see the user guide available upon download (Roger 2017).\n\n\n\nThe same publicly available dataset from an antidepressant clinical trial that was used to illustrate rbmi is again used for this tutorial. This dataset is also used in the R version of this CAMIS webpage and the quickstart vignette of the rbmi R package.\nThe relevant endpoint for the antidepressant trial was assessed using the Hamilton 17-item depression rating scale (HAMD17), which was measured at baseline and subsequently at weeks 1, 2, 3, 4 and 6 (visits 4-7). Study drug discontinuation occurred in 24% (20/84) of subjects in the active drug group, compared to 26% (23/88) of subjects in the placebo group. Importantly, all data after study drug discontinuation are missing and there is a single intermittent missing observation.\n\nproc print data=dat (obs=10);\n    var PATIENT GENDER THERAPY RELDAYS VISIT BASVAL HAMDTL17 CHANGE;\nrun;\n\n\n\n\n\n\n\n\n\n\nThe number of patients per visit and treatment group are:\n\nproc freq data=dat;\n    table VISIT*THERAPY / norow nocol nopercent nocum;\nrun;\n\n\n\n\n\n\n\n\n\n\nThe mean change from baseline of the HAMD17 endpoint per visit and treatment group using only the complete cases are:\n\nproc means data=dat n mean nonobs;\n    class VISIT THERAPY;\n    var CHANGE;\nrun;\n\n\n\n\n\n\n\n\n\n\nThe missingness pattern is:\n\nproc transpose data=dat out=HAMD_wide(drop=_NAME_) prefix=CHG;\n    by PATIENT THERAPY BASVAL;\n    id VISIT;\n    var CHANGE;\nrun;\n\nproc mi data=HAMD_wide nimpute=0 displaypattern=NOMEANS;\n    var CHG4 CHG5 CHG6 CHG7;\nrun;\n\n\n\n\n\n\n\n\n\n\nThere is a single patient with an intermittent missing observation at visit 5, which is patient 3618. Special considerations need to be taken when applying delta adjustments to intermittent missing observations like this one (more on this below)."
  },
  {
    "objectID": "SAS/tipping_point.html#tipping-point-analysis-and-delta-adjustment",
    "href": "SAS/tipping_point.html#tipping-point-analysis-and-delta-adjustment",
    "title": "SAS Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "When analyses for endpoints are performed under MAR or MNAR assumptions for missing data, it is important to perform sensitivity analyses to assess the impact of deviations from these assumptions. Tipping point analysis (or delta adjustment method) is an example of a sensitivity analysis that can be used to assess the robustness of a clinical trial when its result is based on imputed missing data.\nGenerally, tipping point analysis explores the influence of missingness on the overall conclusion of the treatment difference by shifting imputed missing values in the treatment group towards the reference group until the result becomes non-significant. The tipping point is the minimum shift needed to make the result non-significant. If the minimum shift needed to make the result non-significant is implausible, then greater confidence in the primary results can be inferred.\nTipping point analysis generally happens by adjusting imputing values by a so-called delta values. The observed tipping point is the minimum delta needed to make the result non-significant. Mostly a range of delta values is explored and only imputed values from the active treatment group are adjusted by the delta value. However, delta adjustments to the control group are possible as well. Naturally, the range of acceptable values for delta should be agreed a priori, before taking this approach.\nFor an extensive discussion on delta adjustment methods, we refer to Cro et al. 2020."
  },
  {
    "objectID": "SAS/tipping_point.html#tipping-point-analysis-mar-approach",
    "href": "SAS/tipping_point.html#tipping-point-analysis-mar-approach",
    "title": "SAS Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "As mentioned, we will illustrate the use of the so-called five macros in SAS for delta adjustment and tipping point analysis. These are available at LSHTM DIA Missing Data under Imputation based approaches &gt; Reference-based MI via Multivariate Normal RM (the “five macros” and MIWithD) &gt; Downloads.\n\n\nTo conduct a tipping point analysis under the MAR assumption, we simply specify method = MAR under Part2A() of the five macros. Generally, the rest of Part1 and Part2 are the same as in the scenario without any delta adjustment.\n\n%part1A(jobname = HAMD, \n        Data=dat,\n        Subject=PATIENT,\n        RESPONSE = CHANGE,\n        Time = VISIT,\n        Treat = THERAPY,\n        Covbytime = BASVAL,\n        Catcov = GENDER);\n\n%part1B(jobname = HAMD,\n        Ndraws = 500,\n        thin = 10,\n        seed = 12345);\n\n%part2A(jobname = HAMD_MAR,\n        inname = HAMD,\n        method = MAR);\n\n%part2B(jobname = HAMD_MAR,\n        seed = 12345);\n\nThen, in Part3(), we create a series of delta values that increases sequentially for the intervention group by changing the Delta argument within a do loop, and setting Dgroups = DRUG and Dlag = 1 0 0 0 (more on this below).\nA clear description of these arguments is given in the documentation:\n\nDelta: A vector of Delta values from visit 1 up to the final visit (default is not applying a delta adjustment)\nDlag: A vector of multipliers for each Lag after withdrawal for the Delta values (default is all values of 1)\nDgroups: The treatment groups to which Delta should be applied (default is all treatment groups)\n\nTo automate the tipping point analysis, you can create a new macro like shown below. The first part of this macro prints all results, while the second part prints the non-significant and significant results separately by filtering on Probt.\n\ndata all_results;\n    length DELTA 8 VISIT $10 THERAPY $20 _THERAPY $20 Diff SE_Diff df Probt LCL_Diff UCL_Diff 8;\n    stop;\nrun;\n\n%macro part3_TP;\n\n%do delta = -5 %to 10 %by 1;\n%part3(Jobname = HAMD_MAR, anref=PLACEBO, Delta = &delta &delta &delta &delta, DLag = 1 0 0 0, DGroups = DRUG, Label=MAR);\n\ndata current_result;\n    set HAMD_MAR_OUT(keep = VISIT THERAPY _THERAPY Diff SE_Diff df Probt LCL_Diff UCL_Diff);\n    DELTA = &delta;\nrun;\n\nproc append base=all_results data=current_result force nowarn;\nrun;\n\n%end;\nproc print data = all_results noobs label;\n    where VISIT = \"7\";\n    var DELTA VISIT THERAPY _THERAPY Diff SE_Diff df Probt LCL_Diff UCL_Diff;\n    title \"MAR: all results\";\nrun;\n\n\n\n\n\n\n\n\n\n\n\nproc sql noprint;\n    create table delta_ge_05 as\n    select distinct DELTA\n    from all_results\n    where Probt &gt;= 0.05 and not missing(Probt) and VISIT = \"7\";\n\n    select DELTA into :non_sig_delta separated by ' '\n    from delta_ge_05;\n\n    create table delta_lt_05 as\n    select distinct DELTA\n    from all_results\n    where Probt &lt; 0.05 and not missing(Probt) and VISIT = \"7\";\n\n    select DELTA into :sig_delta separated by ' '\n    from delta_lt_05;\nquit;\n\nproc print data = all_results noobs label;\n    where DELTA in (&non_sig_delta.) and VISIT = \"7\";\n    var DELTA VISIT THERAPY _THERAPY Diff SE_Diff df Probt LCL_Diff UCL_Diff;\n    title \"MAR: non-significant results\";\nrun;\n\nproc print data = all_results noobs label;\n    where DELTA in (&sig_delta.) and VISIT = \"7\";\n    var DELTA VISIT THERAPY _THERAPY Diff SE_Diff df Probt LCL_Diff UCL_Diff;\n    title \"MAR: significant results\";\nrun;\n\n%mend;\n\n%part3_TP;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo determine the exact tipping point between the last “significant” delta and the first “non-significant” delta, you may manually perform linear interpolation for DELTA, Diff, LCL_Diff and UCL_Diff at Probt = 0.05.\n\n\n\n\n\n\n\n\n\nNote: In the five macros, delta adjustments happen right after data imputation under MAR or MNAR (using reference-based imputation approaches) in Part2, but before implementing the analysis model in Part3. Sensitivity analyses can therefore be performed without having to refit the imputation model, which is computationally efficient. This approach is considered a marginal delta adjustment approach, because the delta is simply added to the mean of the conditional multivariate normal distribution (conditional on the observed values and the covariates) for the imputation model (Roger 2017).\n\n\n\nA nice visualization of this tipping point analysis for the MAR approach is shown below. The dashed horizontal line indicates a p-value of 0.05 in the left plot and no treatment effect in the right plot.\n\n\n\n\n\n\n\n\n\nWe clearly see that the p-value under MAR reaches a tipping point from 3 onward in the range of delta’s considered."
  },
  {
    "objectID": "SAS/tipping_point.html#comparison-with-rbmi-mnar-approaches",
    "href": "SAS/tipping_point.html#comparison-with-rbmi-mnar-approaches",
    "title": "SAS Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "In the table below we present the results of the different imputation strategies with varying number of multiple imputation draws, M = 500 and M = 5000. Note that the results can be slightly different from the results above due to a possible different seed. The estimates show the contrast at visit 7 between DRUG and PLACEBO (DRUG - PLACEBO). Delta adjustments were applied to all imputed missing data, except intermittent missing data, in the intervention group only.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\nDelta control\nDelta intervention at TP\nEstimate at TP\n95% CI\nP-value\nOriginal estimate\nOriginal p-value\n\n\n\n\nMI - MAR (M=500)\n0\n3\n-2.081\n-4.337 to 0.175\n0.0703\n-2.810\n0.0134\n\n\nMI - MAR (M=5000)\n0\n3\n-2.096\n-4.353 to 0.161\n0.0684\n-2.825\n0.0130\n\n\nMI - MNAR J2R (M=500)\n0\n-1\n-2.365\n-4.604 to -0.125\n0.0386\n-2.122\n0.0650\n\n\nMI - MNAR J2R (M=5000)\n0\n-1\n-2.387\n-4.617 to -0.157\n0.0361\n-2.144\n0.0611\n\n\nMI - MNAR CR (M=500)\n0\n1\n-2.141\n-4.370 to 0.089\n0.0597\n-2.384\n0.0350\n\n\nMI - MNAR CR (M=5000)\n0\n1\n-2.157\n-4.377 to 0.062\n0.0566\n-2.400\n0.0330\n\n\nMI - MNAR CIR (M=500)\n0\n1\n-2.218\n-4.446 to 0.010\n0.0510\n-2.461\n0.0296\n\n\nMI - MNAR CIR (M=5000)\n0\n2\n-1.995\n-4.229 to 0.240\n0.0798\n-2.481\n0.0276\n\n\n\nOf all considered approaches, the MAR approach yields the largest delta adjustment at its tipping point, with a delta intervention of 3 at both M = 500 and M = 5000. This indicates that the MAR assumption is the most robust against slight deviations of its conditions. Notice that for the MNAR JR approach we included, for completeness, tipping point analyses to know when the results switch from non-significant to significant. Correspondingly, two negative delta’s (-1) are found at the tipping point. This is expected, given that the original analyses are non-significant (p ~ 0.0650 and p ~ 0.0611) and a tipping point analysis here aims to find the point at which the analysis turns to be significant, instead of non-significant."
  },
  {
    "objectID": "SAS/tipping_point.html#flexible-delta-adjustments",
    "href": "SAS/tipping_point.html#flexible-delta-adjustments",
    "title": "SAS Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "So far, we have only considered simple delta adjustments that add the same value to all imputed missing data. However, you may want to implement more flexible delta adjustments for missing data following an intercurrent event (ICE), where the magnitude of the delta varies depending on the distance of the visit from the ICE visit.\nTo enable flexible delta adjustments, Part3() includes three delta arguments: Delta, DLag and DGroups. Although these arguments were introduced earlier in the tutorial, we will now elaborate on how exactly these arguments allow for flexible delta adjustments with a few examples taken from the advanced functionality vignette of the rbmi R package.\n\n\nAssume a setting with 4 visits and the user specified Delta = 5 6 7 8 and DLag = 1 2 3 4. For a subject for whom the first visit affected by the ICE is visit 2, these values of Delta and DLag would imply the following delta adjustments:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n5\n6\n7\n8\n\n\nDLag\n0\n1\n2\n3\n\n\nDelta * DLag\n0\n6\n14\n24\n\n\nCumulative sum\n0\n6\n20\n44\n\n\n\nThat is, the subject would have a delta adjustment of 0 applied to visit 1, 6 for visit 2, 20 for visit 3 and 44 for visit 4.\nAssume instead, that the subject’s first visit affected by the ICE was visit 3. Then, the above values of Delta and DLag would imply the following delta adjustment:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n5\n6\n7\n8\n\n\nDLag\n0\n0\n1\n2\n\n\nDelta * DLag\n0\n0\n7\n16\n\n\nCumulative sum\n0\n0\n7\n23\n\n\n\nAnd thus the subject would have a delta adjustment of 0 applied to visits 1 and 2, 7 for visit 3 and 23 for visit 4.\nAnother way of using these arguments is to set Delta to the difference in time between visits and DLag to be the amount of delta per unit of time. For example, let’s say that visits occur on weeks 1, 5, 6 and 9 and that we want a delta of 3 to be applied for each week after an ICE. For simplicity, we assume that the ICE occurs immediately after the subject’s last visit which is not affected by the ICE. This this could be achieved by setting Delta = 1 4 1 3, i.e. the difference in weeks between each visit, and DLag = 3 3 3 3.\nAssume a subject’s first visit affected by the ICE was visit 2, then these values of Delta and DLag would imply the following delta offset:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n1\n4\n1\n3\n\n\nDLag\n0\n3\n3\n3\n\n\nDelta * DLag\n0\n12\n3\n9\n\n\nCumulative sum\n0\n12\n15\n24\n\n\n\nLet’s now consider the antidepressant data again. Suppose we apply a delta adjustment of 2 for each week following an ICE in the intervention group only. For example, if the ICE took place immediately after visit 4, then the cumulative delta applied to a missing value from visit 5 would be 2, from visit 6 would be 4, and from visit 7 would be 6.\nTo program this, we would define Delta, DLag and DGroups in Part3() of the five macros as follows:\n\n%part3(Jobname = HAMD_MAR, \n        anref=PLACEBO, \n        Delta = 2 2 2 2, \n        DLag = 1 1 1 1, \n        DGroups = DRUG, \n        Label=MAR);\n\nNotice that DLag = 1 1 1 1 is the default for this argument in SAS, you may also leave it unspecified in this case.\n\n\n\nAs already illustrated in the tipping point analysis assuming MAR above, you may also add a simple, fixed delta using the Delta and DLag arguments. To do this, Delta should be the same value repeated for each visit, e.g. 5 5 5 5, while DLag should be 1 0 0 0. This ensures a delta of 5 is added to each imputed missing value following an ICE, which we here assume to occur at the visit 2:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n5\n5\n5\n5\n\n\nDlag\n0\n1\n0\n0\n\n\nDelta * dlag\n0\n0\n0\n0\n\n\nCumulative sum\n0\n5\n5\n5\n\n\n\nTo apply this delta = 5 to both groups we leave DGroups unspecified.\n\n%part3(Jobname = HAMD_MAR, \n        anref=PLACEBO, \n        Delta = 5 5 5 5, \n        DLag = 1 0 0 0, \n        Label=MAR);\n\nIn the five macros, delta adjustments are not applied to intermittent missing observations, but only to missing observations after withdrawal. From the documentation, it seems like this cannot be altered. In contrast, the choice of which missing data to apply delta adjustments to can be more freely managed using the rbmi R package. This may lead to discrepancies between tipping point analyses conducted in SAS and R, and may have important implications for datasets with high proportions of intermittent missing values in particular.\nNote: By making use of the DGroupsV argument in Part3 (see five macros documentation) one can specify a variable in the dataset that indicates whether a delta adjustment should be applied to any imputed value for the record after withdrawal. The five macros documentation states that “As an alternative to DGroups=, this option specifies a numeric variable with a logical value indicating whether Delta should be applied to any imputed value for the record. This variable should be Numeric holding a logical value.”. However, from our experience the intermittent missing values are not delta adjusted using this argument, only the missing values after withdrawal.\nNote: By making use of the DeltaV argument in Part3 (see five macros documentation) one can set specific delta adjustments by records."
  },
  {
    "objectID": "SAS/tipping_point.html#references",
    "href": "SAS/tipping_point.html#references",
    "title": "SAS Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "Cro et al. 2020. Sensitivity analysis for clinical trials with missing continuous outcome data using controlled multiple imputation: A practical guide. Statistics in Medicine. 2020;39(21):2815-2842.\nrbmi: Advanced Functionality\nrbmi: Quickstart\nRoger 2022. Other statistical software for continuous longitudinal endpoints: SAS macros for multiple imputation. Addressing intercurrent events: Treatment policy and hypothetical strategies. Joint EFSPI and BBS virtual event.\nRoger 2017. Fitting reference-based models for missing data to longitudinal repeated-measures Normal data. User guide five macros."
  },
  {
    "objectID": "SAS/SAS_Friedmantest.html",
    "href": "SAS/SAS_Friedmantest.html",
    "title": "Friedman Chi-Square test using SAS",
    "section": "",
    "text": "The Friedman test is a non-parametric statistical test developed by Milton Friedman similar to the parametric repeated measures ANOVA. It is used to detect differences in groups across multiple blocks. The procedure involves ranking each row (or block) together, then considering the values of ranks by columns. Applicable to complete block designs, it is thus a special case of the Durbin test.\nThe Friedman test is used for one-way repeated measures analysis of variance by ranks. In its use of ranks it is similar to the Kruskal–Wallis one-way analysis of variance by ranks.\n\n\nSAS 9.4\n\n\n\nSimulated dataset of 10 subjects(blocks) with continuous endpoints are generated for single-drug repeated measurements to check whether any significance exists between the responses(y) at different time points(4 time points simulated)(groups). The p-value will indicate whether differences in response for different time points are significant.\n\n\n\n#| eval: false\ndata one_way_repeat;\n  do subject = 1 to 10;\n    do timepoint = 1 to 4;\n      response = round(rand('Uniform',10,50));\n      output;\n    end;\n  end;\nrun;\n\nproc print;\nrun;\n\n\n\nThe FREQ procedure computes CMH statistic, Friedman’s test is identical to the ANOVA (row means scores) CMH statistic when the analysis uses rank scores (SCORES=RANK). The TABLES statement creates a three-way table i.e., timepoint and response stratified by subject. The output produces following statistics along with its degrees of freedom and p-value(Prob):\n\nNonzero Correlation\nRow Mean Scores Differ\n\nThe row corresponding to ‘Row Mean Scores Differ’ gives the required statistic and p-value for Friedman’s test.\n\n\n\nWhen the data contains missing response, the procedure discards the corresponding row and calculates the required statistic with a message about number of missing responses below the test statisitc output.\n\n\n\n#| eval: false\nproc freq data=one_way_repeat;\n    tables subject*timepoint*response / \n            cmh2 scores=rank noprint;\nrun;\n\n\n\n                                               The FREQ Procedure\n\n                                  Summary Statistics for timepoint by response\n                                            Controlling for subject\n\n                           Cochran-Mantel-Haenszel Statistics (Based on Rank Scores)\n\n                        Statistic    Alternative Hypothesis    DF       Value      Prob\n                        ---------------------------------------------------------------\n                            1        Nonzero Correlation        1      0.0276    0.8682\n                            2        Row Mean Scores Differ     3      3.6429    0.3027\n\n\n                                             Total Sample Size = 40\n\n\n\nExamples: FREQ Procedure (sas.com)"
  },
  {
    "objectID": "SAS/SAS_Friedmantest.html#sas-version",
    "href": "SAS/SAS_Friedmantest.html#sas-version",
    "title": "Friedman Chi-Square test using SAS",
    "section": "",
    "text": "SAS 9.4"
  },
  {
    "objectID": "SAS/SAS_Friedmantest.html#data-used",
    "href": "SAS/SAS_Friedmantest.html#data-used",
    "title": "Friedman Chi-Square test using SAS",
    "section": "",
    "text": "Simulated dataset of 10 subjects(blocks) with continuous endpoints are generated for single-drug repeated measurements to check whether any significance exists between the responses(y) at different time points(4 time points simulated)(groups). The p-value will indicate whether differences in response for different time points are significant."
  },
  {
    "objectID": "SAS/SAS_Friedmantest.html#data-source",
    "href": "SAS/SAS_Friedmantest.html#data-source",
    "title": "Friedman Chi-Square test using SAS",
    "section": "",
    "text": "#| eval: false\ndata one_way_repeat;\n  do subject = 1 to 10;\n    do timepoint = 1 to 4;\n      response = round(rand('Uniform',10,50));\n      output;\n    end;\n  end;\nrun;\n\nproc print;\nrun;"
  },
  {
    "objectID": "SAS/SAS_Friedmantest.html#overview",
    "href": "SAS/SAS_Friedmantest.html#overview",
    "title": "Friedman Chi-Square test using SAS",
    "section": "",
    "text": "The FREQ procedure computes CMH statistic, Friedman’s test is identical to the ANOVA (row means scores) CMH statistic when the analysis uses rank scores (SCORES=RANK). The TABLES statement creates a three-way table i.e., timepoint and response stratified by subject. The output produces following statistics along with its degrees of freedom and p-value(Prob):\n\nNonzero Correlation\nRow Mean Scores Differ\n\nThe row corresponding to ‘Row Mean Scores Differ’ gives the required statistic and p-value for Friedman’s test."
  },
  {
    "objectID": "SAS/SAS_Friedmantest.html#handling-missing-values",
    "href": "SAS/SAS_Friedmantest.html#handling-missing-values",
    "title": "Friedman Chi-Square test using SAS",
    "section": "",
    "text": "When the data contains missing response, the procedure discards the corresponding row and calculates the required statistic with a message about number of missing responses below the test statisitc output."
  },
  {
    "objectID": "SAS/SAS_Friedmantest.html#example-code-for-friedman-chi-square-test",
    "href": "SAS/SAS_Friedmantest.html#example-code-for-friedman-chi-square-test",
    "title": "Friedman Chi-Square test using SAS",
    "section": "",
    "text": "#| eval: false\nproc freq data=one_way_repeat;\n    tables subject*timepoint*response / \n            cmh2 scores=rank noprint;\nrun;"
  },
  {
    "objectID": "SAS/SAS_Friedmantest.html#results",
    "href": "SAS/SAS_Friedmantest.html#results",
    "title": "Friedman Chi-Square test using SAS",
    "section": "",
    "text": "The FREQ Procedure\n\n                                  Summary Statistics for timepoint by response\n                                            Controlling for subject\n\n                           Cochran-Mantel-Haenszel Statistics (Based on Rank Scores)\n\n                        Statistic    Alternative Hypothesis    DF       Value      Prob\n                        ---------------------------------------------------------------\n                            1        Nonzero Correlation        1      0.0276    0.8682\n                            2        Row Mean Scores Differ     3      3.6429    0.3027\n\n\n                                             Total Sample Size = 40"
  },
  {
    "objectID": "SAS/SAS_Friedmantest.html#references",
    "href": "SAS/SAS_Friedmantest.html#references",
    "title": "Friedman Chi-Square test using SAS",
    "section": "",
    "text": "Examples: FREQ Procedure (sas.com)"
  },
  {
    "objectID": "SAS/correlation.html",
    "href": "SAS/correlation.html",
    "title": "Correlation Analysis using SAS",
    "section": "",
    "text": "Data source: Loprinzi CL. Laurie JA. Wieand HS. Krook JE. Novotny PJ. Kugler JW. Bartel J. Law M. Bateman M. Klatt NE. et al. Prospective evaluation of prognostic variables from patient-completed questionnaires. North Central Cancer Treatment Group. Journal of Clinical Oncology. 12(3):601-7, 1994.\nSurvival in patients with advanced lung cancer from the North Central Cancer Treatment Group. Performance scores rate how well the patient can perform usual daily activities.\n\n\nThe CORR procedure computes Pearson correlation coefficients, three nonparametric measures of association, and the probabilities associated with these statistics. The correlation statistics include the following:\n\nPearson product-moment correlation\nSpearman rank-order correlation\nKendall’s tau-b coefficient\nHoeffding’s measure of dependence, \nPearson, Spearman, and Kendall partial correlation\n\nThis program works on the first three correlation coefficients.\nMissing Values\nPROC CORR excludes observations with missing values in the WEIGHT and FREQ variables. By default, PROC CORR uses pairwise deletion when observations contain missing values. PROC CORR includes all nonmissing pairs of values for each pair of variables in the statistical computations. Therefore, the correlation statistics might be based on different numbers of observations.\nIf you specify the NOMISS option, PROC CORR uses listwise deletion when a value of the VAR or WITH statement variable is missing. PROC CORR excludes all observations with missing values from the analysis. Therefore, the number of observations for each pair of variables is identical.\nThe PARTIAL statement always excludes the observations with missing values by automatically invoking the NOMISS option. With the NOMISS option, the data are processed more efficiently because fewer resources are needed. Also, the resulting correlation matrix is nonnegative definite.\nIn contrast, if the data set contains missing values for the analysis variables and the NOMISS option is not specified, the resulting correlation matrix might not be nonnegative definite. This leads to several statistical difficulties if you use the correlations as input to regression or other statistical procedures.\n\n\n\n#| eval: false\nproc corr data=lung pearson;\n    var age mealcal;\nrun;\n\n\n\n\n\n\n\n\n#| eval: false\nproc corr data=lung spearman; \n    var age mealcal; \nrun;\n\n\n\n\n\n\n\n\n#| eval: false\nproc corr data=lung kendall;\n    var age mealcal;\nrun;\n\n\n\n\n\n\n\n\nPROC CORR: The CORR Procedure (sas.com)"
  },
  {
    "objectID": "SAS/correlation.html#overview",
    "href": "SAS/correlation.html#overview",
    "title": "Correlation Analysis using SAS",
    "section": "",
    "text": "The CORR procedure computes Pearson correlation coefficients, three nonparametric measures of association, and the probabilities associated with these statistics. The correlation statistics include the following:\n\nPearson product-moment correlation\nSpearman rank-order correlation\nKendall’s tau-b coefficient\nHoeffding’s measure of dependence, \nPearson, Spearman, and Kendall partial correlation\n\nThis program works on the first three correlation coefficients.\nMissing Values\nPROC CORR excludes observations with missing values in the WEIGHT and FREQ variables. By default, PROC CORR uses pairwise deletion when observations contain missing values. PROC CORR includes all nonmissing pairs of values for each pair of variables in the statistical computations. Therefore, the correlation statistics might be based on different numbers of observations.\nIf you specify the NOMISS option, PROC CORR uses listwise deletion when a value of the VAR or WITH statement variable is missing. PROC CORR excludes all observations with missing values from the analysis. Therefore, the number of observations for each pair of variables is identical.\nThe PARTIAL statement always excludes the observations with missing values by automatically invoking the NOMISS option. With the NOMISS option, the data are processed more efficiently because fewer resources are needed. Also, the resulting correlation matrix is nonnegative definite.\nIn contrast, if the data set contains missing values for the analysis variables and the NOMISS option is not specified, the resulting correlation matrix might not be nonnegative definite. This leads to several statistical difficulties if you use the correlations as input to regression or other statistical procedures."
  },
  {
    "objectID": "SAS/correlation.html#pearson-correlation",
    "href": "SAS/correlation.html#pearson-correlation",
    "title": "Correlation Analysis using SAS",
    "section": "",
    "text": "#| eval: false\nproc corr data=lung pearson;\n    var age mealcal;\nrun;"
  },
  {
    "objectID": "SAS/correlation.html#spearman-correlation",
    "href": "SAS/correlation.html#spearman-correlation",
    "title": "Correlation Analysis using SAS",
    "section": "",
    "text": "#| eval: false\nproc corr data=lung spearman; \n    var age mealcal; \nrun;"
  },
  {
    "objectID": "SAS/correlation.html#kendalls-rank-correlation",
    "href": "SAS/correlation.html#kendalls-rank-correlation",
    "title": "Correlation Analysis using SAS",
    "section": "",
    "text": "#| eval: false\nproc corr data=lung kendall;\n    var age mealcal;\nrun;"
  },
  {
    "objectID": "SAS/correlation.html#references",
    "href": "SAS/correlation.html#references",
    "title": "Correlation Analysis using SAS",
    "section": "",
    "text": "PROC CORR: The CORR Procedure (sas.com)"
  },
  {
    "objectID": "SAS/logistic-regr.html",
    "href": "SAS/logistic-regr.html",
    "title": "Logistic Regression in SAS",
    "section": "",
    "text": "For a brief description of what is logistic regression see here."
  },
  {
    "objectID": "SAS/logistic-regr.html#summary-of-common-mistakes-in-sas",
    "href": "SAS/logistic-regr.html#summary-of-common-mistakes-in-sas",
    "title": "Logistic Regression in SAS",
    "section": "Summary of Common Mistakes in SAS",
    "text": "Summary of Common Mistakes in SAS\n\nHandling of missing data. Check SAS output that the number of missing values is as you expect. Make sure you have changed any NA results in the raw data to be missing, since SAS would consider NA as a valid category (a non-missing character result).\nMake sure you consider continuous or categorical variables as you intended. Just because a variable is character or numeric in the dataset, doesn’t mean SAS will treat it that way in the model. You have to use Class row to tell SAS which variables should be treated as character factors. You also have to use ref=' ' to tell SAS which is the reference category, otherwise SAS by default which use the last value of the variable alphabetically (e..g a categorical variable with 1, 2, 3 would default to 3 as the reference).\nBe careful you are modelling the correct event (response vs non-response, or weight_gain vs weight_loss for example)\nBe careful when interpreting any odds ratios that you have the factor of interest the correct way around (0 vs 1, or 1 vs 0)\nIf using proc logistic, be careful of how SAS creates its parameters used in the model as this determines how you can use the parameter estimates! It is often easiest to use param=glm so that the exp(maximum likelihood parameter estimate) = odds ratio. Check the class level information (Design variables) is as you would expect. See below for more detail on effect and ref parameterization and here for more options such as polynomial coding.\nBy default, SAS includes an intercept in the model. The intercept represents the baseline log odds of the outcome when all predictor variables are set to zero. SAS outputs a p-value testing if the baseline log odds is significantly different to zero, however this is not generally of interest because the purpose of our modelling is to find out which parameters have a significant effect on the probability of an event occurring. This baseline log odds is simply shifting the linear expression up or down so that the variable components are most accurate. The baseline log odds, may be not interpretable if it’s not possible for some variables to take a value of zero (e.g. age=0 is not yet born!). Therefore, we generally ignore the intercept and instead calculate odds ratios for parameters of interest. How your model is parameterised (param=glm, param=effect, param=ref, can also affect the estimate, so intercept estimates may not align when using different parameterization."
  },
  {
    "objectID": "SAS/logistic-regr.html#modelling-using-proc-genmod",
    "href": "SAS/logistic-regr.html#modelling-using-proc-genmod",
    "title": "Logistic Regression in SAS",
    "section": "Modelling using Proc Genmod",
    "text": "Modelling using Proc Genmod\nProc Genmod is a procedure that allows the fitting of Generalized Linear Models. By using the options dist=bin and link=logit, it fits a logistic regression as shown below. For more information see the SAS help here.\nAlways check that the Class Level Information matches what you expect (SAS puts the reference class level last). Also check that you are modelling the correct ‘event’ and that the algorithm has converged.\nBelow we are fitting trt01pn and sex as categorical variables, age, ph_ecog2 and meal_caln as continuous variables.\nYou can use exponential of the maximum likelihood parameter estimate and the exponential of the Wald 95% Confidence Limits to obtain the odds ratios and 95% CIs. Proc Genmod uses GLM parameterization.\n#| eval: false\nExample data: . = missing, trt01pn (1 or 2), sex (1 or 2), ph_ecog2 (0,1,2,3)\nwt_gain (1=gain, 0=no gain)\nwt_gain   trt01pn  age   sex    ph_ecog2   meal_caln\n-----------------------------------------------------------------------------\n.         1        74    1       1          1175\n0         1        68    2       0          1225\n1         2        60    1       2           .\n#| eval: false\nproc genmod data=lung;       \n    class trt01pn (ref=\"1\") sex (ref=\"1\");    \n    model wt_gain (event=\"1\") = trt01pn age sex ph_ecog2 meal_caln / \n        dist=bin link=logit;\nrun;\nClass Level Information\nClass     Levels      Values\n-----------------------------------------------------------------------------\ntrt01pn   2           2 1 \nsex       2           2 1\n-----------------------------------------------------------------------------\n\nResponse Profile\nOrdered value     wt_gain         Total Frequency\n-----------------------------------------------------------------------------\n1                 1                48 \n2                 0                122\n-----------------------------------------------------------------------------\n\nPROC GENMOD is modeling the probability that wt_gain='1'. \n\nAlgorithm Converged.\n\n                    Analysis of Maximum Likelihood Estimates                 \n\nParameter   DF  Estimate  Standard   Wald 95%        Wald         Pr&gt;ChiSq\n                          Error      CIs             Chi-Square\n-----------------------------------------------------------------------------\nIntercept   1   -2.6415   1.5140   -5.6090 0.3259    3.04         0.0810\ntrt01pn 2   1    0.3888   0.3782   -0.3524 1.1299    1.03         0.3039\ntrt01pn 1   0    0.0000   0.0000    0.0000 0.0000    .            .\nage         1    0.0123   0.0212   -0.0292 0.0537    0.34         0.5624    \nsex 2       1    0.8321   0.3744    0.0983 1.5659    4.97         0.0262  \nsex 1       0    0.0000   0.0000    0.0000 0.0000    .            .\nph_ecog     1   -0.3764   0.2638   -0.8935 0.1407    2.03         0.1537   \nmeal_cal    1   -0.0008   0.0004   -0.0000 0.0017    3.59         0.0581  \nscale       0    1.0000   0.0000    1.0000 1.0000\n----------------------------------------------------------------------------\nNote: The scale parameter was held fixed"
  },
  {
    "objectID": "SAS/logistic-regr.html#modelling-using-proc-logistic",
    "href": "SAS/logistic-regr.html#modelling-using-proc-logistic",
    "title": "Logistic Regression in SAS",
    "section": "Modelling using Proc Logistic",
    "text": "Modelling using Proc Logistic\nThe same model above can also be modelled using Proc Logistic. You no longer have to specify the distribution and link function, however you do need to add an option / param=glm on the class row. Different parameterizations are discussed later in the context of forming treatment contrast statements.\nFor now, all you need to know is that using /param=glm ensures exp(estimates)=odds ratio. You will also note that in the class level information, SAS now tells you the design variables. This will also be important later when we learn more about parameterization.\nProc Logistic is often preferred above Proc Genmod as it outputs the Odds Ratios and 95% CIs for you, without you having to back transform them using exponential of the MLEs yourself.\nNOTE: that the 95% confidence limits are being calculated using the Wald method. This assumes symmetric intervals around the maximum likelihood estimate using a normal distribution assumption (MLE +/-1.96* SE). Alternative confidence interval estimation methods exist such as the profile likelihood method but SAS does not calculate these.\n#| eval: false\nproc logistic data=lung;  \n    class trt01pn (ref=\"1\") sex (ref=\"1\") /param=glm;\n    model  wt_gain(event=\"1\") = trt01pn age sex ph_ecog2 meal_caln;\nrun;\nResponse Profile\nOrdered value     wt_gain         Total Frequency\n-----------------------------------------------------------------------------\n1                 0                122 \n2                 1                48\n-----------------------------------------------------------------------------\nProbability modeled is wt_gain=1\n\nNote: 58 observations were deleted due to missing values fro the repsonse or\nexplanatory variables.\n\nClass Level Information\nClass     Levels      Design Variables\n-----------------------------------------------------------------------------\ntrt01pn   2           1  0 \n          1           0  1\nsex       2           1  0\n          1           0  1\n-----------------------------------------------------------------------------\nConvergence criterion (GCONV=1E-8) satisfied.\n\n                    Analysis of Maximum Likelihood Estimates                 \n\nParameter   DF  Estimate  Standard     Wald         Pr&gt;ChiSq\n                          Error        Chi-Square\n-----------------------------------------------------------------------------\nIntercept   1   -2.6415   1.5140       3.0440       0.0810\ntrt01pn 2   1    0.3888   0.3782       1.0569       0.3039\ntrt01pn 1   0    0.0000   .            .            .\nage         1    0.0123   0.0212       0.3356       0.5624    \nsex 2       1    0.8321   0.3744       4.9400       0.0262  \nsex 1       0    0.0000   .            .            .\nph_ecog     1   -0.3764   0.2638       2.0349       0.1537   \nmeal_cal    1   -0.000850 0.000449     3.5895       0.0581  \n----------------------------------------------------------------------------\n  \n                   Odds Ratio Estimates                \n\nEffect           Point Estimate    95% Wald Confidence Limits\n-----------------------------------------------------------------------------\ntrt01pn 2 vs 1   1.475             0.703   3.095\nage              1.012             0.971   1.055\nsex     2 vs 1   2.298             1.103   4.787    \nph_ecog          0.686             0.409   1.151  \nmeal_cal         1.001             1.000   1.002 \n----------------------------------------------------------------------------"
  },
  {
    "objectID": "SAS/logistic-regr.html#model-comparison",
    "href": "SAS/logistic-regr.html#model-comparison",
    "title": "Logistic Regression in SAS",
    "section": "Model Comparison",
    "text": "Model Comparison\nTo compare two logistic models, the -2 * Log Likelihood from each model can be compared against a \\(\\chi^2\\)-distribution with degrees of freedom calculated using the difference in the two models’ parameters.\n#| eval: false\nModel 1:  model  wt_gain(event=\"1\") = trt01pn age sex ph_ecog2 meal_caln;\nModel Fit Statistics\nCriterion   Intercept Only     Intercept and Covariates       \n--------------------------------------------------------\nAIC         204.355            202.460\nSC          207.491            221.274\n-2 Log L    202.355            190.460   \n--------------------------------------------------------\n\nModel 2:  model  wt_gain(event=\"1\") = trt01pn sex ph_ecog2 meal_caln;\n\nModel Fit Statistics\nCriterion   Intercept Only     Intercept and Covariates       \n--------------------------------------------------------\nAIC         204.355            200.798\nSC          207.491            216.477\n-2 Log L    202.355            190.798   \n--------------------------------------------------------\n\n190.460 - 190.798 = -0.338 which using a $\\chi^2$-distribution corresponds to p=0.5606\nSAS also allows us to fit forward or backwards stepwise selection. Below we specify to stop when we have 4 variables left in the model. This is not commonly done in practice but is included to highlight the difference in using a selection procedure compared to doing the difference betweeen the -2 * log likelihood models using a \\(\\chi^2\\)-distribution.\n#| eval: false\nproc logistic data=lung;  \n    class trt01pn (ref=\"1\") sex (ref=\"1\") /param=glm;\n    model  wt_gain(event=\"1\") = trt01pn age sex ph_ecog2 meal_caln/ \n            selection=backward stop=4;\nrun;\nStep 1: Effect age is removed\nSummary of Backward Elimination\nStep   Effect Removed   DF     Number In     Wald Chi-Square   Pr&gt;ChiSq\n-----------------------------------------------------------------------------\n1      Age              1      4             0.3356            0.5624   \n-----------------------------------------------------------------------------\nNOTE: the chi-square test summary of backward elimination, p=0.5624 is slightly different to using the -2 * log likelihood models using a \\(\\chi^2\\)-distribution p=0.5606.\nThis is because the backward elimination process in SAS uses the residual sums of squares and the F statistic. Starting with the full model, it removes the parameter with the least significant F statistic until all effects in the model have F statistics significant as a certain level. The F statistic is calculated as:\n\\[F=\\frac{(RSS_{p-k}-RSS_p)/k}{RSS_p /(n-p-k)}\\] where RSS = Residual sums of squares, n=number of observations in the analysis, p=number of parameters in fuller model (exc. intercept), k=number of degrees of freedom associated with the effect you are dropping, \\[RSS_p\\] =RSS for the fuller model, \\[RSS_{p-k}\\] = RSS for the reduced model."
  },
  {
    "objectID": "SAS/logistic-regr.html#parameterization-of-model-effects-categorical-covariates-in-sas",
    "href": "SAS/logistic-regr.html#parameterization-of-model-effects-categorical-covariates-in-sas",
    "title": "Logistic Regression in SAS",
    "section": "Parameterization of model effects (categorical covariates) in SAS",
    "text": "Parameterization of model effects (categorical covariates) in SAS\nThe most common problem when fitting logistic regression in SAS, is getting SAS to model the binary variable (events) and any categorical covariates correctly. Using proc genmod (using dist=bin and link=logit options), there is no issue as SAS defaults to using GLM parameterization. However using proc logistic there are three ways to parameterize categorical variables, and the default is /PARAM=EFFECT which can cause confusion when interpreting your model.\nTo demonstrate, we will now model a categorical variable called Dose, which has 3 treatment levels (1=10mg Active, 2=20 mg Active, 3=Placebo). The reference is now dose=3. You must pay close attention to the table of Class level information in order to understand how SAS is modelling your data.\n\nCLASS X Y Z /PARAM=Effect\nThis is the SAS default such that if you do not specify the /param option, SAS defaults to using this method.\nWith the EFFECT option, dose_id has 3 levels, and so needs 2 design variables (β1 and β2). Sex has 2 levels so uses just 1 design variable (β1). For dose_id, the reference level (Placebo) is given values of “-1” for both of the β1 and β2 parameters. General model: Y= α + β1x1 + β2x1 {+β3x3} etc, representing each parameter in the model.\n#| eval: false\nproc logistic data=lung;  \n    class dose_id (ref=\"3\") sex (ref=\"1\") /param=effect;\n    model  wt_gain(event=\"1\") = dose_id age sex ph_ecog2 meal_caln;\nrun;\nClass Level Information\nClass       Value            Design Variables\n--------------------------------------------------------\n                             dose_β1  dose_β2\ndose_id      1                1           0\n             2                0           1\n             3               -1          -1\n             \n                             sex_β3      \nSEX          1               -1\n             2                1\n--------------------------------------------------------\nIf we want to estimate the effect of treatment (ignoring the other covariates), the Class Level Information can be translated into the table below, which is then used to form contrast statements.\nα is the intercept, and β1 and β2 (including the sign +/-) are from the design variables above.\n                              \nDose_id       Effect          \n------------------------------\n10mg Active   Y = α + β1          \n20mg Active   Y = α + β2          \nPlacebo       Y = α - β1 - β2    \n------------------------------\nTo compare 10mg Active vs Placebo, we would do the following:\n(α + β1 ) - (α - β1 - β2)\n= 2 β1 + β2  \n= 2 β1 + 1 β2\nThis equates to a contrast statement as follows:\n#| eval: false\nproc logistic data=lung;  \n    class dose_id (ref=\"3\") sex (ref=\"1\") /param=effect;\n    model  wt_gain(event=\"1\") = dose_id age sex ph_ecog2 meal_caln;\n    CONTRAST \"10mg vs. Placebo\" dose_id 2 1 / e; \nrun;\nTo compare the average of (10mg Active and 20mg Active) vs Placebo, we would do the following:\n((α + β1 + α + β2 ) /2 ) - (α - β1 - β2)\n= α + 0.5 β1 + 0.5 β2 - α + β1 + β2  \n= 1.5 β1 + 1.5 β2\nThis equates to a contrast statement as follows:\n#| eval: false\nproc logistic data=lung;  \n    class dose_id (ref=\"3\") sex (ref=\"1\") /param=effect;\n    model  wt_gain(event=\"1\") = dose_id age sex ph_ecog2 meal_caln;\n    CONTRAST \"Active (10mg + 20mg) vs. Placebo\" dose_id 1.5 1.5 / e; \nrun;\nAs you can see, these contrasts are not very intuitive and hence it is not reccomended to use the default SAS option of /param=effect, since its easy to end up with the wrong contrasts.\nContract Test Results\nContrast                           DF        Wald Chi-Square      Pr&gt;ChiSq\n--------------------------------------------------------\nActive (10mg +20mg) vs Placebo     1          1.1610               0.2813\n\n\nCLASS X Y Z /PARAM=glm\nNow let’s look at the param=glm option. GLM parameterization has a design variable for each level of a parameter. Hence for dose with 3 levels, we have 3 design variables (β1, β2 and β3).\n#| eval: false\nproc logistic data=lung;  \n    class dose_id (ref=\"3\") sex (ref=\"1\") /param=glm;\n    model  wt_gain(event=\"1\") = dose_id age sex ph_ecog2 meal_caln;\nrun;\nClass Level Information\nClass       Value            Design Variables\n--------------------------------------------------------\n                             dose_β1  dose_β2 dose_β3\ndose_id      1                1           0       0\n             2                0           1       0  \n             3                0           0       1\n             \n                             sex_β3   sex_β4   \nSEX          1                1           0\n             2                0           1\n--------------------------------------------------------\nIf we want to estimate the effect of treatment (ignoring the other covariates), the Class Level Information can be translated into the table below, which is then used to form contrast statements.\nα is the intercept, and β1 and β2 and β3 (including the sign +/-) are from the design variables above.\n                              \nDose_id       Effect          \n------------------------------\n10mg Active   Y = α + β1          \n20mg Active   Y = α + β2          \nPlacebo       Y = α - β3    \n--------------------------------------------------------\nTo compare 10mg Active vs Placebo, we would do the following:\n(α + β1 ) - (α - β3)\n=  β1 - β3  \n= 1 β1 - 1 β3\nThis equates to a contrast statement as follows:\n#| eval: false\nproc logistic data=lung;  \n    class dose_id (ref=\"3\") sex (ref=\"1\") /param=glm;\n    model  wt_gain(event=\"1\") = dose_id age sex ph_ecog2 meal_caln;\n    CONTRAST \"10mg vs. Placebo\" trt 1 -1 / e; \nrun;\nAs you can see, this contrast is much more intuitive. If you want to compare the effect of Active (10mg) compared to placebo, you take the effect of 10mg and subtract the effect of placebo !\nTo compare the average of (10mg Active and 20mg Active) vs Placebo, we would do the following:\n(α + β1 + α + β2)/2 - (α + β3) \n= α + 0.5 β1 + 0.5 β2 - α - β3 \n= 0.5 β1 + 0.5 β2 - β3\nThis equates to a contrast statement as follows:\n#| eval: false\nproc logistic data=lung;  \n    class dose_id (ref=\"3\") sex (ref=\"1\") /param=glm;\n    model  wt_gain(event=\"1\") = dose_id age sex ph_ecog2 meal_caln;\nCONTRAST \"Active (10mg + 20mg) vs. Placebo (1)\" trt 0.5 0.5 -1 / e; \nrun;\nAs you can see, this contrast is much more intuitive. If you want to compare the average of Active (10mg + 20mg) compared to placebo, you take half the effect of 10mg plus half the effect of 20mg and substract the effect of placebo!\nContract Test Results\nContrast                           DF        Wald Chi-Square      Pr&gt;ChiSq\n--------------------------------------------------------\nActive (10mg +20mg) vs Placebo     1          1.1610               0.2813\n\n\nCLASS X Y Z /PARAM=Ref\nNow let’s look at the param=ref option. Similar to param=effect, ref parameterization uses 1 less design variable compared to the number of levels each parameter has, but the parameterization is different. For dose with 3 levels, we have 2 design variables (β1 and β2).\n#| eval: false\nproc logistic data=lung;   \n    class dose_id (ref=\"3\") sex (ref=\"1\") /param=ref;\n    model  wt_gain(event=\"1\") = dose_id age sex ph_ecog2 meal_caln;\nrun;\nClass Level Information\nClass       Value            Design Variables\n--------------------------------------------------------\n                             dose_β1  dose_β2 \ndose_id      1                1           0       \n             2                0           1         \n             3                0           0       \n             \n                             sex_β3     \nSEX          1                0           \n             2                1           \n--------------------------------------------------------\nIf we want to estimate the effect of treatment (ignoring the other covariates), the Class Level Information can be translated into the table below, which is then used to form contrast statements.\nα is the intercept, and β1 and β2 and β3 (including the sign +/-) are from the design variables above.\n                              \nDose_id       Effect          \n------------------------------\n10mg Active   Y = α + β1          \n20mg Active   Y = α + β2          \nPlacebo       Y = α     \n--------------------------------------------------------\nTo compare 10mg Active vs Placebo, we would do the following:\n(α + β1 ) - (α ) =  β1  \nThis equates to a contrast statement as follows:\n#| eval: false\nproc logistic data=lung;  \n    class dose_id (ref=\"3\") sex (ref=\"1\") /param=glm;\n    model  wt_gain(event=\"1\") = dose_id age sex ph_ecog2 meal_caln;\n    CONTRAST \"10mg vs. Placebo\" trt 1  / e; \nrun;\nTo compare the average of (10mg Active and 20mg Active) vs Placebo, we would do the following:\n(α + β1 + α + β2)/2 -  α  \n= α + 0.5 β1 + 0.5 β2 - α  \n= 0.5 β1 + 0.5 β2\nThis equates to a contrast statement as follows:\n#| eval: false\nproc logistic data=lung;  \n    class dose_id (ref=\"3\") sex (ref=\"1\") /param=glm;\n    model  wt_gain(event=\"1\") = dose_id age sex ph_ecog2 meal_caln;\nCONTRAST \"Active (10mg + 20mg) vs. Placebo (1)\" trt 0.5 0.5  / e; \nrun;\nAgain this is less intuitive than the param=glm parameterization, but the same results are obtained.\nContract Test Results\nContrast                           DF        Wald Chi-Square      Pr&gt;ChiSq\n--------------------------------------------------------\nActive (10mg +20mg) vs Placebo     1          1.1610               0.2813"
  },
  {
    "objectID": "SAS/summary_skew_kurt.html",
    "href": "SAS/summary_skew_kurt.html",
    "title": "Skewness/Kurtosis",
    "section": "",
    "text": "In SAS, Skewness and Kurtosis are usually calculated using PROC MEANS. The procedures can produce both statistics in the same call. The procedure provides options for different methodologies.\n\n\nThe following data was used in this example.\n\ndata dat;\n    input team $ points assists;\n    datalines;\n  A 10 2\n  A 17 5\n  A 17 6\n  A 18 3\n  A 15 0\n  B 10 2\n  B 14 5\n  B 13 4\n  B 29 0\n  B 25 2\n  C 12 1\n  C 30 1\n  C 34 3\n  C 12 4\n  C 11 7\n  ;\nrun;\n\n\n\n\nBy default, SAS PROC MEANS uses VARDEF option “DF”. The other options are “N”, “WEIGHT”, and “WDF. Note that the WEIGHT and WDF options produce no results, as weighted calculations are not supported in PROC MEANS for Skewness and Kurtosis.\nThe following shows the SAS documentation for the two measures.\n\n\nThe SAS documentation for Skewness is provided here for convenience:\n\n\n\n\n\n\n\n\n\n\n\n\nThe SAS documentation for Kurtosis is as follows:\n\n\n\n\n\n\n\n\n\n\n\n\nSkewness and Kurtosis are commonly calculated in SAS as follows:\n\nproc means data=dat SKEWNESS KURTOSIS;\n    var points;\nrun;\n\nOutput:\n\n\n\n\n\n\n\n\n\nThe above results correspond to the Type 2 methodology in R.\n\n\n\nThe N option produces the following results\n\nproc means data=dat SKEWNESS KURTOSIS vardef = N;\n    var points;\nrun;\n\nOutput:\n\n\n\n\n\n\n\n\n\nThe above results correspond to the Type 1 methodology in R.\n\n\n\n\nSAS options provide for Type 1 and Type 2 Skewness and Kurtosis. Skewness Type 3 and Kurtosis Type 3 are not supported. Also Pearson’s Kurtosis is not supported."
  },
  {
    "objectID": "SAS/summary_skew_kurt.html#sas",
    "href": "SAS/summary_skew_kurt.html#sas",
    "title": "Skewness/Kurtosis",
    "section": "",
    "text": "By default, SAS PROC MEANS uses VARDEF option “DF”. The other options are “N”, “WEIGHT”, and “WDF. Note that the WEIGHT and WDF options produce no results, as weighted calculations are not supported in PROC MEANS for Skewness and Kurtosis.\nThe following shows the SAS documentation for the two measures.\n\n\nThe SAS documentation for Skewness is provided here for convenience:\n\n\n\n\n\n\n\n\n\n\n\n\nThe SAS documentation for Kurtosis is as follows:\n\n\n\n\n\n\n\n\n\n\n\n\nSkewness and Kurtosis are commonly calculated in SAS as follows:\n\nproc means data=dat SKEWNESS KURTOSIS;\n    var points;\nrun;\n\nOutput:\n\n\n\n\n\n\n\n\n\nThe above results correspond to the Type 2 methodology in R.\n\n\n\nThe N option produces the following results\n\nproc means data=dat SKEWNESS KURTOSIS vardef = N;\n    var points;\nrun;\n\nOutput:\n\n\n\n\n\n\n\n\n\nThe above results correspond to the Type 1 methodology in R."
  },
  {
    "objectID": "SAS/summary_skew_kurt.html#summary",
    "href": "SAS/summary_skew_kurt.html#summary",
    "title": "Skewness/Kurtosis",
    "section": "",
    "text": "SAS options provide for Type 1 and Type 2 Skewness and Kurtosis. Skewness Type 3 and Kurtosis Type 3 are not supported. Also Pearson’s Kurtosis is not supported."
  },
  {
    "objectID": "SAS/ttest_1Sample.html",
    "href": "SAS/ttest_1Sample.html",
    "title": "One Sample t-test in SAS",
    "section": "",
    "text": "In SAS, a one sample t-test is usually performed using PROC TTEST. The one sample t-test compares the mean of the sample to a provided null hypothesis, called “h0”. The h0 value is provided as an option. By default, the h0 value is zero (0). Running the procedure produces a set of results that suggest whether or not the null hypothesis should be rejected."
  },
  {
    "objectID": "SAS/ttest_1Sample.html#normal",
    "href": "SAS/ttest_1Sample.html#normal",
    "title": "One Sample t-test in SAS",
    "section": "Normal Data",
    "text": "Normal Data\nBy default, SAS PROC TTEST t-test assumes normality in the data and uses a classic Student’s t-test.\n\nCode\nThe following code was used to test the comparison of a reading scores against a baseline hypothesis value of 30:\n\nproc ttest data=read h0=30;\n    var score;\nrun;\n\nOutput:"
  },
  {
    "objectID": "SAS/ttest_1Sample.html#lognormal",
    "href": "SAS/ttest_1Sample.html#lognormal",
    "title": "One Sample t-test in SAS",
    "section": "Lognormal Data",
    "text": "Lognormal Data\nThe SAS one sample t-test also supports lognormal analysis for a one sample t-test.\n\nCode\nUsing the same data as above, we will set the “DIST” option to “lognormal” to perform this analysis:\n\nproc ttest data=read h0=30 dist=lognormal;\n    var score;\nrun;\n\nOutput:\n\n\n\n\n\n\n\n\n\nAs can be seen in the figure above, the lognormal variation of the one sample TTEST provides results for geometric mean, coefficient of variation, and 95% confidence limits for the coefficient of variation."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CAMIS - A PHUSE DVOST Working Group",
    "section": "",
    "text": "Introduction to CAMIS\nComparing Analysis Method Implementations in Software (CAMIS) is a cross-industry PHUSE DVOST Working Group, run in collaboration with members from PHUSE, PSI, ASA and IASCT. In addition to issue comments, which are hosted in the GitHub Repository, we meet monthly on the 2nd Monday of each month. If you would like to join us please contact us at workinggroups@phuse.global.\n\nMotivation\nThe goal of this project is to demystify conflicting results in statistical analysis methods and results between primarily SAS, R, and Python programming languages by providing comparisons and comprehensive explanations of similarities and differences. Many discrepancies have been discovered in statistical analysis results between these and other programming languages. The differences in results are due to fundamental approaches implemented by each language, which are each correct in their own right. The fact that these differences exist is a challenge, especially related to sponsor companies when submitting to a regulatory agency.\nIn its Statistical Software Clarifying Statement, the US Food and Drug Administration (FDA) states that it “FDA does not require use of any specific software for statistical analyses” and that “the computer software used for data management and statistical analysis should be reliable.” Observing differences across languages can reduce the analyst’s confidence in reliability and, by understanding the source of any discrepancies, one can reinstate confidence in reliability. CAMIS seeks to explore and explain some of the differences and similarities in statical analysis methods between these languages to ease these concerns.\n\n\nRepository\nThe repository below provides examples of statistical methodology in different software and languages, along with a comparison of the results obtained and description of any discrepancies.\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n  \n  \n    \n      Statistical Methodology\n      R\n      SAS\n      Python\n      Comparison\n    \n  \n  \n    \n      Summary Statistics\n    \n    Rounding\nR\nSAS\nPython\nR vs SAS\n    Summary statistics\nR\nSAS\nPython\nR vs SAS\n    Skewness/Kurtosis\nR\nSAS\nPython\nR vs SAS\n    \n      General Linear Models\n    \n    One-sample t-test\nR\nSAS\nPython\nR vs SAS\n    Paired t-test\nR\nSAS\nPython\nR vs SAS\n    Two-sample t-test\nR\nSAS\nPython\nR vs SAS\n    ANOVA\nR\nSAS\nPython\nR vs SAS\n    ANCOVA\nR\nSAS\nPython\nR vs SAS\n    MANOVA\nR\nSAS\nPython\nR vs SAS\n    Linear regression\nR\nSAS\nPython\nR vs SAS\n    \n      Generalized Linear Models\n    \n    Logistic regression\nR\nSAS\nPython\nR vs SAS\n    Poisson/negative binomial regression\nR\nSAS\n\nR vs SAS\n    \n      Non-Parametric Analysis\n    \n    Wilcoxon signed-rank test\nR\nSAS/ StatXact\n\nR vs SAS\n    Mann-Whitney U/Wilcoxon rank-sum test\nR\nSAS\n\nR vs SAS\n    Kolmogorov-Smirnov test\n\n\n\n\n    Kruskal-Wallis test\nR\nSAS\nPython\nR vs SAS\n    Friedman test\nR\nSAS\n\nR vs SAS\n    Jonckheere-Terpstra test\nR\nSAS\n\nR vs SAS\n    Hodges-Lehman estimator\nR\nSAS\n\n\n    \n      Categorical Data Analysis\n    \n    Binomial test\nR\nSAS\nPython\n\n    McNemar's test\nR\nSAS\n\nR vs SAS\n    Marginal homogeneity tests\nR\n\n\n\n    Chi-square test/Fisher's exact test\nR\nSAS\nPython\nR vs SAS\n    Cochran-Mantel-Haenszel test\nR\nSAS\n\nR vs SAS\n    Confidence intervals for proportions\nR\nSAS\n\nR vs SAS\n    \n      Repeated Measures\n    \n    Linear Mixed Model (MMRM)\nR\nSAS\n\nR vs SAS\n    Linear Mixed Model (degrees of freedom)\n\n\n\n\n    Generalized Linear Mixed Model (GLMM)\n\n\n\n\n    Generalized Estimating Equation (GEE)\n\n\n\n\n    \n      Multiple Imputation - Continuous Data MAR\n    \n    Linear regression imputation\nR\nSAS\n\n\n    Predictive mean matching\nR\n\n\n\n    \n      Multiple Imputation - Continuous Data MNAR\n    \n    Tipping point analysis (delta adjustment)\nR\nSAS\n\nR vs SAS\n    Reference-based imputation/joint modeling\nR\nSAS\n\nR vs SAS\n    \n      Correlation\n    \n    Pearson/Spearman/Kendall's Rank\nR\nSAS\nPython\nR vs SAS\n    \n      Survival Models\n    \n    Kaplan-Meier/log-rank test/Cox proportional hazards\nR\nSAS\n\nR vs SAS\n    Cause-specific hazards\nR\nSAS\n\nR vs SAS\n    Accelerated failure time\nR\n\n\n\n    Weighted log-rank test\nR\n\n\n\n    Recurrent events\nR\nSAS\n\nR vs SAS\n    Cumulative incidence functions\nR\nSAS\n\nR vs SAS\n    Tobit regression\nR\nSAS\n\nR vs SAS\n    Restricted Mean Survival Time (RMST)\n\nSAS\n\n\n    \n      Bayesian Methods\n    \n    Intro to Bayesian Analysis\n\n\n\n\n    Repeated Measures MMRM\n\n\n\n\n    \n      Sample size/ Power calculations\n    \n    Intro to Sample Size\n\n\n\nSummary\n    Superiority Single timepoint\nR\nSAS\n\n\n    Equivalence Single timepoint\nR\nSAS\n\n\n    Non-Inferiority Single timepoint\nR\nSAS\n\n\n    Average BioEquivalence\nR\n\n\n\n    Cochran-Armitage Test For Trend\nR\nSAS/ StatXact\n\n\n    Group sequential designs-Survival\nR\nSAS\nEast\nR vs SAS vs East\n    Group sequential designs-Binary Endpoint\n\n\n\n\n    \n      Causal inference/ Machine learning\n    \n    Intro to Machine Learning\n\n\n\nSummary\n    Propensity Score Matching\nR\n\n\nR vs SAS\n    Propensity Score Weighting\n\n\n\nR vs SAS\n    Clustering\nR\n\n\n\n    Principal Components Analysis (PCA)\nR\n\n\n\n    Lasso\n\n\n\n\n    Ridge Regression\n\n\n\n\n    xgboost\nR\n\n\n\n    \n      Other Methods\n    \n    Survey statistics\nR\nSAS\nPython\nR vs SAS vs Python"
  },
  {
    "objectID": "non_website_content/conferences/2024/abstract_useR2024.html",
    "href": "non_website_content/conferences/2024/abstract_useR2024.html",
    "title": "Conference information",
    "section": "",
    "text": "Conference information\nUseR 2024 (Salzburg)\nJuly 8-11 2024\nhttps://events.linuxfoundation.org/user/\n\nSubmission\nDeadline: March 11\nWho is submitting: Chi Zhang\n\n\n\nTitle\nIntroducing CAMIS: an open-source, community endeavor for Comparing Analysis Method Implementations in Software\n\n\nAbstract\n(No longer than 1200 characters)\nStatisticians using multiple softwares (SAS, R, Python) will have found differences in analysis results that warrant further justification. Whilst some industries may accept results not being the same as long as they are “close”, the highly regulated pharmaceutical industry would require an identical match in results. Yet, discrepancies might still occur, and knowing the reasons (different methods, options, algorithms etc) is critical to the modern statistician and subsequent regulatory submissions.\nIn this talk I will introduce CAMIS: Comparing Analysis Method Implementations in Software (CAMIS). https://psiaims.github.io/CAMIS/. It is a joint-project between PHUSE DVOST, the R Validation Hub, PSI AIMS, R consortium and ASA openstatsware. The aim of CAMIS is to investigate and document differences and similarities between different statistical softwares such as SAS and R. We use Quarto and Github to document methods, algorithms and comparisons between softwares through small case studies, and all articles are contributed by the community. In the transition from proprietary to open source technology in the industry, CAMIS can serve as a guidebook to navigate this process.\n\nkeywords: cross industry collaboration, multi-lingua, open-source, quarto\n\n\n\nLearning outcomes\n\nCAMIS is a cross-industry collaboration, focusing on documenting differences between statistical softwares (SAS, R)\nWe use open source technology (Quarto, Github, R), all articles are contributed by the community\nCAMIS aims to facilitate the transition from proprietary to open source in the industry"
  },
  {
    "objectID": "non_website_content/Conferences 2024 archive.html",
    "href": "non_website_content/Conferences 2024 archive.html",
    "title": "Conferences 2024",
    "section": "",
    "text": "2024 Conference Schedule\nList of seminars and conferences that the CAMIS team will be attending in 2024.\nIf you are a volunteer on the CAMIS project and plan to present at a seminar or conference, please add details of the conference below. For help with slides or content go to HERE.\nIf you want a single slide which advertises the CAMIS project, you can find this HERE\nTo cite the CAMIS project work in online content or presentations please use: “Content reproduced with the permission of PHUSE CAMIS - A DVOST Working Group”.\n\n\n\nConference name\nDate (2024)\nLocation\nName Attending\nDetails\nWebsite\n\n\n\n\nRSS Local Group Seminar\n28 Feb\nSheffield, England\nLyn Taylor\nSlides\nRSS\n\n\nphuse US Connect\n25-28 Feb\nBethesa, Maryland, USA\nSoma Sekhar Sriadibhatla, Vikash Jain, Brian Varney\nPoster\nConnect\n\n\nphuse chapter connect\n03 APR\nBangalore\nHarshal Khanolkar\n\n\n\n\nphuse/FDA CSS\n3-5 June\nSilver Spring Maryland, USA\nMike Stackhouse\nCAMIS Discussion\nCSS\n\n\nR/Medicine\n10-14 June\nOnline\nAgnieszka Tomczyk, Lyn Taylor\nslides\nR/Medicine 2024\n\n\nUseR!\n8-11 July\nSalzburg, Austria\nChi Zhang\nPresentation\nuseR! 2024\n\n\nPHUSE Belgian SDE\n23 Sept\nBrussels, Belgium\nQian Wang (msd)\nPresentation\nPHUSE SDE\n\n\nSESUG\n22-24 Sept\nBethesda, MD, USA\nBrian\n\nSESUG 2024\n\n\nR/pharma APAC track\n30 Oct- 1 Nov\nOnline, APAC\nSamrit Pramanik\nPresentation\n\n\n\nphuse EU\n11-13 Nov\nStrasbourg, France\nAgnieszka Tomczyk, Christina Fillmore, Stephen Mccawille and Anwesha Roy\nPresentation\nPHUSE EU Connect\n\n\nEffective statistician conference\n11-12 Nov\nVirtual\nLyn Taylor\nPresentation\nlink\n\n\n\n\n\nYearly Conference Planner\nTo help to plan our attendance throughout the year, here is a list of conferences we are looking to send representation to. If you plan to attend one of these conferences and are interested in representing us, then please get in touch.\n\n\n\nConference name\nUsual Abstract Deadline\nUsual Conference Date\nRegion\nLinks\n\n\n\n\nJoint Statistical Meetings (JSM) American Statistical Association (ASA)\n1st February\n1st week of August\nUSA\nJSM-ASA\n\n\nASA Biopharmaceutical Section Regulatory-Industry Statistics workshop\nEnd March\nLast week of September\nUSA\nBIOP\n\n\nPhuse US Connect\nNovember\nLast week of Feb\nUSA\nCDISC\n\n\nPhuse/FDA Computational Science Symposium(CSS)\nDecember\n1st week of June\nUSA\nCSS\n\n\nIASCT (ConSPIC)\nMid March\nEarly May\nIndia\nIASCT\n\n\nSociety of Clinical Trials (SCT)\nJanuary\nMid May\nUSA\nSCT\n\n\nPharmaSUG\nMid Jan\nMid May\nUSA\nPharmaSUG\n\n\nuseR\nEarly March\nEarly July\nEurope/Online\nuseR\n\n\nPSI\nNov-oral, Feb-Poster\nMid June\nEurope\nPSI\n\n\nDIA Global\nEnd Feb-poster\nMid June\nUSA\nDIA-USA\n\n\nDIA Europe\nNov\nMid March\nEurope\nDIA-Europe\n\n\nDIA China\nJan\nMid May\nChina\nDIA-China\n\n\nInternational Society for Clinical Biostatistics (ISCB)\nMid Feb\nMid July\nEurope\nISCB\n\n\nRoyal Statistical Society (RSS)\nEarly April\nEarly September\nEngland\nRSS\n\n\nSouthEast SAS User Group (SESUG)\nEnd Feb\nEnd Sept\nMaryland, USA\nSESUG\n\n\nPHUSE EU Connect\nMid March\nMid Nov\nEurope\nPHUSE EU Connect\n\n\nR/Pharma\nApril\nMid October\nVirtual\nR/pharma\n\n\nPOSIT conf.\nInvite only\nSeptember\nUSA\nPOSIT conf"
  },
  {
    "objectID": "blogs/posts/2023-12-01_highlights/index.html",
    "href": "blogs/posts/2023-12-01_highlights/index.html",
    "title": "2023 Highlights",
    "section": "",
    "text": "As we draw towards the end of 2023, the PHUSE DVOST CAMIS Working Group Project reflect on their key progress and successes this year.\nThe CAMIS repository went live in January 2023, drawing on the content from the CSRMLW Working Group. This searchable repository compares analysis method implementations in software (CAMIS) such as SAS, R and python.\nThe white paper, Key Considerations When Understanding Differences in Statistical Methodology Implementations Across Programming Languages – An Introduction to the CAMIS Project was published in June, which highlighted the importance of clearly specifying your analysis, such that it can be replicated in different software and doesn’t rely on default options, which can be different.\nFor more complex analyses, it can still be hard to understand what defaults and algorithms your software is using, so the team focused 2023 on expanding our github repo content, comparing SAS vs R methods. By August, we had covered the following topics in the repo: quartiles, rounding, ANOVA, MMRM, the CMH test, log-rank, Cox PH, the McNemar test, the Kruskal-Wallis test and logistic. October saw the launch of the CAMIS-Oncology sub-group, led by Somasekhar Sriadibhatla (AstraZeneca). This team will focus specifically on oncology endpoints and analysing them in SAS, R and Python.\nThe CAMIS team have expanded in membership this year and presented at conferences around the world. In November, we welcomed Harshal Khanolkar (Novo Nordisk) to join the leadership team alongside Christina Fillmore (GSK) and Lyn Taylor (Parexel). Our focus for 2024 will be on creating additional content for the repo and sharing awareness of the project across the medical research and wider community.\nWe would like to take this opportunity to thank all of our team members and contributors, and encourage everyone to check out the repository and help us grow our content. If you would like to join the team, please get in touch through the github repo."
  },
  {
    "objectID": "blogs/posts/2025-06-17_psi-conference/index.html",
    "href": "blogs/posts/2025-06-17_psi-conference/index.html",
    "title": "PSI Conference 2025",
    "section": "",
    "text": "The PSI Conference 2025 took place 8th-11th June 2025 in Wembley, London.\nThe CAMIS team in collaboration with the PSI AIMS SIG presented 2 talks at the conference. PHUSE kindly supported the team with provision of PHUSE CAMIS t-shirts and stickers to hand out, which contained the QR code for the repo. This really helped us to stand out among the 400+ statisticians and to spread the word about the CAMIS project repository.\nThe first of the talks entitled: “R you (all) right, SAS? Replicating statistical results between software”, contained an introduction to the CAMIS project presented by Lyn Taylor, followed by a case study example on how to compare methods across software and in particular methods to assess which r packages to use, presented by Christina Fillmore. Slides can be found here: CAMIS\nIn the second talk entitled: (Sample) size matters - demonstrating sample size calculations across software, Agnieszka Tomczyk presented findings from replicating sample size methods in SAS, StatXact, EAST and R. Slides can be found here: Samplesize\nWe received really positive feedback from the industry on our CAMIS repository, with everyone agreeing it will help to eliminate duplication of researching the methodology differences between software.\nPlease help to promote CAMIS by sharing the sticker below !"
  },
  {
    "objectID": "publication/index.html",
    "href": "publication/index.html",
    "title": "Publications",
    "section": "",
    "text": "Whitepaper\nKey Considerations When Understanding Differences in Statistical Methodology Implementations Across Programming Languages - An Introduction to the CAMIS Project\nRead the whitepaper here\n\n\nConference presentations\n\n2024 Conference Schedule\nList of seminars and conferences that the CAMIS team will be attending in 2024.\nIf you are a volunteer on the CAMIS project and plan to present at a seminar or conference, please add details of the conference below. For help with slides or content go to HERE.\nTo cite the CAMIS project work in online content or presentations please use: “Content reproduced with the permission of PHUSE CAMIS - A DVOST Working Group”.\n\n\n\nConference name\nDate (2024)\nLocation\nName Attending\nDetails\nWebsite\n\n\n\n\nRSS Local Group Seminar\n28 Feb\nSheffield, England\nLyn Taylor\nSlides\nRSS\n\n\nphuse US Connect\n25-28 Feb\nBethesa, Maryland, USA\nSoma Sekhar Sriadibhatla, Vikash Jain, Brian Varney\nPoster\nConnect\n\n\nphuse chapter connect\n03 APR\nBangalore\nHarshal Khanolkar\n\n\n\n\nphuse/FDA CSS\n3-5 June\nSilver Spring Maryland, USA\nMike Stackhouse\nCAMIS Discussion\nCSS\n\n\nR/Medicine\n10-14 June\nOnline\nAgnieszka Tomczyk, Lyn Taylor\nPart1 and Part2 and slides\nR/Medicine 2024\n\n\nUseR!\n8-11 July\nSalzburg, Austria\nChi Zhang\nPresentation\nuseR! 2024\n\n\nphuse EU\n11-13 Nov\nStrasbourg, France\nAgnieszka Tomczyk, Christina Fillmore\nPresentation\nPHUSE EU Connect\n\n\n\n\n\nYearly Conference Planner\nTo help to plan our attendance throughout the year, here is a list of conferences we are looking to send representation to. If you plan to attend one of these conferences and are interested in representing us, then please get in touch.\n\n\n\nConference name\nUsual Abstract Deadline\nUsual Conference Date\nRegion\nLinks\n\n\n\n\nJoint Statistical Meetings (JSM) American Statistical Association (ASA)\n1st February\n1st week of August\nUSA\nJSM-ASA\n\n\nASA Biopharmaceutical Section Regulatory-Industry Statistics workshop\nEnd March\nLast week of September\nUSA\nBIOP\n\n\nPhuse US Connect\nNovember\nLast week of Feb\nUSA\nCDISC\n\n\nPhuse/FDA Computational Science Symposium(CSS)\nDecember\n1st week of June\nUSA\nCSS\n\n\nIASCT (ConSPIC)\nMid March\nEarly May\nIndia\nIASCT\n\n\nSociety of Clinical Trials (SCT)\nJanuary\nMid May\nUSA\nSCT\n\n\nPharmaSUG\nMid Jan\nMid May\nUSA\nPharmaSUG\n\n\nuseR\nEarly March\nEarly July\nEurope/Online\nuseR\n\n\nPSI\nNov-oral, Feb-Poster\nMid June\nEurope\nPSI\n\n\nDIA Global\nEnd Feb-poster\nMid June\nUSA\nDIA-USA\n\n\nDIA Europe\nNov\nMid March\nEurope\nDIA-Europe\n\n\nDIA China\nJan\nMid May\nChina\nDIA-China\n\n\nInternational Society for Clinical Biostatistics (ISCB)\nMid Feb\nMid July\nEurope\nISCB\n\n\nRoyal Statistical Society (RSS)\nEarly April\nEarly September\nEngland\nRSS\n\n\nSouthEast SAS User Group (SESUG)\nEnd Feb\nEnd Sept\nMaryland, USA\nSESUG\n\n\nPHUSE EU Connect\nMid March\nMid Nov\nEurope\nPHUSE EU Connect\n\n\nR/Pharma\nApril\nMid October\nVirtual\nR/pharma\n\n\nPOSIT conf.\nInvite only\nSeptember\nUSA\nPOSIT conf"
  },
  {
    "objectID": "publication/dissertation.html",
    "href": "publication/dissertation.html",
    "title": "Dissertation projects",
    "section": "",
    "text": "CAMIS have a number of dissertation projects which are likely to be suitable for MSc or BSc dissertation projects that are part of a Statistical degree.\nThis content will be useful for you, if you are:\n\na student looking for a dissertation project?\nan academic looking for projects for your students?\na researcher (academic or industry) who wants to partner with a university and student to help progress your research?\n\n\nAvailable proposals\nIf you are interested in working on one of these projects, please reach out for more information.\nAvailable dissertation projects proposals (further information pending)\n\nMax-Combo\nMultivariate methods\n\n\n\nOngoing and Previously Completed projects\nMMRM - Ongoing\nConversion of MSc Statistics Course notes from R to SAS to be used for English Medical Statistician Apprenticeship scheme - Completed 2022\n\n\nNew proposals\nIf you have an idea for a future proposal, please feel free to tell us what you are interested in!\n\nContact\n@DrLynTaylor"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "CAMIS: Comparing Analysis Method Implementations in Software\nWe are a cross-industry PHUSE DVOST Working Group, run in collaboration with members from PHUSE, PSI, ASA and IASCT. In addition to issue comments, which are hosted in the GitHub Repository, we meet monthly on the 2nd Monday of each month. If you would like to join us please fill in the new members form or contact workinggroups@phuse.global.\nThe Leadership team consists of Christina Fillmore, Lyn Taylor, Chi Zhang and Yannick Vandendijck."
  },
  {
    "objectID": "about.html#who-are-we",
    "href": "about.html#who-are-we",
    "title": "About",
    "section": "",
    "text": "CAMIS: Comparing Analysis Method Implementations in Software\nWe are a cross-industry PHUSE DVOST Working Group, run in collaboration with members from PHUSE, PSI, ASA and IASCT. In addition to issue comments, which are hosted in the GitHub Repository, we meet monthly on the 2nd Monday of each month. If you would like to join us please fill in the new members form or contact workinggroups@phuse.global.\nThe Leadership team consists of Christina Fillmore, Lyn Taylor, Chi Zhang and Yannick Vandendijck."
  },
  {
    "objectID": "about.html#disclaimer",
    "href": "about.html#disclaimer",
    "title": "About",
    "section": "Disclaimer",
    "text": "Disclaimer\nThe PHUSE CAMIS project accepts no responsibility for any issues with the content provided on this repository. You use the content at your own risk."
  },
  {
    "objectID": "about.html#objectives",
    "href": "about.html#objectives",
    "title": "About",
    "section": "Objectives",
    "text": "Objectives\nThrough the creation of the CAMIS White Paper, the group provided guidance on the types of questions statistical staff should ask to aid with replication of analysis methods in different software and to identify the fundamental sources of discrepant results between software.\nThe group aims to save unnecessary repetition of work within the community, through the creation of this open source repository. This repository welcomes contributions from the wider community and is a resource comparing and documenting differences in analysis method implementations in software."
  },
  {
    "objectID": "about.html#background",
    "href": "about.html#background",
    "title": "About",
    "section": "Background",
    "text": "Background\nTraditionally, highly regulated industries (such as the pharmaceutical industry), have limited themselves to the use of commercially available software. When taking such an approach, the responsibility for the validation and testing of the product was often delegated to the software development company themselves, to ensure the software performs in line with its documentation, producing accurate reliable and reproducible results. However, one downside of this approach is that new methods and functionality can be slow to be adopted, limiting new method implementation and tools that can bring in efficiency.\nWith the increase in popularity of data science, the rate at which community led tools and methods are being developed in open-source software is rapid. The availability of advanced analytic capabilities, has led to increased desire for statistical staff in regulated industries to have access and approval to use to open source software (Rimler et al. 2022). The use of open source software is now widely accepted (FDA 2015), however, this increased variety of tools has resulted in an overlap of capabilities. This has raised challenging questions of traditional approaches to clinical analyses – particularly in situations where the overlap yields different results.\nOne example of this challenge encompasses discrepancies which have been discovered in statistical analysis results between different programming languages, even when working within qualified statistical computing environments. Subtle differences exist between the fundamental approaches and assumptions implemented within each language, yielding differences in results which are correct and consistent with their respective documentation. The fact that these differences exist may cause unease for sponsor companies when submitting to a regulatory agency, as it is uncertain if the agency will view these differences as problematic. By understanding the source of any discrepancies, one can reinstate that confidence.\nThis cross-industry group aims to empower statistical staff to make informed choices on the implementation of statistical analyses when multiple languages yield different results."
  },
  {
    "objectID": "about.html#references",
    "href": "about.html#references",
    "title": "About",
    "section": "References",
    "text": "References\n\nMichael S. Rimler, Joseph Rickert, Min-Hua Jen, Mike Stackhouse. 2022. Understanding differences in statistical methodology implementations across programming languages.\nStatistical Software Clarifying Statement (fda.gov)\nCAMIS White Paper"
  },
  {
    "objectID": "method_summary/stat_ml_methods.html",
    "href": "method_summary/stat_ml_methods.html",
    "title": "A Brief Guide to Statistics and Machine Learning Methods",
    "section": "",
    "text": "The crux of the matter\nWhatever book about machine learning you take, it begins with more or less detailed classification of algorithms. The depths of classification varies from simple “supervised vs unsupervised” dichotomy to much more confusing partitioning consists of supervised, un-, semi- and self-supervised methods as well as reinforcement learning. Supervised learning commonly divides to classification and regression, and we still have enough stuff beyond it including learning to rank or specific computer vision tasks like image segmentation (actually, pixel-wise classification) and object detection (required solving classification and regression tasks simultaneously).\nAt the same time, all kinds of supervised learning are not so different as one would consider. Generalized linear models, random forest and various implementation of gradient boosting (xgboost/lightgbm/catboost/etc.) can be used for both classification and regression.\nA more notable problem in studying machine learning is its opposition to “traditional” statistics. Fundamental theoretical textbooks clearly point the origin of machine learning in approx. 100-years-old statistical algorithms but contain significant amount of math details making it barely suitable for non-STEM specialists. On the other hand, more practically-oriented manuals often start from programming perspective and describe machine learning as completely separated universe, so no p-values and confidence intervals here. And of course we will unlikely find any mentions about cross-validation in all but most recent statistics textbooks.\n\n\nBridging the gap\nWe propose to use the intention-based models classification presented in Tidy Modeling with R book by Max Kuhn and Julia Silge:\n\nDescriptive models - effectively any model when no predictions or statistical inference is made with it even if the model is capable to do both. Common examples are adding LOESS smoothing on ggplot2 scatterplots and plotting data in PCA coordinates or in coordinates of some embedding space like t-SNE. The key point is to make no assumptions and conclusions about how this model works for new, unseen samples.\nInferential models - models that can produce p-values, confidence intervals and/or Bayesian estimates when we use it to answer pre-formulated questions via some kind of hypothesis testing. It is worth noting that machine learning approaches like cross-validation are fully applicable for inferential model selection, because they help to reduce the risk of overfitting. Even if a researcher isn’t interested in prediction quality for new samples, estimating model characteristics using out-of-fold samples using k-fold cross-validation is valuable and somewhat undervalued opportunity. See Inferential Analysis and Chapter 11 in Regression and Other Stories for details.\nPredictive models - any model created with optimal prediction quality in mind and with intention to make prediction for new samples ensuring certain error rate. If model can serve as inferential, it also can be used as predictive (e.g. generalized linear model), but not vice versa. There are bunch of models like clustering, decision trees and gradient boosting intended for prediction task only.\n\nAs was already mentioned, all models suffer from overfitting when repetitively modelling procedures with different settings are made on the same data. For inferential models it can lead to higher than expected type I and type II error rates or simply incorrect parameters estimations. Predictive models will report overestimated prediction quality if validation and test sets violate representativity or contain data leakage even if formal model selection procedure with (cross-)validation was done.\nСommon aspect of criticism in machine learning pipelines concerns the point estimation of performance. Best model are selected by mean/median validation folds scores during model tuning with k-fold cross-validation (or other resampling methods) without taking into account confidence intervals for the scores. This issue is easy to fix because existing procedures already provide the set of validation scores ready to do the math. So we came back to statistical inference, but in terms of model performance metrics rather than model itself. It’s also possible to generate multiple resamples from single test dataset and obtain interval estimates for metrics of interest, although this approach is not widely adopted yet.\n\n\nSoftware infrastructure to make it work\nWhile Python programmers don’t need anything but scikit-learn to begin machine learning models development (at least for structured tabular data), R admirers have too much choice: deprecated caret and mlr packages as well as more recent, actively developing mlr3 and tidymodels. We recommend focusing on studying the latest despite so many caret/mlr use cases can be found on the Internet.\nBoth mlr3 and tidymodels packages provide general framework for machine leaning models development, including interfaces for vast majority of ML algorithms implementations, (cross-)validation schemes, preprocessing steps and performance metrics. The choice between them is highly opinionated. Suggested simple rule of thumb:\n\nif you prefer more functional, less object-oriented programming and/or relies on tidyverse in your work, tidymodels is the choice;\nif you are familiar with Python scikit-learn and object-oriented programming paradigm with mutable objects, mlr3 will be the best match.\n\nIt’s necessary to point out one important difference between scikit-learn and R frameworks with similar functionality. scikit-learn itself implements bunch of ML algorithms, and many external implementations like xgboost are created with sklearn-compatible interface included. On the contrary, R packages mentioned above are solely wrappers over algorithms provided by the other packages. But even these packages are developed without regard of interfacing with mlr3/tidymodels/etc., all required unification is already done. So we can use any supported model without memorizing multiple names for the equivalent model parameter (like number of iterations in xgboost, catboost and lightgbm) or doing input data types conversion.\nWe haven’t said anything about many important topics like model interpretation, reproducibility, deep learning and MLOps to keep things simple and to save some room for further publications. This guide should be considered just as starting point for mastering machine learning, particularly in biomedical research applications."
  },
  {
    "objectID": "R/rounding.html",
    "href": "R/rounding.html",
    "title": "Rounding in R",
    "section": "",
    "text": "The round() function in Base R will round to the nearest whole number and ‘rounding to the even number’ when equidistant, meaning that exactly 12.5 rounds to the integer 12.\nThe round(12.5,digits=1) function tells R to round to 1 decimal place.\nHowever, rounding is dependent on OS services and on representation error since for example, if 0.15 is not represented exactly, if could actually be the number 0.15000000001 or 0.149999999999! The rounding rule applies to the represented number and not to the printed number, and so round(0.15, 1) could be either 0.1 or 0.2).\n\nround(1:9 / 10 + 0.05, 1)\n\n[1] 0.2 0.2 0.3 0.4 0.6 0.7 0.8 0.9 1.0"
  },
  {
    "objectID": "R/rounding.html#round-from-r-base",
    "href": "R/rounding.html#round-from-r-base",
    "title": "Rounding in R",
    "section": "",
    "text": "The round() function in Base R will round to the nearest whole number and ‘rounding to the even number’ when equidistant, meaning that exactly 12.5 rounds to the integer 12.\nThe round(12.5,digits=1) function tells R to round to 1 decimal place.\nHowever, rounding is dependent on OS services and on representation error since for example, if 0.15 is not represented exactly, if could actually be the number 0.15000000001 or 0.149999999999! The rounding rule applies to the represented number and not to the printed number, and so round(0.15, 1) could be either 0.1 or 0.2).\n\nround(1:9 / 10 + 0.05, 1)\n\n[1] 0.2 0.2 0.3 0.4 0.6 0.7 0.8 0.9 1.0"
  },
  {
    "objectID": "R/rounding.html#round_half_up-from-package-janitor",
    "href": "R/rounding.html#round_half_up-from-package-janitor",
    "title": "Rounding in R",
    "section": "round_half_up from package janitor",
    "text": "round_half_up from package janitor\nNote that the janitor package in R contains a function round_half_up() that rounds away from zero. In this case it rounds to the nearest whole number and ‘away from zero’ or ‘rounding up’ when equidistant, meaning that exactly 12.5 rounds to the integer 13.\n\n# Example code\nmy_number &lt;- c(2.2, 3.99, 1.2345, 7.876, 13.8739)\n\nr_0_dec &lt;- round(my_number, digits = 0)\nr_0_dec\n\n[1]  2  4  1  8 14\n\nr_1_dec &lt;- round(my_number, digits = 1)\nr_1_dec\n\n[1]  2.2  4.0  1.2  7.9 13.9\n\nr_2_dec &lt;- round(my_number, digits = 2)\nr_2_dec\n\n[1]  2.20  3.99  1.23  7.88 13.87\n\nr_3_dec &lt;- round(my_number, digits = 3)\nr_3_dec\n\n[1]  2.200  3.990  1.234  7.876 13.874\n\n\nIf using the janitor package in R, and the function round_half_up(), the results would be the same with the exception of rounding 1.2345 to 3 decimal places where a result of 1.235 would be obtained instead of 1.234. However, in some rare cases, round_half_up() does not return result as expected. There are two kinds of cases for it. 1. Round down for positive decimal like 0.xx5.\n\njanitor::round_half_up(524288.1255, digits = 3)\n\n[1] 524288.1\n\n\nThe cause is that when the decimal is stored in binary, the value usually does not exactly the same with the original number. In the example above, 524288.1255 is stored as a value a little less than the original value. Then round_half_up() rounds it down.\n\noptions(digits = 22)\n524288.1255\n\n[1] 524288.1254999999655411\n\n\nIn round_half_up(), a small decimal sqrt(.Machine$double.eps) is added before rounding. It avoids some incorrect rounding due to the stored numeric value is a little less than the original value, but does not cover all conditions.\n\nround_half_up &lt;- function(x, digits = 0) {\n  posneg &lt;- sign(x)\n  z &lt;- abs(x) * 10^digits\n  z &lt;- z + 0.5 + sqrt(.Machine$double.eps)\n  z &lt;- trunc(z)\n  z &lt;- z / 10^digits\n  z * posneg\n}\n\nMore examples can be found from the code below. It creates numeric values containing different digit numbers of integer part and decimal part, and all ending with 5 for rounding.\n\noptions(digits = 15) # set digit number to display\nint1 &lt;- c(0, 2^(1:19)) # create values of integer part\nround_digits &lt;- 1:7 # define values of rounding digits\n\ndec1 &lt;- 2^(-round_digits) + 10^(-round_digits - 1) * 5 # create values of decimal part\n\ndf1 &lt;- cross_join(tibble(int1), tibble(dec1, round_digits)) |&gt;\n  mutate(num1 = int1 + dec1) # combine integer part and decimal part\n\ndf1 |&gt;\n  mutate(rounded_num = round_half_up(num1, round_digits)) |&gt; # round the numbers\n  filter(rounded_num &lt; num1) |&gt; # incorrect if rounded result is less than the original number\n  print.data.frame()\n\n    int1       dec1 round_digits            num1    rounded_num\n1  32768 0.01562550            6  32768.01562550  32768.0156250\n2  65536 0.03125500            5  65536.03125500  65536.0312500\n3 262144 0.06255000            4 262144.06255000 262144.0625000\n4 262144 0.03125500            5 262144.03125500 262144.0312500\n5 524288 0.12550000            3 524288.12550000 524288.1250000\n6 524288 0.00781255            7 524288.00781255 524288.0078125\n\n\n6 of 140 numbers have incorrect results. Most of them are big numbers or long decimals to round.\n\nRound up for positive decimal like 0.4999….\n\n\noptions(digits = 16)\nround_half_up(1.4999999851, 0)\n\n[1] 2\n\n\nIt occurs when the number is smaller than but so closed to 0.xx5. As described in point 1 above, in round_half_up(), a small decimal sqrt(.Machine$double.eps) is added before rounding, which causes a number bigger than 0.xx5 to be rounded. It occurs only when the decimal is long, so round_half_up() is still reliable.\nAnd the added decimal sqrt(.Machine$double.eps) is necessary. Without it, or even replace it to a smaller decimal, there will be more incorrect results under point 1, as the example below. Some of them are common, e.g. rounding 16.1255 to 3 decimals.\n\n# a new function to round away from zero, by replacing sqrt(.Machine$double.eps) in round_half_up to a smaller number\nround_half_up_test &lt;- function(x, digits = 0) {\n  posneg &lt;- sign(x)\n  z &lt;- abs(x) * 10^digits\n  z &lt;- z + 0.5 + .Machine$double.eps * 100\n  z &lt;- trunc(z)\n  z &lt;- z / 10^digits\n  z * posneg\n}\n\noptions(digits = 15)\ndf1 |&gt;\n  mutate(rounded_num = round_half_up_test(num1, round_digits)) |&gt;\n  filter(rounded_num &lt; num1) |&gt;\n  print.data.frame()\n\n     int1       dec1 round_digits            num1    rounded_num\n1       2 0.03125500            5      2.03125500      2.0312500\n2       4 0.01562550            6      4.01562550      4.0156250\n3      16 0.12550000            3     16.12550000     16.1250000\n4      16 0.01562550            6     16.01562550     16.0156250\n5     128 0.12550000            3    128.12550000    128.1250000\n6     128 0.06255000            4    128.06255000    128.0625000\n7     128 0.03125500            5    128.03125500    128.0312500\n8    8192 0.25500000            2   8192.25500000   8192.2500000\n9   16384 0.12550000            3  16384.12550000  16384.1250000\n10  32768 0.25500000            2  32768.25500000  32768.2500000\n11  32768 0.01562550            6  32768.01562550  32768.0156250\n12  65536 0.12550000            3  65536.12550000  65536.1250000\n13  65536 0.03125500            5  65536.03125500  65536.0312500\n14 262144 0.06255000            4 262144.06255000 262144.0625000\n15 262144 0.03125500            5 262144.03125500 262144.0312500\n16 524288 0.12550000            3 524288.12550000 524288.1250000\n17 524288 0.00781255            7 524288.00781255 524288.0078125"
  },
  {
    "objectID": "R/rounding.html#other-methods",
    "href": "R/rounding.html#other-methods",
    "title": "Rounding in R",
    "section": "Other methods",
    "text": "Other methods\nhttps://stackoverflow.com/a/12688836 discussed multiple algorithms to round away from zero, including the one implemented in round_half_up(). Below is another algorithm modified from it.\n\nround_v2 &lt;- function(x, digits = 0, eps = .Machine$double.eps) {\n  round(x + x * eps, digits = digits)\n}\n\nLike round_half_up(), it also contains the two kinds of incorrect results. And like round_half_up(), a small decimal is added to make 0.xx5 round up. The parameter eps is provided to let user decide which small decimal to add.\nTo avoid the rounding issue totally, the only way is to increase precision, e.g. using package Rmpfr. It will need CPU resource. And it’s not always necessary considering the accuracy of current functions."
  },
  {
    "objectID": "R/rounding.html#round5-from-package-cards",
    "href": "R/rounding.html#round5-from-package-cards",
    "title": "Rounding in R",
    "section": "round5() from package cards",
    "text": "round5() from package cards\nThe cards::round5() package does the same rounding as the janitor::round_half_up()."
  },
  {
    "objectID": "R/rounding.html#conclusion",
    "href": "R/rounding.html#conclusion",
    "title": "Rounding in R",
    "section": "Conclusion",
    "text": "Conclusion\nSo far, round_half_up() from package janitor (or cards::round5() ) is still one of the best solutions to round away from zero, though users may meet incorrect results in rare cases when the numbers are big or the decimal is long.\n\noptions(digits = 7) # This just returns the number of displayed digits back to the default\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package * version date (UTC) lib source\n P dplyr   * 1.1.4   2023-11-17 [?] CRAN (R 4.4.0)\n P janitor * 2.2.0   2023-02-02 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/sample_s_equivalence.html",
    "href": "R/sample_s_equivalence.html",
    "title": "Sample size for equivalence studies",
    "section": "",
    "text": "Equivalence studies\nEquivalence trials are defined as trials that test whether a drug has the same (or similar) efficacy as an active agent or standard therapy. In practice, this is done by defining an “equivalence margin”, or limits, within which the treatment effect must lie to be considered equivalent.\n\nCalculations in R\nCan be performed in 2 packages: TrialSize and SampleSize4ClinicalTrials.\n\n\n\nComparing means for parallel design (unpaired)\n\nExample 1\nIt is anticipated that patients will have the same mean diastolic BP of 96 mmHg on both the new drug and the active comparator. It is also anticipated that the SD (ơ) of the diastolic BP is approximately 8 mmHg. The decision is made by clinical to accept equivalence if the difference found between the treatments is less than 5 mmHg. How many patients are required for an 80% power and an overall significance level of 5%?\n\n# TrialSize:\nTrialSize::TwoSampleMean.Equivalence(0.05, 0.2, 8, 1, 5, 0)\n\n[1] 43.8469\n\n# SampleSize4ClinicalTrials:\nSampleSize4ClinicalTrials::ssc_meancomp(\n  design = 4L,\n  ratio = 1,\n  alpha = 0.05,\n  power = 0.8,\n  sd = 8,\n  theta = 0,\n  delta = 5\n)\n\n  Treatment Control\n1        44      44\n\n\n\n\nExample 2\nA client is interested in conducting a clinical trial to compare two cholesterol lowering agents for treatment of hypercholesterolemic patients through a parallel design. The primary efficacy parameter is a low-density lipidprotein cholesterol (LDL-C). For establishing equivalence, suppose the true mean difference is 0.01 (1%) and the equivalence limit is 0.05 (5%). Assuming SD = 0.1 (10%), how many patients are required for an 80% power and an overall significance level of 5%?\n\n# TrialSize:\nTrialSize::TwoSampleMean.Equivalence(0.05, 0.2, 0.1, 1, 0.05, 0.01)\n\n[1] 107.0481\n\n# SampleSize4ClinicalTrials:\nSampleSize4ClinicalTrials::ssc_meancomp(\n  design = 4L,\n  ratio = 1,\n  alpha = 0.05,\n  power = 0.8,\n  sd = 0.1,\n  theta = 0.01,\n  delta = 0.05\n)\n\n  Treatment Control\n1       108     108\n\n\n\n\n\nComparing means for crossover design (paired)\n\nExample\nLet’s consider a standard standard two-sequence, two period crossover design for trials to establish therapeutic equivalence between a test drug and a standard therapy. The sponsor is interested in heaving an 80% power for stablishing equivalence. Based on the results from previous trials, it is estimated that the variance (of the difference) is 0.2 (20%). Suppose that the true mean difference is -0.1 (-10%) and the equivalence limit is 0.25 (25%). What is the required sample size, assuming significance level of 5%?\n\n# TrialSize:\nTrialSize::TwoSampleCrossOver.Equivalence(0.05, 0.2, 0.2, 0.25, -0.1)\n\n[1] 7.612309\n\n\n\n\nReferences\nMajority of the examples are taken from: Chow SC, Liu JP (1998). Design and analysis of clinical trials. Concepts and methodologies. Wiley, New York. and Machin, D., Campbell, M. J., Fayers, P., & Pinol, A. (Eds.) (1997). Sample Size Tables for Clinical Studies. (2nd ed.) Blackwell Science."
  },
  {
    "objectID": "R/sample_s_superiority.html",
    "href": "R/sample_s_superiority.html",
    "title": "Sample size for superiority studies",
    "section": "",
    "text": "Introduction about sample size calculations\nFor determination of the sample size, in most cases, all of the below parameters will be required to perform the calculations:\n\nPower\nclinically relevant/significant difference\nalpha (α)\nbeta (β)\nEffect size (Cohen’s d) (required only in some R packages), can be defined as:\nDifference between the means divided by the pooled standard deviation. In general, 0.2 can be considered a small effect, 0.5 a medium effect and 0.8 a large effect.\n\n\n\nSuperiority studies\nSuperiority trials aim to prove that the investigated treatment is better than the comparator. The null hypothesis states that is no difference between the treatments and the alternative that there is some difference between the treatments (difference ≠ 0).\n\nCalculations in R\nCan be performed in 3 packages in R: samplesize, stats and pwr.\n\n\n\nComparing means for parallel design (unpaired)\nIn the most common scenario SDs are known and the same. Otherwise Student t distribution is used instead of the normal distribution. Then approach between SAS and R is different - SAS follows only the Satterthwaite method, whilst in R both, Satterthwaiteand Welch one are available. The results differ slightly.\nPrimarily, we will consider the case with the same SDs.\n\nExample\nA client is interested in conducting a clinical trial to compare two cholesterol lowering agents for treatment of hypercholesterolemic patients. The primary efficacy parameter is a low-density lipidprotein cholesterol (LDL-C). Suppose that a difference of 8% in the percent change of LDL-C is considered a clinically meaningful difference and that the standard deviation is assumed to be 15%. What sample size is required for a two-sided false positive rate of 5% and a power of 80%?\n\nsamplesize::n.ttest(\n  power = 0.8,\n  alpha = 0.05,\n  mean.diff = 8,\n  sd1 = 15,\n  k = 1,\n  design = \"unpaired\",\n  fraction = \"balanced\",\n  variance = \"equal\"\n)\n\n$`Total sample size`\n[1] 114\n\n$`Sample size group 1`\n[1] 57\n\n$`Sample size group 2`\n[1] 57\n\nstats::power.t.test(\n  delta = 8,\n  sd = 15,\n  sig.level = 0.05,\n  power = 0.8,\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n\n\n     Two-sample t test power calculation \n\n              n = 56.16413\n          delta = 8\n             sd = 15\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\npwr::pwr.t.test(\n  d = 8 / 15,\n  sig.level = 0.05,\n  power = 0.80,\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n\n\n     Two-sample t test power calculation \n\n              n = 56.164\n              d = 0.5333333\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\n\n\nComparing means for crossover design (paired)\nIt is important to differenciate here between the within patient SD and the SD of the difference. We may need to recalculate one to the other, depending on the case.\nVariance of the difference = 2x Variance within patient. \\[Var_{diff} = 2 * Var_{patient}\\]\n\nExample\nWe wish to run an AB/BA single dose crossover to compare two brochodilators. The primary outcome is peak expiratory flow, and a clinically relevant difference of 30 l/min is sought with 80% power, the significance level is 5% and the best estimate of the within patient standard deviation is 32 l/min. What size of trial do we require?\n(After recalculating: \\[32 * \\sqrt{2} = 45\\])\n\nsamplesize::n.ttest(\n  power = 0.8,\n  alpha = 0.05,\n  mean.diff = 30,\n  sd1 = 45,\n  k = 1,\n  design = \"paired\",\n  fraction = \"balanced\"\n)\n\n$`Total sample size`\n[1] 20\n\nstats::power.t.test(\n  delta = 30,\n  sd = 45,\n  sig.level = 0.05,\n  power = 0.8,\n  type = \"one.sample\",\n  alternative = \"two.sided\"\n)\n\n\n     One-sample t test power calculation \n\n              n = 19.66697\n          delta = 30\n             sd = 45\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\npwr::pwr.t.test(\n  d = 30 / 45,\n  sig.level = 0.05,\n  power = 0.80,\n  type = \"one.sample\",\n  alternative = \"two.sided\"\n)\n\n\n     One-sample t test power calculation \n\n              n = 19.66695\n              d = 0.6666667\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\n\n\n\nReferences\nMajority of the examples are taken from: Chow SC, Liu JP (1998). Design and analysis of clinical trials. Concepts and methodologies. Wiley, New York."
  },
  {
    "objectID": "R/count_data_regression.html",
    "href": "R/count_data_regression.html",
    "title": "Regression for Count Data",
    "section": "",
    "text": "The most commonly used models for count data in clinical trials include:\n\nPoisson regression: assumes the response variable \\(Y\\) has a Poisson distribution, which is linked using the logarithm with explanatory variables \\(\\bf{x}\\).\n\n\\[\n\\text{log}(E(Y|x))= \\beta_0 + \\beta' x, \\; i = 1,\\ldots,n\n\\]\n\nQuasi-Poisson regression: Poisson model that allows overdispersion, i.e. dispersion parameter is not fixed at one.\nNegative-Binomial regression: popular generalization which loosens the assumption that the variance is equal to the mean made by the Poisson model.\n\nOther models include hurdle or zero-inflated models, if data have more zero observations than expected.\n\nExample: Familial Andenomatous Polyposis Data\nData source: F. M. Giardiello, S. R. Hamilton, A. J. Krush, S. Piantadosi, L. M. Hylind, P. Celano, S. V. Booker, C. R. Robinson and G. J. A. Offerhaus (1993), Treatment of colonic and rectal adenomas with sulindac in familial adenomatous polyposis. New England Journal of Medicine, 328(18), 1313–1316.\nData from a placebo-controlled trial of a non-steroidal anti-inflammatory drug in the treatment of familial andenomatous polyposis (FAP). (see ?polyps for details).\n\npolyps &lt;- HSAUR2::polyps\nglimpse(polyps)\n\nRows: 20\nColumns: 3\n$ number &lt;dbl&gt; 63, 2, 28, 17, 61, 1, 7, 15, 44, 25, 3, 28, 10, 40, 33, 46, 50,…\n$ treat  &lt;fct&gt; placebo, drug, placebo, drug, placebo, drug, placebo, placebo, …\n$ age    &lt;dbl&gt; 20, 16, 18, 22, 13, 23, 34, 50, 19, 17, 23, 22, 30, 27, 23, 22,…\n\n\nWe analyze the number of colonic polyps at 12 months in dependency of treatment and age of the patient.\n\npolyps |&gt;\n  ggplot(aes(y = number, x = age, color = treat)) +\n  geom_point() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nModel Fit\nWe fit a generalized linear model for number using the Poisson distribution with default log link.\n\n# Poisson\nm1 &lt;- stats::glm(number ~ treat + age, data = polyps, family = poisson)\nsummary(m1)\n\n\nCall:\nstats::glm(formula = number ~ treat + age, family = poisson, \n    data = polyps)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.529024   0.146872   30.84  &lt; 2e-16 ***\ntreatdrug   -1.359083   0.117643  -11.55  &lt; 2e-16 ***\nage         -0.038830   0.005955   -6.52 7.02e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 378.66  on 19  degrees of freedom\nResidual deviance: 179.54  on 17  degrees of freedom\nAIC: 273.88\n\nNumber of Fisher Scoring iterations: 5\n\n\nThe parameter estimates are on log-scale. For better interpretation, we can exponentiate these estimates, to obtain estimates and provide \\(95\\)% confidence intervals:\n\n# OR and CI\nexp(coef(m1))\n\n(Intercept)   treatdrug         age \n 92.6681047   0.2568961   0.9619140 \n\nexp(confint(m1))\n\nWaiting for profiling to be done...\n\n\n                 2.5 %      97.5 %\n(Intercept) 69.5361752 123.6802476\ntreatdrug    0.2028078   0.3218208\nage          0.9505226   0.9729788\n\n\nPredictions for number of colonic polyps given a new 25-year-old patient on either treatment using predict():\n\n# new 25 year old patient\nnew_pt &lt;- data.frame(treat = c(\"drug\", \"placebo\"), age = 25)\npredict(m1, new_pt, type = \"response\")\n\n        1         2 \n 9.017654 35.102332 \n\n\n\n\nModelling Overdispersion\nPoisson model assumes that mean and variance are equal, which can be a very restrictive assumption. One option to relax the assumption is adding a overdispersion constant to the relationship, i.e. \\(\\text{Var}(\\text{response}) = \\phi\\cdot \\mu\\), which results in a quasipoisson model:\n\n# Quasi poisson\nm2 &lt;- stats::glm(number ~ treat + age, data = polyps, family = quasipoisson)\nsummary(m2)\n\n\nCall:\nstats::glm(formula = number ~ treat + age, family = quasipoisson, \n    data = polyps)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4.52902    0.48106   9.415 3.72e-08 ***\ntreatdrug   -1.35908    0.38533  -3.527  0.00259 ** \nage         -0.03883    0.01951  -1.991  0.06284 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 10.72805)\n\n    Null deviance: 378.66  on 19  degrees of freedom\nResidual deviance: 179.54  on 17  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\n\nAlternatively, we can explicitly model the count data with overdispersion using the negative Binomial model. In this case, the overdispersion is a function of both \\(\\mu\\) and \\(\\mu^2\\):\n\\[\n\\text{Var}(\\text{response}) = \\mu + \\kappa\\,\\mu^2.\n\\]\n\n# Negative Binomial\nm3 &lt;- MASS::glm.nb(number ~ treat + age, data = polyps)\nsummary(m3)\n\n\nCall:\nMASS::glm.nb(formula = number ~ treat + age, data = polyps, init.theta = 1.719491, \n    link = log)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.52603    0.59466   7.611 2.72e-14 ***\ntreatdrug   -1.36812    0.36903  -3.707 0.000209 ***\nage         -0.03856    0.02095  -1.840 0.065751 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.7195) family taken to be 1)\n\n    Null deviance: 36.734  on 19  degrees of freedom\nResidual deviance: 22.002  on 17  degrees of freedom\nAIC: 164.88\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.719 \n          Std. Err.:  0.607 \n\n 2 x log-likelihood:  -156.880 \n\n\nBoth model result very similar parameter estimates, but vary in estimates for their respective standard deviation."
  },
  {
    "objectID": "R/manova.html",
    "href": "R/manova.html",
    "title": "Multivariate Analysis of Variance in R",
    "section": "",
    "text": "For a detailed description of MANOVA including assumptions see Renesh Bedre\nExample 39.6 Multivariate Analysis of Variance from SAS MANOVA User Guide\nThis example employs multivariate analysis of variance (MANOVA) to measure differences in the chemical characteristics of ancient pottery found at four kiln sites in Great Britain. The data are from Tubb, Parker, and Nickless (1980), as reported in Hand et al. (1994).\nFor each of 26 samples of pottery, the percentages of oxides of five metals are measured. The following statements create the data set and perform a one-way MANOVA. Additionally, it is of interest to know whether the pottery from one site in Wales (Llanederyn) differs from the samples from other sites.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(knitr)\nlibrary(emmeans)\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nknitr::opts_chunk$set(echo = TRUE)\npottery &lt;- read.csv(\"../data/manova1.csv\")\npottery\n\n           site   al   fe   mg   ca   na\n1    Llanederyn 14.4 7.00 4.30 0.15 0.51\n2    Llanederyn 13.8 7.08 3.43 0.12 0.17\n3    Llanederyn 14.6 7.09 3.88 0.13 0.20\n4    Llanederyn 11.5 6.37 5.64 0.16 0.14\n5    Llanederyn 13.8 7.06 5.34 0.20 0.20\n6    Llanederyn 10.9 6.26 3.47 0.17 0.22\n7    Llanederyn 10.1 4.26 4.26 0.20 0.18\n8    Llanederyn 11.6 5.78 5.91 0.18 0.16\n9    Llanederyn 11.1 5.49 4.52 0.29 0.30\n10   Llanederyn 13.4 6.92 7.23 0.28 0.20\n11   Llanederyn 12.4 6.13 5.69 0.22 0.54\n12   Llanederyn 13.1 6.64 5.51 0.31 0.24\n13   Llanederyn 12.7 6.69 4.45 0.20 0.22\n14   Llanederyn 12.5 6.44 3.94 0.22 0.23\n15     Caldicot 11.8 5.44 3.94 0.30 0.04\n16     Caldicot 11.6 5.39 3.77 0.29 0.06\n17 IslandThorns 18.3 1.28 0.67 0.03 0.03\n18 IslandThorns 15.8 2.39 0.63 0.01 0.04\n19 IslandThorns 18.0 1.50 0.67 0.01 0.06\n20 IslandThorns 18.0 1.88 0.68 0.01 0.04\n21 IslandThorns 20.8 1.51 0.72 0.07 0.10\n22  AshleyRails 17.7 1.12 0.56 0.06 0.06\n23  AshleyRails 18.3 1.14 0.67 0.06 0.05\n24  AshleyRails 16.7 0.92 0.53 0.01 0.05\n25  AshleyRails 14.8 2.74 0.67 0.03 0.05\n26  AshleyRails 19.1 1.64 0.60 0.10 0.03\n\n\n1 Perform one way MANOVA\nResponse ID for ANOVA is order of 1=al, 2=fe, 3=mg, ca, na.\nWe are testing H0: group mean vectors are the same for all groups or they dont differ significantly vs\nH1: At least one of the group mean vectors is different from the rest.\n\ndep_vars &lt;- cbind(pottery$al, pottery$fe, pottery$mg, pottery$ca, pottery$na)\nfit &lt;- stats::manova(dep_vars ~ pottery$site)\nstats::summary.aov(fit)\n\n Response 1 :\n             Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \npottery$site  3 175.610  58.537  26.669 1.627e-07 ***\nResiduals    22  48.288   2.195                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response 2 :\n             Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \npottery$site  3 134.222  44.741  89.883 1.679e-12 ***\nResiduals    22  10.951   0.498                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response 3 :\n             Df Sum Sq Mean Sq F value    Pr(&gt;F)    \npottery$site  3 103.35  34.450   49.12 6.452e-10 ***\nResiduals    22  15.43   0.701                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response 4 :\n             Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \npottery$site  3 0.204703 0.068234  29.157 7.546e-08 ***\nResiduals    22 0.051486 0.002340                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response 5 :\n             Df  Sum Sq  Mean Sq F value    Pr(&gt;F)    \npottery$site  3 0.25825 0.086082  9.5026 0.0003209 ***\nResiduals    22 0.19929 0.009059                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n‘summary(fit)’ outputs the MANOVA testing of an overall site effect.\nP&lt;0.001 suggests there is an overall difference between the chemical composition of samples from different sites.\n\nsummary(fit)\n\n             Df Pillai approx F num Df den Df    Pr(&gt;F)    \npottery$site  3 1.5539   4.2984     15     60 2.413e-05 ***\nResiduals    22                                            \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n2 Now we test to see if the Llanaderyn site is different to the other sites\nNOTE: interest may now lie in using pre-planned contrast statements to investigate if one site differs when compared to the average of the others. You would imagine this could be done using the ‘contrast’ function something like the code below, however this result does not match the SAS user guide and so looks to be doing a different analysis. SUGGEST THIS IS NOT USED UNTIL MORE RESEARCH INTO THIS METHOD CAN BE PERFORMED. One alternative suggestion is to perform a linear descriminent analysis (LDA).\n\nmanova(dep_vars ~ pottery$site) |&gt;\n  emmeans::emmeans(\"site\") |&gt;\n  contrast(\n    method = list(\n      \"Llanederyn vs other sites\" = c(\n        \"Llanederyn\" = -3,\n        \"Caldicot\" = 1,\n        \"IslandThorns\" = 1,\n        \"AshleyRails\" = 1\n      )\n    )\n  )\n\n contrast                  estimate    SE df t.ratio p.value\n Llanederyn vs other sites     1.51 0.661 22   2.288  0.0321\n\nResults are averaged over the levels of: rep.meas \n\n\nNOTE: if you feel you can help with the above discrepancy please contribute to the CAMIS repo by following the instructions on the contributions page."
  },
  {
    "objectID": "R/association.html",
    "href": "R/association.html",
    "title": "Association Analysis for Count Data Using R",
    "section": "",
    "text": "The most commonly used association analysis methods for count data/contingency tables compare observed frequencies with those expected under the assumption of independence:\n\\[\nX^2 = \\sum_{i=1}^k \\frac{(x_i-e_i)^2}{e_i},\n\\] where \\(k\\) is the number of contingency table cells.\nOther measures for the correlation of two continuous variables are:"
  },
  {
    "objectID": "R/association.html#chi-squared-test",
    "href": "R/association.html#chi-squared-test",
    "title": "Association Analysis for Count Data Using R",
    "section": "Chi-Squared test",
    "text": "Chi-Squared test\n\nchisq.test(tab)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tab\nX-squared = 1.8261, df = 1, p-value = 0.1766"
  },
  {
    "objectID": "R/association.html#fisher-exact-test",
    "href": "R/association.html#fisher-exact-test",
    "title": "Association Analysis for Count Data Using R",
    "section": "Fisher Exact Test",
    "text": "Fisher Exact Test\nFor \\(2 \\times 2\\) contingency tables, p-values are obtained directly using the hypergeometric distribution.\n\nfisher.test(tab)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  tab\np-value = 0.135\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.8158882 3.2251299\nsample estimates:\nodds ratio \n  1.630576"
  },
  {
    "objectID": "R/association.html#chi-squared-test-1",
    "href": "R/association.html#chi-squared-test-1",
    "title": "Association Analysis for Count Data Using R",
    "section": "Chi-Squared Test",
    "text": "Chi-Squared Test\n\nchisq.test(tab2)\n\nWarning in chisq.test(tab2): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  tab2\nX-squared = 260.76, df = 15, p-value &lt; 2.2e-16\n\n\nThe warning means that the smallest expected frequencies is lower than 5. It is recommended to use the Fisher’s exact test in this case."
  },
  {
    "objectID": "R/association.html#fisher-exact-test-1",
    "href": "R/association.html#fisher-exact-test-1",
    "title": "Association Analysis for Count Data Using R",
    "section": "Fisher Exact Test",
    "text": "Fisher Exact Test\nFor contingency tables larger than \\(2 \\times 2\\), p-values are based on simulations, which might require a lot of time (see ?fisher.test for details).\n\nfisher.test(tab2, simulate.p.value=TRUE)\n\n\n    Fisher's Exact Test for Count Data with simulated p-value (based on\n    2000 replicates)\n\ndata:  tab2\np-value = 0.0004998\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "R/xgboost.html",
    "href": "R/xgboost.html",
    "title": "XGBoost",
    "section": "",
    "text": "XGBoost which stands for eXtreme Gradient Boosting is an efficent implementation of gradient boosting. Gradient boosting is an ensemble technique in machine learning. Unlike traditional models that learn from the data independently, boosting combines the predictions of multiple weak learners to create a single, more accurate strong learner.\nAn XGBoost model is based on trees, so we don’t need to do much preprocessing for our data; we don’t need to worry about the factors or centering or scaling our data.\n\n\nThere are multiple packages that can be used to to implement xgboost in R.\n\n{tidymodels}\n{xgboost}\n{caret}\n\n{tidymodels} and {caret} easy ways to access xgboost easily. This example will use {tidymodels} because of the functionality included in {tidymodels} and is being heavily supported by Posit. {caret} was the precursor to {tidymodels} and it is recommended that you use {tidymodels} over {caret} as no new features are being added.\n\n\n\nData used for this example is birthwt which is part of the {MASS} package. This data-set considers a number of risk factors associated with birth weight in infants.\n\nlibrary(tidyverse)\nlibrary(MASS)\nlibrary(rsample)\nlibrary(parsnip)\nlibrary(xgboost)\n\nhead(birthwt)\n\nOur modeling goal using the birthwt dataset is to predict whether the birth weight is low or not low based on factors such as mother’s age, smoking status, and history of hypertension.\n\n\n\nUse {tidymodels} metadata package to split the data into training and testing data. For classification, we need to change the Low variable into a factor, since currently coded as an integer (0,1).\n\nbirthwt &lt;- birthwt |&gt;\n  mutate(\n    low_f = lvls_revalue(factor(low), c(\"Not Low\", \"Low\")),\n    smoke_f = lvls_revalue(factor(smoke), c(\"Non-smoker\", \"Smoker\"))\n  )\n\nbrthwt_split &lt;- rsample::initial_split(birthwt, strata = low)\nbrthwt_train &lt;- rsample::training(brthwt_split)\nbrthwt_test &lt;- rsample::testing(brthwt_split)\n\n\n\nAfter creating the data split, we setup the params of the model.\n\nxgboost_spec &lt;- parsnip::boost_tree(trees = 15) |&gt;\n  # This model can be used for classification or regression, so set mode\n  parsnip::set_mode(\"classification\") |&gt;\n  parsnip::set_engine(\"xgboost\")\n\nxgboost_spec\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  trees = 15\n\nComputational engine: xgboost \n\nxgboost_cls_fit &lt;- xgboost_spec |&gt;\n  fit(low_f ~ ., data = brthwt_train)\nxgboost_cls_fit\n\nparsnip model object\n\n##### xgb.Booster\nraw: 15.2 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n    colsample_bytree = 1, colsample_bynode = 1, min_child_weight = 1, \n    subsample = 1), data = x$data, nrounds = 15, watchlist = x$watchlist, \n    verbose = 0, nthread = 1, objective = \"binary:logistic\")\nparams (as set within xgb.train):\n  eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"1\", min_child_weight = \"1\", subsample = \"1\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 12 \nniter: 15\nnfeatures : 12 \nevaluation_log:\n  iter training_logloss\n &lt;num&gt;            &lt;num&gt;\n     1       0.44894346\n     2       0.31033704\n   ---              ---\n    14       0.01571681\n    15       0.01396153\n\nbind_cols(\n  predict(xgboost_cls_fit, brthwt_test),\n  predict(xgboost_cls_fit, brthwt_test, type = \"prob\")\n)\n\n# A tibble: 48 × 3\n   .pred_class `.pred_Not Low` .pred_Low\n   &lt;fct&gt;                 &lt;dbl&gt;     &lt;dbl&gt;\n 1 Not Low               0.985    0.0151\n 2 Not Low               0.985    0.0151\n 3 Not Low               0.985    0.0151\n 4 Not Low               0.985    0.0151\n 5 Not Low               0.985    0.0151\n 6 Not Low               0.988    0.0116\n 7 Not Low               0.988    0.0116\n 8 Not Low               0.988    0.0116\n 9 Not Low               0.988    0.0116\n10 Not Low               0.988    0.0116\n# ℹ 38 more rows\n\n\n\n\n\nTo perform xgboost with regression, when setting up the parameter of the model, set the mode of xgboost to regression. After that switch and then changing the variable of interest back to an integer, the rest of the code is the same.\n\nxgboost_reg_spec &lt;- parsnip::boost_tree(trees = 15) |&gt;\n  # This model can be used for classification or regression, so set mode\n  parsnip::set_mode(\"regression\") |&gt;\n  parsnip::set_engine(\"xgboost\")\n\nxgboost_reg_spec\n\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  trees = 15\n\nComputational engine: xgboost \n\n# For a regression model, the outcome should be `numeric`, not a `factor`.\nxgboost_reg_fit &lt;- xgboost_reg_spec |&gt;\n  fit(low ~ ., data = brthwt_train)\nxgboost_reg_fit\n\nparsnip model object\n\n##### xgb.Booster\nraw: 15.2 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n    colsample_bytree = 1, colsample_bynode = 1, min_child_weight = 1, \n    subsample = 1), data = x$data, nrounds = 15, watchlist = x$watchlist, \n    verbose = 0, nthread = 1, objective = \"reg:squarederror\")\nparams (as set within xgb.train):\n  eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"1\", min_child_weight = \"1\", subsample = \"1\", nthread = \"1\", objective = \"reg:squarederror\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 13 \nniter: 15\nnfeatures : 13 \nevaluation_log:\n  iter training_rmse\n &lt;num&gt;         &lt;num&gt;\n     1   0.352094163\n     2   0.247943366\n   ---           ---\n    14   0.003690328\n    15   0.002599106\n\npredict(xgboost_reg_fit, brthwt_test)\n\n# A tibble: 48 × 1\n     .pred\n     &lt;dbl&gt;\n 1 0.00253\n 2 0.00253\n 3 0.00253\n 4 0.00253\n 5 0.00253\n 6 0.00253\n 7 0.00253\n 8 0.00253\n 9 0.00253\n10 0.00253\n# ℹ 38 more rows\n\n\n\n\n\n\n\nXGBoost with tidymodels by Julia Silge\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package     * version date (UTC) lib source\n P BiocManager   1.30.25 2024-08-28 [?] CRAN (R 4.4.1)\n P cli           3.6.3   2024-06-21 [?] CRAN (R 4.4.0)\n   codetools     0.2-20  2024-03-31 [2] CRAN (R 4.4.2)\n P colorspace    2.1-1   2024-07-26 [?] CRAN (R 4.4.0)\n P data.table    1.16.0  2024-08-27 [?] CRAN (R 4.4.1)\n P digest        0.6.37  2024-08-19 [?] CRAN (R 4.4.1)\n P dplyr       * 1.1.4   2023-11-17 [?] CRAN (R 4.4.0)\n P evaluate      1.0.0   2024-09-17 [?] CRAN (R 4.4.1)\n P fansi         1.0.6   2023-12-08 [?] CRAN (R 4.4.0)\n P fastmap       1.2.0   2024-05-15 [?] CRAN (R 4.4.0)\n P forcats     * 1.0.0   2023-01-29 [?] CRAN (R 4.4.0)\n P furrr         0.3.1   2022-08-15 [?] CRAN (R 4.4.0)\n P future        1.34.0  2024-07-29 [?] CRAN (R 4.4.0)\n P generics      0.1.3   2022-07-05 [?] CRAN (R 4.4.0)\n P ggplot2     * 3.5.1   2024-04-23 [?] CRAN (R 4.4.0)\n P globals       0.16.3  2024-03-08 [?] CRAN (R 4.4.0)\n P glue          1.8.0   2024-09-30 [?] CRAN (R 4.4.1)\n P gtable        0.3.5   2024-04-22 [?] CRAN (R 4.4.0)\n P hardhat       1.4.0   2024-06-02 [?] CRAN (R 4.4.0)\n P hms           1.1.3   2023-03-21 [?] CRAN (R 4.4.0)\n P htmltools     0.5.8.1 2024-04-04 [?] CRAN (R 4.4.0)\n P htmlwidgets   1.6.4   2023-12-06 [?] CRAN (R 4.4.0)\n P jsonlite      1.8.9   2024-09-20 [?] CRAN (R 4.4.1)\n   knitr         1.50    2025-03-16 [1] RSPM (R 4.4.0)\n   lattice       0.22-6  2024-03-20 [2] CRAN (R 4.4.2)\n P lifecycle     1.0.4   2023-11-07 [?] CRAN (R 4.4.0)\n P listenv       0.9.1   2024-01-29 [?] CRAN (R 4.4.0)\n P lubridate   * 1.9.3   2023-09-27 [?] CRAN (R 4.4.0)\n P magrittr      2.0.3   2022-03-30 [?] CRAN (R 4.4.0)\n   MASS        * 7.3-61  2024-06-13 [2] CRAN (R 4.4.2)\n   Matrix        1.7-1   2024-10-18 [2] CRAN (R 4.4.2)\n P munsell       0.5.1   2024-04-01 [?] CRAN (R 4.4.0)\n P parallelly    1.38.0  2024-07-27 [?] CRAN (R 4.4.0)\n P parsnip     * 1.2.1   2024-03-22 [?] CRAN (R 4.4.0)\n P pillar        1.9.0   2023-03-22 [?] CRAN (R 4.4.0)\n P pkgconfig     2.0.3   2019-09-22 [?] CRAN (R 4.4.0)\n P purrr       * 1.0.2   2023-08-10 [?] CRAN (R 4.4.0)\n P R6            2.5.1   2021-08-19 [?] CRAN (R 4.4.0)\n P readr       * 2.1.5   2024-01-10 [?] CRAN (R 4.4.0)\n   renv          1.0.10  2024-10-05 [1] CRAN (R 4.4.1)\n P rlang         1.1.4   2024-06-04 [?] CRAN (R 4.4.0)\n P rmarkdown     2.28    2024-08-17 [?] CRAN (R 4.4.0)\n P rsample     * 1.2.1   2024-03-25 [?] CRAN (R 4.4.0)\n P rstudioapi    0.16.0  2024-03-24 [?] CRAN (R 4.4.0)\n P scales        1.3.0   2023-11-28 [?] CRAN (R 4.4.0)\n P sessioninfo   1.2.2   2021-12-06 [?] CRAN (R 4.4.0)\n P stringi       1.8.4   2024-05-06 [?] CRAN (R 4.4.0)\n P stringr     * 1.5.1   2023-11-14 [?] CRAN (R 4.4.0)\n P tibble      * 3.2.1   2023-03-20 [?] CRAN (R 4.4.0)\n P tidyr       * 1.3.1   2024-01-24 [?] CRAN (R 4.4.0)\n P tidyselect    1.2.1   2024-03-11 [?] CRAN (R 4.4.0)\n P tidyverse   * 2.0.0   2023-02-22 [?] CRAN (R 4.4.0)\n P timechange    0.3.0   2024-01-18 [?] CRAN (R 4.4.0)\n P tzdb          0.4.0   2023-05-12 [?] CRAN (R 4.4.0)\n P utf8          1.2.4   2023-10-22 [?] CRAN (R 4.4.0)\n P vctrs         0.6.5   2023-12-01 [?] CRAN (R 4.4.0)\n P withr         3.0.1   2024-07-31 [?] CRAN (R 4.4.0)\n   xfun          0.52    2025-04-02 [1] RSPM (R 4.4.0)\n P xgboost     * 1.7.8.1 2024-07-24 [?] CRAN (R 4.4.0)\n P yaml          2.3.10  2024-07-26 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/xgboost.html#available-r-packages",
    "href": "R/xgboost.html#available-r-packages",
    "title": "XGBoost",
    "section": "",
    "text": "There are multiple packages that can be used to to implement xgboost in R.\n\n{tidymodels}\n{xgboost}\n{caret}\n\n{tidymodels} and {caret} easy ways to access xgboost easily. This example will use {tidymodels} because of the functionality included in {tidymodels} and is being heavily supported by Posit. {caret} was the precursor to {tidymodels} and it is recommended that you use {tidymodels} over {caret} as no new features are being added."
  },
  {
    "objectID": "R/xgboost.html#data-used",
    "href": "R/xgboost.html#data-used",
    "title": "XGBoost",
    "section": "",
    "text": "Data used for this example is birthwt which is part of the {MASS} package. This data-set considers a number of risk factors associated with birth weight in infants.\n\nlibrary(tidyverse)\nlibrary(MASS)\nlibrary(rsample)\nlibrary(parsnip)\nlibrary(xgboost)\n\nhead(birthwt)\n\nOur modeling goal using the birthwt dataset is to predict whether the birth weight is low or not low based on factors such as mother’s age, smoking status, and history of hypertension."
  },
  {
    "objectID": "R/xgboost.html#example-code",
    "href": "R/xgboost.html#example-code",
    "title": "XGBoost",
    "section": "",
    "text": "Use {tidymodels} metadata package to split the data into training and testing data. For classification, we need to change the Low variable into a factor, since currently coded as an integer (0,1).\n\nbirthwt &lt;- birthwt |&gt;\n  mutate(\n    low_f = lvls_revalue(factor(low), c(\"Not Low\", \"Low\")),\n    smoke_f = lvls_revalue(factor(smoke), c(\"Non-smoker\", \"Smoker\"))\n  )\n\nbrthwt_split &lt;- rsample::initial_split(birthwt, strata = low)\nbrthwt_train &lt;- rsample::training(brthwt_split)\nbrthwt_test &lt;- rsample::testing(brthwt_split)\n\n\n\nAfter creating the data split, we setup the params of the model.\n\nxgboost_spec &lt;- parsnip::boost_tree(trees = 15) |&gt;\n  # This model can be used for classification or regression, so set mode\n  parsnip::set_mode(\"classification\") |&gt;\n  parsnip::set_engine(\"xgboost\")\n\nxgboost_spec\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  trees = 15\n\nComputational engine: xgboost \n\nxgboost_cls_fit &lt;- xgboost_spec |&gt;\n  fit(low_f ~ ., data = brthwt_train)\nxgboost_cls_fit\n\nparsnip model object\n\n##### xgb.Booster\nraw: 15.2 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n    colsample_bytree = 1, colsample_bynode = 1, min_child_weight = 1, \n    subsample = 1), data = x$data, nrounds = 15, watchlist = x$watchlist, \n    verbose = 0, nthread = 1, objective = \"binary:logistic\")\nparams (as set within xgb.train):\n  eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"1\", min_child_weight = \"1\", subsample = \"1\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 12 \nniter: 15\nnfeatures : 12 \nevaluation_log:\n  iter training_logloss\n &lt;num&gt;            &lt;num&gt;\n     1       0.44894346\n     2       0.31033704\n   ---              ---\n    14       0.01571681\n    15       0.01396153\n\nbind_cols(\n  predict(xgboost_cls_fit, brthwt_test),\n  predict(xgboost_cls_fit, brthwt_test, type = \"prob\")\n)\n\n# A tibble: 48 × 3\n   .pred_class `.pred_Not Low` .pred_Low\n   &lt;fct&gt;                 &lt;dbl&gt;     &lt;dbl&gt;\n 1 Not Low               0.985    0.0151\n 2 Not Low               0.985    0.0151\n 3 Not Low               0.985    0.0151\n 4 Not Low               0.985    0.0151\n 5 Not Low               0.985    0.0151\n 6 Not Low               0.988    0.0116\n 7 Not Low               0.988    0.0116\n 8 Not Low               0.988    0.0116\n 9 Not Low               0.988    0.0116\n10 Not Low               0.988    0.0116\n# ℹ 38 more rows\n\n\n\n\n\nTo perform xgboost with regression, when setting up the parameter of the model, set the mode of xgboost to regression. After that switch and then changing the variable of interest back to an integer, the rest of the code is the same.\n\nxgboost_reg_spec &lt;- parsnip::boost_tree(trees = 15) |&gt;\n  # This model can be used for classification or regression, so set mode\n  parsnip::set_mode(\"regression\") |&gt;\n  parsnip::set_engine(\"xgboost\")\n\nxgboost_reg_spec\n\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  trees = 15\n\nComputational engine: xgboost \n\n# For a regression model, the outcome should be `numeric`, not a `factor`.\nxgboost_reg_fit &lt;- xgboost_reg_spec |&gt;\n  fit(low ~ ., data = brthwt_train)\nxgboost_reg_fit\n\nparsnip model object\n\n##### xgb.Booster\nraw: 15.2 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n    colsample_bytree = 1, colsample_bynode = 1, min_child_weight = 1, \n    subsample = 1), data = x$data, nrounds = 15, watchlist = x$watchlist, \n    verbose = 0, nthread = 1, objective = \"reg:squarederror\")\nparams (as set within xgb.train):\n  eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"1\", min_child_weight = \"1\", subsample = \"1\", nthread = \"1\", objective = \"reg:squarederror\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 13 \nniter: 15\nnfeatures : 13 \nevaluation_log:\n  iter training_rmse\n &lt;num&gt;         &lt;num&gt;\n     1   0.352094163\n     2   0.247943366\n   ---           ---\n    14   0.003690328\n    15   0.002599106\n\npredict(xgboost_reg_fit, brthwt_test)\n\n# A tibble: 48 × 1\n     .pred\n     &lt;dbl&gt;\n 1 0.00253\n 2 0.00253\n 3 0.00253\n 4 0.00253\n 5 0.00253\n 6 0.00253\n 7 0.00253\n 8 0.00253\n 9 0.00253\n10 0.00253\n# ℹ 38 more rows"
  },
  {
    "objectID": "R/xgboost.html#reference",
    "href": "R/xgboost.html#reference",
    "title": "XGBoost",
    "section": "",
    "text": "XGBoost with tidymodels by Julia Silge\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package     * version date (UTC) lib source\n P BiocManager   1.30.25 2024-08-28 [?] CRAN (R 4.4.1)\n P cli           3.6.3   2024-06-21 [?] CRAN (R 4.4.0)\n   codetools     0.2-20  2024-03-31 [2] CRAN (R 4.4.2)\n P colorspace    2.1-1   2024-07-26 [?] CRAN (R 4.4.0)\n P data.table    1.16.0  2024-08-27 [?] CRAN (R 4.4.1)\n P digest        0.6.37  2024-08-19 [?] CRAN (R 4.4.1)\n P dplyr       * 1.1.4   2023-11-17 [?] CRAN (R 4.4.0)\n P evaluate      1.0.0   2024-09-17 [?] CRAN (R 4.4.1)\n P fansi         1.0.6   2023-12-08 [?] CRAN (R 4.4.0)\n P fastmap       1.2.0   2024-05-15 [?] CRAN (R 4.4.0)\n P forcats     * 1.0.0   2023-01-29 [?] CRAN (R 4.4.0)\n P furrr         0.3.1   2022-08-15 [?] CRAN (R 4.4.0)\n P future        1.34.0  2024-07-29 [?] CRAN (R 4.4.0)\n P generics      0.1.3   2022-07-05 [?] CRAN (R 4.4.0)\n P ggplot2     * 3.5.1   2024-04-23 [?] CRAN (R 4.4.0)\n P globals       0.16.3  2024-03-08 [?] CRAN (R 4.4.0)\n P glue          1.8.0   2024-09-30 [?] CRAN (R 4.4.1)\n P gtable        0.3.5   2024-04-22 [?] CRAN (R 4.4.0)\n P hardhat       1.4.0   2024-06-02 [?] CRAN (R 4.4.0)\n P hms           1.1.3   2023-03-21 [?] CRAN (R 4.4.0)\n P htmltools     0.5.8.1 2024-04-04 [?] CRAN (R 4.4.0)\n P htmlwidgets   1.6.4   2023-12-06 [?] CRAN (R 4.4.0)\n P jsonlite      1.8.9   2024-09-20 [?] CRAN (R 4.4.1)\n   knitr         1.50    2025-03-16 [1] RSPM (R 4.4.0)\n   lattice       0.22-6  2024-03-20 [2] CRAN (R 4.4.2)\n P lifecycle     1.0.4   2023-11-07 [?] CRAN (R 4.4.0)\n P listenv       0.9.1   2024-01-29 [?] CRAN (R 4.4.0)\n P lubridate   * 1.9.3   2023-09-27 [?] CRAN (R 4.4.0)\n P magrittr      2.0.3   2022-03-30 [?] CRAN (R 4.4.0)\n   MASS        * 7.3-61  2024-06-13 [2] CRAN (R 4.4.2)\n   Matrix        1.7-1   2024-10-18 [2] CRAN (R 4.4.2)\n P munsell       0.5.1   2024-04-01 [?] CRAN (R 4.4.0)\n P parallelly    1.38.0  2024-07-27 [?] CRAN (R 4.4.0)\n P parsnip     * 1.2.1   2024-03-22 [?] CRAN (R 4.4.0)\n P pillar        1.9.0   2023-03-22 [?] CRAN (R 4.4.0)\n P pkgconfig     2.0.3   2019-09-22 [?] CRAN (R 4.4.0)\n P purrr       * 1.0.2   2023-08-10 [?] CRAN (R 4.4.0)\n P R6            2.5.1   2021-08-19 [?] CRAN (R 4.4.0)\n P readr       * 2.1.5   2024-01-10 [?] CRAN (R 4.4.0)\n   renv          1.0.10  2024-10-05 [1] CRAN (R 4.4.1)\n P rlang         1.1.4   2024-06-04 [?] CRAN (R 4.4.0)\n P rmarkdown     2.28    2024-08-17 [?] CRAN (R 4.4.0)\n P rsample     * 1.2.1   2024-03-25 [?] CRAN (R 4.4.0)\n P rstudioapi    0.16.0  2024-03-24 [?] CRAN (R 4.4.0)\n P scales        1.3.0   2023-11-28 [?] CRAN (R 4.4.0)\n P sessioninfo   1.2.2   2021-12-06 [?] CRAN (R 4.4.0)\n P stringi       1.8.4   2024-05-06 [?] CRAN (R 4.4.0)\n P stringr     * 1.5.1   2023-11-14 [?] CRAN (R 4.4.0)\n P tibble      * 3.2.1   2023-03-20 [?] CRAN (R 4.4.0)\n P tidyr       * 1.3.1   2024-01-24 [?] CRAN (R 4.4.0)\n P tidyselect    1.2.1   2024-03-11 [?] CRAN (R 4.4.0)\n P tidyverse   * 2.0.0   2023-02-22 [?] CRAN (R 4.4.0)\n P timechange    0.3.0   2024-01-18 [?] CRAN (R 4.4.0)\n P tzdb          0.4.0   2023-05-12 [?] CRAN (R 4.4.0)\n P utf8          1.2.4   2023-10-22 [?] CRAN (R 4.4.0)\n P vctrs         0.6.5   2023-12-01 [?] CRAN (R 4.4.0)\n P withr         3.0.1   2024-07-31 [?] CRAN (R 4.4.0)\n   xfun          0.52    2025-04-02 [1] RSPM (R 4.4.0)\n P xgboost     * 1.7.8.1 2024-07-24 [?] CRAN (R 4.4.0)\n P yaml          2.3.10  2024-07-26 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/kruskal_wallis.html",
    "href": "R/kruskal_wallis.html",
    "title": "Kruskal Wallis R",
    "section": "",
    "text": "The Kruskal-Wallis test is a non-parametric equivalent to the one-way ANOVA. For this example, the data used is a subset of datasets::iris, testing for difference in sepal width between species of flower.\n\n\n      Species Sepal_Width\n1      setosa         3.4\n2      setosa         3.0\n3      setosa         3.4\n4      setosa         3.2\n5      setosa         3.5\n6      setosa         3.1\n7  versicolor         2.7\n8  versicolor         2.9\n9  versicolor         2.7\n10 versicolor         2.6\n11 versicolor         2.5\n12 versicolor         2.5\n13  virginica         3.0\n14  virginica         3.0\n15  virginica         3.1\n16  virginica         3.8\n17  virginica         2.7\n18  virginica         3.3"
  },
  {
    "objectID": "R/kruskal_wallis.html#introduction",
    "href": "R/kruskal_wallis.html#introduction",
    "title": "Kruskal Wallis R",
    "section": "",
    "text": "The Kruskal-Wallis test is a non-parametric equivalent to the one-way ANOVA. For this example, the data used is a subset of datasets::iris, testing for difference in sepal width between species of flower.\n\n\n      Species Sepal_Width\n1      setosa         3.4\n2      setosa         3.0\n3      setosa         3.4\n4      setosa         3.2\n5      setosa         3.5\n6      setosa         3.1\n7  versicolor         2.7\n8  versicolor         2.9\n9  versicolor         2.7\n10 versicolor         2.6\n11 versicolor         2.5\n12 versicolor         2.5\n13  virginica         3.0\n14  virginica         3.0\n15  virginica         3.1\n16  virginica         3.8\n17  virginica         2.7\n18  virginica         3.3"
  },
  {
    "objectID": "R/kruskal_wallis.html#implementing-kruskal-wallis-in-r",
    "href": "R/kruskal_wallis.html#implementing-kruskal-wallis-in-r",
    "title": "Kruskal Wallis R",
    "section": "Implementing Kruskal-Wallis in R",
    "text": "Implementing Kruskal-Wallis in R\nThe Kruskal-Wallis test can be implemented in R using stats::kruskal.test. Below, the test is defined using R’s formula interface (dependent ~ independent variable) and specifying the data set. The null hypothesis is that the samples are from identical populations.\n\nstats::kruskal.test(Sepal_Width ~ Species, data = iris_sub)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sepal_Width by Species\nKruskal-Wallis chi-squared = 10.922, df = 2, p-value = 0.004249"
  },
  {
    "objectID": "R/kruskal_wallis.html#results",
    "href": "R/kruskal_wallis.html#results",
    "title": "Kruskal Wallis R",
    "section": "Results",
    "text": "Results\nAs seen above, R outputs the Kruskal-Wallis rank sum statistic (10.922), the degrees of freedom (2), and the p-value of the test (0.004249). Therefore, the difference in population medians is statistically significant at the 5% level."
  },
  {
    "objectID": "R/recurrent_events.html",
    "href": "R/recurrent_events.html",
    "title": "R Recurrent Events",
    "section": "",
    "text": "library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(gt)\n\n\n\n\n\nlibrary(survival)\n\n\n\n\n\n\n\nTraditionally, survival analysis focuses on the time to a single first event. While there are many applications for such time-to-event analysis in clinical trials, this approach falls short when events of interest can occur multiple times within the same subject. Recurrent event models extend the traditional Cox proportional hazards framework to account for multiple events per subject (Ozga et al. 2018, Amorim & Cai 2015).\nIn this tutorial, we will demonstrate how to implement different recurrent event models in R, specifically the Andersen-Gill, proportional means/rates, Prentice-Williams-Peterson, and Wei-Lin-Weissfeld models, using the well-known survival package. The R code follows the layout of Amor 2023, with additional insights taken from Lu et al. 2018.\nRecurrent event models can roughly be divided in three categories: counting process models, conditional models and marginal models. In the section below, we will explore the difference between each of these approaches. In addition, important aspects of data structure will be discussed by means of two fictional subjects, one with 4 events and 0 censored observations (events at time 6, 9, 56 and 88), and another with 2 events and 1 censored observation (events at time 42, 57, and censored at time 91).\nDefine the following:\n\n\n\n\n\n\nNote\n\n\n\n\\(\\lambda_i(t)\\): hazard function for the \\(i\\)th subject at time \\(t\\)\n\\(\\lambda_{ij}(t)\\): hazard function for the \\(j\\)th event of the \\(i\\)th subject at time \\(t\\)\n\\(\\lambda_0(t)\\): common baseline hazard for all events\n\\(\\lambda_{0j}(t)\\): event-specific baseline hazard for the \\(j\\)th event at time \\(t\\)\n\\(\\beta\\): common parameter vector\n\\(\\beta_j\\): event-specific parameter vector for the \\(j\\)th event\n\\(X_{ij}\\): covariate vector for the \\(j\\)th event of the \\(i\\)th subject\n\n\n\n\n\n\n\n\\[\n\\lambda_i(t) = \\lambda_0(t) \\exp \\left( \\beta X_{ij}(t) \\right) \\\n\\]\n\nCounting process approach: treats each subject as a multiple events counting process\nCommon baseline hazard \\(\\lambda_0(t)\\)\nCommon regression coefficients \\(\\beta\\)\nUnrestricted risk set: a subject contributes to the risk set for an event as long as the subject is under observation, i.e. it can be at risk for a subsequent event even though the previous event did not yet occur\nOrder of events is not important\n\nAn essential assumption of the Andersen-Gill model is that of independent events within subjects. This, however, is often not realistic in clinical trial data. For example, let’s say that we are modelling myocardial infarction (MI). If a patient has already experienced one MI, their risk of subsequent events may increase due to underlying cardiovascular damage or presence of other risk factors. Thus, the more events a patient has, the more likely they are to experience future events, indicating dependence rather than independence. To accurately model this within-subject correlation, extensions like time-varying covariates, a robust sandwich covariance estimator or frailty terms may be needed. In this tutorial, we will discuss the sandwich correction.\nLin-Wei-Yang-Ying (LWYY) model or proportional means/rates model (Lin, Wei, Yang & Ying 2000)\nLin, Wei, Yang, and Ying introduced an improved version of the Andersen-Gill model in 2000 (often referred to as proportional means/rates model), featuring a robust sandwich estimator that explicitly accounts for individual subject clusters. These robust standard errors yield wider confidence intervals and provide asymptotically valid inference even when the independence assumption does not hold (Lee et al. 2025). The original and improved Andersen-Gill model often appear interchangeable in the literature, and while they produce identical estimates, their robust standard errors can differ substantially, which may impact the conclusions drawn from statistical inference.\nFor both versions of the Andersen-Gill model, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(6, 9]\n1\n1\n\n\n1\n(9, 56]\n1\n1\n\n\n1\n(56, 88]\n1\n1\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(42, 87]\n1\n1\n\n\n2\n(87, 91]\n0\n1\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nIn both versions of the Andersen-Gill model, each new time interval starts where the previous one ends.\n\n\n\n\n\n\n\nConditional approach: incorporates conditional strata to account for ordering/dependence of events\nStratified baseline hazard \\(\\lambda_{0j}(t)\\)\nStratified regression coefficients \\(\\beta_j\\): can be pooled (\\(\\beta\\)) or kept as event-specific (\\(\\beta_j\\)) in the output\nRestricted risk set: contributions to the risk set for a subsequent event are restricted to only consider subjects that already experienced the previous event\nOrder of events is important\n\nThe Prentice-Williams-Peterson model can incorporate both overall and event-specific effects \\(\\beta_j\\) for each covariate. An often made assumption is to set \\(\\beta_1 = \\beta_2 = ... = \\beta_k = \\beta\\) to estimate a common parameter \\(\\beta\\).\nDepending on the outcome of interest, Prentice, Williams and Peterson suggested two distinct models:\n\nTotal time model\n\n\\[\n\\lambda_{ij}(t) = \\lambda_{0j}(t) \\exp \\left( \\beta_j X_{ij}(t) \\right) \\\n\\]\nThe total time variant of the Prentice-Williams-Peterson model uses the same time intervals as the counting process approach (Andersen-Gill model), which is useful for modelling the full time course (\\(t\\)) of the recurrent event process, i.e. the hazard of any recurrence.\nFor the total time model, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(6, 9]\n1\n2\n\n\n1\n(9, 56]\n1\n3\n\n\n1\n(56, 88]\n1\n4\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(42, 87]\n1\n2\n\n\n2\n(87, 91]\n0\n3\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nAgain, in the total time model, each new time intervals starts where the previous one ends.\n\nGap time model\n\n\\[\n\\lambda_{ij}(t) = \\lambda_{0j}(t - t_{j-1}) \\exp \\left( \\beta_j X_{ij}(t) \\right) \\\n\\]\nThe gap time variant of the Prentice-Williams-Peterson model uses time intervals that start at zero and end at the length of time until the next event, which is useful for modelling the time between each of the recurring events (\\(t - t_{j-1}\\)), i.e. the hazard of recurrence after the previous event.\nFor the gap time model, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(0, 3]\n1\n2\n\n\n1\n(0, 47]\n1\n3\n\n\n1\n(0, 32]\n1\n4\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(0, 45]\n1\n2\n\n\n2\n(0, 3]\n0\n3\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nIn the gap time model, each time interval starts at zero and has a length equal to the gap time between two neighboring events.\n\n\n\n\n\n\n\\[\n\\lambda_{ij}(t) = \\lambda_{0j}(t) \\exp \\left( \\beta_j X_{ij}(t) \\right) \\\n\\]\n\nMarginal approach: treats each (recurrent) event as having a separate, marginal process\nStratified baseline hazard \\(\\lambda_{0j}(t)\\)\nStratified regression coefficients \\(\\beta_j\\): can be pooled (\\(\\beta\\)) or kept as event-specific (\\(\\beta_j\\)) in the output\nSemi-restricted risk set: all subjects contribute follow-up times to all potential events, i.e. each subject is at risk for all potential events, regardless of how many events that subject actually experiences\nOrder of events is not important\n\nAlthough the Wei-Lin-Weissfeld model has it roots in competing risks analysis, it conveniently lends itself to model recurrent events as well. Like the Andersen-Gill model, the Wei-Lin-Weissfeld model also assumes independence of events, which is often not feasible in practice. In addition, it is assumed there is no specific order among the events or that the events are different types of events, and not necessarily recurrent events.\nLike the Prentice-Williams-Peterson models, the Wei-Lin-Weissfeld model can incorporate both overall and event-specific effects \\(\\beta_j\\) for each covariate. An often made assumption is to set \\(\\beta_1 = \\beta_2 = ... = \\beta_k = \\beta\\) to estimate a common parameter \\(\\beta\\). Another approach is to combine event-specific effects \\(\\beta_j\\) to get an estimator of the average effect, as described in Wei, Lin & Weissfeld 1989 (this is not discussed further here).\nFor Wei-Lin-Weissfeld models, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(0, 9]\n1\n2\n\n\n1\n(0, 56]\n1\n3\n\n\n1\n(0, 88]\n1\n4\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(0, 87]\n1\n2\n\n\n2\n(0, 91]\n0\n3\n\n\n2\n(0, 91]\n0\n4\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nIn the Wei-Lin-Weissfeld model, each time intervals starts at zero and ends at its respective event time.\n\n\n\n\nIn summary, the selection of the model to use would depend on the type of events, the importance of the order of the events and the time intervals to be analyzed. We made an effort to summarize the similarities and differences between the models in the table below.\n\n\n\n\n\n\n\n\n\n\n\nAG\nPWPtt\nPWPgt\nWLW\n\n\n\n\nApproach\ncounting process\nconditional\nconditional\nmarginal\n\n\nBaseline hazard\ncommon\nstratified\nstratified\nstratified\n\n\nRegression coefficients\ncommon\nstratified possible\nstratified possible\nstratified possible\n\n\nRisk set\nunrestricted\nrestricted\nrestricted\nsemi-restricted\n\n\nTime interval\ntotal time\ntotal time\ngap time\ntotal time\n\n\nOrder of events\nnot important\nimportant\nimportant\nnot important\n\n\nHazard ratio (HR)\nrisk of any recurrence\nrisk of any recurrence\nrisk of recurrence after previous event\nrisk of event of any type, not necessarily recurrent event\n\n\n\nNote that, because the ordering of events is not important in the Andersen-Gill and Wei-Lin-Weissfeld model, these models come with the assumption of independence of events. In contrast, the Prentice-Williams-Peterson models overcome the need for this assumption by capturing the dependence structure between recurrent events in conditional strata. Consequently, events are assumed to be conditionally independent in the Prentice-Williams-Peterson models.\nA nice visual representation of the stratification and time interval structure of each model is given below. The correct data structure is pivotal when modelling recurrent events and depends on the methodology you want to use, as illustrated in the figure.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor this tutorial we will use the bladder data from the survival package, which captures recurrences of bladder cancer from a clinical trial for an oncolytic called thiotepa. The bladder data is regularly used by many statisticians to demonstrate methodology for recurrent event modelling. Somewhat confusingly, there are three versions of this data available:\n\nbladder1: original data from the study on all subjects (294 records)\nbladder2: data in Andersen-Gill format on subset of subjects with nonzero follow-up time (178 records)\nbladder: data in Wei-Lin-Weissfeld format on subset of subjects with nonzero follow-up time (340 records)\n\nFor this tutorial, we will use bladder2 to illustrate Andersen-Gill and Prentice-Williams-Peterson models, and bladder to illustrate the Wei-Lin-Weissfeld model.\nThe variables included in both datasets are:\n\nid: patient id\nrx: treatment group (1 = placebo, 2 = thiotepa)\nnumber: initial number of tumors (8 = 8 or more)\nsize: size in cm of largest initial tumor\nstart: start of time interval; this variable is not present in bladder\nstop: (recurrent) event or censoring time\nevent: event indicator (1 = event, 0 = censored)\nenum: order of recurrence\n\nImportantly, both datasets collect the data in a counting process structure. This means that there is one record for each subject and time interval, where a time interval is defined as the time to its respective event (event = 1), or the time to follow-up if the event did not occur (event = 0).\nLet’s look more closely at the bladder2 and bladder data:\n\nbladder2 &lt;- survival::bladder2\ngt(head(bladder2, 6))\n\n\n\n\n\n\n\nid\nrx\nnumber\nsize\nstart\nstop\nevent\nenum\n\n\n\n\n1\n1\n1\n3\n0\n1\n0\n1\n\n\n2\n1\n2\n1\n0\n4\n0\n1\n\n\n3\n1\n1\n1\n0\n7\n0\n1\n\n\n4\n1\n5\n1\n0\n10\n0\n1\n\n\n5\n1\n4\n1\n0\n6\n1\n1\n\n\n5\n1\n4\n1\n6\n10\n0\n2\n\n\n\n\n\n\n\n\nbladder2 %&gt;%\n  group_by(enum) %&gt;% summarise(n = n()) %&gt;% gt()\n\n\n\n\n\n\n\nenum\nn\n\n\n\n\n1\n85\n\n\n2\n46\n\n\n3\n27\n\n\n4\n20\n\n\n\n\n\n\n\nIn bladder2, in the Andersen-Gill format, each subject has a variable amount of records, depending on the amount of events that subject experienced.\n\nbladder &lt;- survival::bladder\ngt(head(bladder, 20))\n\n\n\n\n\n\n\nid\nrx\nnumber\nsize\nstop\nevent\nenum\n\n\n\n\n1\n1\n1\n3\n1\n0\n1\n\n\n1\n1\n1\n3\n1\n0\n2\n\n\n1\n1\n1\n3\n1\n0\n3\n\n\n1\n1\n1\n3\n1\n0\n4\n\n\n2\n1\n2\n1\n4\n0\n1\n\n\n2\n1\n2\n1\n4\n0\n2\n\n\n2\n1\n2\n1\n4\n0\n3\n\n\n2\n1\n2\n1\n4\n0\n4\n\n\n3\n1\n1\n1\n7\n0\n1\n\n\n3\n1\n1\n1\n7\n0\n2\n\n\n3\n1\n1\n1\n7\n0\n3\n\n\n3\n1\n1\n1\n7\n0\n4\n\n\n4\n1\n5\n1\n10\n0\n1\n\n\n4\n1\n5\n1\n10\n0\n2\n\n\n4\n1\n5\n1\n10\n0\n3\n\n\n4\n1\n5\n1\n10\n0\n4\n\n\n5\n1\n4\n1\n6\n1\n1\n\n\n5\n1\n4\n1\n10\n0\n2\n\n\n5\n1\n4\n1\n10\n0\n3\n\n\n5\n1\n4\n1\n10\n0\n4\n\n\n\n\n\n\n\n\nbladder %&gt;%\n  group_by(enum) %&gt;% summarise(n = n()) %&gt;% gt()\n\n\n\n\n\n\n\nenum\nn\n\n\n\n\n1\n85\n\n\n2\n85\n\n\n3\n85\n\n\n4\n85\n\n\n\n\n\n\n\nIn bladder, in the Wei-Lin-Weissfeld format, each subject has four records, regardless of how many events that subject actually experienced. In addition, there is no start variable, as all time intervals start at zero.\n\n\n\nIn the survival package, any survival analysis based on the Cox proportional hazard model can be conducted using the coxph() function. Hence, conveniently, when modelling time-to-event data with recurrent events, the same function can be used. The caveat here is that an adequate data structure is required, which must be in correspondence with the model you want to use.\nIn this section of the tutorial, we will explain how the arguments of the coxph() function and data structure must be defined to fit every type of recurrent event model correctly.\n\n\n\nImproved Andersen-Gill model (LWYY model or proportional means/rates model)\n\nFor the improved version of the Andersen-Gill model you must specify:\n\nformula = Surv(start, stop, event) ~ 'predictors'\ncluster = id\n\nAnd the data structure must be:\n\n\n\nId\nTime interval\nStart\nStop\nEvent\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n\n\n2\n(0, 4]\n0\n4\n0\n\n\n3\n(0, 7]\n0\n7\n0\n\n\n4\n(0, 10]\n0\n10\n0\n\n\n5\n(0, 6]\n0\n6\n1\n\n\n5\n(6, 10]\n6\n10\n0\n\n\n\nWe will use the bladder2 data for this.\n\nAG &lt;- coxph(Surv(start, stop, event) ~ as.factor(rx) + number + size,\n            ties = \"breslow\",\n            cluster = id,\n            data = bladder2)\nsummary(AG)\n\nCall:\ncoxph(formula = Surv(start, stop, event) ~ as.factor(rx) + number + \n    size, data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                   coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nas.factor(rx)2 -0.45979   0.63142  0.19996   0.25801 -1.782  0.07474 . \nnumber          0.17164   1.18726  0.04733   0.06131  2.799  0.00512 **\nsize           -0.04256   0.95833  0.06903   0.07555 -0.563  0.57317   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.6314     1.5837    0.3808     1.047\nnumber            1.1873     0.8423    1.0528     1.339\nsize              0.9583     1.0435    0.8264     1.111\n\nConcordance= 0.634  (se = 0.032 )\nLikelihood ratio test= 16.77  on 3 df,   p=8e-04\nWald test            = 11.76  on 3 df,   p=0.008\nScore (logrank) test = 18.57  on 3 df,   p=3e-04,   Robust = 11.44  p=0.01\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\nBy defining the cluster argument, coxph() will automatically set robust = TRUE, and compute a robust sandwich covariance. The summary function will then display both the non-robust (se(coef)) and robust (robust se) standard error estimates. Under the hood, the robust standard errors will consider all id clusters separately and ultimately sum up the score residuals for each distinct cluster.\n\nOriginal Andersen-Gill model\n\nTo our knowledge, the original Andersen-Gill model of 1989 can only be fitted in R by adding an artificial clustering variable with unique entries to the bladder2 data, which we call id2. This artificial clustering variable will ignore any clustering that is actually present in the data.\n\nbladder2 &lt;- bladder2 %&gt;%\n  dplyr::mutate(id2 = row_number())\n\nExcept for cluster = id2, the rest of the code remains the same.\n\nAG_original &lt;- coxph(Surv(start, stop, event) ~ as.factor(rx) + number + size,\n            ties = \"breslow\",\n            cluster = id2,\n            data = bladder2)\nsummary(AG_original)\n\nCall:\ncoxph(formula = Surv(start, stop, event) ~ as.factor(rx) + number + \n    size, data = bladder2, ties = \"breslow\", cluster = id2)\n\n  n= 178, number of events= 112 \n\n                   coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nas.factor(rx)2 -0.45979   0.63142  0.19996   0.22902 -2.008  0.04468 * \nnumber          0.17164   1.18726  0.04733   0.06469  2.653  0.00797 **\nsize           -0.04256   0.95833  0.06903   0.07325 -0.581  0.56119   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.6314     1.5837    0.4031    0.9891\nnumber            1.1873     0.8423    1.0459    1.3477\nsize              0.9583     1.0435    0.8302    1.1063\n\nConcordance= 0.634  (se = 0.032 )\nLikelihood ratio test= 16.77  on 3 df,   p=8e-04\nWald test            = 9.36  on 3 df,   p=0.02\nScore (logrank) test = 18.57  on 3 df,   p=3e-04,   Robust = 14.27  p=0.003\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\nAlthough the original Andersen-Gill model does not consider separate id clusters, it still computes robust standard errors using the sandwich estimator, as robust = TRUE. The resulting robust standard errors (robust se) differ from those provided for the improved Andersen-Gill model, while the estimated coefficients (coef) and non-robust standard errors (se(coef)) remain perfectly unchanged.\n\n\n\n\nTotal time model\n\nFor the Prentice-Williams-Peterson total time model you must specify:\n\nformula = Surv(start, stop, event) ~ 'predictors' + strata(enum)\ncluster = id\n\nAnd the data structure must be:\n\n\n\nId\nTime interval\nStart\nStop\nEvent\nEnum\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n1\n\n\n2\n(0, 4]\n0\n4\n0\n1\n\n\n3\n(0, 7]\n0\n7\n0\n1\n\n\n4\n(0, 10]\n0\n10\n0\n1\n\n\n5\n(0, 6]\n0\n6\n1\n1\n\n\n5\n(6, 10]\n6\n10\n0\n2\n\n\n\nWe will use the bladder2 data for this.\n\nPWPtt &lt;- coxph(Surv(start, stop, event) ~ as.factor(rx) + number + size + strata(enum),\n            ties = \"breslow\",\n            cluster = id,\n            data = bladder2)\nsummary(PWPtt)\n\nCall:\ncoxph(formula = Surv(start, stop, event) ~ as.factor(rx) + number + \n    size + strata(enum), data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                    coef exp(coef)  se(coef) robust se      z Pr(&gt;|z|)  \nas.factor(rx)2 -0.334295  0.715842  0.216087  0.197064 -1.696   0.0898 .\nnumber          0.115653  1.122606  0.053681  0.049913  2.317   0.0205 *\nsize           -0.008051  0.991982  0.072725  0.060124 -0.134   0.8935  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.7158     1.3970    0.4865     1.053\nnumber            1.1226     0.8908    1.0180     1.238\nsize              0.9920     1.0081    0.8817     1.116\n\nConcordance= 0.615  (se = 0.032 )\nLikelihood ratio test= 6.11  on 3 df,   p=0.1\nWald test            = 7.19  on 3 df,   p=0.07\nScore (logrank) test = 6.45  on 3 df,   p=0.09,   Robust = 8.76  p=0.03\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\nThe conditional strata of the Prentice-Williams-Peterson model are set by strata(enum) in the formula, where enum captures the ordering of recurrent events.\n\nGap time model\n\nFor the Prentice-Williams-Peterson gap time model you must specify:\n\nformula = Surv(gtime, event) ~ 'predictors' + strata(enum)\ncluster = id\n\nAnd the data structure must be:\n\n\n\nId\nTime interval\nStart\nStop\nEvent\nEnum\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n1\n\n\n2\n(0, 4]\n0\n4\n0\n1\n\n\n3\n(0, 7]\n0\n7\n0\n1\n\n\n4\n(0, 10]\n0\n10\n0\n1\n\n\n5\n(0, 6]\n0\n6\n1\n1\n\n\n5\n(0, 4]\n0\n4\n0\n2\n\n\n\nThis data structure can be achieved in bladder2 by adding a gtime variable.\n\nbladder2 &lt;- bladder2 %&gt;%\n  dplyr::mutate(gtime = stop - start)\n  \ngt(head(bladder2, 6))\n\n\n\n\n\n\n\nid\nrx\nnumber\nsize\nstart\nstop\nevent\nenum\nid2\ngtime\n\n\n\n\n1\n1\n1\n3\n0\n1\n0\n1\n1\n1\n\n\n2\n1\n2\n1\n0\n4\n0\n1\n2\n4\n\n\n3\n1\n1\n1\n0\n7\n0\n1\n3\n7\n\n\n4\n1\n5\n1\n0\n10\n0\n1\n4\n10\n\n\n5\n1\n4\n1\n0\n6\n1\n1\n5\n6\n\n\n5\n1\n4\n1\n6\n10\n0\n2\n6\n4\n\n\n\n\n\n\n\nWe artificially set start = 0 for each gap time interval by including gtime instead of start, stop in the Surv() object.\n\nPWPgt &lt;- coxph(Surv(gtime, event) ~ as.factor(rx) + number + size + strata(enum),\n            ties = \"breslow\",\n            cluster = id,\n            data = bladder2)\nsummary(PWPgt)\n\nCall:\ncoxph(formula = Surv(gtime, event) ~ as.factor(rx) + number + \n    size + strata(enum), data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                   coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nas.factor(rx)2 -0.26952   0.76375  0.20766   0.20808 -1.295  0.19522   \nnumber          0.15353   1.16595  0.05211   0.04889  3.140  0.00169 **\nsize            0.00684   1.00686  0.07001   0.06222  0.110  0.91246   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.7637     1.3093    0.5080     1.148\nnumber            1.1659     0.8577    1.0594     1.283\nsize              1.0069     0.9932    0.8913     1.137\n\nConcordance= 0.596  (se = 0.032 )\nLikelihood ratio test= 8.76  on 3 df,   p=0.03\nWald test            = 12.14  on 3 df,   p=0.007\nScore (logrank) test = 9.6  on 3 df,   p=0.02,   Robust = 10.21  p=0.02\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\n\n\n\nFor the Wei-Lin-Weissfeld model you must specify:\n\nformula = Surv(stop, event) ~ 'predictors' + strata(enum)\ncluster = id\n\nAnd the data structure must be:\n\n\n\nId\nTime interval\nStart\nStop\nEvent\nEnum\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n1\n\n\n1\n(0, 1]\n0\n1\n0\n2\n\n\n1\n(0, 1]\n0\n1\n0\n3\n\n\n1\n(0, 1]\n0\n1\n0\n4\n\n\n2\n(0, 4]\n0\n4\n0\n1\n\n\n2\n(0, 4]\n0\n4\n0\n2\n\n\n2\n(0, 4]\n0\n4\n0\n3\n\n\n2\n(0, 4]\n0\n4\n0\n4\n\n\n3\n(0, 7]\n0\n7\n0\n1\n\n\n3\n(0, 7]\n0\n7\n0\n2\n\n\n3\n(0, 7]\n0\n7\n0\n3\n\n\n3\n(0, 7]\n0\n7\n0\n4\n\n\n4\n(0, 10]\n0\n10\n0\n1\n\n\n4\n(0, 10]\n0\n10\n0\n2\n\n\n4\n(0, 10]\n0\n10\n0\n3\n\n\n4\n(0, 10]\n0\n10\n0\n4\n\n\n5\n(0, 6]\n0\n6\n1\n1\n\n\n5\n(0, 10]\n0\n10\n0\n2\n\n\n5\n(0, 10]\n0\n10\n0\n3\n\n\n5\n(0, 10]\n0\n10\n0\n4\n\n\n\nWe will use the bladder data for this.\n\nWLW &lt;- coxph(Surv(stop, event) ~ as.factor(rx) + number + size + strata(enum),\n            ties = \"breslow\",\n            cluster = id,\n            data = bladder)\nsummary(WLW)\n\nCall:\ncoxph(formula = Surv(stop, event) ~ as.factor(rx) + number + \n    size + strata(enum), data = bladder, ties = \"breslow\", cluster = id)\n\n  n= 340, number of events= 112 \n\n                   coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nas.factor(rx)2 -0.57986   0.55998  0.20118   0.30344 -1.911   0.0560 . \nnumber          0.20849   1.23182  0.04691   0.06567  3.175   0.0015 **\nsize           -0.05094   0.95034  0.06967   0.09304 -0.548   0.5840   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.5600     1.7858    0.3089     1.015\nnumber            1.2318     0.8118    1.0830     1.401\nsize              0.9503     1.0523    0.7919     1.140\n\nConcordance= 0.663  (se = 0.036 )\nLikelihood ratio test= 24.71  on 3 df,   p=2e-05\nWald test            = 15.56  on 3 df,   p=0.001\nScore (logrank) test = 27.89  on 3 df,   p=4e-06,   Robust = 11.75  p=0.008\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\nImportantly, the strata of the Wei-Lin-Weissfeld model as set by strata(enum) are substantially different from the conditional strata of the Prentice-Williams-Peterson model. The enum variable is now no longer assumed to be an ordinal variable.\n\n\n\nNote: For all recurrent event models, another way of defining the subject clusters is by using cluster(id) in the formula, rather than setting cluster = id. This results in the same outcomes, as shown below.\n\nAG_v1 &lt;- coxph(Surv(start, stop, event) ~ as.factor(rx) + number + size,\n            ties = \"breslow\",\n            cluster = id,\n            data = bladder2)\n\nsummary(AG_v1)\n\nCall:\ncoxph(formula = Surv(start, stop, event) ~ as.factor(rx) + number + \n    size, data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                   coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nas.factor(rx)2 -0.45979   0.63142  0.19996   0.25801 -1.782  0.07474 . \nnumber          0.17164   1.18726  0.04733   0.06131  2.799  0.00512 **\nsize           -0.04256   0.95833  0.06903   0.07555 -0.563  0.57317   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.6314     1.5837    0.3808     1.047\nnumber            1.1873     0.8423    1.0528     1.339\nsize              0.9583     1.0435    0.8264     1.111\n\nConcordance= 0.634  (se = 0.032 )\nLikelihood ratio test= 16.77  on 3 df,   p=8e-04\nWald test            = 11.76  on 3 df,   p=0.008\nScore (logrank) test = 18.57  on 3 df,   p=3e-04,   Robust = 11.44  p=0.01\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\n\nAG_v2 &lt;- coxph(Surv(start, stop, event) ~ as.factor(rx) + number + size + cluster(id),\n            ties = \"breslow\",\n            data = bladder2)\n\nsummary(AG_v2)\n\nCall:\ncoxph(formula = Surv(start, stop, event) ~ as.factor(rx) + number + \n    size, data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                   coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nas.factor(rx)2 -0.45979   0.63142  0.19996   0.25801 -1.782  0.07474 . \nnumber          0.17164   1.18726  0.04733   0.06131  2.799  0.00512 **\nsize           -0.04256   0.95833  0.06903   0.07555 -0.563  0.57317   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.6314     1.5837    0.3808     1.047\nnumber            1.1873     0.8423    1.0528     1.339\nsize              0.9583     1.0435    0.8264     1.111\n\nConcordance= 0.634  (se = 0.032 )\nLikelihood ratio test= 16.77  on 3 df,   p=8e-04\nWald test            = 11.76  on 3 df,   p=0.008\nScore (logrank) test = 18.57  on 3 df,   p=3e-04,   Robust = 11.44  p=0.01\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\nNote: R uses ties = \"efron\" by default, while SAS uses ties = breslow by default. In this tutorial, we forced R to use ties = \"breslow\" to match SAS for all recurrent event models. For more information, be sure to check the CAMIS webpage on the comparison of Cox proportional hazards models in R and SAS.\n\n\n\n\nIn terms of interpretation, hazard ratios (\\(\\exp(\\beta_j)\\)) are often used when making inferences based on Cox proportional hazards models. Now, as you may remember from the overview presented earlier, it is important to recognize that each of the recurrent event models comes with a slightly different interpretation of the hazard ratio, as defined by the assumptions around the model.\n\n\n\n\n\n\n\n\n\n\n\nAG\nPWPtt\nPWPgt\nWLW\n\n\n\n\nHazard ratio (HR)\nrisk of any recurrence\nrisk of any recurrence\nrisk of recurrence after previous event\nrisk of event of any type, not necessarily recurrent event\n\n\n\nThis means that, for the bladder data, we can draw slightly different conclusions on the hazard ratio of the group treated with thiotepa (rx = 2) versus the placebo group (rx = 1).\n\n\n\nModel\nHR: rx2 vs rx1\n95% CI\nP-value\n\n\n\n\nAG\n0.631\n0.381 to 1.047\n0.0747\n\n\nOriginal AG\n0.631\n0.403 to 0.989\n0.0447\n\n\nPWPtt\n0.716\n0.487 to 1.053\n0.0898\n\n\nPWPgt\n0.764\n0.508 to 1.148\n0.1952\n\n\nWLW\n0.560\n0.309 to 1.015\n0.0560\n\n\n\nThese conclusions are:\n\nAndersen-Gill: the risk of having any new tumor recurrence in the treatment group is 0.631 (0.381 - 1.047) times that of the placebo group\nPrentice-Williams-Peterson: total time: the risk of having any new tumor recurrence in the treatment group is 0.716 (0.487 - 1.053) times that of the placebo group\nPrentice-Williams-Peterson: gap time: the risk of having a new tumor recurrence after a previous event in the treatment group is 0.764 (0.508 - 1.148) times that of the placebo group\nWei-Lin-Weissfeld: the risk of having any type of event in the treatment group is 0.560 (0.309 - 1.015) times that of the placebo group\n\nNote: The improved Andersen-Gill model (LWYY model or proportional means/rates model) is preferred over the original Andersen-Gill model.\n\n\n\nFor the Prentice-Williams-Peterson and Wei-Lin-Weissfeld models we can incorporate both overall (\\(\\beta\\)) and event-specific (\\(\\beta_j\\)) effects for each covariate. To arrive at pooled model parameters these models assume that \\(\\beta_1 = \\beta_2 = ... = \\beta_k = \\beta\\). Until now, we have only considered pooled model parameters, but given the underlying stratification of these two models in particular, it may be valuable to look into the event-specific estimates as well (Amorim & Cai 2015).\nTo output event-specific estimates for the treatment effect (rx), we simply specify rx:strata(enum) in the formula.\n\n\nTotal time model\n\nPWPtt_stratified &lt;- coxph(Surv(start, stop, event) ~ rx:strata(enum) + number + size,\n                          ties = \"breslow\", cluster = id, data = bladder2)\nsummary(PWPtt_stratified)\n\nCall:\ncoxph(formula = Surv(start, stop, event) ~ rx:strata(enum) + \n    number + size, data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                           coef exp(coef)  se(coef) robust se      z Pr(&gt;|z|)  \nnumber                 0.111071  1.117475  0.054397  0.050063  2.219   0.0265 *\nsize                  -0.006674  0.993349  0.073173  0.061409 -0.109   0.9135  \nrx:strata(enum)enum=1 -0.409893  0.663721  0.304293  0.286737 -1.430   0.1529  \nrx:strata(enum)enum=2 -0.416339  0.659457  0.398266  0.423632 -0.983   0.3257  \nrx:strata(enum)enum=3 -0.142970  0.866780  0.593818  0.405303 -0.353   0.7243  \nrx:strata(enum)enum=4  0.105362  1.111112  0.679095  0.469706  0.224   0.8225  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                      exp(coef) exp(-coef) lower .95 upper .95\nnumber                   1.1175     0.8949    1.0130     1.233\nsize                     0.9933     1.0067    0.8807     1.120\nrx:strata(enum)enum=1    0.6637     1.5067    0.3784     1.164\nrx:strata(enum)enum=2    0.6595     1.5164    0.2875     1.513\nrx:strata(enum)enum=3    0.8668     1.1537    0.3917     1.918\nrx:strata(enum)enum=4    1.1111     0.9000    0.4425     2.790\n\nConcordance= 0.609  (se = 0.033 )\nLikelihood ratio test= 6.73  on 6 df,   p=0.3\nWald test            = 8.22  on 6 df,   p=0.2\nScore (logrank) test = 7.02  on 6 df,   p=0.3,   Robust = 9.37  p=0.2\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\nGap time model\nPWPgt_stratified &lt;- coxph(Surv(gtime, event) ~ rx:strata(enum) + number + size,\nties = “breslow”, cluster = id, data = bladder2)\nsummary(PWPgt_stratified)\n\nPWPgt_stratified &lt;- coxph(Surv(gtime, event) ~ rx:strata(enum) + number + size,\n                          ties = \"breslow\", cluster = id, data = bladder2)\nsummary(PWPgt_stratified)\n\nCall:\ncoxph(formula = Surv(gtime, event) ~ rx:strata(enum) + number + \n    size, data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                          coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nnumber                 0.15193   1.16408  0.05259   0.04864  3.124  0.00179 **\nsize                   0.01319   1.01328  0.07021   0.06297  0.209  0.83406   \nrx:strata(enum)enum=1 -0.43665   0.64620  0.30521   0.28376 -1.539  0.12385   \nrx:strata(enum)enum=2 -0.30182   0.73947  0.39752   0.38907 -0.776  0.43789   \nrx:strata(enum)enum=3  0.01485   1.01497  0.47722   0.49843  0.030  0.97622   \nrx:strata(enum)enum=4  0.06019   1.06204  0.58289   0.53982  0.112  0.91122   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                      exp(coef) exp(-coef) lower .95 upper .95\nnumber                   1.1641     0.8590    1.0582     1.281\nsize                     1.0133     0.9869    0.8956     1.146\nrx:strata(enum)enum=1    0.6462     1.5475    0.3705     1.127\nrx:strata(enum)enum=2    0.7395     1.3523    0.3449     1.585\nrx:strata(enum)enum=3    1.0150     0.9853    0.3821     2.696\nrx:strata(enum)enum=4    1.0620     0.9416    0.3687     3.059\n\nConcordance= 0.603  (se = 0.032 )\nLikelihood ratio test= 9.73  on 6 df,   p=0.1\nWald test            = 14.45  on 6 df,   p=0.02\nScore (logrank) test = 10.49  on 6 df,   p=0.1,   Robust = 11.41  p=0.08\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\n\n\n\n\nWLW_stratified &lt;- coxph(Surv(stop, event) ~ rx:strata(enum) + number + size,\n                        ties = \"breslow\", cluster = id, data = bladder)\nsummary(WLW_stratified)\n\nCall:\ncoxph(formula = Surv(stop, event) ~ rx:strata(enum) + number + \n    size, data = bladder, ties = \"breslow\", cluster = id)\n\n  n= 340, number of events= 112 \n\n                          coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nnumber                 0.20747   1.23056  0.04685   0.06573  3.156   0.0016 **\nsize                  -0.05187   0.94945  0.06966   0.09300 -0.558   0.5770   \nrx:strata(enum)enum=1 -0.47890   0.61947  0.30583   0.28313 -1.691   0.0908 . \nrx:strata(enum)enum=2 -0.64914   0.52249  0.39217   0.36826 -1.763   0.0779 . \nrx:strata(enum)enum=3 -0.71783   0.48781  0.45971   0.42148 -1.703   0.0885 . \nrx:strata(enum)enum=4 -0.56175   0.57021  0.56143   0.49592 -1.133   0.2573   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                      exp(coef) exp(-coef) lower .95 upper .95\nnumber                   1.2306     0.8126    1.0818     1.400\nsize                     0.9494     1.0532    0.7912     1.139\nrx:strata(enum)enum=1    0.6195     1.6143    0.3556     1.079\nrx:strata(enum)enum=2    0.5225     1.9139    0.2539     1.075\nrx:strata(enum)enum=3    0.4878     2.0500    0.2135     1.114\nrx:strata(enum)enum=4    0.5702     1.7537    0.2157     1.507\n\nConcordance= 0.661  (se = 0.036 )\nLikelihood ratio test= 24.95  on 6 df,   p=3e-04\nWald test            = 16.54  on 6 df,   p=0.01\nScore (logrank) test = 28.19  on 6 df,   p=9e-05,   Robust = 11.92  p=0.06\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\n\n\n\n\n\nAmor 2023. Eat, Sleep, R, Repeat.\nAmorim & Cai 2015. Modelling recurrent events: a tutorial for analysis in epidemiology. International Journal of Epidemiology. 2015 Feb;44(1):324-33.\nAndersen & Gill 1982. Cox’s Regression Model for Counting Processes: A Large Sample Study. The Annals of Statistics. 10(4):1100–1120.\nbladder data\nLee et al. 2025. Comparison of total event analysis and first event analysis in relation to heterogeneity in cardiovascular trials. BMC Medical Research Methodology. 2025 Jun 9;25(1):159.\nLin, Wei, Yang & Ying 2000. Semiparametric regression for the mean and rate functions of recurrent events. Journal of the Royal Statistical Society: Series B. 62(4):711–730.\nLu & Shen 2018. Application of Survival Analysis in Multiple Events Using SAS. PharmaSUG 2018.\nOzga et al. 2018. A systematic comparison of recurrent event models for application to composite endpoints. BMC Medical Research Methodology. 2018 Jan 4;18(1):2.\nPrentice, Williams & Peterson 1981. On the Regression Analysis of Multivariate Failure Time Data. Biometrika. 68(2):373–379.\nsurvival package\nWei, Lin & Weissfeld 1989. Regression Analysis of Multivariate Incomplete Failure Time Data by Modeling Marginal Distributions. Journal of the American Statistical Association. 84(408):1065–1073.\n\n\n\n\n\n\nNoteSession info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package     * version date (UTC) lib source\n P BiocManager   1.30.25 2024-08-28 [?] CRAN (R 4.4.1)\n P cli           3.6.3   2024-06-21 [?] CRAN (R 4.4.0)\n P digest        0.6.37  2024-08-19 [?] CRAN (R 4.4.1)\n P dplyr       * 1.1.4   2023-11-17 [?] CRAN (R 4.4.0)\n P evaluate      1.0.0   2024-09-17 [?] CRAN (R 4.4.1)\n P fansi         1.0.6   2023-12-08 [?] CRAN (R 4.4.0)\n P fastmap       1.2.0   2024-05-15 [?] CRAN (R 4.4.0)\n P generics      0.1.3   2022-07-05 [?] CRAN (R 4.4.0)\n P glue          1.8.0   2024-09-30 [?] CRAN (R 4.4.1)\n P gt          * 0.11.1  2024-10-04 [?] CRAN (R 4.4.1)\n P htmltools     0.5.8.1 2024-04-04 [?] CRAN (R 4.4.0)\n P htmlwidgets   1.6.4   2023-12-06 [?] CRAN (R 4.4.0)\n P jsonlite      1.8.9   2024-09-20 [?] CRAN (R 4.4.1)\n   knitr         1.50    2025-03-16 [1] RSPM (R 4.4.0)\n   lattice       0.22-6  2024-03-20 [2] CRAN (R 4.4.2)\n P lifecycle     1.0.4   2023-11-07 [?] CRAN (R 4.4.0)\n P magrittr      2.0.3   2022-03-30 [?] CRAN (R 4.4.0)\n   Matrix        1.7-1   2024-10-18 [2] CRAN (R 4.4.2)\n P pillar        1.9.0   2023-03-22 [?] CRAN (R 4.4.0)\n P pkgconfig     2.0.3   2019-09-22 [?] CRAN (R 4.4.0)\n P R6            2.5.1   2021-08-19 [?] CRAN (R 4.4.0)\n   renv          1.0.10  2024-10-05 [1] CRAN (R 4.4.1)\n P rlang         1.1.6   2025-04-11 [?] RSPM\n P rmarkdown     2.28    2024-08-17 [?] CRAN (R 4.4.0)\n P rstudioapi    0.16.0  2024-03-24 [?] CRAN (R 4.4.0)\n P sass          0.4.9   2024-03-15 [?] CRAN (R 4.4.0)\n P sessioninfo   1.2.2   2021-12-06 [?] CRAN (R 4.4.0)\n P survival    * 3.7-0   2024-06-05 [?] CRAN (R 4.4.0)\n P tibble        3.2.1   2023-03-20 [?] CRAN (R 4.4.0)\n P tidyselect    1.2.1   2024-03-11 [?] CRAN (R 4.4.0)\n P utf8          1.2.4   2023-10-22 [?] CRAN (R 4.4.0)\n P vctrs         0.6.5   2023-12-01 [?] CRAN (R 4.4.0)\n P withr         3.0.1   2024-07-31 [?] CRAN (R 4.4.0)\n   xfun          0.52    2025-04-02 [1] RSPM (R 4.4.0)\n P xml2          1.3.6   2023-12-04 [?] CRAN (R 4.4.0)\n P yaml          2.3.10  2024-07-26 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/recurrent_events.html#setup",
    "href": "R/recurrent_events.html#setup",
    "title": "R Recurrent Events",
    "section": "",
    "text": "library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(gt)\n\n\n\n\n\nlibrary(survival)"
  },
  {
    "objectID": "R/recurrent_events.html#modelling-recurrent-events",
    "href": "R/recurrent_events.html#modelling-recurrent-events",
    "title": "R Recurrent Events",
    "section": "",
    "text": "Traditionally, survival analysis focuses on the time to a single first event. While there are many applications for such time-to-event analysis in clinical trials, this approach falls short when events of interest can occur multiple times within the same subject. Recurrent event models extend the traditional Cox proportional hazards framework to account for multiple events per subject (Ozga et al. 2018, Amorim & Cai 2015).\nIn this tutorial, we will demonstrate how to implement different recurrent event models in R, specifically the Andersen-Gill, proportional means/rates, Prentice-Williams-Peterson, and Wei-Lin-Weissfeld models, using the well-known survival package. The R code follows the layout of Amor 2023, with additional insights taken from Lu et al. 2018.\nRecurrent event models can roughly be divided in three categories: counting process models, conditional models and marginal models. In the section below, we will explore the difference between each of these approaches. In addition, important aspects of data structure will be discussed by means of two fictional subjects, one with 4 events and 0 censored observations (events at time 6, 9, 56 and 88), and another with 2 events and 1 censored observation (events at time 42, 57, and censored at time 91).\nDefine the following:\n\n\n\n\n\n\nNote\n\n\n\n\\(\\lambda_i(t)\\): hazard function for the \\(i\\)th subject at time \\(t\\)\n\\(\\lambda_{ij}(t)\\): hazard function for the \\(j\\)th event of the \\(i\\)th subject at time \\(t\\)\n\\(\\lambda_0(t)\\): common baseline hazard for all events\n\\(\\lambda_{0j}(t)\\): event-specific baseline hazard for the \\(j\\)th event at time \\(t\\)\n\\(\\beta\\): common parameter vector\n\\(\\beta_j\\): event-specific parameter vector for the \\(j\\)th event\n\\(X_{ij}\\): covariate vector for the \\(j\\)th event of the \\(i\\)th subject\n\n\n\n\n\n\n\n\\[\n\\lambda_i(t) = \\lambda_0(t) \\exp \\left( \\beta X_{ij}(t) \\right) \\\n\\]\n\nCounting process approach: treats each subject as a multiple events counting process\nCommon baseline hazard \\(\\lambda_0(t)\\)\nCommon regression coefficients \\(\\beta\\)\nUnrestricted risk set: a subject contributes to the risk set for an event as long as the subject is under observation, i.e. it can be at risk for a subsequent event even though the previous event did not yet occur\nOrder of events is not important\n\nAn essential assumption of the Andersen-Gill model is that of independent events within subjects. This, however, is often not realistic in clinical trial data. For example, let’s say that we are modelling myocardial infarction (MI). If a patient has already experienced one MI, their risk of subsequent events may increase due to underlying cardiovascular damage or presence of other risk factors. Thus, the more events a patient has, the more likely they are to experience future events, indicating dependence rather than independence. To accurately model this within-subject correlation, extensions like time-varying covariates, a robust sandwich covariance estimator or frailty terms may be needed. In this tutorial, we will discuss the sandwich correction.\nLin-Wei-Yang-Ying (LWYY) model or proportional means/rates model (Lin, Wei, Yang & Ying 2000)\nLin, Wei, Yang, and Ying introduced an improved version of the Andersen-Gill model in 2000 (often referred to as proportional means/rates model), featuring a robust sandwich estimator that explicitly accounts for individual subject clusters. These robust standard errors yield wider confidence intervals and provide asymptotically valid inference even when the independence assumption does not hold (Lee et al. 2025). The original and improved Andersen-Gill model often appear interchangeable in the literature, and while they produce identical estimates, their robust standard errors can differ substantially, which may impact the conclusions drawn from statistical inference.\nFor both versions of the Andersen-Gill model, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(6, 9]\n1\n1\n\n\n1\n(9, 56]\n1\n1\n\n\n1\n(56, 88]\n1\n1\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(42, 87]\n1\n1\n\n\n2\n(87, 91]\n0\n1\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nIn both versions of the Andersen-Gill model, each new time interval starts where the previous one ends.\n\n\n\n\n\n\n\nConditional approach: incorporates conditional strata to account for ordering/dependence of events\nStratified baseline hazard \\(\\lambda_{0j}(t)\\)\nStratified regression coefficients \\(\\beta_j\\): can be pooled (\\(\\beta\\)) or kept as event-specific (\\(\\beta_j\\)) in the output\nRestricted risk set: contributions to the risk set for a subsequent event are restricted to only consider subjects that already experienced the previous event\nOrder of events is important\n\nThe Prentice-Williams-Peterson model can incorporate both overall and event-specific effects \\(\\beta_j\\) for each covariate. An often made assumption is to set \\(\\beta_1 = \\beta_2 = ... = \\beta_k = \\beta\\) to estimate a common parameter \\(\\beta\\).\nDepending on the outcome of interest, Prentice, Williams and Peterson suggested two distinct models:\n\nTotal time model\n\n\\[\n\\lambda_{ij}(t) = \\lambda_{0j}(t) \\exp \\left( \\beta_j X_{ij}(t) \\right) \\\n\\]\nThe total time variant of the Prentice-Williams-Peterson model uses the same time intervals as the counting process approach (Andersen-Gill model), which is useful for modelling the full time course (\\(t\\)) of the recurrent event process, i.e. the hazard of any recurrence.\nFor the total time model, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(6, 9]\n1\n2\n\n\n1\n(9, 56]\n1\n3\n\n\n1\n(56, 88]\n1\n4\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(42, 87]\n1\n2\n\n\n2\n(87, 91]\n0\n3\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nAgain, in the total time model, each new time intervals starts where the previous one ends.\n\nGap time model\n\n\\[\n\\lambda_{ij}(t) = \\lambda_{0j}(t - t_{j-1}) \\exp \\left( \\beta_j X_{ij}(t) \\right) \\\n\\]\nThe gap time variant of the Prentice-Williams-Peterson model uses time intervals that start at zero and end at the length of time until the next event, which is useful for modelling the time between each of the recurring events (\\(t - t_{j-1}\\)), i.e. the hazard of recurrence after the previous event.\nFor the gap time model, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(0, 3]\n1\n2\n\n\n1\n(0, 47]\n1\n3\n\n\n1\n(0, 32]\n1\n4\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(0, 45]\n1\n2\n\n\n2\n(0, 3]\n0\n3\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nIn the gap time model, each time interval starts at zero and has a length equal to the gap time between two neighboring events.\n\n\n\n\n\n\n\\[\n\\lambda_{ij}(t) = \\lambda_{0j}(t) \\exp \\left( \\beta_j X_{ij}(t) \\right) \\\n\\]\n\nMarginal approach: treats each (recurrent) event as having a separate, marginal process\nStratified baseline hazard \\(\\lambda_{0j}(t)\\)\nStratified regression coefficients \\(\\beta_j\\): can be pooled (\\(\\beta\\)) or kept as event-specific (\\(\\beta_j\\)) in the output\nSemi-restricted risk set: all subjects contribute follow-up times to all potential events, i.e. each subject is at risk for all potential events, regardless of how many events that subject actually experiences\nOrder of events is not important\n\nAlthough the Wei-Lin-Weissfeld model has it roots in competing risks analysis, it conveniently lends itself to model recurrent events as well. Like the Andersen-Gill model, the Wei-Lin-Weissfeld model also assumes independence of events, which is often not feasible in practice. In addition, it is assumed there is no specific order among the events or that the events are different types of events, and not necessarily recurrent events.\nLike the Prentice-Williams-Peterson models, the Wei-Lin-Weissfeld model can incorporate both overall and event-specific effects \\(\\beta_j\\) for each covariate. An often made assumption is to set \\(\\beta_1 = \\beta_2 = ... = \\beta_k = \\beta\\) to estimate a common parameter \\(\\beta\\). Another approach is to combine event-specific effects \\(\\beta_j\\) to get an estimator of the average effect, as described in Wei, Lin & Weissfeld 1989 (this is not discussed further here).\nFor Wei-Lin-Weissfeld models, the data must be structured as follows:\n\n\n\nSubject\nTime interval\nEvent\nStratum\n\n\n\n\n1\n(0, 6]\n1\n1\n\n\n1\n(0, 9]\n1\n2\n\n\n1\n(0, 56]\n1\n3\n\n\n1\n(0, 88]\n1\n4\n\n\n2\n(0, 42]\n1\n1\n\n\n2\n(0, 87]\n1\n2\n\n\n2\n(0, 91]\n0\n3\n\n\n2\n(0, 91]\n0\n4\n\n\n\nThis can be visually represented:\n\n\n\n\n\n\n\n\n\nIn the Wei-Lin-Weissfeld model, each time intervals starts at zero and ends at its respective event time.\n\n\n\n\nIn summary, the selection of the model to use would depend on the type of events, the importance of the order of the events and the time intervals to be analyzed. We made an effort to summarize the similarities and differences between the models in the table below.\n\n\n\n\n\n\n\n\n\n\n\nAG\nPWPtt\nPWPgt\nWLW\n\n\n\n\nApproach\ncounting process\nconditional\nconditional\nmarginal\n\n\nBaseline hazard\ncommon\nstratified\nstratified\nstratified\n\n\nRegression coefficients\ncommon\nstratified possible\nstratified possible\nstratified possible\n\n\nRisk set\nunrestricted\nrestricted\nrestricted\nsemi-restricted\n\n\nTime interval\ntotal time\ntotal time\ngap time\ntotal time\n\n\nOrder of events\nnot important\nimportant\nimportant\nnot important\n\n\nHazard ratio (HR)\nrisk of any recurrence\nrisk of any recurrence\nrisk of recurrence after previous event\nrisk of event of any type, not necessarily recurrent event\n\n\n\nNote that, because the ordering of events is not important in the Andersen-Gill and Wei-Lin-Weissfeld model, these models come with the assumption of independence of events. In contrast, the Prentice-Williams-Peterson models overcome the need for this assumption by capturing the dependence structure between recurrent events in conditional strata. Consequently, events are assumed to be conditionally independent in the Prentice-Williams-Peterson models.\nA nice visual representation of the stratification and time interval structure of each model is given below. The correct data structure is pivotal when modelling recurrent events and depends on the methodology you want to use, as illustrated in the figure."
  },
  {
    "objectID": "R/recurrent_events.html#modelling-recurrent-events-using-the-survival-package",
    "href": "R/recurrent_events.html#modelling-recurrent-events-using-the-survival-package",
    "title": "R Recurrent Events",
    "section": "",
    "text": "For this tutorial we will use the bladder data from the survival package, which captures recurrences of bladder cancer from a clinical trial for an oncolytic called thiotepa. The bladder data is regularly used by many statisticians to demonstrate methodology for recurrent event modelling. Somewhat confusingly, there are three versions of this data available:\n\nbladder1: original data from the study on all subjects (294 records)\nbladder2: data in Andersen-Gill format on subset of subjects with nonzero follow-up time (178 records)\nbladder: data in Wei-Lin-Weissfeld format on subset of subjects with nonzero follow-up time (340 records)\n\nFor this tutorial, we will use bladder2 to illustrate Andersen-Gill and Prentice-Williams-Peterson models, and bladder to illustrate the Wei-Lin-Weissfeld model.\nThe variables included in both datasets are:\n\nid: patient id\nrx: treatment group (1 = placebo, 2 = thiotepa)\nnumber: initial number of tumors (8 = 8 or more)\nsize: size in cm of largest initial tumor\nstart: start of time interval; this variable is not present in bladder\nstop: (recurrent) event or censoring time\nevent: event indicator (1 = event, 0 = censored)\nenum: order of recurrence\n\nImportantly, both datasets collect the data in a counting process structure. This means that there is one record for each subject and time interval, where a time interval is defined as the time to its respective event (event = 1), or the time to follow-up if the event did not occur (event = 0).\nLet’s look more closely at the bladder2 and bladder data:\n\nbladder2 &lt;- survival::bladder2\ngt(head(bladder2, 6))\n\n\n\n\n\n\n\nid\nrx\nnumber\nsize\nstart\nstop\nevent\nenum\n\n\n\n\n1\n1\n1\n3\n0\n1\n0\n1\n\n\n2\n1\n2\n1\n0\n4\n0\n1\n\n\n3\n1\n1\n1\n0\n7\n0\n1\n\n\n4\n1\n5\n1\n0\n10\n0\n1\n\n\n5\n1\n4\n1\n0\n6\n1\n1\n\n\n5\n1\n4\n1\n6\n10\n0\n2\n\n\n\n\n\n\n\n\nbladder2 %&gt;%\n  group_by(enum) %&gt;% summarise(n = n()) %&gt;% gt()\n\n\n\n\n\n\n\nenum\nn\n\n\n\n\n1\n85\n\n\n2\n46\n\n\n3\n27\n\n\n4\n20\n\n\n\n\n\n\n\nIn bladder2, in the Andersen-Gill format, each subject has a variable amount of records, depending on the amount of events that subject experienced.\n\nbladder &lt;- survival::bladder\ngt(head(bladder, 20))\n\n\n\n\n\n\n\nid\nrx\nnumber\nsize\nstop\nevent\nenum\n\n\n\n\n1\n1\n1\n3\n1\n0\n1\n\n\n1\n1\n1\n3\n1\n0\n2\n\n\n1\n1\n1\n3\n1\n0\n3\n\n\n1\n1\n1\n3\n1\n0\n4\n\n\n2\n1\n2\n1\n4\n0\n1\n\n\n2\n1\n2\n1\n4\n0\n2\n\n\n2\n1\n2\n1\n4\n0\n3\n\n\n2\n1\n2\n1\n4\n0\n4\n\n\n3\n1\n1\n1\n7\n0\n1\n\n\n3\n1\n1\n1\n7\n0\n2\n\n\n3\n1\n1\n1\n7\n0\n3\n\n\n3\n1\n1\n1\n7\n0\n4\n\n\n4\n1\n5\n1\n10\n0\n1\n\n\n4\n1\n5\n1\n10\n0\n2\n\n\n4\n1\n5\n1\n10\n0\n3\n\n\n4\n1\n5\n1\n10\n0\n4\n\n\n5\n1\n4\n1\n6\n1\n1\n\n\n5\n1\n4\n1\n10\n0\n2\n\n\n5\n1\n4\n1\n10\n0\n3\n\n\n5\n1\n4\n1\n10\n0\n4\n\n\n\n\n\n\n\n\nbladder %&gt;%\n  group_by(enum) %&gt;% summarise(n = n()) %&gt;% gt()\n\n\n\n\n\n\n\nenum\nn\n\n\n\n\n1\n85\n\n\n2\n85\n\n\n3\n85\n\n\n4\n85\n\n\n\n\n\n\n\nIn bladder, in the Wei-Lin-Weissfeld format, each subject has four records, regardless of how many events that subject actually experienced. In addition, there is no start variable, as all time intervals start at zero.\n\n\n\nIn the survival package, any survival analysis based on the Cox proportional hazard model can be conducted using the coxph() function. Hence, conveniently, when modelling time-to-event data with recurrent events, the same function can be used. The caveat here is that an adequate data structure is required, which must be in correspondence with the model you want to use.\nIn this section of the tutorial, we will explain how the arguments of the coxph() function and data structure must be defined to fit every type of recurrent event model correctly.\n\n\n\nImproved Andersen-Gill model (LWYY model or proportional means/rates model)\n\nFor the improved version of the Andersen-Gill model you must specify:\n\nformula = Surv(start, stop, event) ~ 'predictors'\ncluster = id\n\nAnd the data structure must be:\n\n\n\nId\nTime interval\nStart\nStop\nEvent\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n\n\n2\n(0, 4]\n0\n4\n0\n\n\n3\n(0, 7]\n0\n7\n0\n\n\n4\n(0, 10]\n0\n10\n0\n\n\n5\n(0, 6]\n0\n6\n1\n\n\n5\n(6, 10]\n6\n10\n0\n\n\n\nWe will use the bladder2 data for this.\n\nAG &lt;- coxph(Surv(start, stop, event) ~ as.factor(rx) + number + size,\n            ties = \"breslow\",\n            cluster = id,\n            data = bladder2)\nsummary(AG)\n\nCall:\ncoxph(formula = Surv(start, stop, event) ~ as.factor(rx) + number + \n    size, data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                   coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nas.factor(rx)2 -0.45979   0.63142  0.19996   0.25801 -1.782  0.07474 . \nnumber          0.17164   1.18726  0.04733   0.06131  2.799  0.00512 **\nsize           -0.04256   0.95833  0.06903   0.07555 -0.563  0.57317   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.6314     1.5837    0.3808     1.047\nnumber            1.1873     0.8423    1.0528     1.339\nsize              0.9583     1.0435    0.8264     1.111\n\nConcordance= 0.634  (se = 0.032 )\nLikelihood ratio test= 16.77  on 3 df,   p=8e-04\nWald test            = 11.76  on 3 df,   p=0.008\nScore (logrank) test = 18.57  on 3 df,   p=3e-04,   Robust = 11.44  p=0.01\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\nBy defining the cluster argument, coxph() will automatically set robust = TRUE, and compute a robust sandwich covariance. The summary function will then display both the non-robust (se(coef)) and robust (robust se) standard error estimates. Under the hood, the robust standard errors will consider all id clusters separately and ultimately sum up the score residuals for each distinct cluster.\n\nOriginal Andersen-Gill model\n\nTo our knowledge, the original Andersen-Gill model of 1989 can only be fitted in R by adding an artificial clustering variable with unique entries to the bladder2 data, which we call id2. This artificial clustering variable will ignore any clustering that is actually present in the data.\n\nbladder2 &lt;- bladder2 %&gt;%\n  dplyr::mutate(id2 = row_number())\n\nExcept for cluster = id2, the rest of the code remains the same.\n\nAG_original &lt;- coxph(Surv(start, stop, event) ~ as.factor(rx) + number + size,\n            ties = \"breslow\",\n            cluster = id2,\n            data = bladder2)\nsummary(AG_original)\n\nCall:\ncoxph(formula = Surv(start, stop, event) ~ as.factor(rx) + number + \n    size, data = bladder2, ties = \"breslow\", cluster = id2)\n\n  n= 178, number of events= 112 \n\n                   coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nas.factor(rx)2 -0.45979   0.63142  0.19996   0.22902 -2.008  0.04468 * \nnumber          0.17164   1.18726  0.04733   0.06469  2.653  0.00797 **\nsize           -0.04256   0.95833  0.06903   0.07325 -0.581  0.56119   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.6314     1.5837    0.4031    0.9891\nnumber            1.1873     0.8423    1.0459    1.3477\nsize              0.9583     1.0435    0.8302    1.1063\n\nConcordance= 0.634  (se = 0.032 )\nLikelihood ratio test= 16.77  on 3 df,   p=8e-04\nWald test            = 9.36  on 3 df,   p=0.02\nScore (logrank) test = 18.57  on 3 df,   p=3e-04,   Robust = 14.27  p=0.003\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\nAlthough the original Andersen-Gill model does not consider separate id clusters, it still computes robust standard errors using the sandwich estimator, as robust = TRUE. The resulting robust standard errors (robust se) differ from those provided for the improved Andersen-Gill model, while the estimated coefficients (coef) and non-robust standard errors (se(coef)) remain perfectly unchanged.\n\n\n\n\nTotal time model\n\nFor the Prentice-Williams-Peterson total time model you must specify:\n\nformula = Surv(start, stop, event) ~ 'predictors' + strata(enum)\ncluster = id\n\nAnd the data structure must be:\n\n\n\nId\nTime interval\nStart\nStop\nEvent\nEnum\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n1\n\n\n2\n(0, 4]\n0\n4\n0\n1\n\n\n3\n(0, 7]\n0\n7\n0\n1\n\n\n4\n(0, 10]\n0\n10\n0\n1\n\n\n5\n(0, 6]\n0\n6\n1\n1\n\n\n5\n(6, 10]\n6\n10\n0\n2\n\n\n\nWe will use the bladder2 data for this.\n\nPWPtt &lt;- coxph(Surv(start, stop, event) ~ as.factor(rx) + number + size + strata(enum),\n            ties = \"breslow\",\n            cluster = id,\n            data = bladder2)\nsummary(PWPtt)\n\nCall:\ncoxph(formula = Surv(start, stop, event) ~ as.factor(rx) + number + \n    size + strata(enum), data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                    coef exp(coef)  se(coef) robust se      z Pr(&gt;|z|)  \nas.factor(rx)2 -0.334295  0.715842  0.216087  0.197064 -1.696   0.0898 .\nnumber          0.115653  1.122606  0.053681  0.049913  2.317   0.0205 *\nsize           -0.008051  0.991982  0.072725  0.060124 -0.134   0.8935  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.7158     1.3970    0.4865     1.053\nnumber            1.1226     0.8908    1.0180     1.238\nsize              0.9920     1.0081    0.8817     1.116\n\nConcordance= 0.615  (se = 0.032 )\nLikelihood ratio test= 6.11  on 3 df,   p=0.1\nWald test            = 7.19  on 3 df,   p=0.07\nScore (logrank) test = 6.45  on 3 df,   p=0.09,   Robust = 8.76  p=0.03\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\nThe conditional strata of the Prentice-Williams-Peterson model are set by strata(enum) in the formula, where enum captures the ordering of recurrent events.\n\nGap time model\n\nFor the Prentice-Williams-Peterson gap time model you must specify:\n\nformula = Surv(gtime, event) ~ 'predictors' + strata(enum)\ncluster = id\n\nAnd the data structure must be:\n\n\n\nId\nTime interval\nStart\nStop\nEvent\nEnum\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n1\n\n\n2\n(0, 4]\n0\n4\n0\n1\n\n\n3\n(0, 7]\n0\n7\n0\n1\n\n\n4\n(0, 10]\n0\n10\n0\n1\n\n\n5\n(0, 6]\n0\n6\n1\n1\n\n\n5\n(0, 4]\n0\n4\n0\n2\n\n\n\nThis data structure can be achieved in bladder2 by adding a gtime variable.\n\nbladder2 &lt;- bladder2 %&gt;%\n  dplyr::mutate(gtime = stop - start)\n  \ngt(head(bladder2, 6))\n\n\n\n\n\n\n\nid\nrx\nnumber\nsize\nstart\nstop\nevent\nenum\nid2\ngtime\n\n\n\n\n1\n1\n1\n3\n0\n1\n0\n1\n1\n1\n\n\n2\n1\n2\n1\n0\n4\n0\n1\n2\n4\n\n\n3\n1\n1\n1\n0\n7\n0\n1\n3\n7\n\n\n4\n1\n5\n1\n0\n10\n0\n1\n4\n10\n\n\n5\n1\n4\n1\n0\n6\n1\n1\n5\n6\n\n\n5\n1\n4\n1\n6\n10\n0\n2\n6\n4\n\n\n\n\n\n\n\nWe artificially set start = 0 for each gap time interval by including gtime instead of start, stop in the Surv() object.\n\nPWPgt &lt;- coxph(Surv(gtime, event) ~ as.factor(rx) + number + size + strata(enum),\n            ties = \"breslow\",\n            cluster = id,\n            data = bladder2)\nsummary(PWPgt)\n\nCall:\ncoxph(formula = Surv(gtime, event) ~ as.factor(rx) + number + \n    size + strata(enum), data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                   coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nas.factor(rx)2 -0.26952   0.76375  0.20766   0.20808 -1.295  0.19522   \nnumber          0.15353   1.16595  0.05211   0.04889  3.140  0.00169 **\nsize            0.00684   1.00686  0.07001   0.06222  0.110  0.91246   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.7637     1.3093    0.5080     1.148\nnumber            1.1659     0.8577    1.0594     1.283\nsize              1.0069     0.9932    0.8913     1.137\n\nConcordance= 0.596  (se = 0.032 )\nLikelihood ratio test= 8.76  on 3 df,   p=0.03\nWald test            = 12.14  on 3 df,   p=0.007\nScore (logrank) test = 9.6  on 3 df,   p=0.02,   Robust = 10.21  p=0.02\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\n\n\n\nFor the Wei-Lin-Weissfeld model you must specify:\n\nformula = Surv(stop, event) ~ 'predictors' + strata(enum)\ncluster = id\n\nAnd the data structure must be:\n\n\n\nId\nTime interval\nStart\nStop\nEvent\nEnum\n\n\n\n\n1\n(0, 1]\n0\n1\n0\n1\n\n\n1\n(0, 1]\n0\n1\n0\n2\n\n\n1\n(0, 1]\n0\n1\n0\n3\n\n\n1\n(0, 1]\n0\n1\n0\n4\n\n\n2\n(0, 4]\n0\n4\n0\n1\n\n\n2\n(0, 4]\n0\n4\n0\n2\n\n\n2\n(0, 4]\n0\n4\n0\n3\n\n\n2\n(0, 4]\n0\n4\n0\n4\n\n\n3\n(0, 7]\n0\n7\n0\n1\n\n\n3\n(0, 7]\n0\n7\n0\n2\n\n\n3\n(0, 7]\n0\n7\n0\n3\n\n\n3\n(0, 7]\n0\n7\n0\n4\n\n\n4\n(0, 10]\n0\n10\n0\n1\n\n\n4\n(0, 10]\n0\n10\n0\n2\n\n\n4\n(0, 10]\n0\n10\n0\n3\n\n\n4\n(0, 10]\n0\n10\n0\n4\n\n\n5\n(0, 6]\n0\n6\n1\n1\n\n\n5\n(0, 10]\n0\n10\n0\n2\n\n\n5\n(0, 10]\n0\n10\n0\n3\n\n\n5\n(0, 10]\n0\n10\n0\n4\n\n\n\nWe will use the bladder data for this.\n\nWLW &lt;- coxph(Surv(stop, event) ~ as.factor(rx) + number + size + strata(enum),\n            ties = \"breslow\",\n            cluster = id,\n            data = bladder)\nsummary(WLW)\n\nCall:\ncoxph(formula = Surv(stop, event) ~ as.factor(rx) + number + \n    size + strata(enum), data = bladder, ties = \"breslow\", cluster = id)\n\n  n= 340, number of events= 112 \n\n                   coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nas.factor(rx)2 -0.57986   0.55998  0.20118   0.30344 -1.911   0.0560 . \nnumber          0.20849   1.23182  0.04691   0.06567  3.175   0.0015 **\nsize           -0.05094   0.95034  0.06967   0.09304 -0.548   0.5840   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.5600     1.7858    0.3089     1.015\nnumber            1.2318     0.8118    1.0830     1.401\nsize              0.9503     1.0523    0.7919     1.140\n\nConcordance= 0.663  (se = 0.036 )\nLikelihood ratio test= 24.71  on 3 df,   p=2e-05\nWald test            = 15.56  on 3 df,   p=0.001\nScore (logrank) test = 27.89  on 3 df,   p=4e-06,   Robust = 11.75  p=0.008\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\nImportantly, the strata of the Wei-Lin-Weissfeld model as set by strata(enum) are substantially different from the conditional strata of the Prentice-Williams-Peterson model. The enum variable is now no longer assumed to be an ordinal variable.\n\n\n\nNote: For all recurrent event models, another way of defining the subject clusters is by using cluster(id) in the formula, rather than setting cluster = id. This results in the same outcomes, as shown below.\n\nAG_v1 &lt;- coxph(Surv(start, stop, event) ~ as.factor(rx) + number + size,\n            ties = \"breslow\",\n            cluster = id,\n            data = bladder2)\n\nsummary(AG_v1)\n\nCall:\ncoxph(formula = Surv(start, stop, event) ~ as.factor(rx) + number + \n    size, data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                   coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nas.factor(rx)2 -0.45979   0.63142  0.19996   0.25801 -1.782  0.07474 . \nnumber          0.17164   1.18726  0.04733   0.06131  2.799  0.00512 **\nsize           -0.04256   0.95833  0.06903   0.07555 -0.563  0.57317   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.6314     1.5837    0.3808     1.047\nnumber            1.1873     0.8423    1.0528     1.339\nsize              0.9583     1.0435    0.8264     1.111\n\nConcordance= 0.634  (se = 0.032 )\nLikelihood ratio test= 16.77  on 3 df,   p=8e-04\nWald test            = 11.76  on 3 df,   p=0.008\nScore (logrank) test = 18.57  on 3 df,   p=3e-04,   Robust = 11.44  p=0.01\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\n\nAG_v2 &lt;- coxph(Surv(start, stop, event) ~ as.factor(rx) + number + size + cluster(id),\n            ties = \"breslow\",\n            data = bladder2)\n\nsummary(AG_v2)\n\nCall:\ncoxph(formula = Surv(start, stop, event) ~ as.factor(rx) + number + \n    size, data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                   coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nas.factor(rx)2 -0.45979   0.63142  0.19996   0.25801 -1.782  0.07474 . \nnumber          0.17164   1.18726  0.04733   0.06131  2.799  0.00512 **\nsize           -0.04256   0.95833  0.06903   0.07555 -0.563  0.57317   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nas.factor(rx)2    0.6314     1.5837    0.3808     1.047\nnumber            1.1873     0.8423    1.0528     1.339\nsize              0.9583     1.0435    0.8264     1.111\n\nConcordance= 0.634  (se = 0.032 )\nLikelihood ratio test= 16.77  on 3 df,   p=8e-04\nWald test            = 11.76  on 3 df,   p=0.008\nScore (logrank) test = 18.57  on 3 df,   p=3e-04,   Robust = 11.44  p=0.01\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\nNote: R uses ties = \"efron\" by default, while SAS uses ties = breslow by default. In this tutorial, we forced R to use ties = \"breslow\" to match SAS for all recurrent event models. For more information, be sure to check the CAMIS webpage on the comparison of Cox proportional hazards models in R and SAS.\n\n\n\n\nIn terms of interpretation, hazard ratios (\\(\\exp(\\beta_j)\\)) are often used when making inferences based on Cox proportional hazards models. Now, as you may remember from the overview presented earlier, it is important to recognize that each of the recurrent event models comes with a slightly different interpretation of the hazard ratio, as defined by the assumptions around the model.\n\n\n\n\n\n\n\n\n\n\n\nAG\nPWPtt\nPWPgt\nWLW\n\n\n\n\nHazard ratio (HR)\nrisk of any recurrence\nrisk of any recurrence\nrisk of recurrence after previous event\nrisk of event of any type, not necessarily recurrent event\n\n\n\nThis means that, for the bladder data, we can draw slightly different conclusions on the hazard ratio of the group treated with thiotepa (rx = 2) versus the placebo group (rx = 1).\n\n\n\nModel\nHR: rx2 vs rx1\n95% CI\nP-value\n\n\n\n\nAG\n0.631\n0.381 to 1.047\n0.0747\n\n\nOriginal AG\n0.631\n0.403 to 0.989\n0.0447\n\n\nPWPtt\n0.716\n0.487 to 1.053\n0.0898\n\n\nPWPgt\n0.764\n0.508 to 1.148\n0.1952\n\n\nWLW\n0.560\n0.309 to 1.015\n0.0560\n\n\n\nThese conclusions are:\n\nAndersen-Gill: the risk of having any new tumor recurrence in the treatment group is 0.631 (0.381 - 1.047) times that of the placebo group\nPrentice-Williams-Peterson: total time: the risk of having any new tumor recurrence in the treatment group is 0.716 (0.487 - 1.053) times that of the placebo group\nPrentice-Williams-Peterson: gap time: the risk of having a new tumor recurrence after a previous event in the treatment group is 0.764 (0.508 - 1.148) times that of the placebo group\nWei-Lin-Weissfeld: the risk of having any type of event in the treatment group is 0.560 (0.309 - 1.015) times that of the placebo group\n\nNote: The improved Andersen-Gill model (LWYY model or proportional means/rates model) is preferred over the original Andersen-Gill model.\n\n\n\nFor the Prentice-Williams-Peterson and Wei-Lin-Weissfeld models we can incorporate both overall (\\(\\beta\\)) and event-specific (\\(\\beta_j\\)) effects for each covariate. To arrive at pooled model parameters these models assume that \\(\\beta_1 = \\beta_2 = ... = \\beta_k = \\beta\\). Until now, we have only considered pooled model parameters, but given the underlying stratification of these two models in particular, it may be valuable to look into the event-specific estimates as well (Amorim & Cai 2015).\nTo output event-specific estimates for the treatment effect (rx), we simply specify rx:strata(enum) in the formula.\n\n\nTotal time model\n\nPWPtt_stratified &lt;- coxph(Surv(start, stop, event) ~ rx:strata(enum) + number + size,\n                          ties = \"breslow\", cluster = id, data = bladder2)\nsummary(PWPtt_stratified)\n\nCall:\ncoxph(formula = Surv(start, stop, event) ~ rx:strata(enum) + \n    number + size, data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                           coef exp(coef)  se(coef) robust se      z Pr(&gt;|z|)  \nnumber                 0.111071  1.117475  0.054397  0.050063  2.219   0.0265 *\nsize                  -0.006674  0.993349  0.073173  0.061409 -0.109   0.9135  \nrx:strata(enum)enum=1 -0.409893  0.663721  0.304293  0.286737 -1.430   0.1529  \nrx:strata(enum)enum=2 -0.416339  0.659457  0.398266  0.423632 -0.983   0.3257  \nrx:strata(enum)enum=3 -0.142970  0.866780  0.593818  0.405303 -0.353   0.7243  \nrx:strata(enum)enum=4  0.105362  1.111112  0.679095  0.469706  0.224   0.8225  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                      exp(coef) exp(-coef) lower .95 upper .95\nnumber                   1.1175     0.8949    1.0130     1.233\nsize                     0.9933     1.0067    0.8807     1.120\nrx:strata(enum)enum=1    0.6637     1.5067    0.3784     1.164\nrx:strata(enum)enum=2    0.6595     1.5164    0.2875     1.513\nrx:strata(enum)enum=3    0.8668     1.1537    0.3917     1.918\nrx:strata(enum)enum=4    1.1111     0.9000    0.4425     2.790\n\nConcordance= 0.609  (se = 0.033 )\nLikelihood ratio test= 6.73  on 6 df,   p=0.3\nWald test            = 8.22  on 6 df,   p=0.2\nScore (logrank) test = 7.02  on 6 df,   p=0.3,   Robust = 9.37  p=0.2\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\nGap time model\nPWPgt_stratified &lt;- coxph(Surv(gtime, event) ~ rx:strata(enum) + number + size,\nties = “breslow”, cluster = id, data = bladder2)\nsummary(PWPgt_stratified)\n\nPWPgt_stratified &lt;- coxph(Surv(gtime, event) ~ rx:strata(enum) + number + size,\n                          ties = \"breslow\", cluster = id, data = bladder2)\nsummary(PWPgt_stratified)\n\nCall:\ncoxph(formula = Surv(gtime, event) ~ rx:strata(enum) + number + \n    size, data = bladder2, ties = \"breslow\", cluster = id)\n\n  n= 178, number of events= 112 \n\n                          coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nnumber                 0.15193   1.16408  0.05259   0.04864  3.124  0.00179 **\nsize                   0.01319   1.01328  0.07021   0.06297  0.209  0.83406   \nrx:strata(enum)enum=1 -0.43665   0.64620  0.30521   0.28376 -1.539  0.12385   \nrx:strata(enum)enum=2 -0.30182   0.73947  0.39752   0.38907 -0.776  0.43789   \nrx:strata(enum)enum=3  0.01485   1.01497  0.47722   0.49843  0.030  0.97622   \nrx:strata(enum)enum=4  0.06019   1.06204  0.58289   0.53982  0.112  0.91122   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                      exp(coef) exp(-coef) lower .95 upper .95\nnumber                   1.1641     0.8590    1.0582     1.281\nsize                     1.0133     0.9869    0.8956     1.146\nrx:strata(enum)enum=1    0.6462     1.5475    0.3705     1.127\nrx:strata(enum)enum=2    0.7395     1.3523    0.3449     1.585\nrx:strata(enum)enum=3    1.0150     0.9853    0.3821     2.696\nrx:strata(enum)enum=4    1.0620     0.9416    0.3687     3.059\n\nConcordance= 0.603  (se = 0.032 )\nLikelihood ratio test= 9.73  on 6 df,   p=0.1\nWald test            = 14.45  on 6 df,   p=0.02\nScore (logrank) test = 10.49  on 6 df,   p=0.1,   Robust = 11.41  p=0.08\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\n\n\n\n\n\nWLW_stratified &lt;- coxph(Surv(stop, event) ~ rx:strata(enum) + number + size,\n                        ties = \"breslow\", cluster = id, data = bladder)\nsummary(WLW_stratified)\n\nCall:\ncoxph(formula = Surv(stop, event) ~ rx:strata(enum) + number + \n    size, data = bladder, ties = \"breslow\", cluster = id)\n\n  n= 340, number of events= 112 \n\n                          coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)   \nnumber                 0.20747   1.23056  0.04685   0.06573  3.156   0.0016 **\nsize                  -0.05187   0.94945  0.06966   0.09300 -0.558   0.5770   \nrx:strata(enum)enum=1 -0.47890   0.61947  0.30583   0.28313 -1.691   0.0908 . \nrx:strata(enum)enum=2 -0.64914   0.52249  0.39217   0.36826 -1.763   0.0779 . \nrx:strata(enum)enum=3 -0.71783   0.48781  0.45971   0.42148 -1.703   0.0885 . \nrx:strata(enum)enum=4 -0.56175   0.57021  0.56143   0.49592 -1.133   0.2573   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                      exp(coef) exp(-coef) lower .95 upper .95\nnumber                   1.2306     0.8126    1.0818     1.400\nsize                     0.9494     1.0532    0.7912     1.139\nrx:strata(enum)enum=1    0.6195     1.6143    0.3556     1.079\nrx:strata(enum)enum=2    0.5225     1.9139    0.2539     1.075\nrx:strata(enum)enum=3    0.4878     2.0500    0.2135     1.114\nrx:strata(enum)enum=4    0.5702     1.7537    0.2157     1.507\n\nConcordance= 0.661  (se = 0.036 )\nLikelihood ratio test= 24.95  on 6 df,   p=3e-04\nWald test            = 16.54  on 6 df,   p=0.01\nScore (logrank) test = 28.19  on 6 df,   p=9e-05,   Robust = 11.92  p=0.06\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not)."
  },
  {
    "objectID": "R/recurrent_events.html#references",
    "href": "R/recurrent_events.html#references",
    "title": "R Recurrent Events",
    "section": "",
    "text": "Amor 2023. Eat, Sleep, R, Repeat.\nAmorim & Cai 2015. Modelling recurrent events: a tutorial for analysis in epidemiology. International Journal of Epidemiology. 2015 Feb;44(1):324-33.\nAndersen & Gill 1982. Cox’s Regression Model for Counting Processes: A Large Sample Study. The Annals of Statistics. 10(4):1100–1120.\nbladder data\nLee et al. 2025. Comparison of total event analysis and first event analysis in relation to heterogeneity in cardiovascular trials. BMC Medical Research Methodology. 2025 Jun 9;25(1):159.\nLin, Wei, Yang & Ying 2000. Semiparametric regression for the mean and rate functions of recurrent events. Journal of the Royal Statistical Society: Series B. 62(4):711–730.\nLu & Shen 2018. Application of Survival Analysis in Multiple Events Using SAS. PharmaSUG 2018.\nOzga et al. 2018. A systematic comparison of recurrent event models for application to composite endpoints. BMC Medical Research Methodology. 2018 Jan 4;18(1):2.\nPrentice, Williams & Peterson 1981. On the Regression Analysis of Multivariate Failure Time Data. Biometrika. 68(2):373–379.\nsurvival package\nWei, Lin & Weissfeld 1989. Regression Analysis of Multivariate Incomplete Failure Time Data by Modeling Marginal Distributions. Journal of the American Statistical Association. 84(408):1065–1073.\n\n\n\n\n\n\nNoteSession info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package     * version date (UTC) lib source\n P BiocManager   1.30.25 2024-08-28 [?] CRAN (R 4.4.1)\n P cli           3.6.3   2024-06-21 [?] CRAN (R 4.4.0)\n P digest        0.6.37  2024-08-19 [?] CRAN (R 4.4.1)\n P dplyr       * 1.1.4   2023-11-17 [?] CRAN (R 4.4.0)\n P evaluate      1.0.0   2024-09-17 [?] CRAN (R 4.4.1)\n P fansi         1.0.6   2023-12-08 [?] CRAN (R 4.4.0)\n P fastmap       1.2.0   2024-05-15 [?] CRAN (R 4.4.0)\n P generics      0.1.3   2022-07-05 [?] CRAN (R 4.4.0)\n P glue          1.8.0   2024-09-30 [?] CRAN (R 4.4.1)\n P gt          * 0.11.1  2024-10-04 [?] CRAN (R 4.4.1)\n P htmltools     0.5.8.1 2024-04-04 [?] CRAN (R 4.4.0)\n P htmlwidgets   1.6.4   2023-12-06 [?] CRAN (R 4.4.0)\n P jsonlite      1.8.9   2024-09-20 [?] CRAN (R 4.4.1)\n   knitr         1.50    2025-03-16 [1] RSPM (R 4.4.0)\n   lattice       0.22-6  2024-03-20 [2] CRAN (R 4.4.2)\n P lifecycle     1.0.4   2023-11-07 [?] CRAN (R 4.4.0)\n P magrittr      2.0.3   2022-03-30 [?] CRAN (R 4.4.0)\n   Matrix        1.7-1   2024-10-18 [2] CRAN (R 4.4.2)\n P pillar        1.9.0   2023-03-22 [?] CRAN (R 4.4.0)\n P pkgconfig     2.0.3   2019-09-22 [?] CRAN (R 4.4.0)\n P R6            2.5.1   2021-08-19 [?] CRAN (R 4.4.0)\n   renv          1.0.10  2024-10-05 [1] CRAN (R 4.4.1)\n P rlang         1.1.6   2025-04-11 [?] RSPM\n P rmarkdown     2.28    2024-08-17 [?] CRAN (R 4.4.0)\n P rstudioapi    0.16.0  2024-03-24 [?] CRAN (R 4.4.0)\n P sass          0.4.9   2024-03-15 [?] CRAN (R 4.4.0)\n P sessioninfo   1.2.2   2021-12-06 [?] CRAN (R 4.4.0)\n P survival    * 3.7-0   2024-06-05 [?] CRAN (R 4.4.0)\n P tibble        3.2.1   2023-03-20 [?] CRAN (R 4.4.0)\n P tidyselect    1.2.1   2024-03-11 [?] CRAN (R 4.4.0)\n P utf8          1.2.4   2023-10-22 [?] CRAN (R 4.4.0)\n P vctrs         0.6.5   2023-12-01 [?] CRAN (R 4.4.0)\n P withr         3.0.1   2024-07-31 [?] CRAN (R 4.4.0)\n   xfun          0.52    2025-04-02 [1] RSPM (R 4.4.0)\n P xml2          1.3.6   2023-12-04 [?] CRAN (R 4.4.0)\n P yaml          2.3.10  2024-07-26 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/ttest_2Sample.html",
    "href": "R/ttest_2Sample.html",
    "title": "Two Sample t-test",
    "section": "",
    "text": "The Two Sample t-test is used to compare two independent samples against each other. In the Two Sample t-test, the mean of the first sample is compared against the mean of the second sample. In R, a Two Sample t-test can be performed using the Base R t.test() function from the stats package or the proc_ttest() function from the procs package.\n\n\nThe following data was used in this example.\n\n# Create sample data\nd1 &lt;- tibble::tribble(\n  ~trt_grp, ~WtGain,\n  \"placebo\",    94, \"placebo\",  12, \"placebo\",  26, \"placebo\",  89,\n  \"placebo\",    88, \"placebo\",  96, \"placebo\",  85, \"placebo\",  130,\n  \"placebo\",    75, \"placebo\",  54, \"placebo\",  112, \"placebo\", 69,\n  \"placebo\",    104, \"placebo\", 95, \"placebo\",  53, \"placebo\",  21,\n  \"treatment\",  45, \"treatment\",    62, \"treatment\",    96, \"treatment\",    128,\n  \"treatment\",  120, \"treatment\",   99, \"treatment\",    28, \"treatment\",    50,\n  \"treatment\",  109, \"treatment\",   115, \"treatment\",   39, \"treatment\",    96,\n  \"treatment\",  87, \"treatment\",    100, \"treatment\",   76, \"treatment\",    80\n)\n\n\n\n\nIf we have normalized data, we can use the classic Student’s t-test. For a Two sample test where the variances are not equal, we should use the Welch’s t-test. Both of those options are available with the Base R t.test() function.\n\n\n\n\nThe following code was used to test the comparison in Base R. By default, the R two sample t-test function assumes the variances in the data are unequal, and uses a Welch’s t-test. Therefore, to use a classic Student’s t-test with normalized data, we must specify var.equal = TRUE. Also note that we must separate the single variable into two variables to satisfy the t.test() syntax and set paired = FALSE.\n\nd1p &lt;- dplyr::filter(d1, trt_grp == 'placebo')\nd1t &lt;- dplyr::filter(d1, trt_grp == 'treatment')\n\n# Perform t-test\nstats::t.test(d1p$WtGain, d1t$WtGain, var.equal = TRUE, paired = FALSE)\n\n\n    Two Sample t-test\n\ndata:  d1p$WtGain and d1t$WtGain\nt = -0.6969, df = 30, p-value = 0.4912\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -31.19842  15.32342\nsample estimates:\nmean of x mean of y \n  75.1875   83.1250 \n\n\n\n\n\n\n\n\nThe following code was used to test the comparison in Base R using Welch’s t-test. Observe that in this case, the var.equal parameter is set to FALSE.\n\nd1p &lt;- dplyr::filter(d1, trt_grp == 'placebo')\nd1t &lt;- dplyr::filter(d1, trt_grp == 'treatment')\n\n# Perform t-test\nstats::t.test(d1p$WtGain, d1t$WtGain, var.equal = FALSE, paired = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  d1p$WtGain and d1t$WtGain\nt = -0.6969, df = 29.694, p-value = 0.4913\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -31.20849  15.33349\nsample estimates:\nmean of x mean of y \n  75.1875   83.1250 \n\n\n\n\n\n\n\n\n\n\n\nThe following code from the procs package was used to perform a two sample t-test. Note that the proc_ttest() function performs both the Student’s t-test and Welch’s (Satterthwaite) t-test in the same call. The results are displayed on separate rows. This output is similar to SAS.\n\n# Perform t-test\nprocs::proc_ttest(d1, var = WtGain, class = trt_grp)\n\n$Statistics\n     VAR      CLASS        METHOD  N    MEAN      STD    STDERR MIN MAX\n1 WtGain    placebo          &lt;NA&gt; 16 75.1875 33.81167  8.452918  12 130\n2 WtGain  treatment          &lt;NA&gt; 16 83.1250 30.53495  7.633738  28 128\n3 WtGain Diff (1-2)        Pooled NA -7.9375       NA 11.389723  NA  NA\n4 WtGain Diff (1-2) Satterthwaite NA -7.9375       NA 11.389723  NA  NA\n\n$ConfLimits\n     VAR      CLASS        METHOD    MEAN      LCLM     UCLM      STD  LCLMSTD\n1 WtGain    placebo          &lt;NA&gt; 75.1875  57.17053 93.20447 33.81167 24.97685\n2 WtGain  treatment          &lt;NA&gt; 83.1250  66.85407 99.39593 30.53495 22.55632\n3 WtGain Diff (1-2)        Pooled -7.9375 -31.19842 15.32342       NA       NA\n4 WtGain Diff (1-2) Satterthwaite -7.9375 -31.20849 15.33349       NA       NA\n   UCLMSTD\n1 52.33003\n2 47.25868\n3       NA\n4       NA\n\n$TTests\n     VAR        METHOD VARIANCES       DF          T     PROBT\n1 WtGain        Pooled     Equal 30.00000 -0.6969002 0.4912306\n2 WtGain Satterthwaite   Unequal 29.69359 -0.6969002 0.4912856\n\n$Equality\n     VAR   METHOD NDF DDF     FVAL     PROBF\n1 WtGain Folded F  15  15 1.226136 0.6980614\n\n\nViewer Output:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package    * version date (UTC) lib source\n P cli          3.6.3   2024-06-21 [?] CRAN (R 4.4.0)\n P common     * 1.1.3   2024-04-05 [?] CRAN (R 4.4.0)\n P crayon       1.5.3   2024-06-20 [?] CRAN (R 4.4.0)\n P dplyr      * 1.1.4   2023-11-17 [?] CRAN (R 4.4.0)\n P fansi        1.0.6   2023-12-08 [?] CRAN (R 4.4.0)\n P fmtr         1.6.5   2024-06-13 [?] CRAN (R 4.4.0)\n P generics     0.1.3   2022-07-05 [?] CRAN (R 4.4.0)\n P glue         1.8.0   2024-09-30 [?] CRAN (R 4.4.1)\n P jpeg         0.1-10  2022-11-29 [?] CRAN (R 4.4.0)\n P lifecycle    1.0.4   2023-11-07 [?] CRAN (R 4.4.0)\n P magrittr     2.0.3   2022-03-30 [?] CRAN (R 4.4.0)\n P mvtnorm      1.3-1   2024-09-03 [?] CRAN (R 4.4.1)\n P pillar       1.9.0   2023-03-22 [?] CRAN (R 4.4.0)\n P pkgconfig    2.0.3   2019-09-22 [?] CRAN (R 4.4.0)\n P procs      * 1.0.6   2024-03-06 [?] CRAN (R 4.4.0)\n P R6           2.5.1   2021-08-19 [?] CRAN (R 4.4.0)\n P Rcpp         1.0.13  2024-07-17 [?] CRAN (R 4.4.0)\n P reporter     1.4.4   2024-03-19 [?] CRAN (R 4.4.0)\n P rlang        1.1.6   2025-04-11 [?] RSPM\n P sasLM        0.10.5  2024-10-02 [?] CRAN (R 4.4.1)\n P stringi      1.8.4   2024-05-06 [?] CRAN (R 4.4.0)\n P tibble     * 3.2.1   2023-03-20 [?] CRAN (R 4.4.0)\n P tidyselect   1.2.1   2024-03-11 [?] CRAN (R 4.4.0)\n P utf8         1.2.4   2023-10-22 [?] CRAN (R 4.4.0)\n P vctrs        0.6.5   2023-12-01 [?] CRAN (R 4.4.0)\n P withr        3.0.1   2024-07-31 [?] CRAN (R 4.4.0)\n P zip          2.3.1   2024-01-27 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/ttest_2Sample.html#base-r",
    "href": "R/ttest_2Sample.html#base-r",
    "title": "Two Sample t-test",
    "section": "",
    "text": "If we have normalized data, we can use the classic Student’s t-test. For a Two sample test where the variances are not equal, we should use the Welch’s t-test. Both of those options are available with the Base R t.test() function.\n\n\n\n\nThe following code was used to test the comparison in Base R. By default, the R two sample t-test function assumes the variances in the data are unequal, and uses a Welch’s t-test. Therefore, to use a classic Student’s t-test with normalized data, we must specify var.equal = TRUE. Also note that we must separate the single variable into two variables to satisfy the t.test() syntax and set paired = FALSE.\n\nd1p &lt;- dplyr::filter(d1, trt_grp == 'placebo')\nd1t &lt;- dplyr::filter(d1, trt_grp == 'treatment')\n\n# Perform t-test\nstats::t.test(d1p$WtGain, d1t$WtGain, var.equal = TRUE, paired = FALSE)\n\n\n    Two Sample t-test\n\ndata:  d1p$WtGain and d1t$WtGain\nt = -0.6969, df = 30, p-value = 0.4912\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -31.19842  15.32342\nsample estimates:\nmean of x mean of y \n  75.1875   83.1250 \n\n\n\n\n\n\n\n\nThe following code was used to test the comparison in Base R using Welch’s t-test. Observe that in this case, the var.equal parameter is set to FALSE.\n\nd1p &lt;- dplyr::filter(d1, trt_grp == 'placebo')\nd1t &lt;- dplyr::filter(d1, trt_grp == 'treatment')\n\n# Perform t-test\nstats::t.test(d1p$WtGain, d1t$WtGain, var.equal = FALSE, paired = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  d1p$WtGain and d1t$WtGain\nt = -0.6969, df = 29.694, p-value = 0.4913\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -31.20849  15.33349\nsample estimates:\nmean of x mean of y \n  75.1875   83.1250"
  },
  {
    "objectID": "R/ttest_2Sample.html#procs-package",
    "href": "R/ttest_2Sample.html#procs-package",
    "title": "Two Sample t-test",
    "section": "",
    "text": "The following code from the procs package was used to perform a two sample t-test. Note that the proc_ttest() function performs both the Student’s t-test and Welch’s (Satterthwaite) t-test in the same call. The results are displayed on separate rows. This output is similar to SAS.\n\n# Perform t-test\nprocs::proc_ttest(d1, var = WtGain, class = trt_grp)\n\n$Statistics\n     VAR      CLASS        METHOD  N    MEAN      STD    STDERR MIN MAX\n1 WtGain    placebo          &lt;NA&gt; 16 75.1875 33.81167  8.452918  12 130\n2 WtGain  treatment          &lt;NA&gt; 16 83.1250 30.53495  7.633738  28 128\n3 WtGain Diff (1-2)        Pooled NA -7.9375       NA 11.389723  NA  NA\n4 WtGain Diff (1-2) Satterthwaite NA -7.9375       NA 11.389723  NA  NA\n\n$ConfLimits\n     VAR      CLASS        METHOD    MEAN      LCLM     UCLM      STD  LCLMSTD\n1 WtGain    placebo          &lt;NA&gt; 75.1875  57.17053 93.20447 33.81167 24.97685\n2 WtGain  treatment          &lt;NA&gt; 83.1250  66.85407 99.39593 30.53495 22.55632\n3 WtGain Diff (1-2)        Pooled -7.9375 -31.19842 15.32342       NA       NA\n4 WtGain Diff (1-2) Satterthwaite -7.9375 -31.20849 15.33349       NA       NA\n   UCLMSTD\n1 52.33003\n2 47.25868\n3       NA\n4       NA\n\n$TTests\n     VAR        METHOD VARIANCES       DF          T     PROBT\n1 WtGain        Pooled     Equal 30.00000 -0.6969002 0.4912306\n2 WtGain Satterthwaite   Unequal 29.69359 -0.6969002 0.4912856\n\n$Equality\n     VAR   METHOD NDF DDF     FVAL     PROBF\n1 WtGain Folded F  15  15 1.226136 0.6980614\n\n\nViewer Output:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package    * version date (UTC) lib source\n P cli          3.6.3   2024-06-21 [?] CRAN (R 4.4.0)\n P common     * 1.1.3   2024-04-05 [?] CRAN (R 4.4.0)\n P crayon       1.5.3   2024-06-20 [?] CRAN (R 4.4.0)\n P dplyr      * 1.1.4   2023-11-17 [?] CRAN (R 4.4.0)\n P fansi        1.0.6   2023-12-08 [?] CRAN (R 4.4.0)\n P fmtr         1.6.5   2024-06-13 [?] CRAN (R 4.4.0)\n P generics     0.1.3   2022-07-05 [?] CRAN (R 4.4.0)\n P glue         1.8.0   2024-09-30 [?] CRAN (R 4.4.1)\n P jpeg         0.1-10  2022-11-29 [?] CRAN (R 4.4.0)\n P lifecycle    1.0.4   2023-11-07 [?] CRAN (R 4.4.0)\n P magrittr     2.0.3   2022-03-30 [?] CRAN (R 4.4.0)\n P mvtnorm      1.3-1   2024-09-03 [?] CRAN (R 4.4.1)\n P pillar       1.9.0   2023-03-22 [?] CRAN (R 4.4.0)\n P pkgconfig    2.0.3   2019-09-22 [?] CRAN (R 4.4.0)\n P procs      * 1.0.6   2024-03-06 [?] CRAN (R 4.4.0)\n P R6           2.5.1   2021-08-19 [?] CRAN (R 4.4.0)\n P Rcpp         1.0.13  2024-07-17 [?] CRAN (R 4.4.0)\n P reporter     1.4.4   2024-03-19 [?] CRAN (R 4.4.0)\n P rlang        1.1.6   2025-04-11 [?] RSPM\n P sasLM        0.10.5  2024-10-02 [?] CRAN (R 4.4.1)\n P stringi      1.8.4   2024-05-06 [?] CRAN (R 4.4.0)\n P tibble     * 3.2.1   2023-03-20 [?] CRAN (R 4.4.0)\n P tidyselect   1.2.1   2024-03-11 [?] CRAN (R 4.4.0)\n P utf8         1.2.4   2023-10-22 [?] CRAN (R 4.4.0)\n P vctrs        0.6.5   2023-12-01 [?] CRAN (R 4.4.0)\n P withr        3.0.1   2024-07-31 [?] CRAN (R 4.4.0)\n P zip          2.3.1   2024-01-27 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/sample_size_average_bioequivalence.html",
    "href": "R/sample_size_average_bioequivalence.html",
    "title": "Sample Size Calculation for Average Bioequivalence",
    "section": "",
    "text": "The most unambiguous requirements are mentioned in FDA Guidance for Industry. Statistical Approaches to Establishing Bioequivalence:\n\nSample sizes for average BE should be obtained using published formulas. Sample sizes for population and individual BE should be based on simulated data. The simulations should be conducted using a default situation allowing the two formulations to vary as much as 5% in average BA with equal variances and certain magnitude of subject-by-formulation interaction. The study should have 80 or 90% power to conclude BE between these two formulations. Sample size also depends on the magnitude of variability and the design of the study. Variance estimates to determine the number of subjects for a specific drug can be obtained from the biomedical literature and/or pilot studies.\n\nAppropriate method is described in Diletti D, Hauschke D, Steinijans VW. Sample Size Determination for Bioequivalence Assessment by Means of Confidence Intervals. Int J Clin Pharmacol Ther Toxicol. 1991;29(1):1–8 and implemented in R package PowerTOST with one clarification: it is simulation-based (iterative) procedure rather than simple calculation by formula.\n\nlibrary(PowerTOST)\nlibrary(knitr)\nlibrary(data.table)\nlibrary(purrr)\n\n\nAttaching package: 'purrr'\n\n\nThe following object is masked from 'package:data.table':\n\n    transpose"
  },
  {
    "objectID": "R/sample_size_average_bioequivalence.html#regulatory-requirements",
    "href": "R/sample_size_average_bioequivalence.html#regulatory-requirements",
    "title": "Sample Size Calculation for Average Bioequivalence",
    "section": "",
    "text": "The most unambiguous requirements are mentioned in FDA Guidance for Industry. Statistical Approaches to Establishing Bioequivalence:\n\nSample sizes for average BE should be obtained using published formulas. Sample sizes for population and individual BE should be based on simulated data. The simulations should be conducted using a default situation allowing the two formulations to vary as much as 5% in average BA with equal variances and certain magnitude of subject-by-formulation interaction. The study should have 80 or 90% power to conclude BE between these two formulations. Sample size also depends on the magnitude of variability and the design of the study. Variance estimates to determine the number of subjects for a specific drug can be obtained from the biomedical literature and/or pilot studies.\n\nAppropriate method is described in Diletti D, Hauschke D, Steinijans VW. Sample Size Determination for Bioequivalence Assessment by Means of Confidence Intervals. Int J Clin Pharmacol Ther Toxicol. 1991;29(1):1–8 and implemented in R package PowerTOST with one clarification: it is simulation-based (iterative) procedure rather than simple calculation by formula.\n\nlibrary(PowerTOST)\nlibrary(knitr)\nlibrary(data.table)\nlibrary(purrr)\n\n\nAttaching package: 'purrr'\n\n\nThe following object is masked from 'package:data.table':\n\n    transpose"
  },
  {
    "objectID": "R/sample_size_average_bioequivalence.html#sample-size-for-standard-crossover-design-2x2x2-and-4-period-full-replicate-design-2x2x4",
    "href": "R/sample_size_average_bioequivalence.html#sample-size-for-standard-crossover-design-2x2x2-and-4-period-full-replicate-design-2x2x4",
    "title": "Sample Size Calculation for Average Bioequivalence",
    "section": "Sample size for standard crossover design (2x2x2) and 4 period full replicate design (2x2x4)",
    "text": "Sample size for standard crossover design (2x2x2) and 4 period full replicate design (2x2x4)\nsampleN.TOST() function can calculate sample size for different designs:\n\nkable(PowerTOST::known.designs())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nno\ndesign\ndf\ndf2\nsteps\nbk\nbknif\nbkni\nname\n\n\n\n\n0\nparallel\nn-2\nn-2\n2\n4.0\n1/1\n1.0000000\n2 parallel groups\n\n\n1\n2x2\nn-2\nn-2\n2\n2.0\n1/2\n0.5000000\n2x2 crossover\n\n\n1\n2x2x2\nn-2\nn-2\n2\n2.0\n1/2\n0.5000000\n2x2x2 crossover\n\n\n2\n3x3\n2*n-4\nn-3\n3\n2.0\n2/9\n0.2222222\n3x3 crossover\n\n\n3\n3x6x3\n2*n-4\nn-6\n6\n2.0\n1/18\n0.0555556\n3x6x3 crossover\n\n\n4\n4x4\n3*n-6\nn-4\n4\n2.0\n1/8\n0.1250000\n4x4 crossover\n\n\n5\n2x2x3\n2*n-3\nn-2\n2\n1.5\n3/8\n0.3750000\n2x2x3 replicate crossover\n\n\n6\n2x2x4\n3*n-4\nn-2\n2\n1.0\n1/4\n0.2500000\n2x2x4 replicate crossover\n\n\n7\n2x4x4\n3*n-4\nn-4\n4\n1.0\n1/16\n0.0625000\n2x4x4 replicate crossover\n\n\n9\n2x3x3\n2*n-3\nn-3\n3\n1.5\n1/6\n0.1666667\npartial replicate (2x3x3)\n\n\n10\n2x4x2\nn-2\nn-2\n4\n8.0\n1/2\n0.5000000\nBalaam’s (2x4x2)\n\n\n11\n2x2x2r\n3*n-2\nn-2\n2\n1.0\n1/4\n0.2500000\nLiu’s 2x2x2 repeated x-over\n\n\n100\npaired\nn-1\nn-1\n1\n2.0\n2/1\n2.0000000\npaired means\n\n\n\n\n\nBasic usage: we should specify targetpower (power to achieve at least, e.g. 0.8 or 0.9), theta0 (T/R ratio if logscale = TRUE which is convenient default value) and cv (coefficient of variation given as ratio if logscale = TRUE).\n\n# 2x2x2\nPowerTOST::sampleN.TOST(\n  targetpower = 0.8,\n  theta0 = 0.95,\n  CV = 0.3,\n  design = \"2x2x2\"\n)\n\n\n+++++++++++ Equivalence test - TOST +++++++++++\n            Sample size estimation\n-----------------------------------------------\nStudy design: 2x2 crossover \nlog-transformed data (multiplicative model)\n\nalpha = 0.05, target power = 0.8\nBE margins = 0.8 ... 1.25 \nTrue ratio = 0.95,  CV = 0.3\n\nSample size (total)\n n     power\n40   0.815845 \n\n\n\n# 2x2x4\nPowerTOST::sampleN.TOST(\n  targetpower = 0.9,\n  theta0 = 0.98,\n  CV = 0.24,\n  design = \"2x2x4\"\n)\n\n\n+++++++++++ Equivalence test - TOST +++++++++++\n            Sample size estimation\n-----------------------------------------------\nStudy design: 2x2x4 (4 period full replicate) \nlog-transformed data (multiplicative model)\n\nalpha = 0.05, target power = 0.9\nBE margins = 0.8 ... 1.25 \nTrue ratio = 0.98,  CV = 0.24\n\nSample size (total)\n n     power\n14   0.917492 \n\n\nNote that total (not per-sequence) sample size is given.\nalpha (one-sided significance level, default is 0.05) almost never needs to be changed, theta1 (lower bioequivalence limit) and theta2 (upper bioequivalence limit) can be changed for non-standard bioequivalence limits, e.g. for narrow therapeutic index drugs."
  },
  {
    "objectID": "R/sample_size_average_bioequivalence.html#reproduction-of-table-1-from-fda-guidance-for-industry.-statistical-approaches-to-establishing-bioequivalence",
    "href": "R/sample_size_average_bioequivalence.html#reproduction-of-table-1-from-fda-guidance-for-industry.-statistical-approaches-to-establishing-bioequivalence",
    "title": "Sample Size Calculation for Average Bioequivalence",
    "section": "Reproduction of Table 1 from FDA Guidance for Industry. Statistical Approaches to Establishing Bioequivalence",
    "text": "Reproduction of Table 1 from FDA Guidance for Industry. Statistical Approaches to Establishing Bioequivalence\nReproduction of Table 1 from FDA Guidance for Industry. Statistical Approaches to Establishing Bioequivalence is quite tricky because it consists one more parameter to consider - the subject-by-formulation interaction variance component, \\(\\sigma_D^2\\).\n\\[\\sigma_D^2=(\\sigma_{BT}-\\sigma_{BR})^2+2\\times(1-\\rho)\\times\\sigma_{BT}\\times\\sigma_{BR}\\] where \\(\\sigma_{BT}^2\\) and \\(\\sigma_{BR}^2\\) are between-subject variances for the T and R formulations, respectively and \\(\\rho\\) is correlation between subject-specific means \\(\\mu_{Tj}\\) and \\(\\mu_{Rj}\\). These parameters are rarely reported in publications and can’t be estimated from CI boundaries and sample size. In such lack of information one can assume \\(\\sigma_{BT}=\\sigma_{BR}\\) as well as \\(\\rho=1\\). Under these reasonable assumptions \\(\\sigma_D^2=\\sigma_D=0\\), so sampleN.TOST() calculation should be correct.\n\ntargetpower &lt;- c(0.8, 0.9)\ntheta0 &lt;- 1 - 0.05\nCV &lt;- c(0.15, 0.23, 0.3, 0.5)\ndesign &lt;- c(\"2x2x2\", \"2x2x4\")\n\ndt &lt;- data.table::CJ(CV, targetpower, design, theta0)\n\nsample_size &lt;- purrr::pmap(dt, PowerTOST::sampleN.TOST, print = FALSE)\nkable(rbindlist(sample_size))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesign\nalpha\nCV\ntheta0\ntheta1\ntheta2\nSample size\nAchieved power\nTarget power\n\n\n\n\n2x2x2\n0.05\n0.15\n0.95\n0.8\n1.25\n12\n0.8305164\n0.8\n\n\n2x2x4\n0.05\n0.15\n0.95\n0.8\n1.25\n6\n0.8458307\n0.8\n\n\n2x2x2\n0.05\n0.15\n0.95\n0.8\n1.25\n16\n0.9260211\n0.9\n\n\n2x2x4\n0.05\n0.15\n0.95\n0.8\n1.25\n8\n0.9328881\n0.9\n\n\n2x2x2\n0.05\n0.23\n0.95\n0.8\n1.25\n24\n0.8066535\n0.8\n\n\n2x2x4\n0.05\n0.23\n0.95\n0.8\n1.25\n12\n0.8143816\n0.8\n\n\n2x2x2\n0.05\n0.23\n0.95\n0.8\n1.25\n32\n0.9044320\n0.9\n\n\n2x2x4\n0.05\n0.23\n0.95\n0.8\n1.25\n16\n0.9082552\n0.9\n\n\n2x2x2\n0.05\n0.30\n0.95\n0.8\n1.25\n40\n0.8158453\n0.8\n\n\n2x2x4\n0.05\n0.30\n0.95\n0.8\n1.25\n20\n0.8202398\n0.8\n\n\n2x2x2\n0.05\n0.30\n0.95\n0.8\n1.25\n52\n0.9019652\n0.9\n\n\n2x2x4\n0.05\n0.30\n0.95\n0.8\n1.25\n26\n0.9043064\n0.9\n\n\n2x2x2\n0.05\n0.50\n0.95\n0.8\n1.25\n98\n0.8032172\n0.8\n\n\n2x2x4\n0.05\n0.50\n0.95\n0.8\n1.25\n50\n0.8128063\n0.8\n\n\n2x2x2\n0.05\n0.50\n0.95\n0.8\n1.25\n132\n0.9012316\n0.9\n\n\n2x2x4\n0.05\n0.50\n0.95\n0.8\n1.25\n66\n0.9021398\n0.9\n\n\n\n\n\nAs we can see, calculated values are equal to the reference ones for smallest \\(\\sigma_D=0.01\\) if CV=0.15 and CV=0.23. If CV=0.30 and power 80%, sample sizes are also equal, but for other parameters combinations sample sizes are underestimated.\nConclusion: we can trust sampleN.TOST(); for CV less or equal 0.30 with power 80% and for CV less or equal 0.23 with power 90% it can be considered as validated against reference from FDA guidance."
  },
  {
    "objectID": "R/sample_size_average_bioequivalence.html#estimate-cv-from-ci-boundaries-and-sample-size",
    "href": "R/sample_size_average_bioequivalence.html#estimate-cv-from-ci-boundaries-and-sample-size",
    "title": "Sample Size Calculation for Average Bioequivalence",
    "section": "Estimate CV from CI boundaries and sample size",
    "text": "Estimate CV from CI boundaries and sample size\nCV can be calculated from CI boundaries and sample size if only these values are available:\n\nPowerTOST::CVfromCI(lower = 0.95, upper = 1.11, n = 38)\n\n[1] 0.2029806\n\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.4.2 (2024-10-31)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.6.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n[1] purrr_1.1.0       data.table_1.16.0 knitr_1.50        PowerTOST_1.5-6  \n\nloaded via a namespace (and not attached):\n [1] cubature_2.1.1      digest_0.6.37       fastmap_1.2.0      \n [4] xfun_0.52           magrittr_2.0.3      htmltools_0.5.8.1  \n [7] rmarkdown_2.28      lifecycle_1.0.4     mvtnorm_1.3-1      \n[10] cli_3.6.3           vctrs_0.6.5         renv_1.0.10        \n[13] compiler_4.4.2      rstudioapi_0.16.0   tools_4.4.2        \n[16] evaluate_1.0.0      Rcpp_1.0.13         yaml_2.3.10        \n[19] BiocManager_1.30.25 rlang_1.1.6         jsonlite_1.8.9     \n[22] htmlwidgets_1.6.4"
  },
  {
    "objectID": "R/ttest_Paired.html",
    "href": "R/ttest_Paired.html",
    "title": "Paired t-test",
    "section": "",
    "text": "The Paired t-test is used when two samples are naturally correlated. In the Paired t-test, the difference of the means between the two samples is compared to a given number that represents the null hypothesis. For a Paired t-test, the number of observations in each sample must be equal.\nIn R, a Paired t-test can be performed using the Base R t.test() from the stats package or the proc_ttest() function from the procs package.\n\n\nBy default, the R paired t-test functions assume normality in the data and use a classic Student’s t-test.\n\n\nThe following data was used in this example.\n\n# Create sample data\npressure &lt;- tibble::tribble(\n  ~SBPbefore, ~SBPafter,\n  120, 128,   \n  124, 131,   \n  130, 131,   \n  118, 127,\n  140, 132,   \n  128, 125,   \n  140, 141,   \n  135, 137,\n  126, 118,   \n  130, 132,   \n  126, 129,   \n  127, 135\n)\n\n\n\n\n\n\nThe following code was used to test the comparison in Base R.\n\n# Perform t-test\nstats::t.test(pressure$SBPbefore, pressure$SBPafter, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  pressure$SBPbefore and pressure$SBPafter\nt = -1.0896, df = 11, p-value = 0.2992\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -5.536492  1.869825\nsample estimates:\nmean difference \n      -1.833333 \n\n\n\n\n\n\n\n\nThe following code from the procs package was used to perform a paired t-test.\n\nlibrary(procs)\n\n# Perform t-test\nprocs::proc_ttest(pressure, paired = \"SBPbefore*SBPafter\")\n\n$Statistics\n       VAR1     VAR2               DIFF  N      MEAN      STD   STDERR MIN MAX\n1 SBPbefore SBPafter SBPbefore-SBPafter 12 -1.833333 5.828353 1.682501  -9   8\n\n$ConfLimits\n       VAR1     VAR2               DIFF      MEAN      LCLM     UCLM      STD\n1 SBPbefore SBPafter SBPbefore-SBPafter -1.833333 -5.536492 1.869825 5.828353\n   LCLMSTD  UCLMSTD\n1 4.128777 9.895832\n\n$TTests\n       VAR1     VAR2               DIFF DF         T     PROBT\n1 SBPbefore SBPafter SBPbefore-SBPafter 11 -1.089648 0.2991635\n\n\nViewer Output:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Base R t.test() function does not have an option for lognormal data. Likewise, the procs proc_ttest() function also does not have an option for lognormal data.\nOne possibility may be the tTestLnormAltPower() function from the EnvStats package. This package has not been evaluated yet.\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package * version date (UTC) lib source\n P procs   * 1.0.6   2024-03-06 [?] CRAN (R 4.4.0)\n P tibble    3.2.1   2023-03-20 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/ttest_Paired.html#normal",
    "href": "R/ttest_Paired.html#normal",
    "title": "Paired t-test",
    "section": "",
    "text": "By default, the R paired t-test functions assume normality in the data and use a classic Student’s t-test.\n\n\nThe following data was used in this example.\n\n# Create sample data\npressure &lt;- tibble::tribble(\n  ~SBPbefore, ~SBPafter,\n  120, 128,   \n  124, 131,   \n  130, 131,   \n  118, 127,\n  140, 132,   \n  128, 125,   \n  140, 141,   \n  135, 137,\n  126, 118,   \n  130, 132,   \n  126, 129,   \n  127, 135\n)\n\n\n\n\n\n\nThe following code was used to test the comparison in Base R.\n\n# Perform t-test\nstats::t.test(pressure$SBPbefore, pressure$SBPafter, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  pressure$SBPbefore and pressure$SBPafter\nt = -1.0896, df = 11, p-value = 0.2992\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -5.536492  1.869825\nsample estimates:\nmean difference \n      -1.833333 \n\n\n\n\n\n\n\n\nThe following code from the procs package was used to perform a paired t-test.\n\nlibrary(procs)\n\n# Perform t-test\nprocs::proc_ttest(pressure, paired = \"SBPbefore*SBPafter\")\n\n$Statistics\n       VAR1     VAR2               DIFF  N      MEAN      STD   STDERR MIN MAX\n1 SBPbefore SBPafter SBPbefore-SBPafter 12 -1.833333 5.828353 1.682501  -9   8\n\n$ConfLimits\n       VAR1     VAR2               DIFF      MEAN      LCLM     UCLM      STD\n1 SBPbefore SBPafter SBPbefore-SBPafter -1.833333 -5.536492 1.869825 5.828353\n   LCLMSTD  UCLMSTD\n1 4.128777 9.895832\n\n$TTests\n       VAR1     VAR2               DIFF DF         T     PROBT\n1 SBPbefore SBPafter SBPbefore-SBPafter 11 -1.089648 0.2991635\n\n\nViewer Output:"
  },
  {
    "objectID": "R/ttest_Paired.html#lognormal",
    "href": "R/ttest_Paired.html#lognormal",
    "title": "Paired t-test",
    "section": "",
    "text": "The Base R t.test() function does not have an option for lognormal data. Likewise, the procs proc_ttest() function also does not have an option for lognormal data.\nOne possibility may be the tTestLnormAltPower() function from the EnvStats package. This package has not been evaluated yet.\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package * version date (UTC) lib source\n P procs   * 1.0.6   2024-03-06 [?] CRAN (R 4.4.0)\n P tibble    3.2.1   2023-03-20 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/nparestimate.html",
    "href": "R/nparestimate.html",
    "title": "Non-parametric point estimation",
    "section": "",
    "text": "The Hodges-Lehman estimator (Hodges and Lehmann 1962) provides a point estimate which is associated with the Wilcoxon rank sum statistics based on location shift. This is typically used for the 2-sample comparison with small sample size. Note: The Hodges-Lehman estimates the median of the difference and not the difference of the medians. The corresponding distribution-free confidence interval is also based on the Wilcoxon rank sum statistics (Moses).\nThere are several packages covering this functionality. However, we will focus on the wilcox.test function implemented in R base. The {coin} package provides further resources to derive various types of confidence intervals for the pairwise comparison case. This package is very flexible and uses the functions of related packages.\nHodges, J. L. and Lehmann, E. L. (1962) Rank methods for combination of independent experiments in analysis of variance. Annals of Mathematical Statistics, 33, 482-4."
  },
  {
    "objectID": "R/nparestimate.html#base",
    "href": "R/nparestimate.html#base",
    "title": "Non-parametric point estimation",
    "section": "{base}",
    "text": "{base}\nThe base function provides the Hodges-Lehmann estimate and the Moses confidence interval. The function will provide warnings in case of ties in the data and will not provide the exact confidence interval.\n\nwt &lt;- stats::wilcox.test(x, y, exact = TRUE, conf.int = TRUE)\n\nWarning in wilcox.test.default(x, y, exact = TRUE, conf.int = TRUE): cannot\ncompute exact p-value with ties\n\n\nWarning in wilcox.test.default(x, y, exact = TRUE, conf.int = TRUE): cannot\ncompute exact confidence intervals with ties\n\n# Hodges-Lehmann estimator\nwt$estimate\n\ndifference in location \n             0.5600562 \n\n# Moses confidence interval\nwt$conf.int\n\n[1] -0.3699774  1.1829708\nattr(,\"conf.level\")\n[1] 0.95\n\n\nNote: You can process the long format also for wilcox.test using the formula structure:\n\nstats::wilcox.test(all$value ~ all$treat, exact = TRUE, conf.int = TRUE)\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact confidence intervals with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  all$value by all$treat\nW = 58, p-value = 0.1329\nalternative hypothesis: true location shift is not equal to 0\n95 percent confidence interval:\n -0.3699774  1.1829708\nsample estimates:\ndifference in location \n             0.5600562"
  },
  {
    "objectID": "R/nparestimate.html#coin",
    "href": "R/nparestimate.html#coin",
    "title": "Non-parametric point estimation",
    "section": "{coin}",
    "text": "{coin}\n\ncoin::wilcox_test(value ~ as.factor(treat), data = all, conf.int = TRUE)\n\n\n    Asymptotic Wilcoxon-Mann-Whitney Test\n\ndata:  value by as.factor(treat) (A, B)\nZ = 1.5469, p-value = 0.1219\nalternative hypothesis: true mu is not equal to 0\n95 percent confidence interval:\n -0.220  1.082\nsample estimates:\ndifference in location \n                  0.56"
  },
  {
    "objectID": "R/Weighted-log-rank.html",
    "href": "R/Weighted-log-rank.html",
    "title": "Testing approaches under non-proportional hazards",
    "section": "",
    "text": "In clinical studies with time-to-event outcomes, it is commonly assumed that the hazard functions of two groups are proportional. The standard log-rank test is widely used to test the equivalence of survival functions. However, several scenarios can lead to non-proportional hazards (NPH). For example, a delayed treatment effect may be observed in the treatment arm which can lead to departure from proportionality of the survival curves. Thus there are many tests available in the literature that can handle such scenarios. Most commonly used tests are as follows:\n\nWeighted log-rank test\nRestricted Mean Survival Time (RMST)\nMilestone survival\nMax-Combo test.\n\nWhile these tests may be explored in a separate document, this particular document focuses solely on the weighted log-rank test."
  },
  {
    "objectID": "R/Weighted-log-rank.html#survdiff",
    "href": "R/Weighted-log-rank.html#survdiff",
    "title": "Testing approaches under non-proportional hazards",
    "section": "survdiff()",
    "text": "survdiff()\nThis function uses \\(G(\\rho)=\\hat{S}(t)^\\rho, \\rho \\geq 0\\) , where \\(\\hat{S}(t)\\) is the Kaplan-Meier estimate of the survival function at time \\(t\\). If \\(\\rho = 0\\), then this is the standard log-rank test.\n\nlibrary(survival)\nWLRtest &lt;- survival::survdiff(\n  survival::Surv(LENFOL, FSTAT) ~ AFB,\n  rho = 3,\n  data = dat\n)\nWLRtest\n\nCall:\nsurvival::survdiff(formula = survival::Surv(LENFOL, FSTAT) ~ \n    AFB, data = dat, rho = 3)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\nAFB=0 422     86.3     94.5     0.718      7.68\nAFB=1  78     24.2     16.0     4.245      7.68\n\n Chisq= 7.7  on 1 degrees of freedom, p= 0.006 \n\n\nFor the illustration, \\(\\rho\\) is taken as 3 while calculating weights and the weighted log rank test reject the null hypothesis at 2.5% level of significance."
  },
  {
    "objectID": "R/Weighted-log-rank.html#wlrt",
    "href": "R/Weighted-log-rank.html#wlrt",
    "title": "Testing approaches under non-proportional hazards",
    "section": "wlrt()",
    "text": "wlrt()\nThis function uses \\(G(\\rho,\\gamma)=\\hat{S}(t)^\\rho (1-\\hat{S}(t))^\\gamma; \\rho,\\gamma \\geq 0,\\) , where \\(\\hat{S}(t)\\) is the Kaplan-Meier estimate of the survival function at time \\(t\\). If \\(\\rho = \\gamma = 0\\), then this is the standard log-rank test. When \\(\\rho=0, \\gamma=1\\) this test can be used to detect early difference in the survival curves, when \\(\\rho=1, \\gamma = 0\\), this test can be used to detect late differences in the survival curves and when \\(\\rho=1, \\gamma = 1\\) this test can be used to test middle differences in the survival curves. Also it is to be noted that this test gives the Z-score as the test statistic which can be squared to obtain the chi-square statistic.\n\nlibrary(nphRCT)\nWL &lt;- nphRCT::wlrt(\n  survival::Surv(LENFOL, FSTAT) ~ AFB,\n  data = dat,\n  method = \"fh\",\n  rho = 0,\n  gamma = 0\n)\nWL\n\n         u      v_u        z trt_group\n1 16.77487 25.81609 3.301521         1\n\n\nTo obtain the corresponding \\(p\\)-value we can either use 2(1-pnorm(abs(WL$z),0,1)) or we can square the test statistic WL$z by using (WL$z)^2 and obtain the corresponding \\(p\\)-values as 1 - pchisq((WL$z)^2,1) , both the \\(p\\)-values will be the same.\n\n2 * (1 - pnorm(abs(WL$z), 0, 1))\n\n[1] 0.0009616214\n\n(WL$z)^2\n\n[1] 10.90004\n\n1 - pchisq((WL$z)^2, 1)\n\n[1] 0.0009616214\n\n\nFor the illustration purpose we used \\(\\rho=0,\\  \\gamma=0\\) and in this scenario weighted log-rank test becomes standard log-rank test. Therefore, the result obtained in this illustration is consistent with the result obtained in standard log-rank test."
  },
  {
    "objectID": "R/mi_mar_regression.html",
    "href": "R/mi_mar_regression.html",
    "title": "Multiple Imputaton: Linear Regression",
    "section": "",
    "text": "Multiple imputation with regression is one step further from mean imputation (i.e. by a single value: the average of observed). In the case for continuous, normally distributed variable, linear regression can use information from other variables hence could be closer to the true missing values."
  },
  {
    "objectID": "R/mi_mar_regression.html#overview",
    "href": "R/mi_mar_regression.html#overview",
    "title": "Multiple Imputaton: Linear Regression",
    "section": "",
    "text": "Multiple imputation with regression is one step further from mean imputation (i.e. by a single value: the average of observed). In the case for continuous, normally distributed variable, linear regression can use information from other variables hence could be closer to the true missing values."
  },
  {
    "objectID": "R/mi_mar_regression.html#imputation-with-mice",
    "href": "R/mi_mar_regression.html#imputation-with-mice",
    "title": "Multiple Imputaton: Linear Regression",
    "section": "Imputation with mice",
    "text": "Imputation with mice\nmice is a powerful R package developed by Stef van Buuren, Karin Groothuis-Oudshoorn and other contributors. Regression methods (continuous, normal outcome) are implemented in mice with methods starting with norm.\n\nLinear regression without parameter uncertainty, mice.impute.norm.nob\nLinear regression through prediction, mice.impute.norm.predict\nBayesian linear regression, mice.impute.norm\nLinear regression bootstrap, mice.impute.norm.boot"
  },
  {
    "objectID": "R/mi_mar_regression.html#example",
    "href": "R/mi_mar_regression.html#example",
    "title": "Multiple Imputaton: Linear Regression",
    "section": "Example",
    "text": "Example\nHere I use the small dataset nhanes included in mice package. It has 25 rows, and three out of four variables have missings.\nThe original NHANES data is a large national level survey, some are publicly available via R package nhanes.\n\nlibrary(mice)\n\n\nAttaching package: 'mice'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following objects are masked from 'package:base':\n\n    cbind, rbind\n\n# load example dataset from mice\nhead(nhanes)\n\n  age  bmi hyp chl\n1   1   NA  NA  NA\n2   2 22.7   1 187\n3   1   NA   1 187\n4   3   NA  NA  NA\n5   1 20.4   1 113\n6   3   NA  NA 184\n\nsummary(nhanes)\n\n      age            bmi             hyp             chl       \n Min.   :1.00   Min.   :20.40   Min.   :1.000   Min.   :113.0  \n 1st Qu.:1.00   1st Qu.:22.65   1st Qu.:1.000   1st Qu.:185.0  \n Median :2.00   Median :26.75   Median :1.000   Median :187.0  \n Mean   :1.76   Mean   :26.56   Mean   :1.235   Mean   :191.4  \n 3rd Qu.:2.00   3rd Qu.:28.93   3rd Qu.:1.000   3rd Qu.:212.0  \n Max.   :3.00   Max.   :35.30   Max.   :2.000   Max.   :284.0  \n                NA's   :9       NA's   :8       NA's   :10     \n\n\nExamine missing pattern with md.pattern(data).\n\n# 27 missing in total\n# by col: 8 for hyp, 9 for bmi, 10 for chl\n# by row: n missing numbers\n\nmice::md.pattern(nhanes)\n\n\n\n\n\n\n\n\n   age hyp bmi chl   \n13   1   1   1   1  0\n3    1   1   1   0  1\n1    1   1   0   1  1\n1    1   0   0   1  2\n7    1   0   0   0  3\n     0   8   9  10 27\n\n\n\nRegression without parameter uncertainty\nWe can generate two imputed datasets by setting m=2.\nThere is a certain level of randomness, so would be a good idea to set seed.\n\nset.seed(1)\nimpr0 &lt;- mice::mice(nhanes, method = 'norm.nob', m = 2, maxit = 1)\n\n\n iter imp variable\n  1   1  bmi  hyp  chl\n  1   2  bmi  hyp  chl\n\nimpr0\n\nClass: mids\nNumber of multiple imputations:  2 \nImputation methods:\n       age        bmi        hyp        chl \n        \"\" \"norm.nob\" \"norm.nob\" \"norm.nob\" \nPredictorMatrix:\n    age bmi hyp chl\nage   0   1   1   1\nbmi   1   0   1   1\nhyp   1   1   0   1\nchl   1   1   1   0\n\nnhanes_impr0 &lt;- mice::complete(impr0) # by default, returns the first imputation\nnhanes_impr0\n\n   age      bmi       hyp      chl\n1    1 35.53430 1.2503841 256.6153\n2    2 22.70000 1.0000000 187.0000\n3    1 27.31412 1.0000000 187.0000\n4    3 25.31243 2.3880837 267.1435\n5    1 20.40000 1.0000000 113.0000\n6    3 17.94547 1.5855064 184.0000\n7    1 22.50000 1.0000000 118.0000\n8    1 30.10000 1.0000000 187.0000\n9    2 22.00000 1.0000000 238.0000\n10   2 26.99782 1.0810473 206.9927\n11   1 32.71511 0.7819353 213.7222\n12   2 27.65399 0.7904680 209.6716\n13   3 21.70000 1.0000000 206.0000\n14   2 28.70000 2.0000000 204.0000\n15   1 29.60000 1.0000000 252.1596\n16   1 27.47980 0.6071353 145.9557\n17   3 27.20000 2.0000000 284.0000\n18   2 26.30000 2.0000000 199.0000\n19   1 35.30000 1.0000000 218.0000\n20   3 25.50000 2.0000000 245.7884\n21   1 35.12809 0.5807116 232.4652\n22   1 33.20000 1.0000000 229.0000\n23   1 27.50000 1.0000000 131.0000\n24   3 24.90000 1.0000000 268.3929\n25   2 27.40000 1.0000000 186.0000\n\n\nWhen we have two imputed datasets, we can check the values for each of the variables. For example, extract bmi variable from the imputed data imp,\n\n# two imputed datasets (m=2)\nimpr0$imp$bmi\n\n          1        2\n1  35.53430 32.26078\n3  27.31412 22.55473\n4  25.31243 14.90410\n6  17.94547 22.59196\n10 26.99782 25.08534\n11 32.71511 27.71485\n12 27.65399 25.76286\n16 27.47980 30.34985\n21 35.12809 29.89142\n\n\nWe can also specify which imputed dataset to use as our complete data. Set index to 0 (action = 0) returns the original dataset with missing values.\nHere we check which of the imputed data is being used as the completed dataset. First take a note of the row IDs (based on bmi, for example). Then we generate completed dataset.\n\nif no action argument is set, then it returns the first imputation by default\naction=0 corresponds to the original data with missing values\n\n\n# check which imputed data is used for the final result, take note of row id\nid_missing &lt;- which(is.na(nhanes$bmi))\nid_missing\n\n[1]  1  3  4  6 10 11 12 16 21\n\nnhanes_impr0_action0 &lt;- mice::complete(impr0, action = 0)\nnhanes_impr0_action0[id_missing, ] # original data with missing bmi\n\n   age bmi hyp chl\n1    1  NA  NA  NA\n3    1  NA   1 187\n4    3  NA  NA  NA\n6    3  NA  NA 184\n10   2  NA  NA  NA\n11   1  NA  NA  NA\n12   2  NA  NA  NA\n16   1  NA  NA  NA\n21   1  NA  NA  NA\n\nnhanes_impr0_action1 &lt;- mice::complete(impr0, action = 1)\nnhanes_impr0_action1[id_missing, ] # using first imputation\n\n   age      bmi       hyp      chl\n1    1 35.53430 1.2503841 256.6153\n3    1 27.31412 1.0000000 187.0000\n4    3 25.31243 2.3880837 267.1435\n6    3 17.94547 1.5855064 184.0000\n10   2 26.99782 1.0810473 206.9927\n11   1 32.71511 0.7819353 213.7222\n12   2 27.65399 0.7904680 209.6716\n16   1 27.47980 0.6071353 145.9557\n21   1 35.12809 0.5807116 232.4652\n\nnhanes_impr0_action2 &lt;- mice::complete(impr0, action = 2)\nnhanes_impr0_action2[id_missing, ] # using second imputation\n\n   age      bmi       hyp      chl\n1    1 32.26078 0.4616324 228.0022\n3    1 22.55473 1.0000000 187.0000\n4    3 14.90410 1.4558818 212.7958\n6    3 22.59196 1.7664882 184.0000\n10   2 25.08534 1.2940549 201.5872\n11   1 27.71485 0.9410698 169.2427\n12   2 25.76286 1.3570093 168.5961\n16   1 30.34985 0.6878971 163.7262\n21   1 29.89142 1.0452062 212.9144\n\n\n\n\nOther imputation by linear regression\nOther various of imputaton via linear regression can be implemented simply by changing the method argument.\n\nLinear regression through prediction, mice.impute.norm.predict\nBayesian linear regression, mice.impute.norm\nLinear regression bootstrap, mice.impute.norm.boot\n\n\nimpr &lt;- mice::mice(nhanes, method = 'norm.predict', m = 1, maxit = 1)\n\n\n iter imp variable\n  1   1  bmi  hyp  chl\n\nimpr$imp$bmi\n\n          1\n1  28.33396\n3  28.33396\n4  22.75613\n6  21.17519\n10 27.19573\n11 29.12443\n12 26.26576\n16 30.28688\n21 28.33396\n\n\nBayesian linear regression\n\nimpb &lt;- mice(nhanes, method = 'norm', m = 1, maxit = 1)\n\n\n iter imp variable\n  1   1  bmi  hyp  chl\n\nimpb$imp$bmi\n\n          1\n1  33.82959\n3  28.98754\n4  20.88810\n6  19.11391\n10 27.32990\n11 29.44117\n12 22.68062\n16 32.13267\n21 22.03164\n\n# nhanes_impb &lt;- complete(impb)\n\nBootstrap\n\nimpbt &lt;- mice(nhanes, method = 'norm.boot', m = 1, maxit = 1)\n\n\n iter imp variable\n  1   1  bmi  hyp  chl\n\nimpbt$imp$bmi\n\n          1\n1  24.19248\n3  28.77464\n4  22.42321\n6  23.47542\n10 21.95529\n11 23.12703\n12 25.84230\n16 27.68216\n21 26.43770"
  },
  {
    "objectID": "R/survival_csh.html",
    "href": "R/survival_csh.html",
    "title": "Estimating and Testing Cause Specific Hazard Ratio Using R",
    "section": "",
    "text": "In this document we present how to estimate and test cause specific hazard ratio for the probability of experiencing a certain event at a given time in a competing risks model in R. We focus on the basic model where each subject experiences only one out of k possible events as depicted in the figure below.\n\nlibrary(survival)\nlibrary(tidyverse)\n\n\n\n\n\n\n\n\n\n\nAs this document aims to provide syntax for estimating and testing cause-specific hazard ratios using Cox’s PH model for competing risks, we assume that readers have working knowledge of a competing risks framework. The Reference below list a few literature for a quick refresher on this topic.\nThe syntax given here produce results match that produced by the default settings of SAS PROC PHREG (see the companion SAS document). This is usually necessary if validating results from the two software is the objective."
  },
  {
    "objectID": "R/survival_csh.html#objective",
    "href": "R/survival_csh.html#objective",
    "title": "Estimating and Testing Cause Specific Hazard Ratio Using R",
    "section": "",
    "text": "In this document we present how to estimate and test cause specific hazard ratio for the probability of experiencing a certain event at a given time in a competing risks model in R. We focus on the basic model where each subject experiences only one out of k possible events as depicted in the figure below.\n\nlibrary(survival)\nlibrary(tidyverse)\n\n\n\n\n\n\n\n\n\n\nAs this document aims to provide syntax for estimating and testing cause-specific hazard ratios using Cox’s PH model for competing risks, we assume that readers have working knowledge of a competing risks framework. The Reference below list a few literature for a quick refresher on this topic.\nThe syntax given here produce results match that produced by the default settings of SAS PROC PHREG (see the companion SAS document). This is usually necessary if validating results from the two software is the objective."
  },
  {
    "objectID": "R/survival_csh.html#r-package",
    "href": "R/survival_csh.html#r-package",
    "title": "Estimating and Testing Cause Specific Hazard Ratio Using R",
    "section": "R Package",
    "text": "R Package\nWe use the survival package in this document.\n\nData used\nThe bone marrow transplant (BTM) dataset as presented by Guo & So (2018) is used. The dataset has the following variables:\n\nGroup has three levels, indicating three disease groups.\nT is the disease-free survival time in days. A derived variable TYears = T/365.25 is used in the analysis.\nStatus has value 0 if T is censored; 1 if T is time to relapse; 2 if T is time to death.\nWaitTime is the waiting time to transplant in days.\nFor illustration, a categorical variable waitCat is created from waitTime as waitCat = TRUE if waitTime &gt; 200, and FALSE otherwise.\n\n\nbmt &lt;- haven::read_sas(file.path(\"../data/bmt.sas7bdat\")) %&gt;%\n  mutate(\n    Group = factor(\n      Group,\n      levels = c(1, 2, 3),\n      labels = c('ALL', 'AML-Low Risk', 'AML-High Risk')\n    ),\n    Status = factor(\n      Status,\n      levels = c(0, 1, 2),\n      labels = c('Censored', 'Relapse', 'Death')\n    ),\n    TYears = T / 365.25,\n    waitCat = (WaitTime &gt; 200),\n    ID = row_number()\n  )"
  },
  {
    "objectID": "R/survival_csh.html#estimating-and-testing-the-cause-specific-hazard-ratio",
    "href": "R/survival_csh.html#estimating-and-testing-the-cause-specific-hazard-ratio",
    "title": "Estimating and Testing Cause Specific Hazard Ratio Using R",
    "section": "Estimating and testing the cause specific hazard ratio",
    "text": "Estimating and testing the cause specific hazard ratio\nSyntax-wise there are two ways to generate the estimates and related outputs using survival::coxph(). They produce essentially the same results except that the global null hypotheses are different.\n\nSyntax 1: All competing events in one go\n\ncsh.1 &lt;- survival::coxph(\n  survival::Surv(TYears, Status) ~ Group + survival::strata(waitCat),\n  data = bmt,\n  id = ID,\n  ties = 'breslow', ## default is 'efron'\n  robust = FALSE ## default is TRUE\n)\nsummary(csh.1)\n\nCall:\nsurvival::coxph(formula = survival::Surv(TYears, Status) ~ Group + \n    survival::strata(waitCat), data = bmt, ties = \"breslow\", \n    robust = FALSE, id = ID)\n\n  n= 137, number of events= 83 \n\n                                             coef exp(coef) se(coef)      z\nGroupAML-Low Risk_1:2                     -0.9271    0.3957   0.4493 -2.063\nGroupAML-High Risk_1:2                     0.6227    1.8640   0.3635  1.713\nsurvival::strata(waitCat)waitCat=TRUE_1:2 -0.1310    0.8772   0.3240 -0.404\nGroupAML-Low Risk_1:3                     -0.3982    0.6715   0.3936 -1.012\nGroupAML-High Risk_1:3                     0.1177    1.1250   0.4034  0.292\nsurvival::strata(waitCat)waitCat=TRUE_1:3 -0.2487    0.7798   0.3456 -0.720\n                                          Pr(&gt;|z|)  \nGroupAML-Low Risk_1:2                       0.0391 *\nGroupAML-High Risk_1:2                      0.0867 .\nsurvival::strata(waitCat)waitCat=TRUE_1:2   0.6860  \nGroupAML-Low Risk_1:3                       0.3117  \nGroupAML-High Risk_1:3                      0.7704  \nsurvival::strata(waitCat)waitCat=TRUE_1:3   0.4717  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                                          exp(coef) exp(-coef) lower .95\nGroupAML-Low Risk_1:2                        0.3957     2.5272    0.1640\nGroupAML-High Risk_1:2                       1.8640     0.5365    0.9142\nsurvival::strata(waitCat)waitCat=TRUE_1:2    0.8772     1.1400    0.4649\nGroupAML-Low Risk_1:3                        0.6715     1.4891    0.3105\nGroupAML-High Risk_1:3                       1.1250     0.8889    0.5103\nsurvival::strata(waitCat)waitCat=TRUE_1:3    0.7798     1.2824    0.3961\n                                          upper .95\nGroupAML-Low Risk_1:2                        0.9546\nGroupAML-High Risk_1:2                       3.8005\nsurvival::strata(waitCat)waitCat=TRUE_1:2    1.6553\nGroupAML-Low Risk_1:3                        1.4525\nGroupAML-High Risk_1:3                       2.4801\nsurvival::strata(waitCat)waitCat=TRUE_1:3    1.5351\n\nConcordance= 0.631  (se = 0.031 )\nLikelihood ratio test= 18.08  on 6 df,   p=0.006\nWald test            = 16.52  on 6 df,   p=0.01\nScore (logrank) test = 18.71  on 6 df,   p=0.005\n\n\nIn the output, rows with suffix 1:2 are for Status = 2, or Relapse; and 1:3 are for Status = 3, or Death. As usual, censoring must be the lowest level in Status, which in this example is coded 0.\nSince both events (Relapse and Death) are model together, the global tests have 4 degrees of freedom, with the null hypothesis that there is no difference among different levels of Group in either Relapse or Death.\n\n\nSyntax 2: One event at a time\n\ncsh.2 &lt;- survival::coxph(\n  survival::Surv(TYears, Status == 'Relapse') ~\n    Group + survival::strata(waitCat),\n  data = bmt,\n  id = ID,\n  ties = 'breslow', ## default is 'efron'\n  robust = FALSE ## default is TRUE\n)\nsummary(csh.2)\n\nCall:\nsurvival::coxph(formula = survival::Surv(TYears, Status == \"Relapse\") ~ \n    Group + survival::strata(waitCat), data = bmt, ties = \"breslow\", \n    robust = FALSE, id = ID)\n\n  n= 137, number of events= 42 \n\n                                         coef exp(coef) se(coef)      z\nGroupAML-Low Risk                     -0.9271    0.3957   0.4493 -2.063\nGroupAML-High Risk                     0.6227    1.8640   0.3635  1.713\nsurvival::strata(waitCat)waitCat=TRUE -0.1310    0.8772   0.3240 -0.404\n                                      Pr(&gt;|z|)  \nGroupAML-Low Risk                       0.0391 *\nGroupAML-High Risk                      0.0867 .\nsurvival::strata(waitCat)waitCat=TRUE   0.6860  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                                      exp(coef) exp(-coef) lower .95 upper .95\nGroupAML-Low Risk                        0.3957     2.5272    0.1640    0.9546\nGroupAML-High Risk                       1.8640     0.5365    0.9142    3.8005\nsurvival::strata(waitCat)waitCat=TRUE    0.8772     1.1400    0.4649    1.6553\n\nConcordance= 0.69  (se = 0.037 )\nLikelihood ratio test= 16.04  on 3 df,   p=0.001\nWald test            = 14.49  on 3 df,   p=0.002\nScore (logrank) test = 16.66  on 3 df,   p=8e-04\n\n\nThe results are identical to those labeled with 1:2 in the earlier outputs under Syntax 1 above. However, since only Relapse is modeled, the global tests have only 2 degrees of freedom with the null hypothesis that there is no difference among different levels of Group for Relapse."
  },
  {
    "objectID": "R/survival_csh.html#summary",
    "href": "R/survival_csh.html#summary",
    "title": "Estimating and Testing Cause Specific Hazard Ratio Using R",
    "section": "Summary",
    "text": "Summary\n\nIn survival::coxph() the default method for handling ties is ties = 'efron'. To match results with SAS, this needs to be changed to ties =breslow`.\nFor multi-state models such as a competing risk analysis, survival::coxph() by default estimate the standard errors of parameter estimates with a robust sandwich estimator. To match default results with SAS, this needs to be set to robust = FALSE.\nDue to differences in internal numerical estimation methods of R and SAS, results only match up to the 4th decimal places. However, overall consistency can be established between the two for estimating and testing cause-specific hazard ratio using Cox’s PH model.\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package    * version date (UTC) lib source\n   cmprsk       2.2-12  2024-05-19 [1] CRAN (R 4.4.0)\n P survival   * 3.7-0   2024-06-05 [?] CRAN (R 4.4.0)\n   tidycmprsk   1.1.0   2024-08-17 [1] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/survival_csh.html#reference",
    "href": "R/survival_csh.html#reference",
    "title": "Estimating and Testing Cause Specific Hazard Ratio Using R",
    "section": "Reference",
    "text": "Reference\nGuo C and So Y. (2018). “Cause-specific analysis of competing risks using the PHREG procedure.” In Proceedings of the SAS Global Forum 2018 Conference. Cary, NC: SAS Institute Inc. https://support.sas.com/resources/papers/proceedings18/2159-2018.pdf.\nPintilie M. (2006). Competing Risks: A Practical Perspective. Wiley. http://dx.doi.org/10.1002/9780470870709\nTherneau T, Crowson C, and Atkinson E. (2024). “Multi-state models and competing risks.” https://cran.r-project.org/web/packages/survival/vignettes/compete.pdf"
  },
  {
    "objectID": "R/jonckheere.html",
    "href": "R/jonckheere.html",
    "title": "Jonckheere-Terpstra test",
    "section": "",
    "text": "As far as I know, the following packages are available:\n\nDescTools\nclinfun\nPMCMRplus\nfastJT\n\nDue to availability in the company, DescTools version 0.99.55 is used to compare the results with SAS. Of these packages DescTools is the most common."
  },
  {
    "objectID": "R/jonckheere.html#available-r-packages",
    "href": "R/jonckheere.html#available-r-packages",
    "title": "Jonckheere-Terpstra test",
    "section": "",
    "text": "As far as I know, the following packages are available:\n\nDescTools\nclinfun\nPMCMRplus\nfastJT\n\nDue to availability in the company, DescTools version 0.99.55 is used to compare the results with SAS. Of these packages DescTools is the most common."
  },
  {
    "objectID": "R/jonckheere.html#data-used",
    "href": "R/jonckheere.html#data-used",
    "title": "Jonckheere-Terpstra test",
    "section": "Data used",
    "text": "Data used\nThe data for testing is a sample dataset on a dose-response study.\n\nThe Group indicates a dose of a drug. The scores for Group represent ordering of dose arms. Then the boxplot implies a declining dose-response relationship."
  },
  {
    "objectID": "R/jonckheere.html#example-code",
    "href": "R/jonckheere.html#example-code",
    "title": "Jonckheere-Terpstra test",
    "section": "Example Code",
    "text": "Example Code\n\nlibrary(DescTools)\nlibrary(ggplot2)\nlibrary(readr)\n\n# Constants\nk_n_samp &lt;- 10000\n\nset.seed(4989)\n\ninds &lt;- read_csv(\"../data/jonck.csv\", col_select = c(DOSE, value))\n\nNew names:\nRows: 40 Columns: 2\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" dbl\n(2): DOSE, value\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\njt_norm &lt;- DescTools::JonckheereTerpstraTest(\n  value ~ DOSE,\n  alternative = \"decreasing\",\n  data = inds\n)\n\nWarning in JonckheereTerpstraTest.default(alternative = alternative, c(153, : Sample size &gt; 100 or data with ties \n p-value based on normal approximation. Specify nperm for permutation p-value\n\njt_norm\n\n\n    Jonckheere-Terpstra test\n\ndata:  value by DOSE\nJT = 184.5, p-value = 0.002655\nalternative hypothesis: decreasing\n\njt_resamp &lt;- DescTools::JonckheereTerpstraTest(\n  value ~ DOSE,\n  alternative = \"decreasing\",\n  data = inds,\n  nperm = k_n_samp\n)\n\nWarning in JonckheereTerpstraTest.default(alternative = alternative, nperm = nperm, : Sample size &gt; 100 or data with ties \n p-value based on normal approximation. Specify nperm for permutation p-value\n\njt_resamp\n\n\n    Jonckheere-Terpstra test\n\ndata:  value by DOSE\nJT = 184.5, p-value = 0.0023\nalternative hypothesis: decreasing"
  },
  {
    "objectID": "R/jonckheere.html#reference",
    "href": "R/jonckheere.html#reference",
    "title": "Jonckheere-Terpstra test",
    "section": "Reference",
    "text": "Reference\nSignorell A (2024). DescTools: Tools for Descriptive Statistics. R package version 0.99.55, https://github.com/AndriSignorell/DescTools/, https://andrisignorell.github.io/DescTools/."
  },
  {
    "objectID": "R/tipping_point.html",
    "href": "R/tipping_point.html",
    "title": "R Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "# General libraries\nlibrary(mice)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(gt)\nlibrary(labelled)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# Methodology specific libraries\nlibrary(emmeans)\nlibrary(mmrm)\nlibrary(rstan)\nlibrary(rbmi)\n\n# Paralleisation libraries\nlibrary(future)\nlibrary(furrr)\nlibrary(parallelly)\n\n\n\n\nset.seed(12345)\n\n\n\n\n\n\n\nThe concept of delta adjustment and tipping point analysis builds on the framework of reference-based multiple imputation (rbmi) as seen on its respective CAMIS webpage. The use of the rbmi package in R (Gower-Page et al. 2022) for the following standard and reference-based multiple imputation approaches are introduced there:\n\nMissing At Random (MAR)\nJump to Reference (JR)\nCopy Reference (CR)\nCopy Increment from Reference (CIR)\n\nPlease make sure to familiarize yourself with these functionalities of the rbmi package before checking this tutorial. The outline of this page generally follows the rbmi advanced functionality vignette.\n\n\n\nThe same publicly available dataset from an antidepressant clinical trial that was used to illustrate rbmi is again used for this tutorial. This dataset is also used in the rbmi quickstart vignette.\nThe relevant endpoint for the antidepressant trial was assessed using the Hamilton 17-item depression rating scale (HAMD17), which was measured at baseline and subsequently at weeks 1, 2, 3, 4 and 6 (visits 4-7). Study drug discontinuation occurred in 24% (20/84) of subjects in the active drug group, compared to 26% (23/88) of subjects in the placebo group. Importantly, all data after study drug discontinuation are missing and there is a single intermittent missing observation.\n\ndata(\"antidepressant_data\")\n\ndat &lt;- antidepressant_data |&gt;\n  dplyr::select(\n    PATIENT,\n    GENDER,\n    THERAPY,\n    RELDAYS,\n    VISIT,\n    BASVAL,\n    HAMDTL17,\n    CHANGE\n  ) |&gt;\n  dplyr::mutate(THERAPY = factor(THERAPY, levels = c(\"PLACEBO\", \"DRUG\"))) |&gt;\n  labelled::remove_labels()\n\ngt(head(dat, n = 10))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\n\n\n\n\n1503\nF\nDRUG\n7\n4\n32\n21\n-11\n\n\n1503\nF\nDRUG\n14\n5\n32\n20\n-12\n\n\n1503\nF\nDRUG\n28\n6\n32\n19\n-13\n\n\n1503\nF\nDRUG\n42\n7\n32\n17\n-15\n\n\n1507\nF\nPLACEBO\n7\n4\n14\n11\n-3\n\n\n1507\nF\nPLACEBO\n15\n5\n14\n14\n0\n\n\n1507\nF\nPLACEBO\n29\n6\n14\n9\n-5\n\n\n1507\nF\nPLACEBO\n42\n7\n14\n5\n-9\n\n\n1509\nF\nDRUG\n7\n4\n21\n20\n-1\n\n\n1509\nF\nDRUG\n14\n5\n21\n18\n-3\n\n\n\n\n\n\n\nThe number of patients per visit and treatment group are:\n\ndat |&gt;\n  dplyr::summarise(N = n(), .by = c(VISIT, THERAPY))\n\n# A tibble: 8 × 3\n  VISIT THERAPY     N\n  &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n1 4     DRUG       84\n2 5     DRUG       77\n3 6     DRUG       73\n4 7     DRUG       64\n5 4     PLACEBO    88\n6 5     PLACEBO    81\n7 6     PLACEBO    76\n8 7     PLACEBO    65\n\n\nThe mean change from baseline of the HAMD17 endpoint per visit and treatment group using only the complete cases are:\n\ndat |&gt;\n  dplyr::summarise(N = n(), MEAN = mean(CHANGE), .by = c(VISIT, THERAPY))\n\n# A tibble: 8 × 4\n  VISIT THERAPY     N  MEAN\n  &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;dbl&gt;\n1 4     DRUG       84 -1.82\n2 5     DRUG       77 -4.71\n3 6     DRUG       73 -6.79\n4 7     DRUG       64 -8.34\n5 4     PLACEBO    88 -1.51\n6 5     PLACEBO    81 -2.70\n7 6     PLACEBO    76 -4.07\n8 7     PLACEBO    65 -5.14\n\n\nThe missingness pattern is:\n\ndat_wide = dat |&gt;\n  dplyr::select(PATIENT, VISIT, CHANGE) |&gt;\n  pivot_wider(\n    id_cols = PATIENT,\n    names_from = VISIT,\n    names_prefix = \"VISIT_\",\n    values_from = CHANGE\n  )\n\ndat_wide |&gt;\n  dplyr::select(starts_with(\"VISIT_\")) |&gt;\n  mice::md.pattern(plot = TRUE, rotate.names = TRUE)\n\n\n\n\n\n\n\n\n    VISIT_4 VISIT_5 VISIT_6 VISIT_7   \n128       1       1       1       1  0\n20        1       1       1       0  1\n10        1       1       0       0  2\n1         1       0       1       1  1\n13        1       0       0       0  3\n          0      14      23      43 80\n\n\nThere is a single patient with an intermittent missing observation at visit 5, which is patient 3618. Special considerations need to be taken when applying delta adjustments to intermittent missing observations like this one (more on this later).\n\ndat_expand &lt;- rbmi::expand_locf(\n  dat,\n  PATIENT = levels(dat$PATIENT),\n  VISIT = levels(dat$VISIT),\n  vars = c(\"BASVAL\", \"THERAPY\", \"GENDER\"),\n  group = c(\"PATIENT\"),\n  order = c(\"PATIENT\", \"VISIT\")\n)\n\ndat_expand |&gt;\n  dplyr::filter(PATIENT == \"3618\") |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\nNA\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2\n\n\n\n\n\n\n\n\n\n\nThis tutorial will focus on tipping point analysis and delta adjustment. We assume the user used the rbmi package to create an imputation object called imputeObj (see CAMIS webpage).\n\n\n\n\n\n\nWhen analyses for endpoints are performed under MAR or MNAR assumptions for missing data, it is important to perform sensitivity analyses to assess the impact of deviations from these assumptions. Tipping point analysis (or delta adjustment method) is an example of a sensitivity analysis that can be used to assess the robustness of a clinical trial when its result is based on imputed missing data.\nGenerally, tipping point analysis explores the influence of missingness on the overall conclusion of the treatment difference by shifting imputed missing values in the treatment group towards the reference group until the result becomes non-significant. The tipping point is the minimum shift needed to make the result non-significant. If the minimum shift needed to make the result non-significant is implausible, then greater confidence in the primary results can be inferred.\nTipping point analysis generally happens by adjusting imputing values by so-called delta values. The observed tipping point is the minimum delta needed to make the result non-significant. Mostly a range of delta values is explored and only imputed values from the active treatment group are adjusted by the delta value. However, delta adjustments in the control group are possible as well. Naturally, the range of acceptable values for delta should be agreed a priori, before taking this approach.\nFor an extensive discussion on delta adjustment methods, we refer to Cro et al. 2020.\n\n\n\n\n\n\nIn the rbmi package, the delta argument of the analyse() function allows users to adjust the imputed datasets prior to the analysis stage. This delta argument requires a data frame created by delta_template(), which includes a column called delta that specifies the delta values to be added.\nBy default, delta_template() will set delta to 0 for all observations.\n\n# delta template\ndat_delta_0 &lt;- delta_template(imputations = imputeObj)\n\n\ndat_delta_0 |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\n\n\n\n\n1513\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1513\n5\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1513\n6\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1513\n7\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1514\n4\nPLACEBO\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1514\n5\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1514\n6\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1514\n7\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n\n\n\n\n\nYou can add the delta values to the outcome variable (CHANGE) of one of the imputed datasets by using the apply_delta() function. Of course, nothing is changed here as delta = 0.\n\nimputed_dfs = rbmi::extract_imputed_dfs(imputeObj)\nMI_10 = imputed_dfs[[10]]\nMI_10$PATIENT2 = MI_10$PATIENT\nMI_10$PATIENT = dat_expand$PATIENT\n\n\n# imputed dataset\ngt(MI_10 |&gt; dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt; head(8))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n1513\nM\nDRUG\n7\n4\n19\n24\n5.000000\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n5\n19\nNA\n-1.901762\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n6\n19\nNA\n-5.903109\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n7\n19\nNA\n-1.996427\nnew_pt_5\n\n\n1514\nF\nPLACEBO\n7\n4\n21\n23\n2.000000\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n5\n21\nNA\n4.444457\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n6\n21\nNA\n1.231729\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n7\n21\nNA\n5.348181\nnew_pt_6\n\n\n\n\n\n\n# delta adjusted dataset\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_0,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n1513\nM\nDRUG\n7\n4\n19\n24\n5.000000\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n5\n19\nNA\n-1.901762\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n6\n19\nNA\n-5.903109\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n7\n19\nNA\n-1.996427\nnew_pt_5\n\n\n1514\nF\nPLACEBO\n7\n4\n21\n23\n2.000000\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n5\n21\nNA\n4.444457\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n6\n21\nNA\n1.231729\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n7\n21\nNA\n5.348181\nnew_pt_6\n\n\n\n\n\n\n\nYou may have noticed that the is_missing and is_post_ice columns of the delta data frame lend themselves perfectly to adjust the delta values, as the boolean variables TRUE and FALSE are regarded as 1 and 0 by R. If you want to set delta to 5 for all missing values, you can do so by multiplying the is_missing column by 5. In our case, this addition assumes a “worsening” of the imputed outcome variable, CHANGE, which is measured on the HAMD17 scale.\n\n# delta template\ndat_delta_5_v1 &lt;- delta_template(imputations = imputeObj) |&gt;\n  mutate(delta = is_missing * 5)\n\ndat_delta_5_v1 |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\n\n\n\n\n1513\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1513\n5\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n5\n\n\n1513\n6\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n5\n\n\n1513\n7\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n5\n\n\n1514\n4\nPLACEBO\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1514\n5\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n5\n\n\n1514\n6\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n5\n\n\n1514\n7\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n5\n\n\n\n\n\n\n\n\n# imputed dataset\ngt(MI_10 |&gt; dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt; head(8))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n1513\nM\nDRUG\n7\n4\n19\n24\n5.000000\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n5\n19\nNA\n-1.901762\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n6\n19\nNA\n-5.903109\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n7\n19\nNA\n-1.996427\nnew_pt_5\n\n\n1514\nF\nPLACEBO\n7\n4\n21\n23\n2.000000\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n5\n21\nNA\n4.444457\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n6\n21\nNA\n1.231729\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n7\n21\nNA\n5.348181\nnew_pt_6\n\n\n\n\n\n\n# delta adjusted dataset\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_5_v1,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n1513\nM\nDRUG\n7\n4\n19\n24\n5.0000000\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n5\n19\nNA\n3.0982376\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n6\n19\nNA\n-0.9031094\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n7\n19\nNA\n3.0035727\nnew_pt_5\n\n\n1514\nF\nPLACEBO\n7\n4\n21\n23\n2.0000000\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n5\n21\nNA\n9.4444566\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n6\n21\nNA\n6.2317289\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n7\n21\nNA\n10.3481805\nnew_pt_6\n\n\n\n\n\n\n\nImportantly, if you multiply the is_missing column only, you apply the delta adjustment to all imputed missing values, including intermittent missing values. This can be checked by looking at patient 3618, which has an intermittent missing value at visit 5.\n\n# delta template\ngt(dat_delta_5_v1 |&gt; dplyr::filter(PATIENT == \"3618\"))\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\n\n\n\n\n3618\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n3618\n5\nDRUG\nTRUE\nTRUE\nFALSE\nMAR\n5\n\n\n3618\n6\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n3618\n7\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n\n\n\n\n\n\n# imputed dataset\ngt(MI_10 |&gt; dplyr::filter(PATIENT == \"3618\"))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n-0.06964206\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.00000000\nnew_pt_99\n\n\n\n\n\n\n# delta adjusted dataset\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_5_v1,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT == \"3618\") |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n4.930358\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.000000\nnew_pt_99\n\n\n\n\n\n\n\nIf you consider the is_post_ice column too, you can restrict the delta adjustment to missing values that occur after study drug discontinuation due to an intercurrent event (ICE). By multiplying both the is_missing and is_post_ice columns by your chosen delta, the delta value will only be added when both columns are TRUE.\n\n# delta template\ndat_delta_5_v2 &lt;- delta_template(imputations = imputeObj) |&gt;\n  mutate(delta = is_missing * is_post_ice * 5)\n\ndat_delta_5_v2 |&gt;\n  dplyr::filter(PATIENT == \"3618\") |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\n\n\n\n\n3618\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n3618\n5\nDRUG\nTRUE\nTRUE\nFALSE\nMAR\n0\n\n\n3618\n6\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n3618\n7\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n\n\n\n\n\n\n# imputed dataset\ngt(MI_10 |&gt; dplyr::filter(PATIENT == \"3618\"))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n-0.06964206\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.00000000\nnew_pt_99\n\n\n\n\n\n\n# delta adjusted dataset\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_5_v2,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT == \"3618\") |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n-0.06964206\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.00000000\nnew_pt_99\n\n\n\n\n\n\n\nBesides choosing which missing data to apply the delta adjustment to, you may also want to apply different delta adjustments to imputed data from the different groups. As an example, let’s set delta = 0 for the control group, and delta = 5 for the intervention group. Here, we consider the is_missing column only, so that we apply the delta’s to all imputed missing data.\n\n# delta template\ndelta_control = 0\ndelta_intervention = 5\n\ndat_delta_0_5 &lt;- rbmi::delta_template(imputations = imputeObj) |&gt;\n  mutate(\n    delta_ctl = (THERAPY == \"PLACEBO\") * is_missing * delta_control,\n    delta_int = (THERAPY == \"DRUG\") * is_missing * delta_intervention,\n    delta = delta_ctl + delta_int\n  )\n\ndat_delta_0_5 |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\ndelta_ctl\ndelta_int\n\n\n\n\n1513\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n0\n0\n\n\n1513\n5\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n5\n0\n5\n\n\n1513\n6\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n5\n0\n5\n\n\n1513\n7\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n5\n0\n5\n\n\n1514\n4\nPLACEBO\nTRUE\nFALSE\nFALSE\nNA\n0\n0\n0\n\n\n1514\n5\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n0\n0\n\n\n1514\n6\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n0\n0\n\n\n1514\n7\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n0\n0\n\n\n\n\n\n\n\n\n# delta adjusted dataset\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_0_5,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n1513\nM\nDRUG\n7\n4\n19\n24\n5.0000000\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n5\n19\nNA\n3.0982376\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n6\n19\nNA\n-0.9031094\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n7\n19\nNA\n3.0035727\nnew_pt_5\n\n\n1514\nF\nPLACEBO\n7\n4\n21\n23\n2.0000000\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n5\n21\nNA\n4.4444566\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n6\n21\nNA\n1.2317289\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n7\n21\nNA\n5.3481805\nnew_pt_6\n\n\n\n\n\n\n\nThe delta_template() function has two additional arguments, delta and dlag, that can be used to define the delta adjustments. We explain these arguments in more detail in the flexible delta adjustments section below.\n\n\n\nAs mentioned, delta adjustments are implemented via the delta argument of the analyse() function. The adjustment happens right after data imputation under MAR or MNAR (using reference-based imputation approaches), but before implementing the analysis model. Sensitivity analyses can therefore be performed without having to refit the imputation model, which is computationally efficient. This approach is considered a marginal delta adjustment approach, because the delta is simply added to the mean of the conditional multivariate normal distribution (conditional on the observed values and the covariates) for the imputation model (Roger 2017).\nHere, we apply the delta adjustment of 5 to all imputed values of the outcome variable (CHANGE) in the intervention group. The estimated treatment effect at visit 7 is presented below.\n\nanaObj &lt;- rbmi::analyse(\n  imputations = imputeObj,\n  fun = ancova,\n  delta = dat_delta_0_5,\n  vars = vars_analyse\n)\n\npoolObj &lt;- rbmi::pool(anaObj)\n\npoolObj |&gt;\n  data.frame() |&gt;\n  dplyr::filter(grepl(\"7\", parameter)) |&gt;\n  gt()\n\n\n\n\n\n\n\nparameter\nest\nse\nlci\nuci\npval\n\n\n\n\ntrt_7\n-1.587755\n1.1617288\n-3.883977\n0.7084662\n1.738414e-01\n\n\nlsm_ref_7\n-4.839053\n0.8058704\n-6.431863\n-3.2462434\n1.477601e-08\n\n\nlsm_alt_7\n-6.426808\n0.8284919\n-8.064451\n-4.7891650\n1.482193e-12\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo perform a tipping point analysis under the MAR assumption, we must create a range of delta values. In this section, we only specify a range of delta’s for the intervention group.\n\ndelta_df1 &lt;- expand.grid(\n  delta_control = 0,\n  delta_intervention = seq(-3, 8, by = 1)\n) |&gt;\n  as_tibble()\n\n\n\n\nTo enable a tipping point analysis within a single function, we create perform_tipp_analysis(). This custom function requires a stratified delta for delta_control and delta_intervention, alongside cl as set in the previous step.\n\nperform_tipp_analysis &lt;- function(delta_control, delta_intervention) {\n  dat_delta &lt;- rbmi::delta_template(imputeObj) |&gt;\n    mutate(\n      delta_ctl = (THERAPY == \"PLACEBO\") * is_missing * delta_control,\n      delta_int = (THERAPY == \"DRUG\") * is_missing * delta_intervention,\n      delta = delta_ctl + delta_int\n    )\n\n  anaObj &lt;- rbmi::analyse(\n    imputations = imputeObj,\n    fun = ancova,\n    delta = dat_delta,\n    vars = vars_analyse\n  )\n\n  poolObj &lt;- as.data.frame(pool(anaObj)) |&gt;\n    dplyr::filter(grepl(\"trt_7\", parameter))\n\n  list(\n    trt_7 = poolObj[[\"est\"]],\n    pval_7 = poolObj[[\"pval\"]],\n    lci_7 = poolObj[[\"lci\"]],\n    uci_7 = poolObj[[\"uci\"]]\n  )\n}\n\nNow, let’s apply this function to the antidepressant data as follows:\nNote: here we are adding some parallelisation using {furrr} to speed things up.\n\nworkers &lt;- parallelly::availableCores(omit = 1)\nfuture::plan(multisession, workers = workers)\n\nMAR_tipp_df1 &lt;- delta_df1 |&gt; \n  furrr::future_pmap(perform_tipp_analysis) |&gt;\n  purrr::reduce(bind_rows) \n\nMAR_tipp_df1 &lt;- dplyr::bind_cols(delta_df1, MAR_tipp_df1)\n\nThe results of the tipping point analysis under MAR with p-value \\(\\geq\\) 0.05 are:\n\nMAR_tipp_df1 |&gt;\n  filter(pval_7 &gt;= 0.05) |&gt;\n  gt()\n\n\n\n\n\n\n\ndelta_control\ndelta_intervention\ntrt_7\npval_7\nlci_7\nuci_7\n\n\n\n\n0\n3\n-2.0737802\n0.07096941\n-4.327059\n0.1794988\n\n\n0\n4\n-1.8307677\n0.11357323\n-4.103772\n0.4422370\n\n\n0\n5\n-1.5877552\n0.17384142\n-3.883977\n0.7084662\n\n\n0\n6\n-1.3447427\n0.25441183\n-3.667567\n0.9780820\n\n\n0\n7\n-1.1017302\n0.35622522\n-3.454430\n1.2509695\n\n\n0\n8\n-0.8587177\n0.47798920\n-3.244441\n1.5270060\n\n\n\n\n\n\n\nThe results of the tipping point analysis under MAR with p-value \\(&lt;\\) 0.05 are:\n\nMAR_tipp_df1 |&gt;\n  filter(pval_7 &lt; 0.05) |&gt;\n  gt()\n\n\n\n\n\n\n\ndelta_control\ndelta_intervention\ntrt_7\npval_7\nlci_7\nuci_7\n\n\n\n\n0\n-3\n-3.531855\n0.001953328\n-5.744159\n-1.31955114\n\n\n0\n-2\n-3.288843\n0.003806339\n-5.498548\n-1.07913777\n\n\n0\n-1\n-3.045830\n0.007272930\n-5.256735\n-0.83492584\n\n\n0\n0\n-2.802818\n0.013540735\n-5.018714\n-0.58692152\n\n\n0\n1\n-2.559805\n0.024425284\n-4.784460\n-0.33515027\n\n\n0\n2\n-2.316793\n0.042481732\n-4.553929\n-0.07965626\n\n\n\n\n\n\n\nWe can derive an exact tipping point by linearly interpolating between the last “significant” delta and the first “non-significant” delta using the approx() function.\n\ndelta_tp &lt;- approx(\n  x = MAR_tipp_df1$pval_7,\n  y = MAR_tipp_df1$delta_intervention,\n  xout = 0.05\n)$y\n\ntrt_tp &lt;- approx(\n  x = MAR_tipp_df1$delta_intervention,\n  y = MAR_tipp_df1$trt_7,\n  xout = delta_tp\n)$y\n\nlci_tp &lt;- approx(\n  x = MAR_tipp_df1$delta_intervention,\n  y = MAR_tipp_df1$lci_7,\n  xout = delta_tp\n)$y\n\nuci_tp &lt;- approx(\n  x = MAR_tipp_df1$delta_intervention,\n  y = MAR_tipp_df1$uci_7,\n  xout = delta_tp\n)$y\n\ndata.frame(\n  delta_control = 0,\n  delta_intervention = delta_tp,\n  trt_7 = trt_tp,\n  pval_7 = 0.05,\n  lci_7 = lci_tp,\n  uci_7 = uci_tp\n) |&gt;\n  gt()\n\n\n\n\n\n\n\ndelta_control\ndelta_intervention\ntrt_7\npval_7\nlci_7\nuci_7\n\n\n\n\n0\n2.263913\n-2.252659\n0.05\n-4.494055\n-0.01126187\n\n\n\n\n\n\n\n\n\n\nA nice visualization of this tipping point analysis for the MAR approach is shown below. The dashed horizontal line indicates a p-value of 0.05 in the left plot and no treatment effect in the right plot.\n\nMAR_est &lt;- ggplot(MAR_tipp_df1, aes(delta_intervention, trt_7)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(\n    aes(delta_intervention, ymin = lci_7, ymax = uci_7),\n    alpha = 0.25\n  ) +\n  geom_hline(yintercept = 0.0, linetype = 2) +\n  geom_vline(xintercept = delta_tp, linetype = 2) +\n  scale_x_continuous(breaks = seq(-6, 10, 2)) +\n  labs(x = \"Delta (intervention)\", y = \"Treatment effect (95% CI)\")\n\nMAR_pval &lt;- ggplot(MAR_tipp_df1, aes(delta_intervention, pval_7)) +\n  geom_line() +\n  geom_point() +\n  geom_hline(yintercept = 0.05, linetype = 2) +\n  geom_vline(xintercept = delta_tp, linetype = 2) +\n  scale_x_continuous(breaks = seq(-6, 10, 2)) +\n  labs(x = \"Delta (intervention)\", y = \"P-value\")\n\ngrid.arrange(MAR_pval, MAR_est, nrow = 1)\n\n\n\n\n\n\n\n\nWe clearly see that the p-value under MAR reaches a tipping point from 3 onward in the range of delta’s considered.\n\n\n\nLet’s now create a sequence of delta’s for the control group too, and carry out a second tipping point analysis under the MAR assumption.\n\ndelta_df2 &lt;- expand.grid(\n  delta_control = seq(-3, 8, by = 1),\n  delta_intervention = seq(-3, 8, by = 1)\n) |&gt;\n  as_tibble()\n\n\nMAR_tipp_df2 &lt;- delta_df2 |&gt;\n  furrr::future_pmap(perform_tipp_analysis) |&gt;\n  purrr::reduce(bind_rows) \n\n# Adding back the delta's used for reference \nMAR_tipp_df2 &lt;- dplyr::bind_cols(delta_df2, MAR_tipp_df2) |&gt;\n  mutate(\n    pval = cut(\n      pval_7,\n      c(0, 0.001, 0.01, 0.05, 0.2, 1),\n      right = FALSE,\n      labels = c(\n        \"&lt;0.001\",\n        \"0.001 - &lt;0.01\",\n        \"0.01 - &lt;0.05\",\n        \"0.05 - &lt;0.20\",\n        \"&gt;= 0.20\"\n      )\n    )\n  ) \n\nWe can visualize the result of this tipping point analysis using a heatmap. Here, the (0,0) point corresponds to the original result without any delta adjustment (p ~ 0.0125).\n\nMAR_heat &lt;- ggplot(\n  MAR_tipp_df2,\n  aes(delta_control, delta_intervention, fill = pval)\n) +\n  geom_raster() +\n  scale_fill_manual(\n    values = c(\"darkgreen\", \"lightgreen\", \"lightyellow\", \"orange\", \"red\")\n  ) +\n  scale_x_continuous(breaks = seq(-5, 10, 1)) +\n  scale_y_continuous(breaks = seq(-5, 10, 1)) +\n  labs(x = \"Delta (control)\", y = \"Delta (intervention)\", fill = \"P-value\")\nMAR_heat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the table below we present the results of the different imputation strategies with varying number of multiple imputation draws, M = 500 and M = 5000. Note that the results can be slightly different from the results above due to a possible different seed. The estimates show the contrast at visit 7 between DRUG and PLACEBO (DRUG - PLACEBO). Delta adjustments were applied to all imputed missing data in the intervention group only.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\nDelta control\nDelta intervention at TP\nEstimate at TP\n95% CI\nP-value\nOriginal estimate\nOriginal p-value\n\n\n\n\nMI - MAR (M=500)\n0\n3\n-2.074\n-4.324 to 0.176\n0.0709\n-2.798\n0.0135\n\n\nMI - MAR (M=5000)\n0\n3\n-2.100\n-4.354 to 0.154\n0.0675\n-2.829\n0.0128\n\n\nMI - MNAR JR (M=500)\n0\n-1\n-2.380\n-4.595 to -0.165\n0.0354\n-2.137\n0.0602\n\n\nMI - MNAR JR (M=5000)\n0\n-1\n-2.383\n-4.608 to -0.157\n0.0361\n-2.140\n0.0611\n\n\nMI - MNAR CR (M=500)\n0\n1\n-2.151\n-4.359 to 0.057\n0.0561\n-2.394\n0.0326\n\n\nMI - MNAR CR (M=5000)\n0\n1\n-2.162\n-4.377 to 0.054\n0.0558\n-2.405\n0.0324\n\n\nMI - MNAR CIR (M=500)\n0\n2\n-1.986\n-4.211 to 0.239\n0.0798\n-2.472\n0.0274\n\n\nMI - MNAR CIR (M=5000)\n0\n2\n-1.994\n-4.227 to 0.239\n0.0796\n-2.480\n0.0274\n\n\n\nOf all considered approaches, the MAR approach yields the largest delta adjustment at its tipping point, with a delta intervention of 3 at both M = 500 and M = 5000. This indicates that the MAR assumption is the most robust against slight deviations of its conditions. Notice that for the MNAR JR approach we included, for completeness, tipping point analyses to know when the results switch from non-significant to significant. Correspondingly, two negative delta’s (-1) are found at the tipping point for M = 500 and M = 5000. This is expected, given that the original analyses are non-significant (p ~ 0.0602 and p ~ 0.0611) and a tipping point analysis here aims to find the point at which the analysis turns to be significant, instead of non-significant.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSo far, we have only considered simple delta adjustments that add the same value to all imputed missing data. However, you may want to implement more flexible delta adjustments for post-ICE missing data, where the magnitude of the delta varies depending on the distance of the visit from the ICE visit.\nTo facilitate the creation of such flexible delta adjustments, the delta_template() function has two additional arguments delta and dlag:\n\ndelta: specifies the default amount of delta that should be applied to each post-ICE visit (default is NULL)\ndlag: specifies the scaling coefficient to be applied based upon the visits proximity to the first visit affected by the ICE (default is NULL)\n\nThe usage of the delta and dlag arguments is best illustrated with a few examples from the rbmi advanced functionality vignette.\n\n\nAssume a setting with 4 visits and the user specified delta = c(5, 6, 7, 8) and dlag = c(1, 2, 3, 4). For a subject for whom the first visit affected by the ICE is visit 2, these values of delta and dlag would imply the following delta offset:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n5\n6\n7\n8\n\n\nDlag\n0\n1\n2\n3\n\n\nDelta * dlag\n0\n6\n14\n24\n\n\nCumulative sum\n0\n6\n20\n44\n\n\n\nThat is, the subject would have a delta adjustment of 0 applied to visit 1, 6 for visit 2, 20 for visit 3 and 44 for visit 4.\nAssume instead, that the subject’s first visit affected by the ICE was visit 3. Then, the above values of delta and dlag would imply the following delta adjustment:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n5\n6\n7\n8\n\n\nDlag\n0\n0\n1\n2\n\n\nDelta * dlag\n0\n0\n7\n16\n\n\nCumulative sum\n0\n0\n7\n23\n\n\n\nAnd thus the subject would have a delta adjustment of 0 applied to visits 1 and 2, 7 for visit 3 and 23 for visit 4.\nAnother way of using these arguments is to set delta to the difference in time between visits and dlag to be the amount of delta per unit of time. For example, let’s say that visits occur on weeks 1, 5, 6 and 9 and that we want a delta of 3 to be applied for each week after an ICE. For simplicity, we assume that the ICE occurs immediately after the subject’s last visit which is not affected by the ICE. This could be achieved by setting delta = c(1, 4, 1, 3), i.e. the difference in weeks between each visit, and dlag = c(3, 3, 3, 3).\nAssume a subject’s first visit affected by the ICE was visit 2, then these values of delta and dlag would imply the following delta adjustment:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n1\n4\n1\n3\n\n\nDlag\n0\n3\n3\n3\n\n\nDelta * dlag\n0\n12\n3\n9\n\n\nCumulative sum\n0\n12\n15\n24\n\n\n\nLet’s now consider the antidepressant data again. Suppose we apply a delta adjustment of 2 for each week following an ICE in the intervention group only. For example, if the ICE took place immediately after visit 4, then the cumulative delta applied to a missing value from visit 5 would be 2, from visit 6 would be 4, and from visit 7 would be 6.\nTo program this, we first use the delta and dlag arguments of delta_template().\n\ndat_delta &lt;- rbmi::delta_template(\n  imputeObj,\n  delta = c(2, 2, 2, 2),\n  dlag = c(1, 1, 1, 1)\n)\n\ndat_delta |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\n\n\n\n\n1513\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1513\n5\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n2\n\n\n1513\n6\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n4\n\n\n1513\n7\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n6\n\n\n1514\n4\nPLACEBO\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1514\n5\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n2\n\n\n1514\n6\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n4\n\n\n1514\n7\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n6\n\n\n\n\n\n\n\nThen, we use some metadata variables provided by delta_template() to manually reset the delta values for the control group back to 0.\n\ndat_delta &lt;- dat_delta |&gt;\n  mutate(delta = if_else(THERAPY == \"PLACEBO\", 0, delta))\n\ndat_delta |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\n\n\n\n\n1513\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1513\n5\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n2\n\n\n1513\n6\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n4\n\n\n1513\n7\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n6\n\n\n1514\n4\nPLACEBO\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1514\n5\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1514\n6\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1514\n7\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n\n\n\n\n\nAnd lastly we use dat_delta to apply the desired delta offset to our analysis model under the delta argument of the analyse() function.\n\nanaObj &lt;- rbmi::analyse(\n  imputations = imputeObj,\n  fun = ancova,\n  delta = dat_delta,\n  vars = vars_analyse\n)\n\npoolObj &lt;- rbmi::pool(anaObj)\n\n\n\n\nYou may also add a simple, fixed delta using the delta and dlag arguments. To do this, delta should be specified as a vector of length equal to the amount of visits, e.g. c(5, 5, 5, 5), while dlag should be c(1, 0, 0, 0). This ensures a delta of 5 is added to each imputed missing value following an ICE, which we here assume to occur at the visit 2:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n5\n5\n5\n5\n\n\nDlag\n0\n1\n0\n0\n\n\nDelta * dlag\n0\n0\n0\n0\n\n\nCumulative sum\n0\n5\n5\n5\n\n\n\nAdding a fixed delta in this way seems similar to what we explained in the simple delta adjustments section above, but there are some crucial differences. Remember the first case where we added delta = 5 to all imputed is_missing values:\n\n# 1) mutate delta = is_missing * 5\ndat_delta_5_v1 &lt;- delta_template(imputations = imputeObj) |&gt;\n  mutate(delta = is_missing * 5)\n\nAnd remember the second case where we added delta = 5 to all imputed is_missing and is_post_ice values:\n\n# 2) mutate delta = is_missing * is_post_ice * 5\ndat_delta_5_v2 &lt;- delta_template(imputations = imputeObj) |&gt;\n  mutate(delta = is_missing * is_post_ice * 5)\n\nSimilarly, we now set delta = c(5, 5, 5, 5) and dlag = c(1, 0, 0, 0):\n\n# 3) delta = c(5, 5, 5, 5), dlag = c(1, 0, 0, 0)\ndat_delta_5_v3 &lt;- delta_template(\n  imputeObj,\n  delta = c(5, 5, 5, 5),\n  dlag = c(1, 0, 0, 0)\n)\n\nThe difference between these three approaches lies in how they treat intermittent missing values that do not correspond to study drug discontinuation due to an ICE.\nIf we consider patient 3618 again, we see that its intermittent missing value at visit 5 has delta = 5 added in the first approach (using is_missing * 5), while this missing value is not considered at all to receive a delta adjustment in the second or third approach (using is_missing * is_post_ice * 5, or delta = c(5, 5, 5, 5) and dlag = c(1, 0, 0, 0)). Thus by default, the delta and dlag arguments of delta_template() (third approach) only add delta adjustments to post-ICE missing values.\n\n# imputed dataset without delta adjustment\ngt(MI_10 |&gt; dplyr::filter(PATIENT == \"3618\"))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n-0.06964206\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.00000000\nnew_pt_99\n\n\n\n\n\n\n# 1) mutate delta = is_missing * 5\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_5_v1,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT == 3618) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n4.930358\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.000000\nnew_pt_99\n\n\n\n\n\n\n# 2) mutate delta = is_missing * is_post_ice * 5\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_5_v2,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT == 3618) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n-0.06964206\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.00000000\nnew_pt_99\n\n\n\n\n\n\n# 3) delta = c(5, 5, 5, 5), dlag = c(1, 0, 0, 0)\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_5_v3,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT == 3618) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n-0.06964206\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.00000000\nnew_pt_99\n\n\n\n\n\n\n\nOne should be aware of this discrepancy when using the rbmi package for delta adjustments. For all tipping point analyses performed under MAR and MNAR in this tutorial, we adopted the first approach and applied delta adjustments to all imputed missing data. In contrast, we note that the five macros in SAS uses the second delta and dlag approach as discussed here, i.e. it does not apply delta adjustments to intermittent missing values. This could have important implications for datasets with high proportions of intermittent missing values, as it could alter the results of the tipping point analysis substantially.\n\n\n\n\nCro et al. 2020. Sensitivity analysis for clinical trials with missing continuous outcome data using controlled multiple imputation: A practical guide. Statistics in Medicine. 2020;39(21):2815-2842.\nGower-Page et al. 2022. rbmi: A R package for standard and reference-based multiple imputation methods. Journal of Open Source Software 7(74):4251.\nrbmi: Advanced Functionality\nrbmi: Quickstart\nrbmi: Reference-Based Multiple Imputation\nRoger 2022. Other statistical software for continuous longitudinal endpoints: SAS macros for multiple imputation. Addressing intercurrent events: Treatment policy and hypothetical strategies. Joint EFSPI and BBS virtual event.\nRoger 2017. Fitting reference-based models for missing data to longitudinal repeated-measures Normal data. User guide five macros.\n\n\n\n\n\n\nNoteSession info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package      * version  date (UTC) lib source\n P assertthat     0.2.1    2019-03-21 [?] RSPM\n P backports      1.5.0    2024-05-23 [?] CRAN (R 4.4.0)\n P BiocManager    1.30.25  2024-08-28 [?] CRAN (R 4.4.1)\n   boot           1.3-31   2024-08-28 [2] CRAN (R 4.4.2)\n P broom          1.0.7    2024-09-26 [?] CRAN (R 4.4.1)\n P checkmate      2.3.2    2024-07-29 [?] CRAN (R 4.4.0)\n P cli            3.6.3    2024-06-21 [?] CRAN (R 4.4.0)\n P coda           0.19-4.1 2024-01-31 [?] CRAN (R 4.4.0)\n   codetools      0.2-20   2024-03-31 [2] CRAN (R 4.4.2)\n P colorspace     2.1-1    2024-07-26 [?] CRAN (R 4.4.0)\n P curl           5.2.3    2024-09-20 [?] CRAN (R 4.4.1)\n P digest         0.6.37   2024-08-19 [?] CRAN (R 4.4.1)\n P dplyr        * 1.1.4    2023-11-17 [?] CRAN (R 4.4.0)\n P emmeans      * 1.10.4   2024-08-21 [?] CRAN (R 4.4.1)\n P estimability   1.5.1    2024-05-12 [?] CRAN (R 4.4.0)\n P evaluate       1.0.0    2024-09-17 [?] CRAN (R 4.4.1)\n P fansi          1.0.6    2023-12-08 [?] CRAN (R 4.4.0)\n P farver         2.1.2    2024-05-13 [?] CRAN (R 4.4.0)\n P fastmap        1.2.0    2024-05-15 [?] CRAN (R 4.4.0)\n P forcats        1.0.0    2023-01-29 [?] CRAN (R 4.4.0)\n P foreach        1.5.2    2022-02-02 [?] CRAN (R 4.4.0)\n P furrr        * 0.3.1    2022-08-15 [?] CRAN (R 4.4.0)\n   future       * 1.67.0   2025-07-29 [1] RSPM (R 4.4.0)\n P generics       0.1.3    2022-07-05 [?] CRAN (R 4.4.0)\n P ggplot2      * 3.5.1    2024-04-23 [?] CRAN (R 4.4.0)\n P glmnet         4.1-8    2023-08-22 [?] CRAN (R 4.4.0)\n   globals        0.18.0   2025-05-08 [1] RSPM (R 4.4.0)\n P glue           1.8.0    2024-09-30 [?] CRAN (R 4.4.1)\n P gridExtra    * 2.3      2017-09-09 [?] CRAN (R 4.4.0)\n P gt           * 0.11.1   2024-10-04 [?] CRAN (R 4.4.1)\n P gtable         0.3.5    2024-04-22 [?] CRAN (R 4.4.0)\n P haven          2.5.4    2023-11-30 [?] CRAN (R 4.4.0)\n P hms            1.1.3    2023-03-21 [?] CRAN (R 4.4.0)\n P htmltools      0.5.8.1  2024-04-04 [?] CRAN (R 4.4.0)\n P htmlwidgets    1.6.4    2023-12-06 [?] CRAN (R 4.4.0)\n P inline         0.3.21   2025-01-09 [?] RSPM\n P iterators      1.0.14   2022-02-05 [?] CRAN (R 4.4.0)\n P jomo           2.7-6    2023-04-15 [?] CRAN (R 4.4.0)\n P jsonlite       1.8.9    2024-09-20 [?] CRAN (R 4.4.1)\n   knitr          1.50     2025-03-16 [1] RSPM (R 4.4.0)\n P labeling       0.4.3    2023-08-29 [?] CRAN (R 4.4.0)\n P labelled     * 2.14.0   2025-01-08 [?] RSPM\n   lattice        0.22-6   2024-03-20 [2] CRAN (R 4.4.2)\n P lifecycle      1.0.4    2023-11-07 [?] CRAN (R 4.4.0)\n P listenv        0.9.1    2024-01-29 [?] CRAN (R 4.4.0)\n P lme4           1.1-35.5 2024-07-03 [?] CRAN (R 4.4.0)\n P loo            2.8.0    2024-07-03 [?] RSPM\n P magrittr       2.0.3    2022-03-30 [?] CRAN (R 4.4.0)\n   MASS           7.3-61   2024-06-13 [2] CRAN (R 4.4.2)\n   Matrix         1.7-1    2024-10-18 [2] CRAN (R 4.4.2)\n P matrixStats    1.4.1    2024-09-08 [?] CRAN (R 4.4.1)\n P mice         * 3.16.0   2023-06-05 [?] CRAN (R 4.4.0)\n P minqa          1.2.8    2024-08-17 [?] CRAN (R 4.4.0)\n P mitml          0.4-5    2023-03-08 [?] CRAN (R 4.4.0)\n P mmrm         * 0.3.14   2024-09-27 [?] CRAN (R 4.4.1)\n P multcomp       1.4-26   2024-07-18 [?] CRAN (R 4.4.0)\n P munsell        0.5.1    2024-04-01 [?] CRAN (R 4.4.0)\n P mvtnorm        1.3-1    2024-09-03 [?] CRAN (R 4.4.1)\n   nlme           3.1-166  2024-08-14 [2] CRAN (R 4.4.2)\n P nloptr         2.1.1    2024-06-25 [?] CRAN (R 4.4.0)\n   nnet           7.3-19   2023-05-03 [2] CRAN (R 4.4.2)\n P pan            1.9      2023-12-07 [?] CRAN (R 4.4.0)\n   parallelly   * 1.45.1   2025-07-24 [1] RSPM (R 4.4.0)\n P pillar         1.9.0    2023-03-22 [?] CRAN (R 4.4.0)\n P pkgbuild       1.4.4    2024-03-17 [?] CRAN (R 4.4.0)\n P pkgconfig      2.0.3    2019-09-22 [?] CRAN (R 4.4.0)\n   purrr        * 1.1.0    2025-07-10 [1] RSPM (R 4.4.0)\n P QuickJSR       1.8.0    2025-06-09 [?] RSPM\n P R6             2.5.1    2021-08-19 [?] CRAN (R 4.4.0)\n P rbibutils      2.3      2024-10-04 [?] CRAN (R 4.4.1)\n P rbmi         * 1.4.0    2025-02-07 [?] RSPM\n P Rcpp           1.0.13   2024-07-17 [?] CRAN (R 4.4.0)\n P RcppParallel   5.1.10   2025-01-24 [?] RSPM\n P Rdpack         2.6.1    2024-08-06 [?] CRAN (R 4.4.0)\n   renv           1.0.10   2024-10-05 [1] CRAN (R 4.4.1)\n P rlang          1.1.6    2025-04-11 [?] RSPM\n P rmarkdown      2.28     2024-08-17 [?] CRAN (R 4.4.0)\n   rpart          4.1.23   2023-12-05 [2] CRAN (R 4.4.2)\n P rstan        * 2.32.7   2025-03-10 [?] RSPM\n P rstudioapi     0.16.0   2024-03-24 [?] CRAN (R 4.4.0)\n P sandwich       3.1-1    2024-09-15 [?] CRAN (R 4.4.1)\n P sass           0.4.9    2024-03-15 [?] CRAN (R 4.4.0)\n P scales         1.3.0    2023-11-28 [?] CRAN (R 4.4.0)\n P sessioninfo    1.2.2    2021-12-06 [?] CRAN (R 4.4.0)\n P shape          1.4.6.1  2024-02-23 [?] CRAN (R 4.4.0)\n P StanHeaders  * 2.32.10  2024-07-15 [?] RSPM\n P stringi        1.8.4    2024-05-06 [?] CRAN (R 4.4.0)\n P stringr        1.5.1    2023-11-14 [?] CRAN (R 4.4.0)\n P survival       3.7-0    2024-06-05 [?] CRAN (R 4.4.0)\n P TH.data        1.1-2    2023-04-17 [?] CRAN (R 4.4.0)\n P tibble         3.2.1    2023-03-20 [?] CRAN (R 4.4.0)\n P tidyr        * 1.3.1    2024-01-24 [?] CRAN (R 4.4.0)\n P tidyselect     1.2.1    2024-03-11 [?] CRAN (R 4.4.0)\n P TMB            1.9.15   2024-09-09 [?] CRAN (R 4.4.1)\n P utf8           1.2.4    2023-10-22 [?] CRAN (R 4.4.0)\n P V8             5.0.1    2024-09-20 [?] CRAN (R 4.4.1)\n P vctrs          0.6.5    2023-12-01 [?] CRAN (R 4.4.0)\n P withr          3.0.1    2024-07-31 [?] CRAN (R 4.4.0)\n   xfun           0.52     2025-04-02 [1] RSPM (R 4.4.0)\n P xml2           1.3.6    2023-12-04 [?] CRAN (R 4.4.0)\n P xtable         1.8-4    2019-04-21 [?] CRAN (R 4.4.0)\n P yaml           2.3.10   2024-07-26 [?] CRAN (R 4.4.0)\n P zoo            1.8-12   2023-04-13 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/tipping_point.html#setup",
    "href": "R/tipping_point.html#setup",
    "title": "R Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "# General libraries\nlibrary(mice)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(gt)\nlibrary(labelled)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# Methodology specific libraries\nlibrary(emmeans)\nlibrary(mmrm)\nlibrary(rstan)\nlibrary(rbmi)\n\n# Paralleisation libraries\nlibrary(future)\nlibrary(furrr)\nlibrary(parallelly)\n\n\n\n\nset.seed(12345)"
  },
  {
    "objectID": "R/tipping_point.html#reference-based-multiple-imputation-rbmi",
    "href": "R/tipping_point.html#reference-based-multiple-imputation-rbmi",
    "title": "R Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "The concept of delta adjustment and tipping point analysis builds on the framework of reference-based multiple imputation (rbmi) as seen on its respective CAMIS webpage. The use of the rbmi package in R (Gower-Page et al. 2022) for the following standard and reference-based multiple imputation approaches are introduced there:\n\nMissing At Random (MAR)\nJump to Reference (JR)\nCopy Reference (CR)\nCopy Increment from Reference (CIR)\n\nPlease make sure to familiarize yourself with these functionalities of the rbmi package before checking this tutorial. The outline of this page generally follows the rbmi advanced functionality vignette.\n\n\n\nThe same publicly available dataset from an antidepressant clinical trial that was used to illustrate rbmi is again used for this tutorial. This dataset is also used in the rbmi quickstart vignette.\nThe relevant endpoint for the antidepressant trial was assessed using the Hamilton 17-item depression rating scale (HAMD17), which was measured at baseline and subsequently at weeks 1, 2, 3, 4 and 6 (visits 4-7). Study drug discontinuation occurred in 24% (20/84) of subjects in the active drug group, compared to 26% (23/88) of subjects in the placebo group. Importantly, all data after study drug discontinuation are missing and there is a single intermittent missing observation.\n\ndata(\"antidepressant_data\")\n\ndat &lt;- antidepressant_data |&gt;\n  dplyr::select(\n    PATIENT,\n    GENDER,\n    THERAPY,\n    RELDAYS,\n    VISIT,\n    BASVAL,\n    HAMDTL17,\n    CHANGE\n  ) |&gt;\n  dplyr::mutate(THERAPY = factor(THERAPY, levels = c(\"PLACEBO\", \"DRUG\"))) |&gt;\n  labelled::remove_labels()\n\ngt(head(dat, n = 10))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\n\n\n\n\n1503\nF\nDRUG\n7\n4\n32\n21\n-11\n\n\n1503\nF\nDRUG\n14\n5\n32\n20\n-12\n\n\n1503\nF\nDRUG\n28\n6\n32\n19\n-13\n\n\n1503\nF\nDRUG\n42\n7\n32\n17\n-15\n\n\n1507\nF\nPLACEBO\n7\n4\n14\n11\n-3\n\n\n1507\nF\nPLACEBO\n15\n5\n14\n14\n0\n\n\n1507\nF\nPLACEBO\n29\n6\n14\n9\n-5\n\n\n1507\nF\nPLACEBO\n42\n7\n14\n5\n-9\n\n\n1509\nF\nDRUG\n7\n4\n21\n20\n-1\n\n\n1509\nF\nDRUG\n14\n5\n21\n18\n-3\n\n\n\n\n\n\n\nThe number of patients per visit and treatment group are:\n\ndat |&gt;\n  dplyr::summarise(N = n(), .by = c(VISIT, THERAPY))\n\n# A tibble: 8 × 3\n  VISIT THERAPY     N\n  &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n1 4     DRUG       84\n2 5     DRUG       77\n3 6     DRUG       73\n4 7     DRUG       64\n5 4     PLACEBO    88\n6 5     PLACEBO    81\n7 6     PLACEBO    76\n8 7     PLACEBO    65\n\n\nThe mean change from baseline of the HAMD17 endpoint per visit and treatment group using only the complete cases are:\n\ndat |&gt;\n  dplyr::summarise(N = n(), MEAN = mean(CHANGE), .by = c(VISIT, THERAPY))\n\n# A tibble: 8 × 4\n  VISIT THERAPY     N  MEAN\n  &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;dbl&gt;\n1 4     DRUG       84 -1.82\n2 5     DRUG       77 -4.71\n3 6     DRUG       73 -6.79\n4 7     DRUG       64 -8.34\n5 4     PLACEBO    88 -1.51\n6 5     PLACEBO    81 -2.70\n7 6     PLACEBO    76 -4.07\n8 7     PLACEBO    65 -5.14\n\n\nThe missingness pattern is:\n\ndat_wide = dat |&gt;\n  dplyr::select(PATIENT, VISIT, CHANGE) |&gt;\n  pivot_wider(\n    id_cols = PATIENT,\n    names_from = VISIT,\n    names_prefix = \"VISIT_\",\n    values_from = CHANGE\n  )\n\ndat_wide |&gt;\n  dplyr::select(starts_with(\"VISIT_\")) |&gt;\n  mice::md.pattern(plot = TRUE, rotate.names = TRUE)\n\n\n\n\n\n\n\n\n    VISIT_4 VISIT_5 VISIT_6 VISIT_7   \n128       1       1       1       1  0\n20        1       1       1       0  1\n10        1       1       0       0  2\n1         1       0       1       1  1\n13        1       0       0       0  3\n          0      14      23      43 80\n\n\nThere is a single patient with an intermittent missing observation at visit 5, which is patient 3618. Special considerations need to be taken when applying delta adjustments to intermittent missing observations like this one (more on this later).\n\ndat_expand &lt;- rbmi::expand_locf(\n  dat,\n  PATIENT = levels(dat$PATIENT),\n  VISIT = levels(dat$VISIT),\n  vars = c(\"BASVAL\", \"THERAPY\", \"GENDER\"),\n  group = c(\"PATIENT\"),\n  order = c(\"PATIENT\", \"VISIT\")\n)\n\ndat_expand |&gt;\n  dplyr::filter(PATIENT == \"3618\") |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\nNA\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2\n\n\n\n\n\n\n\n\n\n\nThis tutorial will focus on tipping point analysis and delta adjustment. We assume the user used the rbmi package to create an imputation object called imputeObj (see CAMIS webpage)."
  },
  {
    "objectID": "R/tipping_point.html#tipping-point-analysis-and-delta-adjustment",
    "href": "R/tipping_point.html#tipping-point-analysis-and-delta-adjustment",
    "title": "R Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "When analyses for endpoints are performed under MAR or MNAR assumptions for missing data, it is important to perform sensitivity analyses to assess the impact of deviations from these assumptions. Tipping point analysis (or delta adjustment method) is an example of a sensitivity analysis that can be used to assess the robustness of a clinical trial when its result is based on imputed missing data.\nGenerally, tipping point analysis explores the influence of missingness on the overall conclusion of the treatment difference by shifting imputed missing values in the treatment group towards the reference group until the result becomes non-significant. The tipping point is the minimum shift needed to make the result non-significant. If the minimum shift needed to make the result non-significant is implausible, then greater confidence in the primary results can be inferred.\nTipping point analysis generally happens by adjusting imputing values by so-called delta values. The observed tipping point is the minimum delta needed to make the result non-significant. Mostly a range of delta values is explored and only imputed values from the active treatment group are adjusted by the delta value. However, delta adjustments in the control group are possible as well. Naturally, the range of acceptable values for delta should be agreed a priori, before taking this approach.\nFor an extensive discussion on delta adjustment methods, we refer to Cro et al. 2020."
  },
  {
    "objectID": "R/tipping_point.html#simple-delta-adjustments",
    "href": "R/tipping_point.html#simple-delta-adjustments",
    "title": "R Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "In the rbmi package, the delta argument of the analyse() function allows users to adjust the imputed datasets prior to the analysis stage. This delta argument requires a data frame created by delta_template(), which includes a column called delta that specifies the delta values to be added.\nBy default, delta_template() will set delta to 0 for all observations.\n\n# delta template\ndat_delta_0 &lt;- delta_template(imputations = imputeObj)\n\n\ndat_delta_0 |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\n\n\n\n\n1513\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1513\n5\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1513\n6\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1513\n7\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1514\n4\nPLACEBO\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1514\n5\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1514\n6\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1514\n7\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n\n\n\n\n\nYou can add the delta values to the outcome variable (CHANGE) of one of the imputed datasets by using the apply_delta() function. Of course, nothing is changed here as delta = 0.\n\nimputed_dfs = rbmi::extract_imputed_dfs(imputeObj)\nMI_10 = imputed_dfs[[10]]\nMI_10$PATIENT2 = MI_10$PATIENT\nMI_10$PATIENT = dat_expand$PATIENT\n\n\n# imputed dataset\ngt(MI_10 |&gt; dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt; head(8))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n1513\nM\nDRUG\n7\n4\n19\n24\n5.000000\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n5\n19\nNA\n-1.901762\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n6\n19\nNA\n-5.903109\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n7\n19\nNA\n-1.996427\nnew_pt_5\n\n\n1514\nF\nPLACEBO\n7\n4\n21\n23\n2.000000\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n5\n21\nNA\n4.444457\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n6\n21\nNA\n1.231729\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n7\n21\nNA\n5.348181\nnew_pt_6\n\n\n\n\n\n\n# delta adjusted dataset\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_0,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n1513\nM\nDRUG\n7\n4\n19\n24\n5.000000\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n5\n19\nNA\n-1.901762\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n6\n19\nNA\n-5.903109\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n7\n19\nNA\n-1.996427\nnew_pt_5\n\n\n1514\nF\nPLACEBO\n7\n4\n21\n23\n2.000000\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n5\n21\nNA\n4.444457\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n6\n21\nNA\n1.231729\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n7\n21\nNA\n5.348181\nnew_pt_6\n\n\n\n\n\n\n\nYou may have noticed that the is_missing and is_post_ice columns of the delta data frame lend themselves perfectly to adjust the delta values, as the boolean variables TRUE and FALSE are regarded as 1 and 0 by R. If you want to set delta to 5 for all missing values, you can do so by multiplying the is_missing column by 5. In our case, this addition assumes a “worsening” of the imputed outcome variable, CHANGE, which is measured on the HAMD17 scale.\n\n# delta template\ndat_delta_5_v1 &lt;- delta_template(imputations = imputeObj) |&gt;\n  mutate(delta = is_missing * 5)\n\ndat_delta_5_v1 |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\n\n\n\n\n1513\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1513\n5\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n5\n\n\n1513\n6\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n5\n\n\n1513\n7\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n5\n\n\n1514\n4\nPLACEBO\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1514\n5\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n5\n\n\n1514\n6\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n5\n\n\n1514\n7\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n5\n\n\n\n\n\n\n\n\n# imputed dataset\ngt(MI_10 |&gt; dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt; head(8))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n1513\nM\nDRUG\n7\n4\n19\n24\n5.000000\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n5\n19\nNA\n-1.901762\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n6\n19\nNA\n-5.903109\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n7\n19\nNA\n-1.996427\nnew_pt_5\n\n\n1514\nF\nPLACEBO\n7\n4\n21\n23\n2.000000\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n5\n21\nNA\n4.444457\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n6\n21\nNA\n1.231729\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n7\n21\nNA\n5.348181\nnew_pt_6\n\n\n\n\n\n\n# delta adjusted dataset\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_5_v1,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n1513\nM\nDRUG\n7\n4\n19\n24\n5.0000000\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n5\n19\nNA\n3.0982376\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n6\n19\nNA\n-0.9031094\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n7\n19\nNA\n3.0035727\nnew_pt_5\n\n\n1514\nF\nPLACEBO\n7\n4\n21\n23\n2.0000000\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n5\n21\nNA\n9.4444566\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n6\n21\nNA\n6.2317289\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n7\n21\nNA\n10.3481805\nnew_pt_6\n\n\n\n\n\n\n\nImportantly, if you multiply the is_missing column only, you apply the delta adjustment to all imputed missing values, including intermittent missing values. This can be checked by looking at patient 3618, which has an intermittent missing value at visit 5.\n\n# delta template\ngt(dat_delta_5_v1 |&gt; dplyr::filter(PATIENT == \"3618\"))\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\n\n\n\n\n3618\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n3618\n5\nDRUG\nTRUE\nTRUE\nFALSE\nMAR\n5\n\n\n3618\n6\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n3618\n7\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n\n\n\n\n\n\n# imputed dataset\ngt(MI_10 |&gt; dplyr::filter(PATIENT == \"3618\"))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n-0.06964206\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.00000000\nnew_pt_99\n\n\n\n\n\n\n# delta adjusted dataset\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_5_v1,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT == \"3618\") |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n4.930358\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.000000\nnew_pt_99\n\n\n\n\n\n\n\nIf you consider the is_post_ice column too, you can restrict the delta adjustment to missing values that occur after study drug discontinuation due to an intercurrent event (ICE). By multiplying both the is_missing and is_post_ice columns by your chosen delta, the delta value will only be added when both columns are TRUE.\n\n# delta template\ndat_delta_5_v2 &lt;- delta_template(imputations = imputeObj) |&gt;\n  mutate(delta = is_missing * is_post_ice * 5)\n\ndat_delta_5_v2 |&gt;\n  dplyr::filter(PATIENT == \"3618\") |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\n\n\n\n\n3618\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n3618\n5\nDRUG\nTRUE\nTRUE\nFALSE\nMAR\n0\n\n\n3618\n6\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n3618\n7\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n\n\n\n\n\n\n# imputed dataset\ngt(MI_10 |&gt; dplyr::filter(PATIENT == \"3618\"))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n-0.06964206\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.00000000\nnew_pt_99\n\n\n\n\n\n\n# delta adjusted dataset\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_5_v2,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT == \"3618\") |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n-0.06964206\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.00000000\nnew_pt_99\n\n\n\n\n\n\n\nBesides choosing which missing data to apply the delta adjustment to, you may also want to apply different delta adjustments to imputed data from the different groups. As an example, let’s set delta = 0 for the control group, and delta = 5 for the intervention group. Here, we consider the is_missing column only, so that we apply the delta’s to all imputed missing data.\n\n# delta template\ndelta_control = 0\ndelta_intervention = 5\n\ndat_delta_0_5 &lt;- rbmi::delta_template(imputations = imputeObj) |&gt;\n  mutate(\n    delta_ctl = (THERAPY == \"PLACEBO\") * is_missing * delta_control,\n    delta_int = (THERAPY == \"DRUG\") * is_missing * delta_intervention,\n    delta = delta_ctl + delta_int\n  )\n\ndat_delta_0_5 |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\ndelta_ctl\ndelta_int\n\n\n\n\n1513\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n0\n0\n\n\n1513\n5\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n5\n0\n5\n\n\n1513\n6\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n5\n0\n5\n\n\n1513\n7\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n5\n0\n5\n\n\n1514\n4\nPLACEBO\nTRUE\nFALSE\nFALSE\nNA\n0\n0\n0\n\n\n1514\n5\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n0\n0\n\n\n1514\n6\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n0\n0\n\n\n1514\n7\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n0\n0\n\n\n\n\n\n\n\n\n# delta adjusted dataset\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_0_5,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n1513\nM\nDRUG\n7\n4\n19\n24\n5.0000000\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n5\n19\nNA\n3.0982376\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n6\n19\nNA\n-0.9031094\nnew_pt_5\n\n\n1513\nM\nDRUG\nNA\n7\n19\nNA\n3.0035727\nnew_pt_5\n\n\n1514\nF\nPLACEBO\n7\n4\n21\n23\n2.0000000\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n5\n21\nNA\n4.4444566\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n6\n21\nNA\n1.2317289\nnew_pt_6\n\n\n1514\nF\nPLACEBO\nNA\n7\n21\nNA\n5.3481805\nnew_pt_6\n\n\n\n\n\n\n\nThe delta_template() function has two additional arguments, delta and dlag, that can be used to define the delta adjustments. We explain these arguments in more detail in the flexible delta adjustments section below.\n\n\n\nAs mentioned, delta adjustments are implemented via the delta argument of the analyse() function. The adjustment happens right after data imputation under MAR or MNAR (using reference-based imputation approaches), but before implementing the analysis model. Sensitivity analyses can therefore be performed without having to refit the imputation model, which is computationally efficient. This approach is considered a marginal delta adjustment approach, because the delta is simply added to the mean of the conditional multivariate normal distribution (conditional on the observed values and the covariates) for the imputation model (Roger 2017).\nHere, we apply the delta adjustment of 5 to all imputed values of the outcome variable (CHANGE) in the intervention group. The estimated treatment effect at visit 7 is presented below.\n\nanaObj &lt;- rbmi::analyse(\n  imputations = imputeObj,\n  fun = ancova,\n  delta = dat_delta_0_5,\n  vars = vars_analyse\n)\n\npoolObj &lt;- rbmi::pool(anaObj)\n\npoolObj |&gt;\n  data.frame() |&gt;\n  dplyr::filter(grepl(\"7\", parameter)) |&gt;\n  gt()\n\n\n\n\n\n\n\nparameter\nest\nse\nlci\nuci\npval\n\n\n\n\ntrt_7\n-1.587755\n1.1617288\n-3.883977\n0.7084662\n1.738414e-01\n\n\nlsm_ref_7\n-4.839053\n0.8058704\n-6.431863\n-3.2462434\n1.477601e-08\n\n\nlsm_alt_7\n-6.426808\n0.8284919\n-8.064451\n-4.7891650\n1.482193e-12"
  },
  {
    "objectID": "R/tipping_point.html#tipping-point-analysis-mar-approach",
    "href": "R/tipping_point.html#tipping-point-analysis-mar-approach",
    "title": "R Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "To perform a tipping point analysis under the MAR assumption, we must create a range of delta values. In this section, we only specify a range of delta’s for the intervention group.\n\ndelta_df1 &lt;- expand.grid(\n  delta_control = 0,\n  delta_intervention = seq(-3, 8, by = 1)\n) |&gt;\n  as_tibble()\n\n\n\n\nTo enable a tipping point analysis within a single function, we create perform_tipp_analysis(). This custom function requires a stratified delta for delta_control and delta_intervention, alongside cl as set in the previous step.\n\nperform_tipp_analysis &lt;- function(delta_control, delta_intervention) {\n  dat_delta &lt;- rbmi::delta_template(imputeObj) |&gt;\n    mutate(\n      delta_ctl = (THERAPY == \"PLACEBO\") * is_missing * delta_control,\n      delta_int = (THERAPY == \"DRUG\") * is_missing * delta_intervention,\n      delta = delta_ctl + delta_int\n    )\n\n  anaObj &lt;- rbmi::analyse(\n    imputations = imputeObj,\n    fun = ancova,\n    delta = dat_delta,\n    vars = vars_analyse\n  )\n\n  poolObj &lt;- as.data.frame(pool(anaObj)) |&gt;\n    dplyr::filter(grepl(\"trt_7\", parameter))\n\n  list(\n    trt_7 = poolObj[[\"est\"]],\n    pval_7 = poolObj[[\"pval\"]],\n    lci_7 = poolObj[[\"lci\"]],\n    uci_7 = poolObj[[\"uci\"]]\n  )\n}\n\nNow, let’s apply this function to the antidepressant data as follows:\nNote: here we are adding some parallelisation using {furrr} to speed things up.\n\nworkers &lt;- parallelly::availableCores(omit = 1)\nfuture::plan(multisession, workers = workers)\n\nMAR_tipp_df1 &lt;- delta_df1 |&gt; \n  furrr::future_pmap(perform_tipp_analysis) |&gt;\n  purrr::reduce(bind_rows) \n\nMAR_tipp_df1 &lt;- dplyr::bind_cols(delta_df1, MAR_tipp_df1)\n\nThe results of the tipping point analysis under MAR with p-value \\(\\geq\\) 0.05 are:\n\nMAR_tipp_df1 |&gt;\n  filter(pval_7 &gt;= 0.05) |&gt;\n  gt()\n\n\n\n\n\n\n\ndelta_control\ndelta_intervention\ntrt_7\npval_7\nlci_7\nuci_7\n\n\n\n\n0\n3\n-2.0737802\n0.07096941\n-4.327059\n0.1794988\n\n\n0\n4\n-1.8307677\n0.11357323\n-4.103772\n0.4422370\n\n\n0\n5\n-1.5877552\n0.17384142\n-3.883977\n0.7084662\n\n\n0\n6\n-1.3447427\n0.25441183\n-3.667567\n0.9780820\n\n\n0\n7\n-1.1017302\n0.35622522\n-3.454430\n1.2509695\n\n\n0\n8\n-0.8587177\n0.47798920\n-3.244441\n1.5270060\n\n\n\n\n\n\n\nThe results of the tipping point analysis under MAR with p-value \\(&lt;\\) 0.05 are:\n\nMAR_tipp_df1 |&gt;\n  filter(pval_7 &lt; 0.05) |&gt;\n  gt()\n\n\n\n\n\n\n\ndelta_control\ndelta_intervention\ntrt_7\npval_7\nlci_7\nuci_7\n\n\n\n\n0\n-3\n-3.531855\n0.001953328\n-5.744159\n-1.31955114\n\n\n0\n-2\n-3.288843\n0.003806339\n-5.498548\n-1.07913777\n\n\n0\n-1\n-3.045830\n0.007272930\n-5.256735\n-0.83492584\n\n\n0\n0\n-2.802818\n0.013540735\n-5.018714\n-0.58692152\n\n\n0\n1\n-2.559805\n0.024425284\n-4.784460\n-0.33515027\n\n\n0\n2\n-2.316793\n0.042481732\n-4.553929\n-0.07965626\n\n\n\n\n\n\n\nWe can derive an exact tipping point by linearly interpolating between the last “significant” delta and the first “non-significant” delta using the approx() function.\n\ndelta_tp &lt;- approx(\n  x = MAR_tipp_df1$pval_7,\n  y = MAR_tipp_df1$delta_intervention,\n  xout = 0.05\n)$y\n\ntrt_tp &lt;- approx(\n  x = MAR_tipp_df1$delta_intervention,\n  y = MAR_tipp_df1$trt_7,\n  xout = delta_tp\n)$y\n\nlci_tp &lt;- approx(\n  x = MAR_tipp_df1$delta_intervention,\n  y = MAR_tipp_df1$lci_7,\n  xout = delta_tp\n)$y\n\nuci_tp &lt;- approx(\n  x = MAR_tipp_df1$delta_intervention,\n  y = MAR_tipp_df1$uci_7,\n  xout = delta_tp\n)$y\n\ndata.frame(\n  delta_control = 0,\n  delta_intervention = delta_tp,\n  trt_7 = trt_tp,\n  pval_7 = 0.05,\n  lci_7 = lci_tp,\n  uci_7 = uci_tp\n) |&gt;\n  gt()\n\n\n\n\n\n\n\ndelta_control\ndelta_intervention\ntrt_7\npval_7\nlci_7\nuci_7\n\n\n\n\n0\n2.263913\n-2.252659\n0.05\n-4.494055\n-0.01126187\n\n\n\n\n\n\n\n\n\n\nA nice visualization of this tipping point analysis for the MAR approach is shown below. The dashed horizontal line indicates a p-value of 0.05 in the left plot and no treatment effect in the right plot.\n\nMAR_est &lt;- ggplot(MAR_tipp_df1, aes(delta_intervention, trt_7)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(\n    aes(delta_intervention, ymin = lci_7, ymax = uci_7),\n    alpha = 0.25\n  ) +\n  geom_hline(yintercept = 0.0, linetype = 2) +\n  geom_vline(xintercept = delta_tp, linetype = 2) +\n  scale_x_continuous(breaks = seq(-6, 10, 2)) +\n  labs(x = \"Delta (intervention)\", y = \"Treatment effect (95% CI)\")\n\nMAR_pval &lt;- ggplot(MAR_tipp_df1, aes(delta_intervention, pval_7)) +\n  geom_line() +\n  geom_point() +\n  geom_hline(yintercept = 0.05, linetype = 2) +\n  geom_vline(xintercept = delta_tp, linetype = 2) +\n  scale_x_continuous(breaks = seq(-6, 10, 2)) +\n  labs(x = \"Delta (intervention)\", y = \"P-value\")\n\ngrid.arrange(MAR_pval, MAR_est, nrow = 1)\n\n\n\n\n\n\n\n\nWe clearly see that the p-value under MAR reaches a tipping point from 3 onward in the range of delta’s considered.\n\n\n\nLet’s now create a sequence of delta’s for the control group too, and carry out a second tipping point analysis under the MAR assumption.\n\ndelta_df2 &lt;- expand.grid(\n  delta_control = seq(-3, 8, by = 1),\n  delta_intervention = seq(-3, 8, by = 1)\n) |&gt;\n  as_tibble()\n\n\nMAR_tipp_df2 &lt;- delta_df2 |&gt;\n  furrr::future_pmap(perform_tipp_analysis) |&gt;\n  purrr::reduce(bind_rows) \n\n# Adding back the delta's used for reference \nMAR_tipp_df2 &lt;- dplyr::bind_cols(delta_df2, MAR_tipp_df2) |&gt;\n  mutate(\n    pval = cut(\n      pval_7,\n      c(0, 0.001, 0.01, 0.05, 0.2, 1),\n      right = FALSE,\n      labels = c(\n        \"&lt;0.001\",\n        \"0.001 - &lt;0.01\",\n        \"0.01 - &lt;0.05\",\n        \"0.05 - &lt;0.20\",\n        \"&gt;= 0.20\"\n      )\n    )\n  ) \n\nWe can visualize the result of this tipping point analysis using a heatmap. Here, the (0,0) point corresponds to the original result without any delta adjustment (p ~ 0.0125).\n\nMAR_heat &lt;- ggplot(\n  MAR_tipp_df2,\n  aes(delta_control, delta_intervention, fill = pval)\n) +\n  geom_raster() +\n  scale_fill_manual(\n    values = c(\"darkgreen\", \"lightgreen\", \"lightyellow\", \"orange\", \"red\")\n  ) +\n  scale_x_continuous(breaks = seq(-5, 10, 1)) +\n  scale_y_continuous(breaks = seq(-5, 10, 1)) +\n  labs(x = \"Delta (control)\", y = \"Delta (intervention)\", fill = \"P-value\")\nMAR_heat"
  },
  {
    "objectID": "R/tipping_point.html#comparison-with-rbmi-mnar-approaches",
    "href": "R/tipping_point.html#comparison-with-rbmi-mnar-approaches",
    "title": "R Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "In the table below we present the results of the different imputation strategies with varying number of multiple imputation draws, M = 500 and M = 5000. Note that the results can be slightly different from the results above due to a possible different seed. The estimates show the contrast at visit 7 between DRUG and PLACEBO (DRUG - PLACEBO). Delta adjustments were applied to all imputed missing data in the intervention group only.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\nDelta control\nDelta intervention at TP\nEstimate at TP\n95% CI\nP-value\nOriginal estimate\nOriginal p-value\n\n\n\n\nMI - MAR (M=500)\n0\n3\n-2.074\n-4.324 to 0.176\n0.0709\n-2.798\n0.0135\n\n\nMI - MAR (M=5000)\n0\n3\n-2.100\n-4.354 to 0.154\n0.0675\n-2.829\n0.0128\n\n\nMI - MNAR JR (M=500)\n0\n-1\n-2.380\n-4.595 to -0.165\n0.0354\n-2.137\n0.0602\n\n\nMI - MNAR JR (M=5000)\n0\n-1\n-2.383\n-4.608 to -0.157\n0.0361\n-2.140\n0.0611\n\n\nMI - MNAR CR (M=500)\n0\n1\n-2.151\n-4.359 to 0.057\n0.0561\n-2.394\n0.0326\n\n\nMI - MNAR CR (M=5000)\n0\n1\n-2.162\n-4.377 to 0.054\n0.0558\n-2.405\n0.0324\n\n\nMI - MNAR CIR (M=500)\n0\n2\n-1.986\n-4.211 to 0.239\n0.0798\n-2.472\n0.0274\n\n\nMI - MNAR CIR (M=5000)\n0\n2\n-1.994\n-4.227 to 0.239\n0.0796\n-2.480\n0.0274\n\n\n\nOf all considered approaches, the MAR approach yields the largest delta adjustment at its tipping point, with a delta intervention of 3 at both M = 500 and M = 5000. This indicates that the MAR assumption is the most robust against slight deviations of its conditions. Notice that for the MNAR JR approach we included, for completeness, tipping point analyses to know when the results switch from non-significant to significant. Correspondingly, two negative delta’s (-1) are found at the tipping point for M = 500 and M = 5000. This is expected, given that the original analyses are non-significant (p ~ 0.0602 and p ~ 0.0611) and a tipping point analysis here aims to find the point at which the analysis turns to be significant, instead of non-significant."
  },
  {
    "objectID": "R/tipping_point.html#flexible-delta-adjustments",
    "href": "R/tipping_point.html#flexible-delta-adjustments",
    "title": "R Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "So far, we have only considered simple delta adjustments that add the same value to all imputed missing data. However, you may want to implement more flexible delta adjustments for post-ICE missing data, where the magnitude of the delta varies depending on the distance of the visit from the ICE visit.\nTo facilitate the creation of such flexible delta adjustments, the delta_template() function has two additional arguments delta and dlag:\n\ndelta: specifies the default amount of delta that should be applied to each post-ICE visit (default is NULL)\ndlag: specifies the scaling coefficient to be applied based upon the visits proximity to the first visit affected by the ICE (default is NULL)\n\nThe usage of the delta and dlag arguments is best illustrated with a few examples from the rbmi advanced functionality vignette.\n\n\nAssume a setting with 4 visits and the user specified delta = c(5, 6, 7, 8) and dlag = c(1, 2, 3, 4). For a subject for whom the first visit affected by the ICE is visit 2, these values of delta and dlag would imply the following delta offset:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n5\n6\n7\n8\n\n\nDlag\n0\n1\n2\n3\n\n\nDelta * dlag\n0\n6\n14\n24\n\n\nCumulative sum\n0\n6\n20\n44\n\n\n\nThat is, the subject would have a delta adjustment of 0 applied to visit 1, 6 for visit 2, 20 for visit 3 and 44 for visit 4.\nAssume instead, that the subject’s first visit affected by the ICE was visit 3. Then, the above values of delta and dlag would imply the following delta adjustment:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n5\n6\n7\n8\n\n\nDlag\n0\n0\n1\n2\n\n\nDelta * dlag\n0\n0\n7\n16\n\n\nCumulative sum\n0\n0\n7\n23\n\n\n\nAnd thus the subject would have a delta adjustment of 0 applied to visits 1 and 2, 7 for visit 3 and 23 for visit 4.\nAnother way of using these arguments is to set delta to the difference in time between visits and dlag to be the amount of delta per unit of time. For example, let’s say that visits occur on weeks 1, 5, 6 and 9 and that we want a delta of 3 to be applied for each week after an ICE. For simplicity, we assume that the ICE occurs immediately after the subject’s last visit which is not affected by the ICE. This could be achieved by setting delta = c(1, 4, 1, 3), i.e. the difference in weeks between each visit, and dlag = c(3, 3, 3, 3).\nAssume a subject’s first visit affected by the ICE was visit 2, then these values of delta and dlag would imply the following delta adjustment:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n1\n4\n1\n3\n\n\nDlag\n0\n3\n3\n3\n\n\nDelta * dlag\n0\n12\n3\n9\n\n\nCumulative sum\n0\n12\n15\n24\n\n\n\nLet’s now consider the antidepressant data again. Suppose we apply a delta adjustment of 2 for each week following an ICE in the intervention group only. For example, if the ICE took place immediately after visit 4, then the cumulative delta applied to a missing value from visit 5 would be 2, from visit 6 would be 4, and from visit 7 would be 6.\nTo program this, we first use the delta and dlag arguments of delta_template().\n\ndat_delta &lt;- rbmi::delta_template(\n  imputeObj,\n  delta = c(2, 2, 2, 2),\n  dlag = c(1, 1, 1, 1)\n)\n\ndat_delta |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\n\n\n\n\n1513\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1513\n5\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n2\n\n\n1513\n6\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n4\n\n\n1513\n7\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n6\n\n\n1514\n4\nPLACEBO\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1514\n5\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n2\n\n\n1514\n6\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n4\n\n\n1514\n7\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n6\n\n\n\n\n\n\n\nThen, we use some metadata variables provided by delta_template() to manually reset the delta values for the control group back to 0.\n\ndat_delta &lt;- dat_delta |&gt;\n  mutate(delta = if_else(THERAPY == \"PLACEBO\", 0, delta))\n\ndat_delta |&gt;\n  dplyr::filter(PATIENT %in% c(\"1513\", \"1514\")) |&gt;\n  head(8) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nVISIT\nTHERAPY\nis_mar\nis_missing\nis_post_ice\nstrategy\ndelta\n\n\n\n\n1513\n4\nDRUG\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1513\n5\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n2\n\n\n1513\n6\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n4\n\n\n1513\n7\nDRUG\nTRUE\nTRUE\nTRUE\nMAR\n6\n\n\n1514\n4\nPLACEBO\nTRUE\nFALSE\nFALSE\nNA\n0\n\n\n1514\n5\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1514\n6\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n1514\n7\nPLACEBO\nTRUE\nTRUE\nTRUE\nMAR\n0\n\n\n\n\n\n\n\nAnd lastly we use dat_delta to apply the desired delta offset to our analysis model under the delta argument of the analyse() function.\n\nanaObj &lt;- rbmi::analyse(\n  imputations = imputeObj,\n  fun = ancova,\n  delta = dat_delta,\n  vars = vars_analyse\n)\n\npoolObj &lt;- rbmi::pool(anaObj)\n\n\n\n\nYou may also add a simple, fixed delta using the delta and dlag arguments. To do this, delta should be specified as a vector of length equal to the amount of visits, e.g. c(5, 5, 5, 5), while dlag should be c(1, 0, 0, 0). This ensures a delta of 5 is added to each imputed missing value following an ICE, which we here assume to occur at the visit 2:\n\n\n\n\nVisit 1\nVisit 2\nVisit 3\nVisit 4\n\n\n\n\nDelta\n5\n5\n5\n5\n\n\nDlag\n0\n1\n0\n0\n\n\nDelta * dlag\n0\n0\n0\n0\n\n\nCumulative sum\n0\n5\n5\n5\n\n\n\nAdding a fixed delta in this way seems similar to what we explained in the simple delta adjustments section above, but there are some crucial differences. Remember the first case where we added delta = 5 to all imputed is_missing values:\n\n# 1) mutate delta = is_missing * 5\ndat_delta_5_v1 &lt;- delta_template(imputations = imputeObj) |&gt;\n  mutate(delta = is_missing * 5)\n\nAnd remember the second case where we added delta = 5 to all imputed is_missing and is_post_ice values:\n\n# 2) mutate delta = is_missing * is_post_ice * 5\ndat_delta_5_v2 &lt;- delta_template(imputations = imputeObj) |&gt;\n  mutate(delta = is_missing * is_post_ice * 5)\n\nSimilarly, we now set delta = c(5, 5, 5, 5) and dlag = c(1, 0, 0, 0):\n\n# 3) delta = c(5, 5, 5, 5), dlag = c(1, 0, 0, 0)\ndat_delta_5_v3 &lt;- delta_template(\n  imputeObj,\n  delta = c(5, 5, 5, 5),\n  dlag = c(1, 0, 0, 0)\n)\n\nThe difference between these three approaches lies in how they treat intermittent missing values that do not correspond to study drug discontinuation due to an ICE.\nIf we consider patient 3618 again, we see that its intermittent missing value at visit 5 has delta = 5 added in the first approach (using is_missing * 5), while this missing value is not considered at all to receive a delta adjustment in the second or third approach (using is_missing * is_post_ice * 5, or delta = c(5, 5, 5, 5) and dlag = c(1, 0, 0, 0)). Thus by default, the delta and dlag arguments of delta_template() (third approach) only add delta adjustments to post-ICE missing values.\n\n# imputed dataset without delta adjustment\ngt(MI_10 |&gt; dplyr::filter(PATIENT == \"3618\"))\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n-0.06964206\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.00000000\nnew_pt_99\n\n\n\n\n\n\n# 1) mutate delta = is_missing * 5\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_5_v1,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT == 3618) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n4.930358\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.000000\nnew_pt_99\n\n\n\n\n\n\n# 2) mutate delta = is_missing * is_post_ice * 5\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_5_v2,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT == 3618) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n-0.06964206\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.00000000\nnew_pt_99\n\n\n\n\n\n\n# 3) delta = c(5, 5, 5, 5), dlag = c(1, 0, 0, 0)\nrbmi:::apply_delta(\n  MI_10,\n  delta = dat_delta_5_v3,\n  group = c(\"PATIENT\", \"VISIT\", \"THERAPY\"),\n  outcome = \"CHANGE\"\n) |&gt;\n  dplyr::filter(PATIENT == 3618) |&gt;\n  gt()\n\n\n\n\n\n\n\nPATIENT\nGENDER\nTHERAPY\nRELDAYS\nVISIT\nBASVAL\nHAMDTL17\nCHANGE\nPATIENT2\n\n\n\n\n3618\nM\nDRUG\n8\n4\n8\n15\n7.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\nNA\n5\n8\nNA\n-0.06964206\nnew_pt_99\n\n\n3618\nM\nDRUG\n28\n6\n8\n14\n6.00000000\nnew_pt_99\n\n\n3618\nM\nDRUG\n42\n7\n8\n10\n2.00000000\nnew_pt_99\n\n\n\n\n\n\n\nOne should be aware of this discrepancy when using the rbmi package for delta adjustments. For all tipping point analyses performed under MAR and MNAR in this tutorial, we adopted the first approach and applied delta adjustments to all imputed missing data. In contrast, we note that the five macros in SAS uses the second delta and dlag approach as discussed here, i.e. it does not apply delta adjustments to intermittent missing values. This could have important implications for datasets with high proportions of intermittent missing values, as it could alter the results of the tipping point analysis substantially."
  },
  {
    "objectID": "R/tipping_point.html#references",
    "href": "R/tipping_point.html#references",
    "title": "R Tipping Point (Delta Adjustment): Continuous Data",
    "section": "",
    "text": "Cro et al. 2020. Sensitivity analysis for clinical trials with missing continuous outcome data using controlled multiple imputation: A practical guide. Statistics in Medicine. 2020;39(21):2815-2842.\nGower-Page et al. 2022. rbmi: A R package for standard and reference-based multiple imputation methods. Journal of Open Source Software 7(74):4251.\nrbmi: Advanced Functionality\nrbmi: Quickstart\nrbmi: Reference-Based Multiple Imputation\nRoger 2022. Other statistical software for continuous longitudinal endpoints: SAS macros for multiple imputation. Addressing intercurrent events: Treatment policy and hypothetical strategies. Joint EFSPI and BBS virtual event.\nRoger 2017. Fitting reference-based models for missing data to longitudinal repeated-measures Normal data. User guide five macros.\n\n\n\n\n\n\nNoteSession info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package      * version  date (UTC) lib source\n P assertthat     0.2.1    2019-03-21 [?] RSPM\n P backports      1.5.0    2024-05-23 [?] CRAN (R 4.4.0)\n P BiocManager    1.30.25  2024-08-28 [?] CRAN (R 4.4.1)\n   boot           1.3-31   2024-08-28 [2] CRAN (R 4.4.2)\n P broom          1.0.7    2024-09-26 [?] CRAN (R 4.4.1)\n P checkmate      2.3.2    2024-07-29 [?] CRAN (R 4.4.0)\n P cli            3.6.3    2024-06-21 [?] CRAN (R 4.4.0)\n P coda           0.19-4.1 2024-01-31 [?] CRAN (R 4.4.0)\n   codetools      0.2-20   2024-03-31 [2] CRAN (R 4.4.2)\n P colorspace     2.1-1    2024-07-26 [?] CRAN (R 4.4.0)\n P curl           5.2.3    2024-09-20 [?] CRAN (R 4.4.1)\n P digest         0.6.37   2024-08-19 [?] CRAN (R 4.4.1)\n P dplyr        * 1.1.4    2023-11-17 [?] CRAN (R 4.4.0)\n P emmeans      * 1.10.4   2024-08-21 [?] CRAN (R 4.4.1)\n P estimability   1.5.1    2024-05-12 [?] CRAN (R 4.4.0)\n P evaluate       1.0.0    2024-09-17 [?] CRAN (R 4.4.1)\n P fansi          1.0.6    2023-12-08 [?] CRAN (R 4.4.0)\n P farver         2.1.2    2024-05-13 [?] CRAN (R 4.4.0)\n P fastmap        1.2.0    2024-05-15 [?] CRAN (R 4.4.0)\n P forcats        1.0.0    2023-01-29 [?] CRAN (R 4.4.0)\n P foreach        1.5.2    2022-02-02 [?] CRAN (R 4.4.0)\n P furrr        * 0.3.1    2022-08-15 [?] CRAN (R 4.4.0)\n   future       * 1.67.0   2025-07-29 [1] RSPM (R 4.4.0)\n P generics       0.1.3    2022-07-05 [?] CRAN (R 4.4.0)\n P ggplot2      * 3.5.1    2024-04-23 [?] CRAN (R 4.4.0)\n P glmnet         4.1-8    2023-08-22 [?] CRAN (R 4.4.0)\n   globals        0.18.0   2025-05-08 [1] RSPM (R 4.4.0)\n P glue           1.8.0    2024-09-30 [?] CRAN (R 4.4.1)\n P gridExtra    * 2.3      2017-09-09 [?] CRAN (R 4.4.0)\n P gt           * 0.11.1   2024-10-04 [?] CRAN (R 4.4.1)\n P gtable         0.3.5    2024-04-22 [?] CRAN (R 4.4.0)\n P haven          2.5.4    2023-11-30 [?] CRAN (R 4.4.0)\n P hms            1.1.3    2023-03-21 [?] CRAN (R 4.4.0)\n P htmltools      0.5.8.1  2024-04-04 [?] CRAN (R 4.4.0)\n P htmlwidgets    1.6.4    2023-12-06 [?] CRAN (R 4.4.0)\n P inline         0.3.21   2025-01-09 [?] RSPM\n P iterators      1.0.14   2022-02-05 [?] CRAN (R 4.4.0)\n P jomo           2.7-6    2023-04-15 [?] CRAN (R 4.4.0)\n P jsonlite       1.8.9    2024-09-20 [?] CRAN (R 4.4.1)\n   knitr          1.50     2025-03-16 [1] RSPM (R 4.4.0)\n P labeling       0.4.3    2023-08-29 [?] CRAN (R 4.4.0)\n P labelled     * 2.14.0   2025-01-08 [?] RSPM\n   lattice        0.22-6   2024-03-20 [2] CRAN (R 4.4.2)\n P lifecycle      1.0.4    2023-11-07 [?] CRAN (R 4.4.0)\n P listenv        0.9.1    2024-01-29 [?] CRAN (R 4.4.0)\n P lme4           1.1-35.5 2024-07-03 [?] CRAN (R 4.4.0)\n P loo            2.8.0    2024-07-03 [?] RSPM\n P magrittr       2.0.3    2022-03-30 [?] CRAN (R 4.4.0)\n   MASS           7.3-61   2024-06-13 [2] CRAN (R 4.4.2)\n   Matrix         1.7-1    2024-10-18 [2] CRAN (R 4.4.2)\n P matrixStats    1.4.1    2024-09-08 [?] CRAN (R 4.4.1)\n P mice         * 3.16.0   2023-06-05 [?] CRAN (R 4.4.0)\n P minqa          1.2.8    2024-08-17 [?] CRAN (R 4.4.0)\n P mitml          0.4-5    2023-03-08 [?] CRAN (R 4.4.0)\n P mmrm         * 0.3.14   2024-09-27 [?] CRAN (R 4.4.1)\n P multcomp       1.4-26   2024-07-18 [?] CRAN (R 4.4.0)\n P munsell        0.5.1    2024-04-01 [?] CRAN (R 4.4.0)\n P mvtnorm        1.3-1    2024-09-03 [?] CRAN (R 4.4.1)\n   nlme           3.1-166  2024-08-14 [2] CRAN (R 4.4.2)\n P nloptr         2.1.1    2024-06-25 [?] CRAN (R 4.4.0)\n   nnet           7.3-19   2023-05-03 [2] CRAN (R 4.4.2)\n P pan            1.9      2023-12-07 [?] CRAN (R 4.4.0)\n   parallelly   * 1.45.1   2025-07-24 [1] RSPM (R 4.4.0)\n P pillar         1.9.0    2023-03-22 [?] CRAN (R 4.4.0)\n P pkgbuild       1.4.4    2024-03-17 [?] CRAN (R 4.4.0)\n P pkgconfig      2.0.3    2019-09-22 [?] CRAN (R 4.4.0)\n   purrr        * 1.1.0    2025-07-10 [1] RSPM (R 4.4.0)\n P QuickJSR       1.8.0    2025-06-09 [?] RSPM\n P R6             2.5.1    2021-08-19 [?] CRAN (R 4.4.0)\n P rbibutils      2.3      2024-10-04 [?] CRAN (R 4.4.1)\n P rbmi         * 1.4.0    2025-02-07 [?] RSPM\n P Rcpp           1.0.13   2024-07-17 [?] CRAN (R 4.4.0)\n P RcppParallel   5.1.10   2025-01-24 [?] RSPM\n P Rdpack         2.6.1    2024-08-06 [?] CRAN (R 4.4.0)\n   renv           1.0.10   2024-10-05 [1] CRAN (R 4.4.1)\n P rlang          1.1.6    2025-04-11 [?] RSPM\n P rmarkdown      2.28     2024-08-17 [?] CRAN (R 4.4.0)\n   rpart          4.1.23   2023-12-05 [2] CRAN (R 4.4.2)\n P rstan        * 2.32.7   2025-03-10 [?] RSPM\n P rstudioapi     0.16.0   2024-03-24 [?] CRAN (R 4.4.0)\n P sandwich       3.1-1    2024-09-15 [?] CRAN (R 4.4.1)\n P sass           0.4.9    2024-03-15 [?] CRAN (R 4.4.0)\n P scales         1.3.0    2023-11-28 [?] CRAN (R 4.4.0)\n P sessioninfo    1.2.2    2021-12-06 [?] CRAN (R 4.4.0)\n P shape          1.4.6.1  2024-02-23 [?] CRAN (R 4.4.0)\n P StanHeaders  * 2.32.10  2024-07-15 [?] RSPM\n P stringi        1.8.4    2024-05-06 [?] CRAN (R 4.4.0)\n P stringr        1.5.1    2023-11-14 [?] CRAN (R 4.4.0)\n P survival       3.7-0    2024-06-05 [?] CRAN (R 4.4.0)\n P TH.data        1.1-2    2023-04-17 [?] CRAN (R 4.4.0)\n P tibble         3.2.1    2023-03-20 [?] CRAN (R 4.4.0)\n P tidyr        * 1.3.1    2024-01-24 [?] CRAN (R 4.4.0)\n P tidyselect     1.2.1    2024-03-11 [?] CRAN (R 4.4.0)\n P TMB            1.9.15   2024-09-09 [?] CRAN (R 4.4.1)\n P utf8           1.2.4    2023-10-22 [?] CRAN (R 4.4.0)\n P V8             5.0.1    2024-09-20 [?] CRAN (R 4.4.1)\n P vctrs          0.6.5    2023-12-01 [?] CRAN (R 4.4.0)\n P withr          3.0.1    2024-07-31 [?] CRAN (R 4.4.0)\n   xfun           0.52     2025-04-02 [1] RSPM (R 4.4.0)\n P xml2           1.3.6    2023-12-04 [?] CRAN (R 4.4.0)\n P xtable         1.8-4    2019-04-21 [?] CRAN (R 4.4.0)\n P yaml           2.3.10   2024-07-26 [?] CRAN (R 4.4.0)\n P zoo            1.8-12   2023-04-13 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/causal_ps_matching.html",
    "href": "R/causal_ps_matching.html",
    "title": "PS matching with R",
    "section": "",
    "text": "This article provide a general and simple workflow of data analysis of propensity score matching using the MatchIt package.\nThe dataset used here can be found in the data folder, with name ps_data.csv. It is the same data included in the CAMIS article on Propensity score matching: SAS vs R, which provides some good information on the comparison between SAS and R. For more details and different options, please refer to the doc there.\nThis article is based on the vignette for the MatchIt package. For more implementation and methodology details, please refer to the vignette."
  },
  {
    "objectID": "R/causal_ps_matching.html#about-this-article",
    "href": "R/causal_ps_matching.html#about-this-article",
    "title": "PS matching with R",
    "section": "",
    "text": "This article provide a general and simple workflow of data analysis of propensity score matching using the MatchIt package.\nThe dataset used here can be found in the data folder, with name ps_data.csv. It is the same data included in the CAMIS article on Propensity score matching: SAS vs R, which provides some good information on the comparison between SAS and R. For more details and different options, please refer to the doc there.\nThis article is based on the vignette for the MatchIt package. For more implementation and methodology details, please refer to the vignette."
  },
  {
    "objectID": "R/causal_ps_matching.html#propensity-score-matching-with-matchit",
    "href": "R/causal_ps_matching.html#propensity-score-matching-with-matchit",
    "title": "PS matching with R",
    "section": "Propensity Score Matching with MatchIt",
    "text": "Propensity Score Matching with MatchIt\nA matching analysis has a few steps:\n\nplanning\nmatching\nassess quality of matches\nestimate treatment effect and uncertainty\n\nIn the following example, we will go through a data analysis that covers these steps.\n\nExample\nWe load the dataset ps_data. Also load the necessary packges: MatchIt and dplyr.\n\nlibrary(MatchIt)\nlibrary(dplyr)\nlibrary(optmatch)\n\nInspect the dataset\n\n# load data\ndata &lt;- read.csv('../data/ps_data.csv')\nglimpse(data)\n\nRows: 300\nColumns: 5\n$ trtp    &lt;chr&gt; \"trt\", \"trt\", \"trt\", \"trt\", \"trt\", \"trt\", \"trt\", \"trt\", \"trt\",…\n$ sex     &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F…\n$ age     &lt;int&gt; 62, 60, 63, 98, 29, 41, 67, 53, 64, 62, 36, 63, 71, 102, 57, 4…\n$ weight  &lt;dbl&gt; 64.4, 67.1, 69.0, 69.0, 64.1, 62.9, 66.6, 62.1, 65.0, 74.0, 54…\n$ bmi_cat &lt;chr&gt; \"underweight\", \"underweight\", \"underweight\", \"underweight\", \"u…\n\n\nDo a bit of data processing: some character variables need to be factors.\n\n# maybe need to set factors\nvars &lt;- c('trtp', 'sex', 'bmi_cat')\ndata[vars] &lt;- lapply(data[vars], factor)\n\n\n\nCheck initial imbalance\nWe need to assess the balance in the treatment variable.\n\ntable(data$trtp)\n\n\ncontrol     trt \n    180     120 \n\n\nThe pre-matching imbalance can also be assessed in the following way.\n\nm0 &lt;- matchit(\n  trtp ~ age + sex + weight + bmi_cat,\n  data = data,\n1  method = NULL,\n2  distance = \"glm\"\n)\nsummary(m0)\n\n\n1\n\nNo matching is performed\n\n2\n\nglm for generalized linear model - logistic regression\n\n\n\n\n\nCall:\nmatchit(formula = trtp ~ age + sex + weight + bmi_cat, data = data, \n    method = NULL, distance = \"glm\")\n\nSummary of Balance for All Data:\n                   Means Treated Means Control Std. Mean Diff. Var. Ratio\ndistance                  0.5269        0.3154          0.8805     2.0576\nage                      61.4833       49.4000          0.7057     2.6343\nsexF                      0.5833        0.5000          0.1690          .\nsexM                      0.4167        0.5000         -0.1690          .\nweight                   67.2992       63.8250          0.4741     0.5779\nbmi_catnormal             0.4750        0.3389          0.2726          .\nbmi_catoverweight         0.2417        0.3111         -0.1622          .\nbmi_catunderweight        0.2833        0.3500         -0.1479          .\n                   eCDF Mean eCDF Max\ndistance              0.2593   0.4500\nage                   0.1635   0.3722\nsexF                  0.0833   0.0833\nsexM                  0.0833   0.0833\nweight                0.1241   0.2639\nbmi_catnormal         0.1361   0.1361\nbmi_catoverweight     0.0694   0.0694\nbmi_catunderweight    0.0667   0.0667\n\nSample Sizes:\n          Control Treated\nAll           180     120\nMatched       180     120\nUnmatched       0       0\nDiscarded       0       0\n\n\nWhen checking the results, standardized mean difference, variance ratios, eCDF are important measures. SMD and eCDF should be close to zero, while variance ratios should be close to 1.\n\n\nNearest neighbor matching\nThe first matching method we use is the 1:1 nearest neighbor (NN).\n\nm1 &lt;- matchit(\n  trtp ~ age + sex + weight + bmi_cat,\n  data = data,\n  method = \"nearest\", # set method NN\n  distance = \"glm\"\n)\nm1\n\nA `matchit` object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score\n             - estimated with logistic regression\n - number of obs.: 300 (original), 240 (matched)\n - target estimand: ATT\n - covariates: age, sex, weight, bmi_cat\n\n\nCheck the quality of the matches.\n\nsummary(m1)\n\n\nCall:\nmatchit(formula = trtp ~ age + sex + weight + bmi_cat, data = data, \n    method = \"nearest\", distance = \"glm\")\n\nSummary of Balance for All Data:\n                   Means Treated Means Control Std. Mean Diff. Var. Ratio\ndistance                  0.5269        0.3154          0.8805     2.0576\nage                      61.4833       49.4000          0.7057     2.6343\nsexF                      0.5833        0.5000          0.1690          .\nsexM                      0.4167        0.5000         -0.1690          .\nweight                   67.2992       63.8250          0.4741     0.5779\nbmi_catnormal             0.4750        0.3389          0.2726          .\nbmi_catoverweight         0.2417        0.3111         -0.1622          .\nbmi_catunderweight        0.2833        0.3500         -0.1479          .\n                   eCDF Mean eCDF Max\ndistance              0.2593   0.4500\nage                   0.1635   0.3722\nsexF                  0.0833   0.0833\nsexM                  0.0833   0.0833\nweight                0.1241   0.2639\nbmi_catnormal         0.1361   0.1361\nbmi_catoverweight     0.0694   0.0694\nbmi_catunderweight    0.0667   0.0667\n\nSummary of Balance for Matched Data:\n                   Means Treated Means Control Std. Mean Diff. Var. Ratio\ndistance                  0.5269        0.3882          0.5774     2.3477\nage                      61.4833       52.7833          0.5081     3.1020\nsexF                      0.5833        0.5333          0.1014          .\nsexM                      0.4167        0.4667         -0.1014          .\nweight                   67.2992       66.3850          0.1247     0.6031\nbmi_catnormal             0.4750        0.3917          0.1669          .\nbmi_catoverweight         0.2417        0.3083         -0.1557          .\nbmi_catunderweight        0.2833        0.3000         -0.0370          .\n                   eCDF Mean eCDF Max Std. Pair Dist.\ndistance              0.1412   0.3667          0.5780\nage                   0.1208   0.2833          0.7066\nsexF                  0.0500   0.0500          1.0480\nsexM                  0.0500   0.0500          1.0480\nweight                0.0653   0.1333          1.2639\nbmi_catnormal         0.0833   0.0833          0.9345\nbmi_catoverweight     0.0667   0.0667          0.9733\nbmi_catunderweight    0.0167   0.0167          0.7767\n\nSample Sizes:\n          Control Treated\nAll           180     120\nMatched       120     120\nUnmatched      60       0\nDiscarded       0       0\n\n\n\nm1$weights # membership, 1 or 0\n\n  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n 21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n 41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n 81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 \n  1   1   0   1   1   0   0   1   1   0   0   0   0   0   0   0   1   1   0   1 \n141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 \n  0   0   1   1   1   0   1   0   1   1   1   0   0   1   1   1   1   1   0   1 \n161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   0   1   1   1 \n181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 \n  1   1   0   0   1   1   0   1   1   1   1   1   1   1   1   1   1   1   0   1 \n201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 \n  1   1   1   0   0   0   1   1   1   1   0   0   0   0   1   1   0   1   0   1 \n221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 \n  1   1   1   1   0   1   1   1   1   0   0   1   0   1   1   0   1   1   1   1 \n241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 \n  1   0   1   0   1   1   0   1   0   1   1   1   1   1   1   0   1   1   1   1 \n261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 \n  0   0   1   0   1   1   1   0   0   1   0   1   1   1   1   1   1   0   1   1 \n281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 \n  1   0   1   1   1   0   0   0   1   1   0   0   0   1   0   1   1   0   0   0 \n\nm1$weights |&gt; table() # 244 unmatched, 370 (185:185 tr ct)\n\n\n  0   1 \n 60 240 \n\n\nCan also visualize the PS after matching.\n\nplot(m1, type = \"jitter\", interactive = FALSE)\n\n\n\n\n\n\n\n\n\n\nFull matching\nA different method can be used (full matching).\n\nm2 &lt;- matchit(\n  trtp ~ age + sex + weight + bmi_cat,\n  data = data,\n  method = \"full\",\n  distance = \"glm\",\n  link = \"probit\"\n)\nsummary(m2)\n\n\nCall:\nmatchit(formula = trtp ~ age + sex + weight + bmi_cat, data = data, \n    method = \"full\", distance = \"glm\", link = \"probit\")\n\nSummary of Balance for All Data:\n                   Means Treated Means Control Std. Mean Diff. Var. Ratio\ndistance                  0.5276        0.3179          0.8789     2.0294\nage                      61.4833       49.4000          0.7057     2.6343\nsexF                      0.5833        0.5000          0.1690          .\nsexM                      0.4167        0.5000         -0.1690          .\nweight                   67.2992       63.8250          0.4741     0.5779\nbmi_catnormal             0.4750        0.3389          0.2726          .\nbmi_catoverweight         0.2417        0.3111         -0.1622          .\nbmi_catunderweight        0.2833        0.3500         -0.1479          .\n                   eCDF Mean eCDF Max\ndistance              0.2574   0.4417\nage                   0.1635   0.3722\nsexF                  0.0833   0.0833\nsexM                  0.0833   0.0833\nweight                0.1241   0.2639\nbmi_catnormal         0.1361   0.1361\nbmi_catoverweight     0.0694   0.0694\nbmi_catunderweight    0.0667   0.0667\n\nSummary of Balance for Matched Data:\n                   Means Treated Means Control Std. Mean Diff. Var. Ratio\ndistance                  0.5276        0.5207          0.0291     1.0618\nage                      61.4833       56.4109          0.2962     2.2516\nsexF                      0.5833        0.6848         -0.2058          .\nsexM                      0.4167        0.3152          0.2058          .\nweight                   67.2992       70.6259         -0.4540     0.4518\nbmi_catnormal             0.4750        0.6306         -0.3116          .\nbmi_catoverweight         0.2417        0.1712          0.1647          .\nbmi_catunderweight        0.2833        0.1982          0.1889          .\n                   eCDF Mean eCDF Max Std. Pair Dist.\ndistance              0.0084   0.1167          0.0363\nage                   0.0729   0.2028          0.5135\nsexF                  0.1015   0.1015          0.9918\nsexM                  0.1015   0.1015          0.9918\nweight                0.0805   0.2732          1.2674\nbmi_catnormal         0.1556   0.1556          0.8822\nbmi_catoverweight     0.0705   0.0705          0.8232\nbmi_catunderweight    0.0851   0.0851          0.9385\n\nSample Sizes:\n              Control Treated\nAll            180.       120\nMatched (ESS)   29.88     120\nMatched        180.       120\nUnmatched        0.         0\nDiscarded        0.         0\n\n\nAssess the balance with Love plot. Read more in vignette('assessing-balance').\n\nplot(summary(m2))\n\n\n\n\n\n\n\n\n\n\nEstimate treatment effect\nFirst match the data. We focus on the full matching. Some new columns are added.\n\nm.data &lt;- match_data(m2)\nhead(m.data)\n\n  trtp sex age weight     bmi_cat   distance weights subclass\n1  trt   F  62   64.4 underweight 0.49077924       1        1\n2  trt   F  60   67.1 underweight 0.48967733       1        1\n3  trt   F  63   69.0 underweight 0.55924944       1       29\n4  trt   F  98   69.0 underweight 0.93988057       1       35\n5  trt   F  29   64.1 underweight 0.08752362       1       39\n6  trt   F  41   62.9 underweight 0.18167583       1       45\n\n\nFit model with weights\n\nfit &lt;- lm(\n  weight ~ trtp + age + sex + bmi_cat,\n1  data = m.data,\n2  weights = weights\n)\nsummary(fit)\n\n\n1\n\nuse the matched data\n\n2\n\nadd weights. this is a column in m.data\n\n\n\n\n\nCall:\nlm(formula = weight ~ trtp + age + sex + bmi_cat, data = m.data, \n    weights = weights)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-38.881  -5.868  -1.966   1.987  52.368 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        71.88164    2.47256  29.072  &lt; 2e-16 ***\ntrtptrt            -2.59401    1.13479  -2.286 0.022972 *  \nage                 0.01184    0.03942   0.300 0.764090    \nsexM               -0.50322    1.13855  -0.442 0.658824    \nbmi_catoverweight  -5.40009    1.42960  -3.777 0.000192 ***\nbmi_catunderweight -4.24149    1.34187  -3.161 0.001737 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.272 on 294 degrees of freedom\nMultiple R-squared:  0.09304,   Adjusted R-squared:  0.07761 \nF-statistic: 6.032 on 5 and 294 DF,  p-value: 2.476e-05\n\n\nIn the end, you can also compare it with the model without matching (lm).\n\nfit0 &lt;- lm(\n  weight ~ trtp + age + sex + bmi_cat,\n  data = data\n)\nsummary(fit0)\n\n\nCall:\nlm(formula = weight ~ trtp + age + sex + bmi_cat, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-27.902  -5.725   0.356   5.487  23.530 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        66.86591    2.16059  30.948   &lt;2e-16 ***\ntrtptrt             3.55584    1.14027   3.118   0.0020 ** \nage                -0.03191    0.03753  -0.850   0.3959    \nsexM                0.05071    1.02071   0.050   0.9604    \nbmi_catoverweight  -2.39144    1.25778  -1.901   0.0582 .  \nbmi_catunderweight -2.13108    1.21236  -1.758   0.0798 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.771 on 294 degrees of freedom\nMultiple R-squared:  0.05354,   Adjusted R-squared:  0.03744 \nF-statistic: 3.326 on 5 and 294 DF,  p-value: 0.006142\n\n\nInterpreting the result is a different topic, which is not covered in this article."
  },
  {
    "objectID": "R/causal_ps_matching.html#summary",
    "href": "R/causal_ps_matching.html#summary",
    "title": "PS matching with R",
    "section": "Summary",
    "text": "Summary\nThere are many diffrent methods implemented in the MatchIt package that we have not elaborated in this article. Please read the MatchIt vignette for more details on the options."
  },
  {
    "objectID": "R/survival_cif.html",
    "href": "R/survival_cif.html",
    "title": "Estimating Cumulative Incidence Functions Using R",
    "section": "",
    "text": "In this document we present how to estimate the cumulative incidence function (CIF) in R. We focus on the competing risks model where each subject experiences only one out of k possible events as depicted in the figure below.\n\nlibrary(ggsurvfit)\nlibrary(survival)\nlibrary(tidycmprsk)\nlibrary(tidyverse)"
  },
  {
    "objectID": "R/survival_cif.html#objective",
    "href": "R/survival_cif.html#objective",
    "title": "Estimating Cumulative Incidence Functions Using R",
    "section": "",
    "text": "In this document we present how to estimate the cumulative incidence function (CIF) in R. We focus on the competing risks model where each subject experiences only one out of k possible events as depicted in the figure below.\n\nlibrary(ggsurvfit)\nlibrary(survival)\nlibrary(tidycmprsk)\nlibrary(tidyverse)"
  },
  {
    "objectID": "R/survival_cif.html#r-packages",
    "href": "R/survival_cif.html#r-packages",
    "title": "Estimating Cumulative Incidence Functions Using R",
    "section": "R Packages",
    "text": "R Packages\nWe identify three packages:\n\ncmprsk\ntidycmprsk\nsurvival\n\nThe cmprsk package implements the methods described in Gray (1988) for testing CIFs across different groups. The tidycmprsk package is a wrapper for cmprsk. It uses syntax similar to other survival analysis packages, and returns survival objects. In this document, we illustrate how to use the tidycmprsk package for estimating and testing CIFs. More details and other functionalities can be found here.\nThe survival package is a general purpose survival analysis package. Its scope is far beyond the competing risks model. We will demonstrate how to estimate the CIFs using this package.\n\nData used\nThe bone marrow transplant (BTM) dataset as presented by Guo & So (2018) is used. The dataset has the following variables:\n\nGroup has three levels, indicating three disease groups: ALL, AML-Low Risk, AML-High Risk.\nT is the disease-free survival time in days. A derived variable TYears = T/365.25 is used in the analysis.\nStatus has value 0 if T is censored; 1 if T is time to relapse; 2 if T is time to death.\nWaitTime is the waiting time to transplant in days. This variable is not used here.\nA new variable ID is created.\n\n\nbmt &lt;- haven::read_sas(file.path(\"../data/bmt.sas7bdat\")) |&gt;\n  mutate(\n    Group = factor(\n      Group,\n      levels = c(1, 2, 3),\n      labels = c('ALL', 'AML-Low Risk', 'AML-High Risk')\n    ),\n    Status = factor(\n      Status,\n      levels = c(0, 1, 2),\n      labels = c('Censored', 'Relapse', 'Death')\n    ),\n    TYears = T / 365.25,\n    ID = row_number()\n  )"
  },
  {
    "objectID": "R/survival_cif.html#estimating-cifs",
    "href": "R/survival_cif.html#estimating-cifs",
    "title": "Estimating Cumulative Incidence Functions Using R",
    "section": "Estimating CIFs",
    "text": "Estimating CIFs\n\nThe tidycmprsk Package\n\nCIF Estimates and Gray’s Test\nThe tidycmprsk::cuminc() function requires a Surv object. Therefore, the first level of the event status variable (in this example Status) must represent censoring.\n\ncif.1 &lt;- tidycmprsk::cuminc(Surv(TYears, Status) ~ Group, data = bmt)\n\nGray’s test statistics and p-value:\n\nknitr::kable(\n  glance(cif.1) |&gt;\n    pivot_longer(\n      everything(),\n      names_to = c(\".value\", \"outcome_id\"),\n      names_pattern = \"(.*)_(.*)\"\n    )\n)\n\n\n\n\noutcome_id\noutcome\nstatistic\ndf\np.value\n\n\n\n\n1\nRelapse\n11.9228820\n2\n0.0025762\n\n\n2\nDeath\n0.1374108\n2\n0.9336017\n\n\n\n\n\nCIF estimates for time to relapse at selected timepoints for ‘AML-Low Risk’ patients:\n\nknitr::kable(\n  cif.1 |&gt;\n    tidy(times = c(0.5, 1, 1.5, 2, 3)) |&gt;\n    select(time, outcome, strata, estimate, std.error, conf.low, conf.high) |&gt;\n    filter(outcome == 'Relapse' & strata == 'AML-Low Risk') |&gt;\n    mutate(\n      time = as.character(time),\n      across(where(is.numeric), ~ num(., digits = 4))\n    )\n)\n\n\n\n\ntime\noutcome\nstrata\nestimate\nstd.error\nconf.low\nconf.high\n\n\n\n\n0.5\nRelapse\nAML-Low Risk\n0.0000\n0.0000\nNA\nNA\n\n\n1\nRelapse\nAML-Low Risk\n0.0741\n0.0360\n0.0234\n0.1646\n\n\n1.5\nRelapse\nAML-Low Risk\n0.1296\n0.0463\n0.0563\n0.2344\n\n\n2\nRelapse\nAML-Low Risk\n0.1481\n0.0489\n0.0685\n0.2565\n\n\n3\nRelapse\nAML-Low Risk\n0.1667\n0.0514\n0.0813\n0.2783\n\n\n\n\n\nTwo points to note:\n\nThe current version of cmprsk, and hence tidycmprsk, estimates the variance of the CIF estimates asymptotically as in Aalen (1978). There is no option to change it to other methods.\ntidycmprsk::cuminc() offers pointwise CIs for the CIF estimates using the log-log transforms. There is no other options.\n\n\n\nCIF Plots\n\ncif.1 |&gt;\n  ggsurvfit::ggcuminc(outcome = 'Death') +\n  ## add_confidence_interval() +\n  ggsurvfit::add_risktable() +\n  xlab('Time (years) to death')\n\n\n\n\n\n\n\ncif.1 |&gt;\n  ggsurvfit::ggcuminc(outcome = 'Relapse') +\n  ## add_confidence_interval() +\n  ggsurvfit::add_risktable() +\n  xlab('Time (years) to relapse')\n\n\n\n\n\n\n\n\n\n\n\nThe survival Package\n\nCIF Estimates\nUsing the bone marrow transplant example, the following code shows how to estimate the CIF for time to relapse or to death:\n\ncif.2 &lt;- survival::survfit(\n  survival::Surv(TYears, Status) ~ Group,\n  data = bmt,\n  se.fit = TRUE,\n  conf.type = 'log-log', ## default is 'log'\n  id = ID,\n  robust = TRUE ## default for multi-state model\n)\n## summary(cif.2)\n\nA few points to note:\n\nsurvfit() returns the probability of being in a state (pstate). The CIF is its complement, i.e., CIF = 1 - pstate.\nGray’s test for testing equality across groups is not performed.\nIn this example survfit() recognizes that the input are in multi-state model format; therefore, it estimates the variances of the CIFs with an infinitesimal jackknife (see Therneau (2024)). The CIs, as a result, are different from that estimated based on Aalen’s or the delta method as done in SAS PROC LIFETEST.\nThe survival package also offers a different syntax for estimating CIFs. Users need to first call finegray() separately for each event to reformat the data, then apply survfit() for each event. The CIF estimates are identical since the same estimation method is used; the variances can be different from directly calling survfit() with data in multi-state model format, since finegray() artificially extends the observed time for the competing events (see Therneau (2024)).\n\n\n\nCIF Plots\nThe same ggcuminc() syntax can be applied to the survfit() output cif.2."
  },
  {
    "objectID": "R/survival_cif.html#summary",
    "href": "R/survival_cif.html#summary",
    "title": "Estimating Cumulative Incidence Functions Using R",
    "section": "Summary",
    "text": "Summary\nBoth tidycmprsk::cminc() (as inherited from cmprsk::cuminc()) and survival::survfit() implement Aalen-Johansen estimator. For competing risks it reduces to CIF, which has a closed form formulation. The results are identical as produced by SAS PROC LIFETEST.\nCertain options in SAS, e.g., the delta method for variance estimation or other types of transformation for calculating the CIs, are not available in the current versions of tidycmprsk::cuminc() or survival::survfit(). However, the outputs from both contain enough information that these options can be manually implemented by users. For example, Pintilie (2006) provides R code for deriving the variances for the estimated CIFs based on the delta method.\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package    * version date (UTC) lib source\n P cmprsk       2.2-12  2024-05-19 [?] CRAN (R 4.4.0)\n P survival   * 3.7-0   2024-06-05 [?] CRAN (R 4.4.0)\n P tidycmprsk * 1.1.0   2024-08-17 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/survival_cif.html#reference",
    "href": "R/survival_cif.html#reference",
    "title": "Estimating Cumulative Incidence Functions Using R",
    "section": "Reference",
    "text": "Reference\nAalen O. (1978). Nonparametric Estimation of Partial Transition Probabilities in Multiple Decrement Models, Annals of Statistics, 6:534-545.\nGray R. (1988). A Class of K-Sample Tests for Comparing the Cumulative Incidence of a Competing Risk, Annals of Statistics, 16:1141-1154.\nGray R. (2024). cmprsk: Subdistribution Analysis of Competing Risks. R package version 2.2-12. https://cran.r-project.org/web/packages/cmprsk/cmprsk.pdf\nGuo C and So Y. (2018). Cause-Specific Analysis of Competing Risks Using the PHREG Procedure. In Proceedings of the SAS Global Forum 2018 Conference. Cary, NC: SAS Institute Inc. https://support.sas.com/resources/papers/proceedings18/2159-2018.pdf.\nPintilie M. (2006). Competing Risks: A Practical Perspective. Wiley.\nhttp://dx.doi.org/10.1002/9780470870709\nSjoberg D and Fei T. (2023). tidycmprsk: Competing Risks Estimation. https://github.com/MSKCC-Epi-Bio/tidycmprsk\nTherneau T. (2024). A Package for Survival Analysis in R. R package version 3.7-0, https://CRAN.R-project.org/package=survival."
  },
  {
    "objectID": "R/sample_s_test_of_trends.html",
    "href": "R/sample_s_test_of_trends.html",
    "title": "Sample size for K ordered binomial populations - Cochran-Armitage trend test",
    "section": "",
    "text": "Cochran-Armitage trend test\nSee the StatXact page for the details of the calculations in StatXact and some background theory of the Cochran-Armitage trend test. We will attempt to replicate the results in R for the same examples. Power and sample size calculations for Cochran-Armitage trend test in R are available only in the multiCA package\n\nExample 1 - Power for dose finding pilot study\nLet’s consider an example of a dose-finding phase I clinical trial of patients with advanced chronic disease. At the lowest dose level the response probability is known to be 0.001. The drug will be considered useful if the log odds of response increase by 0.5 per unit increase in dose (that defines the lambda). The study design assumes doubling the dose up to maximum of 16 units. Sample sizes of 10, 10, 10, 5 and 2, are proposed for the five dose levels, to restrict the total number of subjects at the two highest dose levels due to possible side effects. A one-sided Cochran-Armitage trend test at the 2.5% significance level will performed at the end of the study. What is the power?\nDesign parameter are as below:\n\n\n\n\n\n\n\n\n\nInitially, we need to compute probabilities by defining the logit trend model (unless they are defined by linear trend, which is not the case here):\n\n# logit function of trend to compute probabilities\nlogit_trend &lt;- function(p0, slope, xvec) {\n  logit0 &lt;- log(p0 / (1 - p0))\n  logit_seq &lt;- logit0 + (xvec - xvec[1]) * slope\n  pvec &lt;- 1 / (1 + exp(-logit_seq))\n  pvec\n}\n\n# vector of probabilities (from the logit model):\np0 &lt;- logit_trend(0.001, slope = 0.5, x = c(1, 2, 4, 8, 16))\n\n# or simply (based on the study design table):\np0 &lt;- c(0.001, 0.016, 0.0045, 0.0321, 0.6441)\n\nNow, function power.CA.test can be used:\n\nmultiCA::power.CA.test(\n  N = 37,\n  pvec = p0,\n  n.prop = c(10, 10, 10, 5, 2),\n  scores = c(1, 2, 4, 8, 16),\n  alternative = \"greater\",\n  sig.level = 0.025\n)\n\n\n     Cochran-Armitage trend test \n\n              n = 37\n         n.prop = 0.27027027, 0.27027027, 0.27027027, 0.13513514, 0.05405405\n              p = 0.0010, 0.0160, 0.0045, 0.0321, 0.6441\n    alternative = greater\n      sig.level = 0.025\n          power = 0.7955764\n\n\nAsymptotic power is equal to 82%.\nNote: We can obtain the same results using alternative = “two.sided” and sig.level=0.05.\nFunction power.multiCA.test is designed to calculate power of detecting trend in a categorical (multinomial) outcome. It does work as well in the special case of a binary outcome. However, the computation uses an approximation that is difficult to avoid for the multinomial setting but is not strictly necessary with the binary setting – as a result power may slightly biased away from 50%. Additionally, only two-sided power is implemented there, but we can still use it knowing that 5% is the two-sided significance level corresponding to the one-sided test with 2.5% significance level.\n\nmultiCA::power.multiCA.test(\n  N = 37,\n  pmatrix = rbind(p0, 1 - p0),\n  scores = c(1, 2, 4, 8, 16),\n  n.prop = c(10, 10, 10, 5, 2),\n  sig.level = 0.05\n)\n\n\n     Multinomial Cochran-Armitage trend test \n\n              n = 37\n         n.prop = 0.27027027, 0.27027027, 0.27027027, 0.13513514, 0.05405405\n          p.ave = 0.04496486, 0.95503514\n         slopes = 0.03223203, -0.03223203\n              G = 5\n      sig.level = 0.05\n          power = 0.9341785\n\n\nAsymptotic power is equal to 96%. Result is much higher than the one from power.CA.test function, which is designed for binary outcomes.\n\n\nExample 2 - Power for cohort study of effects of low dose radiation\nLet’s consider an example of a long-term follow-up study of subjects exposed to low-dose radiation in Japan (adapted from Landis, Heyman and Koch, 1978). The cohort was partitioned into four groups based on average radiation exposures of 0, 5, 30 and 75 rads. There were 2500, 3600, 1450 and 410 subjects, respectively, in the four dose groups. Subjects were classified as responders if they died from leukemia and non-responders if they died from other causes. We want detect a trend parameter of 0.049 on the logit scale, given a background response rate of 1 in 10,000. A one-sided Cochran-Armitage trend test at the 5% significance level was performed at the end of the study. What was the power?\nDesign parameter are as below:\n\n\n\n\n\n\n\n\n\nR code:\n\n# only using the power.CA.test and previously defined logit model:\np1 &lt;- logit_trend(0.0001, slope = 0.049, x = c(0, 5, 30, 75))\n\nmultiCA::power.CA.test(\n  N = 7960,\n  pvec = p1,\n  n.prop = c(2500, 3600, 1450, 410),\n  scores = c(0, 5, 30, 75),\n  alternative = \"greater\",\n  sig.level = 0.025\n)\n\n\n     Cochran-Armitage trend test \n\n              n = 7960\n         n.prop = 0.31407035, 0.45226131, 0.18216080, 0.05150754\n              p = 0.0001000000, 0.0001277586, 0.0004347779, 0.0039297563\n    alternative = greater\n      sig.level = 0.025\n          power = 0.7152462\n\n\nAsymptotic power is equal to 72%.\n\n\nExample 3 - Sample size calculation for trend test\nLet’s consider an example of the study where the design parameters are as below:\n\n\n\n\n\n\n\n\n\nWhat is the required sample size to achieve the power of 80% with the significance level 5%?\nR code:\n\nmultiCA::power.CA.test(\n  power = 0.8,\n  pvec = c(0.10, 0.13, 0.16, 0.19, 0.22),\n  scores = c(0, 1, 2, 4, 8),\n  alternative = \"greater\",\n  sig.level = 0.05\n)\n\n\n     Cochran-Armitage trend test \n\n              n = 526.2628\n         n.prop = 0.2, 0.2, 0.2, 0.2, 0.2\n              p = 0.10, 0.13, 0.16, 0.19, 0.22\n    alternative = greater\n      sig.level = 0.05\n          power = 0.8\n\n\nSample size N=527 subjects is required to achieve asymptotic power of 80%. That is the total sample size, including all the treatment arms/groups.\n\n\nAdditional notes\n\nThere are 2 methods to compute the asymptotic power:\n\no Lachin, John M. 2011. “Power and Sample Size Evaluation for the Cochran-Mantel-Haenszel Mean Score (Wilcoxon Rank Sum) Test and the Cochran-Armitage Test for Trend.” Stat Med 30 (25): 3057–66. https://doi.org/10.1002/sim.4330.\no Nam, Jun-mo. 1987. “A Simple Approximation for Calculating Sample Sizes Detecting Linear Trend in Proportions.” Biometrics, 701–5. In R, power.multiCA.test uses the first one and power.CA.test the second.\n\nStatXact is calculating the (exact or asymptotic) power of the exact CA test, and not the exact power of the asymptotic test. That is not implemented in multiCA package in R.\nKudos to Aniko, author of the package, for extra detailed explanations and her continuous work on that unique and extremely useful package!"
  },
  {
    "objectID": "R/summary_skew_kurt.html",
    "href": "R/summary_skew_kurt.html",
    "title": "Skewness/Kurtosis",
    "section": "",
    "text": "Skewness measures the the amount of asymmetry in a distribution, while Kurtosis describes the “tailedness” of the curve. These measures are frequently used to assess the normality of the data. There are several methods to calculate these measures. In R, there are at least four different packages that contain functions for Skewness and Kurtosis. This write-up will examine the following packages: e1071, moments, procs, and sasLM.\n\n\nThe following data was used in this example.\n\n# Create sample data\ndat &lt;- tibble::tribble(\n  ~team, ~points, ~assists,\n  \"A\", 10, 2,\n  \"A\", 17, 5,\n  \"A\", 17, 6,\n  \"A\", 18, 3,\n  \"A\", 15, 0,\n  \"B\", 10, 2,\n  \"B\", 14, 5,\n  \"B\", 13, 4,\n  \"B\", 29, 0,\n  \"B\", 25, 2,\n  \"C\", 12, 1,\n  \"C\", 30, 1,\n  \"C\", 34, 3,\n  \"C\", 12, 4,\n  \"C\", 11, 7 \n)\n\n\n\n\nBase R and the stats package have no native functions for Skewness and Kurtosis. It is therefore necessary to use a packaged function to calculate these statistics. The packages examined use three different methods of calculating Skewness, and four different methods for calculating Kurtosis. Of the available packages, the functions in the e1071 package provide the most flexibility, and have options for three of the different methodologies.\n\n\nThe e1071 package contains miscellaneous statistical functions from the Probability Theory Group at the Vienna University of Technology. The package includes functions for both Skewness and Kurtosis, and each function has a “type” parameter to specify the method. There are three available methods for Skewness, and three methods for Kurtosis. A portion of the documentation for these functions is included below:\n\n\nThe documentation for the skewness() function describes three types of skewness calculations: Joanes and Gill (1998) discusses three methods for estimating skewness:\n\nType 1: This is the typical definition used in many older textbooks\n\n\\[g_1 = m_1/m_2^{3/2}\\]\n\nType 2: Used in SAS and SPSS\n\\[\nG_1 = g_1\\sqrt{n(n-1)}/(n-2)\n\\]\nType 3: Used in MINITAB and BMDP\n\\[\nb_1 = m_3/s^3 = g_1((n-1)/n)^{3/2}\n\\]\n\nAll three skewness measures are unbiased under normality. The three methods are illustrated in the following code:\n\ntype1 &lt;- e1071::skewness(dat$points, type = 1)\nstringr::str_glue(\"Skewness - Type 1: {type1}\")\n\nSkewness - Type 1: 0.905444204379853\n\ntype2 &lt;- e1071::skewness(dat$points, type = 2)\nstringr::str_glue(\"Skewness - Type 2: {type2}\")\n\nSkewness - Type 2: 1.00931792987094\n\ntype3 &lt;- e1071::skewness(dat$points, type = 3)\nstringr::str_glue(\"Skewness - Type 3: {type3}\")\n\nSkewness - Type 3: 0.816426058828937\n\n\nThe default for the e1071 skewness() function is Type 3.\n\n\n\nThe documentation for the kurtosis() function describes three types of kurtosis calculations: Joanes and Gill (1998) discuss three methods for estimating kurtosis:\n\nType 1: This is the typical definition used in many older textbooks\n\n\\[g_2 = m_4/m_2^{2}-3\\]\n\nType 2: Used in SAS and SPSS\n\\[G_2 = ((n+1)g_2+6)*\\frac{(n-1)}{(n-2)(n-3)}\\]\nType 3: Used in MINITAB and BMDP\n\\[b_2 = m_4/s^4-3 = (g_2 + 3)(1-1/n)^2-3\\]\n\nOnly \\(G_2\\) (corresponding to type 2) is unbiased under normality. The three methods are illustrated in the following code:\n\n# Kurtosis - Type 1\ntype1 &lt;- e1071::kurtosis(dat$points, type = 1)\nstringr::str_glue(\"Kurtosis - Type 1: {type1}\")\n\nKurtosis - Type 1: -0.583341077124784\n\n# Kurtosis - Type 2\ntype2 &lt;- e1071::kurtosis(dat$points, type = 2)\nstringr::str_glue(\"Kurtosis - Type 2: {type2}\")\n\nKurtosis - Type 2: -0.299156418435587\n\n# Kurtosis - Type 3\ntype3 &lt;- e1071::kurtosis(dat$points, type = 3)\nstringr::str_glue(\"Kurtosis - Type 3: {type3}\")\n\nKurtosis - Type 3: -0.894821560517589\n\n\nThe default for the e1071 kurtosis() function is Type 3.\n\n\n\n\nThe moments package is a well-known package with a variety of statistical functions. The package contains functions for both Skewness and Kurtosis. But these functions provide no “type” option. The skewness() function in the moments package corresponds to Type 1 above. The kurtosis() function uses a Pearson’s measure of Kurtosis, which corresponds to none of the three types in the e1071 package.\n\nlibrary(moments)\n\n# Skewness - Type 1\nmoments::skewness(dat$points)\n\n[1] 0.9054442\n\n# Kurtosis - Pearson's measure\nmoments::kurtosis(dat$points)\n\n[1] 2.416659\n\n\nNote that neither of the functions from the moments package match SAS.\n\n\n\nThe procs package proc_means() function was written specifically to match SAS, and produces a Type 2 Skewness and Type 2 Kurtosis. This package also produces a data frame output, instead of a scalar value.\n\nlibrary(procs)\n\n# Skewness and Kurtosis - Type 2\nprocs::proc_means(dat, var = points, stats = v(skew, kurt))\n\n# A tibble: 1 × 5\n   TYPE  FREQ VAR     SKEW   KURT\n  &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     0    15 points  1.01 -0.299\n\n\nViewer Output:\n\n\n\n\n\n\n\n\n\n\n\n\nThe sasLM package was also written specifically to match SAS. The Skewness() function produces a Type 2 Skewness, and the Kurtosis() function a Type 2 Kurtosis.\n\nlibrary(sasLM)\n\n# Skewness - Type 2\nsasLM::Skewness(dat$points)\n\n[1] 1.009318\n\n# Kurtosis - Type 2\nsasLM::Kurtosis(dat$points)\n\n[1] -0.2991564\n\n\n\n\n\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package   * version date (UTC) lib source\n   class       7.3-22  2023-05-03 [2] CRAN (R 4.4.2)\n P cli         3.6.3   2024-06-21 [?] CRAN (R 4.4.0)\n P common    * 1.1.3   2024-04-05 [?] CRAN (R 4.4.0)\n P crayon      1.5.3   2024-06-20 [?] CRAN (R 4.4.0)\n P e1071     * 1.7-16  2024-09-16 [?] CRAN (R 4.4.1)\n P evaluate    1.0.0   2024-09-17 [?] CRAN (R 4.4.1)\n P fansi       1.0.6   2023-12-08 [?] CRAN (R 4.4.0)\n P fmtr        1.6.5   2024-06-13 [?] CRAN (R 4.4.0)\n P glue        1.8.0   2024-09-30 [?] CRAN (R 4.4.1)\n   highr       0.11    2024-05-26 [1] CRAN (R 4.4.0)\n P jpeg        0.1-10  2022-11-29 [?] CRAN (R 4.4.0)\n   knitr       1.50    2025-03-16 [1] RSPM (R 4.4.0)\n P lifecycle   1.0.4   2023-11-07 [?] CRAN (R 4.4.0)\n P magrittr    2.0.3   2022-03-30 [?] CRAN (R 4.4.0)\n   MASS        7.3-61  2024-06-13 [2] CRAN (R 4.4.2)\n P moments   * 0.14.1  2022-05-02 [?] CRAN (R 4.4.0)\n P mvtnorm   * 1.3-1   2024-09-03 [?] CRAN (R 4.4.1)\n P pillar      1.9.0   2023-03-22 [?] CRAN (R 4.4.0)\n P pkgconfig   2.0.3   2019-09-22 [?] CRAN (R 4.4.0)\n P procs     * 1.0.6   2024-03-06 [?] CRAN (R 4.4.0)\n P proxy       0.4-27  2022-06-09 [?] CRAN (R 4.4.0)\n P Rcpp        1.0.13  2024-07-17 [?] CRAN (R 4.4.0)\n P reporter    1.4.4   2024-03-19 [?] CRAN (R 4.4.0)\n P rlang       1.1.6   2025-04-11 [?] RSPM\n P sasLM     * 0.10.5  2024-10-02 [?] CRAN (R 4.4.1)\n P stringi     1.8.4   2024-05-06 [?] CRAN (R 4.4.0)\n P stringr     1.5.1   2023-11-14 [?] CRAN (R 4.4.0)\n P tibble    * 3.2.1   2023-03-20 [?] CRAN (R 4.4.0)\n P utf8        1.2.4   2023-10-22 [?] CRAN (R 4.4.0)\n P vctrs       0.6.5   2023-12-01 [?] CRAN (R 4.4.0)\n P withr       3.0.1   2024-07-31 [?] CRAN (R 4.4.0)\n   xfun        0.52    2025-04-02 [1] RSPM (R 4.4.0)\n P yaml        2.3.10  2024-07-26 [?] CRAN (R 4.4.0)\n P zip         2.3.1   2024-01-27 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/summary_skew_kurt.html#data-used",
    "href": "R/summary_skew_kurt.html#data-used",
    "title": "Skewness/Kurtosis",
    "section": "",
    "text": "The following data was used in this example.\n\n# Create sample data\ndat &lt;- tibble::tribble(\n  ~team, ~points, ~assists,\n  \"A\", 10, 2,\n  \"A\", 17, 5,\n  \"A\", 17, 6,\n  \"A\", 18, 3,\n  \"A\", 15, 0,\n  \"B\", 10, 2,\n  \"B\", 14, 5,\n  \"B\", 13, 4,\n  \"B\", 29, 0,\n  \"B\", 25, 2,\n  \"C\", 12, 1,\n  \"C\", 30, 1,\n  \"C\", 34, 3,\n  \"C\", 12, 4,\n  \"C\", 11, 7 \n)"
  },
  {
    "objectID": "R/summary_skew_kurt.html#package-examination",
    "href": "R/summary_skew_kurt.html#package-examination",
    "title": "Skewness/Kurtosis",
    "section": "",
    "text": "Base R and the stats package have no native functions for Skewness and Kurtosis. It is therefore necessary to use a packaged function to calculate these statistics. The packages examined use three different methods of calculating Skewness, and four different methods for calculating Kurtosis. Of the available packages, the functions in the e1071 package provide the most flexibility, and have options for three of the different methodologies.\n\n\nThe e1071 package contains miscellaneous statistical functions from the Probability Theory Group at the Vienna University of Technology. The package includes functions for both Skewness and Kurtosis, and each function has a “type” parameter to specify the method. There are three available methods for Skewness, and three methods for Kurtosis. A portion of the documentation for these functions is included below:\n\n\nThe documentation for the skewness() function describes three types of skewness calculations: Joanes and Gill (1998) discusses three methods for estimating skewness:\n\nType 1: This is the typical definition used in many older textbooks\n\n\\[g_1 = m_1/m_2^{3/2}\\]\n\nType 2: Used in SAS and SPSS\n\\[\nG_1 = g_1\\sqrt{n(n-1)}/(n-2)\n\\]\nType 3: Used in MINITAB and BMDP\n\\[\nb_1 = m_3/s^3 = g_1((n-1)/n)^{3/2}\n\\]\n\nAll three skewness measures are unbiased under normality. The three methods are illustrated in the following code:\n\ntype1 &lt;- e1071::skewness(dat$points, type = 1)\nstringr::str_glue(\"Skewness - Type 1: {type1}\")\n\nSkewness - Type 1: 0.905444204379853\n\ntype2 &lt;- e1071::skewness(dat$points, type = 2)\nstringr::str_glue(\"Skewness - Type 2: {type2}\")\n\nSkewness - Type 2: 1.00931792987094\n\ntype3 &lt;- e1071::skewness(dat$points, type = 3)\nstringr::str_glue(\"Skewness - Type 3: {type3}\")\n\nSkewness - Type 3: 0.816426058828937\n\n\nThe default for the e1071 skewness() function is Type 3.\n\n\n\nThe documentation for the kurtosis() function describes three types of kurtosis calculations: Joanes and Gill (1998) discuss three methods for estimating kurtosis:\n\nType 1: This is the typical definition used in many older textbooks\n\n\\[g_2 = m_4/m_2^{2}-3\\]\n\nType 2: Used in SAS and SPSS\n\\[G_2 = ((n+1)g_2+6)*\\frac{(n-1)}{(n-2)(n-3)}\\]\nType 3: Used in MINITAB and BMDP\n\\[b_2 = m_4/s^4-3 = (g_2 + 3)(1-1/n)^2-3\\]\n\nOnly \\(G_2\\) (corresponding to type 2) is unbiased under normality. The three methods are illustrated in the following code:\n\n# Kurtosis - Type 1\ntype1 &lt;- e1071::kurtosis(dat$points, type = 1)\nstringr::str_glue(\"Kurtosis - Type 1: {type1}\")\n\nKurtosis - Type 1: -0.583341077124784\n\n# Kurtosis - Type 2\ntype2 &lt;- e1071::kurtosis(dat$points, type = 2)\nstringr::str_glue(\"Kurtosis - Type 2: {type2}\")\n\nKurtosis - Type 2: -0.299156418435587\n\n# Kurtosis - Type 3\ntype3 &lt;- e1071::kurtosis(dat$points, type = 3)\nstringr::str_glue(\"Kurtosis - Type 3: {type3}\")\n\nKurtosis - Type 3: -0.894821560517589\n\n\nThe default for the e1071 kurtosis() function is Type 3.\n\n\n\n\nThe moments package is a well-known package with a variety of statistical functions. The package contains functions for both Skewness and Kurtosis. But these functions provide no “type” option. The skewness() function in the moments package corresponds to Type 1 above. The kurtosis() function uses a Pearson’s measure of Kurtosis, which corresponds to none of the three types in the e1071 package.\n\nlibrary(moments)\n\n# Skewness - Type 1\nmoments::skewness(dat$points)\n\n[1] 0.9054442\n\n# Kurtosis - Pearson's measure\nmoments::kurtosis(dat$points)\n\n[1] 2.416659\n\n\nNote that neither of the functions from the moments package match SAS.\n\n\n\nThe procs package proc_means() function was written specifically to match SAS, and produces a Type 2 Skewness and Type 2 Kurtosis. This package also produces a data frame output, instead of a scalar value.\n\nlibrary(procs)\n\n# Skewness and Kurtosis - Type 2\nprocs::proc_means(dat, var = points, stats = v(skew, kurt))\n\n# A tibble: 1 × 5\n   TYPE  FREQ VAR     SKEW   KURT\n  &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     0    15 points  1.01 -0.299\n\n\nViewer Output:\n\n\n\n\n\n\n\n\n\n\n\n\nThe sasLM package was also written specifically to match SAS. The Skewness() function produces a Type 2 Skewness, and the Kurtosis() function a Type 2 Kurtosis.\n\nlibrary(sasLM)\n\n# Skewness - Type 2\nsasLM::Skewness(dat$points)\n\n[1] 1.009318\n\n# Kurtosis - Type 2\nsasLM::Kurtosis(dat$points)\n\n[1] -0.2991564"
  },
  {
    "objectID": "R/summary_skew_kurt.html#reference",
    "href": "R/summary_skew_kurt.html#reference",
    "title": "Skewness/Kurtosis",
    "section": "",
    "text": "NoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package   * version date (UTC) lib source\n   class       7.3-22  2023-05-03 [2] CRAN (R 4.4.2)\n P cli         3.6.3   2024-06-21 [?] CRAN (R 4.4.0)\n P common    * 1.1.3   2024-04-05 [?] CRAN (R 4.4.0)\n P crayon      1.5.3   2024-06-20 [?] CRAN (R 4.4.0)\n P e1071     * 1.7-16  2024-09-16 [?] CRAN (R 4.4.1)\n P evaluate    1.0.0   2024-09-17 [?] CRAN (R 4.4.1)\n P fansi       1.0.6   2023-12-08 [?] CRAN (R 4.4.0)\n P fmtr        1.6.5   2024-06-13 [?] CRAN (R 4.4.0)\n P glue        1.8.0   2024-09-30 [?] CRAN (R 4.4.1)\n   highr       0.11    2024-05-26 [1] CRAN (R 4.4.0)\n P jpeg        0.1-10  2022-11-29 [?] CRAN (R 4.4.0)\n   knitr       1.50    2025-03-16 [1] RSPM (R 4.4.0)\n P lifecycle   1.0.4   2023-11-07 [?] CRAN (R 4.4.0)\n P magrittr    2.0.3   2022-03-30 [?] CRAN (R 4.4.0)\n   MASS        7.3-61  2024-06-13 [2] CRAN (R 4.4.2)\n P moments   * 0.14.1  2022-05-02 [?] CRAN (R 4.4.0)\n P mvtnorm   * 1.3-1   2024-09-03 [?] CRAN (R 4.4.1)\n P pillar      1.9.0   2023-03-22 [?] CRAN (R 4.4.0)\n P pkgconfig   2.0.3   2019-09-22 [?] CRAN (R 4.4.0)\n P procs     * 1.0.6   2024-03-06 [?] CRAN (R 4.4.0)\n P proxy       0.4-27  2022-06-09 [?] CRAN (R 4.4.0)\n P Rcpp        1.0.13  2024-07-17 [?] CRAN (R 4.4.0)\n P reporter    1.4.4   2024-03-19 [?] CRAN (R 4.4.0)\n P rlang       1.1.6   2025-04-11 [?] RSPM\n P sasLM     * 0.10.5  2024-10-02 [?] CRAN (R 4.4.1)\n P stringi     1.8.4   2024-05-06 [?] CRAN (R 4.4.0)\n P stringr     1.5.1   2023-11-14 [?] CRAN (R 4.4.0)\n P tibble    * 3.2.1   2023-03-20 [?] CRAN (R 4.4.0)\n P utf8        1.2.4   2023-10-22 [?] CRAN (R 4.4.0)\n P vctrs       0.6.5   2023-12-01 [?] CRAN (R 4.4.0)\n P withr       3.0.1   2024-07-31 [?] CRAN (R 4.4.0)\n   xfun        0.52    2025-04-02 [1] RSPM (R 4.4.0)\n P yaml        2.3.10  2024-07-26 [?] CRAN (R 4.4.0)\n P zip         2.3.1   2024-01-27 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/friedman_test.html",
    "href": "R/friedman_test.html",
    "title": "Friedman Test Analysis",
    "section": "",
    "text": "Friedman’s test is a non-parametric statistical test used to detect differences in treatments across multiple test attempts. It is often used when the assumptions of ANOVA are not met, particularly the assumption of normality. The test is applicable for repeated measures, or matched groups, making it useful for situations where the same subjects are subjected to different treatments.\nFriedman’s test ranks the data points within each block (or subject) separately, and then analyzes these ranks to see if the mean ranks differ between the groups and conditions. If the test shows significant differences, this suggests that at least one of the treatments differs from the others. Because it is non-parametric, it does not assume the normal distribution of data, which makes it robust for skewed or ordinal data.\n\n# Load required packages\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(rstatix)\n\n\n\nH₀ (Null Hypothesis): There are no significant differences in weight outcomes between the three diets\nH₁ (Alternative Hypothesis): There are significant differences in weight outcomes between at least two diets\n\n# Create the dataset\nDiet_A = c(75, 68, 80, 72, 85, 70, 82, 78, 75, 83)\n\nDiet_B = c(82, 70, 85, 78, 88, 75, 85, 80, 79, 87)\n\nDiet_C = c(78, 65, 82, 75, 84, 72, 80, 76, 77, 84)\n\ndata &lt;- tibble(\n  subjid = rep(1:10, 3),\n  diet = rep(c(\"A\", \"B\", \"C\"), each = 10),\n  weight = c(Diet_A, Diet_B, Diet_C)\n)\n\n\n\n\nTo run a Friedman’s test in R you can use the {stats} package. This will return the chi-squared test statistic and p-value.\n\n# Perform Friedman test\nfriedman_test &lt;- stats::friedman.test(weight ~ diet | subjid, data = data)\nfriedman_test |&gt;\n  broom::tidy()\n\n# A tibble: 1 × 4\n  statistic  p.value parameter method                \n      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                 \n1      15.2 0.000500         2 Friedman rank sum test\n\n\n\n\n\nAlternatively, you can use the {rstatix} package. While these packages give the same results, the {rstatix} results come as a tibble we can easily use.\n\ntest &lt;- data |&gt;\n  rstatix::friedman_test(weight ~ diet | subjid)\ntest\n\n# A tibble: 1 × 6\n  .y.        n statistic    df        p method       \n* &lt;chr&gt;  &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;        \n1 weight    10      15.2     2 0.000500 Friedman test\n\n\n\n# Create boxplot\nggplot(data, aes(x = diet, y = weight, fill = diet)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(\n    title = \"Weight Distribution Across Different Diets\",\n    x = \"Diet Type\",\n    y = \"Weight\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nBased on the analysis:\n\nStatistical Test Results:\n\n\nThe Friedman test yielded a p-value of 5.0045143^{-4}\n\n[If p &lt; 0.05, we reject the null hypothesis\nIf p &gt; 0.05, we fail to reject the null hypothesis]\n\nVisual Analysis:\n\n\nFrom the boxplot, Diet B shows the highest median weight\nDiet B also appears to have the highest overall weight distribution\nDiet A and Diet C show similar distributions but lower than Diet B\n\n\nInterpretation:\n\n\nIf the goal is weight gain: Diet B appears most effective\nIf the goal is weight maintenance: Diet A or C might be more suitable\nHowever, individual responses vary, as shown by the overlapping distributions"
  },
  {
    "objectID": "R/friedman_test.html#friedman-test-analysis",
    "href": "R/friedman_test.html#friedman-test-analysis",
    "title": "Friedman Test Analysis",
    "section": "",
    "text": "Friedman’s test is a non-parametric statistical test used to detect differences in treatments across multiple test attempts. It is often used when the assumptions of ANOVA are not met, particularly the assumption of normality. The test is applicable for repeated measures, or matched groups, making it useful for situations where the same subjects are subjected to different treatments.\nFriedman’s test ranks the data points within each block (or subject) separately, and then analyzes these ranks to see if the mean ranks differ between the groups and conditions. If the test shows significant differences, this suggests that at least one of the treatments differs from the others. Because it is non-parametric, it does not assume the normal distribution of data, which makes it robust for skewed or ordinal data.\n\n# Load required packages\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(rstatix)\n\n\n\nH₀ (Null Hypothesis): There are no significant differences in weight outcomes between the three diets\nH₁ (Alternative Hypothesis): There are significant differences in weight outcomes between at least two diets\n\n# Create the dataset\nDiet_A = c(75, 68, 80, 72, 85, 70, 82, 78, 75, 83)\n\nDiet_B = c(82, 70, 85, 78, 88, 75, 85, 80, 79, 87)\n\nDiet_C = c(78, 65, 82, 75, 84, 72, 80, 76, 77, 84)\n\ndata &lt;- tibble(\n  subjid = rep(1:10, 3),\n  diet = rep(c(\"A\", \"B\", \"C\"), each = 10),\n  weight = c(Diet_A, Diet_B, Diet_C)\n)\n\n\n\n\nTo run a Friedman’s test in R you can use the {stats} package. This will return the chi-squared test statistic and p-value.\n\n# Perform Friedman test\nfriedman_test &lt;- stats::friedman.test(weight ~ diet | subjid, data = data)\nfriedman_test |&gt;\n  broom::tidy()\n\n# A tibble: 1 × 4\n  statistic  p.value parameter method                \n      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                 \n1      15.2 0.000500         2 Friedman rank sum test\n\n\n\n\n\nAlternatively, you can use the {rstatix} package. While these packages give the same results, the {rstatix} results come as a tibble we can easily use.\n\ntest &lt;- data |&gt;\n  rstatix::friedman_test(weight ~ diet | subjid)\ntest\n\n# A tibble: 1 × 6\n  .y.        n statistic    df        p method       \n* &lt;chr&gt;  &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;        \n1 weight    10      15.2     2 0.000500 Friedman test\n\n\n\n# Create boxplot\nggplot(data, aes(x = diet, y = weight, fill = diet)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(\n    title = \"Weight Distribution Across Different Diets\",\n    x = \"Diet Type\",\n    y = \"Weight\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nBased on the analysis:\n\nStatistical Test Results:\n\n\nThe Friedman test yielded a p-value of 5.0045143^{-4}\n\n[If p &lt; 0.05, we reject the null hypothesis\nIf p &gt; 0.05, we fail to reject the null hypothesis]\n\nVisual Analysis:\n\n\nFrom the boxplot, Diet B shows the highest median weight\nDiet B also appears to have the highest overall weight distribution\nDiet A and Diet C show similar distributions but lower than Diet B\n\n\nInterpretation:\n\n\nIf the goal is weight gain: Diet B appears most effective\nIf the goal is weight maintenance: Diet A or C might be more suitable\nHowever, individual responses vary, as shown by the overlapping distributions"
  },
  {
    "objectID": "R/friedman_test.html#reference",
    "href": "R/friedman_test.html#reference",
    "title": "Friedman Test Analysis",
    "section": "Reference",
    "text": "Reference\nCite all sources and references used in the analysis.\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package        * version    date (UTC) lib source\n P abind            1.4-8      2024-09-12 [?] CRAN (R 4.4.1)\n   askpass          1.2.1      2024-10-04 [1] CRAN (R 4.4.1)\n P backports        1.5.0      2024-05-23 [?] CRAN (R 4.4.0)\n   base64enc        0.1-3      2015-07-28 [1] CRAN (R 4.4.0)\n   bit              4.5.0      2024-09-20 [1] CRAN (R 4.4.1)\n   bit64            4.5.2      2024-09-22 [1] CRAN (R 4.4.1)\n   blob             1.2.4      2023-03-17 [1] CRAN (R 4.4.0)\n   boot             1.3-31     2024-08-28 [2] CRAN (R 4.4.2)\n P broom          * 1.0.7      2024-09-26 [?] CRAN (R 4.4.1)\n   bslib            0.8.0      2024-07-29 [1] CRAN (R 4.4.0)\n   cachem           1.1.0      2024-05-16 [1] CRAN (R 4.4.0)\n   callr            3.7.6      2024-03-25 [1] CRAN (R 4.4.0)\n   car              3.1-3      2024-09-27 [1] RSPM (R 4.4.0)\n P carData          3.0-5      2022-01-06 [?] CRAN (R 4.4.0)\n   cellranger       1.1.0      2016-07-27 [1] CRAN (R 4.4.0)\n P cli              3.6.3      2024-06-21 [?] CRAN (R 4.4.0)\n   clipr            0.8.0      2022-02-22 [1] CRAN (R 4.4.0)\n P colorspace       2.1-1      2024-07-26 [?] CRAN (R 4.4.0)\n   conflicted       1.2.0      2023-02-01 [1] CRAN (R 4.4.0)\n   corrplot         0.94       2024-08-17 [1] CRAN (R 4.4.0)\n   cowplot          1.1.3      2024-01-22 [1] CRAN (R 4.4.0)\n   cpp11            0.5.0      2024-08-27 [1] CRAN (R 4.4.1)\n   crayon           1.5.3      2024-06-20 [1] CRAN (R 4.4.0)\n   curl             5.2.3      2024-09-20 [1] CRAN (R 4.4.1)\n   data.table       1.16.0     2024-08-27 [1] CRAN (R 4.4.1)\n   DBI              1.2.3      2024-06-02 [1] CRAN (R 4.4.0)\n   dbplyr           2.5.0      2024-03-19 [1] CRAN (R 4.4.0)\n   Deriv            4.1.6      2024-09-13 [1] CRAN (R 4.4.1)\n P digest           0.6.37     2024-08-19 [?] CRAN (R 4.4.1)\n   doBy             4.6.24     2024-10-07 [1] CRAN (R 4.4.1)\n P dplyr          * 1.1.4      2023-11-17 [?] CRAN (R 4.4.0)\n   dtplyr           1.3.1      2023-03-22 [1] CRAN (R 4.4.0)\n P evaluate         1.0.0      2024-09-17 [?] CRAN (R 4.4.1)\n P fansi            1.0.6      2023-12-08 [?] CRAN (R 4.4.0)\n P farver           2.1.2      2024-05-13 [?] CRAN (R 4.4.0)\n P fastmap          1.2.0      2024-05-15 [?] CRAN (R 4.4.0)\n   fontawesome      0.5.2      2023-08-19 [1] CRAN (R 4.4.0)\n P forcats        * 1.0.0      2023-01-29 [?] CRAN (R 4.4.0)\n P Formula          1.2-5      2023-02-24 [?] CRAN (R 4.4.0)\n   fs               1.6.4      2024-04-25 [1] CRAN (R 4.4.0)\n   gargle           1.5.2      2023-07-20 [1] CRAN (R 4.4.0)\n P generics         0.1.3      2022-07-05 [?] CRAN (R 4.4.0)\n P ggplot2        * 3.5.1      2024-04-23 [?] CRAN (R 4.4.0)\n P glue             1.8.0      2024-09-30 [?] CRAN (R 4.4.1)\n   googledrive      2.1.1      2023-06-11 [1] CRAN (R 4.4.0)\n   googlesheets4    1.1.1      2023-06-11 [1] CRAN (R 4.4.0)\n P gtable           0.3.5      2024-04-22 [?] CRAN (R 4.4.0)\n   haven            2.5.4      2023-11-30 [1] CRAN (R 4.4.0)\n   highr            0.11       2024-05-26 [1] CRAN (R 4.4.0)\n P hms              1.1.3      2023-03-21 [?] CRAN (R 4.4.0)\n P htmltools        0.5.8.1    2024-04-04 [?] CRAN (R 4.4.0)\n   httr             1.4.7      2023-08-15 [1] CRAN (R 4.4.0)\n   ids              1.0.1      2017-05-31 [1] CRAN (R 4.4.0)\n   isoband          0.2.7      2022-12-20 [1] CRAN (R 4.4.0)\n   jquerylib        0.1.4      2021-04-26 [1] CRAN (R 4.4.0)\n P jsonlite         1.8.9      2024-09-20 [?] CRAN (R 4.4.1)\n   knitr            1.50       2025-03-16 [1] RSPM (R 4.4.0)\n P labeling         0.4.3      2023-08-29 [?] CRAN (R 4.4.0)\n   lattice          0.22-6     2024-03-20 [2] CRAN (R 4.4.2)\n P lifecycle        1.0.4      2023-11-07 [?] CRAN (R 4.4.0)\n   lme4             1.1-35.5   2024-07-03 [1] CRAN (R 4.4.0)\n P lubridate      * 1.9.3      2023-09-27 [?] CRAN (R 4.4.0)\n P magrittr         2.0.3      2022-03-30 [?] CRAN (R 4.4.0)\n   MASS             7.3-61     2024-06-13 [2] CRAN (R 4.4.2)\n   Matrix           1.7-1      2024-10-18 [2] CRAN (R 4.4.2)\n   MatrixModels     0.5-3      2023-11-06 [1] CRAN (R 4.4.0)\n   memoise          2.0.1      2021-11-26 [1] CRAN (R 4.4.0)\n   mgcv             1.9-1      2023-12-21 [2] CRAN (R 4.4.2)\n   microbenchmark   1.5.0      2024-09-04 [1] CRAN (R 4.4.1)\n   mime             0.12       2021-09-28 [1] CRAN (R 4.4.0)\n   minqa            1.2.8      2024-08-17 [1] CRAN (R 4.4.0)\n   modelr           0.1.11     2023-03-22 [1] CRAN (R 4.4.0)\n P munsell          0.5.1      2024-04-01 [?] CRAN (R 4.4.0)\n   nlme             3.1-166    2024-08-14 [2] CRAN (R 4.4.2)\n   nloptr           2.1.1      2024-06-25 [1] CRAN (R 4.4.0)\n   nnet             7.3-19     2023-05-03 [2] CRAN (R 4.4.2)\n   numDeriv         2016.8-1.1 2019-06-06 [1] CRAN (R 4.4.0)\n   openssl          2.2.2      2024-09-20 [1] CRAN (R 4.4.1)\n   pbkrtest         0.5.3      2024-06-26 [1] CRAN (R 4.4.0)\n P pillar           1.9.0      2023-03-22 [?] CRAN (R 4.4.0)\n P pkgconfig        2.0.3      2019-09-22 [?] CRAN (R 4.4.0)\n   prettyunits      1.2.0      2023-09-24 [1] CRAN (R 4.4.0)\n   processx         3.8.4      2024-03-16 [1] CRAN (R 4.4.0)\n   progress         1.2.3      2023-12-06 [1] CRAN (R 4.4.0)\n   ps               1.8.0      2024-09-12 [1] CRAN (R 4.4.1)\n P purrr          * 1.0.2      2023-08-10 [?] CRAN (R 4.4.0)\n   quantreg         5.98       2024-05-26 [1] CRAN (R 4.4.0)\n P R6               2.5.1      2021-08-19 [?] CRAN (R 4.4.0)\n   ragg             1.3.3      2024-09-11 [1] CRAN (R 4.4.1)\n   rappdirs         0.3.3      2021-01-31 [1] CRAN (R 4.4.0)\n   RColorBrewer     1.1-3      2022-04-03 [1] CRAN (R 4.4.0)\n   Rcpp             1.0.13     2024-07-17 [1] CRAN (R 4.4.0)\n   RcppEigen        0.3.4.0.2  2024-08-24 [1] CRAN (R 4.4.1)\n P readr          * 2.1.5      2024-01-10 [?] CRAN (R 4.4.0)\n   readxl           1.4.3      2023-07-06 [1] CRAN (R 4.4.0)\n   rematch          2.0.0      2023-08-30 [1] CRAN (R 4.4.0)\n   rematch2         2.1.2      2020-05-01 [1] CRAN (R 4.4.0)\n   reprex           2.1.1      2024-07-06 [1] CRAN (R 4.4.0)\n P rlang            1.1.4      2024-06-04 [?] CRAN (R 4.4.0)\n P rmarkdown        2.28       2024-08-17 [?] CRAN (R 4.4.0)\n P rstatix        * 0.7.2      2023-02-01 [?] CRAN (R 4.4.0)\n P rstudioapi       0.16.0     2024-03-24 [?] CRAN (R 4.4.0)\n   rvest            1.0.4      2024-02-12 [1] CRAN (R 4.4.0)\n   sass             0.4.9      2024-03-15 [1] CRAN (R 4.4.0)\n P scales           1.3.0      2023-11-28 [?] CRAN (R 4.4.0)\n   selectr          0.4-2      2019-11-20 [1] CRAN (R 4.4.0)\n   SparseM          1.84-2     2024-07-17 [1] CRAN (R 4.4.0)\n P stringi          1.8.4      2024-05-06 [?] CRAN (R 4.4.0)\n P stringr        * 1.5.1      2023-11-14 [?] CRAN (R 4.4.0)\n   survival         3.7-0      2024-06-05 [1] CRAN (R 4.4.0)\n   sys              3.4.3      2024-10-04 [1] CRAN (R 4.4.1)\n   systemfonts      1.1.0      2024-05-15 [1] CRAN (R 4.4.0)\n   textshaping      0.4.0      2024-05-24 [1] CRAN (R 4.4.0)\n P tibble         * 3.2.1      2023-03-20 [?] CRAN (R 4.4.0)\n P tidyr          * 1.3.1      2024-01-24 [?] CRAN (R 4.4.0)\n P tidyselect       1.2.1      2024-03-11 [?] CRAN (R 4.4.0)\n P tidyverse      * 2.0.0      2023-02-22 [?] CRAN (R 4.4.0)\n P timechange       0.3.0      2024-01-18 [?] CRAN (R 4.4.0)\n   tinytex          0.53       2024-09-15 [1] CRAN (R 4.4.1)\n P tzdb             0.4.0      2023-05-12 [?] CRAN (R 4.4.0)\n P utf8             1.2.4      2023-10-22 [?] CRAN (R 4.4.0)\n   uuid             1.2-1      2024-07-29 [1] CRAN (R 4.4.0)\n P vctrs            0.6.5      2023-12-01 [?] CRAN (R 4.4.0)\n   viridisLite      0.4.2      2023-05-02 [1] CRAN (R 4.4.0)\n   vroom            1.6.5      2023-12-05 [1] CRAN (R 4.4.0)\n P withr            3.0.1      2024-07-31 [?] CRAN (R 4.4.0)\n   xfun             0.52       2025-04-02 [1] RSPM (R 4.4.0)\n   xml2             1.3.6      2023-12-04 [1] CRAN (R 4.4.0)\n P yaml             2.3.10     2024-07-26 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "R/ttest_1Sample.html",
    "href": "R/ttest_1Sample.html",
    "title": "One Sample t-test",
    "section": "",
    "text": "The One Sample t-test is used to compare a single sample against an expected hypothesis value. In the One Sample t-test, the mean of the sample is compared against the hypothesis value. In R, a One Sample t-test can be performed using the Base R t.test() from the stats package or the proc_ttest() function from the procs package."
  },
  {
    "objectID": "R/ttest_1Sample.html#normal",
    "href": "R/ttest_1Sample.html#normal",
    "title": "One Sample t-test",
    "section": "Normal Data",
    "text": "Normal Data\nBy default, the R one sample t-test functions assume normality in the data and use a classic Student’s t-test.\n\nBase R\n\nCode\nThe following code was used to test the comparison in Base R. Note that the baseline null hypothesis goes in the “mu” parameter.\n\n# Perform t-test\nstats::t.test(read$score, mu = 30)\n\n\n    One Sample t-test\n\ndata:  read$score\nt = 2.3643, df = 29, p-value = 0.02497\nalternative hypothesis: true mean is not equal to 30\n95 percent confidence interval:\n 30.67928 39.38739\nsample estimates:\nmean of x \n 35.03333 \n\n\n\n\n\nProcs Package\n\nCode\nThe following code from the procs package was used to perform a one sample t-test. Note that the null hypothesis value goes in the “options” parameter.\n\nlibrary(procs)\n\n# Perform t-test\nprocs::proc_ttest(read, var = score, options = c(\"h0\" = 30))\n\n$Statistics\n    VAR  N     MEAN      STD   STDERR MIN MAX\n1 score 30 35.03333 11.66038 2.128884  14  54\n\n$ConfLimits\n    VAR     MEAN     LCLM     UCLM      STD  LCLMSTD  UCLMSTD\n1 score 35.03333 30.67928 39.38739 11.66038 9.286404 15.67522\n\n$TTests\n    VAR DF        T     PROBT\n1 score 29 2.364306 0.0249741\n\n\nViewer Output:"
  },
  {
    "objectID": "R/ttest_1Sample.html#lognormal",
    "href": "R/ttest_1Sample.html#lognormal",
    "title": "One Sample t-test",
    "section": "Lognormal Data",
    "text": "Lognormal Data\nThe Base R t.test() function does not have an option for lognormal data. Likewise, the procs proc_ttest() function also does not have an option for lognormal data.\nOne possibility may be the tTestLnormAltPower() function from the EnvStats package. This package has not been evaluated yet.\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package * version date (UTC) lib source\n   knitr     1.50    2025-03-16 [1] RSPM (R 4.4.0)\n P procs   * 1.0.6   2024-03-06 [?] CRAN (R 4.4.0)\n P tibble    3.2.1   2023-03-20 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "minutes/meetings/2024-02-12.html",
    "href": "minutes/meetings/2024-02-12.html",
    "title": "Website structure update, Team list, Conferences",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n12_Feb_24\n\n\n\n\nChristina Fillmore\nYes\n\n\nLyn Taylor\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBrian Varney\nYes\n\n\nChi Zhang\nYes\n\n\nOrla Doyle\nNo\n\n\nHarshal Khanolkar\nNo\n\n\nLily Hseih\nNo\n\n\nFilip Kabaj\nNo\n\n\nMartin Brown\nYes\n\n\nMin-Hua Jen\nNo\n\n\nSarah Rathwell\nYes\n\n\nKasa Andras\nNo\n\n\nAditee Dani\nYes\n\n\nKeaven Anderson\nYes\n\n\nBenjamin Arancibia\nYes\n\n\nWilmar Igl\nYes\n\n\nVikash Jain\nYes\n\n\nMia Qi\nYes\n\n\nLeon Shi\nYes\n\n\nVandaya Yadav\nYes\n\n\nStephen McCawille\nYes\n\n\nVikrant Vijay\nYes\n\n\nVidya Gopal\nYes\n\n\nDhvani Patel\nYes\n\n\nKyle Lee\nYes\n\n\nChelsea Dickens\nNo\n\n\nDavid Bosak\nNo\n\n\nMichael Kane\nNo\n\n\nLukas Brausch\nNo\n\n\nMichael Walshe\nNo\n\n\nSeemani Abhilipsa\nNo\n\n\nAiming Yang\nNo\n\n\nCuifeng Yin\nNo\n\n\nTodd Coffey\nNo\n\n\nJayashree Vedanayagam\nNo\n\n\nAshwath Gadapa\nNo\n\n\nMiriam Amor\nNo\n\n\nAnwesha Roy\nNo\n\n\nSamrit Pramanik\nNo\n\n\nAgnieszka Tomczyk\nNo\n\n\nPrem Kant Shekhar\nNo\n\n\nSunil\nNo\n\n\nKate Booth\nNo\n\n\nPeilin Zhou\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\n\nUpdated website demo – Chi & Christina\nCAMIS membership form / data collection – Lyn\nhttps://docs.google.com/forms/d/e/1FAIpQLSdDX79P5ByStVS_3n4tK1mAWidazIiF6DMEtDMK8KqmJywjqA/viewform?vc=0&c=0&w=1&flr=0&usp=mail_form_link\nNOTE:  We will only collect: team members name, email address, organization, software used, interested in oncology, key interests and affiliations to stats organizations.  The email address is solely for the CAMIS leadership team, to make sure you are included in CAMIS emails.\nWe ask on the form: “Are you happy for your Name and company and interests to be visible on the CAMIS website. Note that email addresses will not be visible”. \nIf you do not give permission then your name will not appear on the CAMIS repo as a CAMIS team member. If you do give permission, your name and company and interests will appear but your email addresses will be hidden from public view. At any time you can ask to be removed from the website team list by emailing me.\nPhuse css workshop for 2024 / CAMIS ONCO– Soma/Vikash/Harshil\n\nFilip, Lyn & Chrstina met re: Python content\nNext steps for workshop & white paper\n\nOther conferences\n\nKeaven - attending JSM & ISBN - and will mention CAMIS.\nChi attending use R conference, Lyn/Christina/All: please review abstract if you wish.\nRegulatory stats workshop: Leon Shih (poster)\n\nVolunteers requested for:\n\nOpenstatsware Bayesian MMRM  {brms.mmrm} package input :  Christine/Orla\nMMRM - Volunteer please to look at Proc Mixed vs Proc GLIMMIX for the SAS/mmrm.qmd file (Stephen McCawille & Leon Shi may be able to look at this in future ).\n\nAOB\n\nChristina: Create a 1 slide - This is CAMIS.\nLyn: Load up Dec2023 blog post\nChi: Add links to blogs & add blog tab when we have content"
  },
  {
    "objectID": "minutes/meetings/2025-07-14.html",
    "href": "minutes/meetings/2025-07-14.html",
    "title": "Package selection",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n14_Jul_25\n\n\n\n\nLyn Taylor\nYes\n\n\nChristina Fillmore\nYes\n\n\nChi Zhang\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBenjamin Arancibia\nNo\n\n\nMichael Kane\nNo\n\n\nMartin Brown\nNo\n\n\nStephen McCawille\nNo\n\n\nMiriam Amor\nNo\n\n\nPeilin Zhou\nYes\n\n\nSamrit Pramanik\nNo\n\n\nBrian Varney\nYes\n\n\nVikrant Vijay\nNo\n\n\nYannick Vandendijck\nYes\n\n\nVikash Jain\nNo\n\n\nMichael Walshe\nYes\n\n\nAnwesha Roy\nNo\n\n\nMin-Hua Jen\nYes\n\n\nJaskaran Saini\nYes\n\n\nMariusz Zieba\nNo\n\n\nChelsea Dickens\nNo\n\n\nTejas Pandit\nYes\n\n\nAshwath Gadapa\nYes\n\n\nSarah Brosens\nYes\n\n\nKirsten Findlay\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\nConferences.\n\nBrian attending SAS users in the fall,\nYannick got a poster accepted for ISBC & has a PHUSE EU presentation. \nLyn & christina attended PSI - lots of interest in CAMIS, many had heard of us, but lots of people still using SAS as their main programing language. Hence, we expect usage of our site to increase as more companies transition to R. Currently, we have a steady 10-30 unique people viewing the website each day.\nAll to update the Conferences.qmd with any confences you are attending.\n\nNext steps for CAMIS.\n\nOver next few months, leadership team to do a review of current content & identify where improvements are needed. Identify new issues - & assign.\nWe plan to follow up with people assigned issues, but that we haven’t heard from for a while. Chase up missing content.\n\nHow to select packages to use in the comparison.\nChristina presented slides from PSI Conferenece with respect to how to check packages for best use see CAMIS\nBrian suggested another useful package to run is pkgdiff written by david bossock, this checks through packages for changes that may break prevoius code and gives a stability score. https://github.com/lvc/pkgdiff\nMichael also suggested you can use https://diffify.com/R to look at the differences between packages."
  },
  {
    "objectID": "minutes/meetings/2024-08-12.html",
    "href": "minutes/meetings/2024-08-12.html",
    "title": "Novartis Hackathon & Content growth",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n12_Aug_24\n\n\n\n\nChristina Fillmore\nYes\n\n\nLyn Taylor\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBrian Varney\nYes\n\n\nChi Zhang\nYes\n\n\nOrla Doyle\nNo\n\n\nHarshal Khanolkar\nYes\n\n\nLily Hseih\nNo\n\n\nFilip Kabaj\nNo\n\n\nMartin Brown\nNo\n\n\nMin-Hua Jen\nNo\n\n\nSarah Rathwell\nNo\n\n\nKasa Andras\nNo\n\n\nAditee Dani\nNo\n\n\nKeaven Anderson\nYes\n\n\nBenjamin Arancibia\nNo\n\n\nWilmar Igl\nNo\n\n\nVikash Jain\nNo\n\n\nMia Qi\nNo\n\n\nLeon Shi\nNo\n\n\nVandaya Yadav\nNo\n\n\nStephen McCawille\nYes\n\n\nVikrant Vijay\nNo\n\n\nVidya Gopal\nNo\n\n\nDhvani Patel\nNo\n\n\nKyle Lee\nNo\n\n\nChelsea Dickens\nNo\n\n\nDavid Bosak\nYes\n\n\nMichael Kane\nNo\n\n\nLukas Brausch\nNo\n\n\nMichael Walshe\nYes\n\n\nSeemani Abhilipsa\nYes\n\n\nAiming Yang\nNo\n\n\nCuifeng Yin\nYes\n\n\nTodd Coffey\nNo\n\n\nJayashree Vedanayagam\nYes\n\n\nAshwath Gadapa\nYes\n\n\nMiriam Amor\nYes\n\n\nAnwesha Roy\nYes\n\n\nSamrit Pramanik\nYes\n\n\nAgnieszka Tomczyk\nYes\n\n\nPrem Kant Shekhar\nNo\n\n\nSunil\nNo\n\n\nKate Booth\nNo\n\n\nPeilin Zhou\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\nWelcome\nWelcome to our new team members on the call.  We have an agenda which is sent prior to the meeting, but please do please ask if you have questions or need clarification regarding what we are talking about.\n\nRepository Content\nNovartis Hackathon\nThe Hackathon was a great success, with CAMIS receiving it’s largest amount of pull requests in any one month to date ! Christina fed back that it was not as much work as you might think, as although they had ‘office hours’ to help people and discuss things, actually not many people used them. Instead, they gave a brief introduction to everyone attending, explaining git / github / pull requests etc, then assigned everyone a topic / mini projects to investigate and let them do the research in their own time.\nOrla & team reviewed each others pull requests prior to submission to CAMIS repo. Christina worked alongside the team approving the content to go live.\nAs it went so well, Christina is planning another hackathon style event in October, but it will be on wider concept, focused on people who haven’t done pull requests to get more involved with open source projects. We can submit CAMIS topics for them to complete.\nIf you or your company interested in hackathon ask christina.\nSurvival\nWill continue to meet and discuss survival needs, some Accelerated failure time content going in as part of hackathon.\nAssignment table / Raising issues\nACTION: Lyn to remove and we will use issues instead, If you have been on a issue for &gt;6 months and have not provided us with any feedback on your progress, then you will be unassigned. Obviously if you need more time and are still working on it, just let Christina or another one of the project leads know.\nIf you want to research a topic, please add an issue or issue comment to tell us what you are working on.\nEnsuring content quality & cross page cohesiveness\nTo date, focus was on population of the pages we were missing, however as we move towards having content available, we will need people to review that content to ensure it is of high quality and makes sense. Ideally, the same dataset would be run through R and SAS showing options, then the comparison would discuss the discrepancies in the results obtained and perhaps the differences in default options / available options.\nWe now have a template for the SAS, and R pages.. and a different one for the comparison pages. This may help us with consistency. Please use the templates if you are starting the work now, it’s Ok to do a PR for anything you are already working on, even if the template wasn’t used.\n\n\nConferences\n\nPHUSE EU Brussels 23rd Sept - Qian Wang (Merck) will attend.\nR/Pharma APAC track – Samrit has submitted an abstract so hopefully will be able to represent us.\nSouthEast SAS User Group (SESUG) – Bethesda: Brian will give us a mention.\nPHUSE EU – Stephen Mccawille, Anwesha Roy, Agniekska Tomczyk & Christina Fillmore are all attending PHUSE EU – if you are attending let Christina know and she will arrange for CAMIS team to meet up for a cuppa & chat at the conference.\nPhuse US Connect November: Maryland. Cuifeng Yin may be able to attend. Lyn asked for volunteers to represent us a US connect and maybe CSS? ACTION : ask PHUSE re: getting a workshop or seminar for CAMIS if we can find volunteers, TBC if at (US CONNECT / or CSS? Or both? )\nChi provided feedback from UseR! We may consider using a better title for abstracts, not just CAMIS. The talk was put into a community stream instead of a multilingual programming stream, so may have got better attendance, but still it was well received. 1 person attended requested that they would like to write an article on CAMIS, so Chi will work with them on that."
  },
  {
    "objectID": "minutes/meetings/2025-01-03.html",
    "href": "minutes/meetings/2025-01-03.html",
    "title": "CAMIS Objectives 2025",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n13_Jan_25\n\n\n\n\nLyn Taylor\nYes\n\n\nChristina Fillmore\nYes\n\n\nChi Zhang\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBenjamin Arancibia\nYes\n\n\nMichael Kane\nYes\n\n\nMartin Brown\nYes\n\n\nStephen McCawille\nYes\n\n\nMiriam Amor\nYes\n\n\nPeilin Zhou\nYes\n\n\nSamrit Pramanik\nYes\n\n\nBrian Varney\nYes\n\n\nVikrant Vijay\nYes\n\n\nYannick Vandendijck\nYes\n\n\nVikash Jain\nYes\n\n\nMichael Walshe\nYes\n\n\nAnwesha Roy\nYes\n\n\nMin-Hua Jen\nNo\n\n\nJaskaran Saini\nNo\n\n\nMariusz Zieba\nNo\n\n\nChelsea Dickens\nNo\n\n\nTejas Pandit\nNo\n\n\nAshwath Gadapa\nNo\n\n\nSarah Brosens\nNo\n\n\nKirsten Findlay\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\n2025 Objectives\nCommunication\n    -   Expanding awareness within companies\n\n    -   More Through PSI (statistician in the pharmaceutical industry) contacts\n\n        -   Volunteers required for: 2025: 3 x series of CAMIS workshops\n\n        -   Introduction to CAMIS project /how to use it contribute\n        \n        -   Key findings of CAMIS project\n        \n        -   How do you do comparisons in software.\n\n\n    -   Other organizations, ASA /OpenStatsWare, EFSPI will be covered through PSI, RinPharma (hosting services YouTube), ISBC -Aug Basel Yannick offered to submit abstract & present on our behalf.\n        ACTION: Lyn to send latest version of slides: & load to website.\n\n    -   Expand awareness to university contacts. Michael Kane can provide introductions through R medicine. Will raise at next meeting to see if we can find an interested professor. There is a desire for students to want projects in pharma topics (master students) -- especially regulatory. We are happy to offer presentations/ workshops to anything they want. (Stephen Waugh could present his experience?)\nConferences\nIf anyone can attend to represent us let us know, we can help with abstracts / slides.\n    -   posit::conf(2025)** Get the full details on [the blog post](https://urldefense.com/v3/__https:/info.posit.co/NzA5LU5YTi03MDYAAAGX8BSQdqgtSXVvlxo3uOEKf6cyZbztuQua15w8xXZxe1apl5i8EF9CsQLDaXVdqYXWvjSHzLo=__;!!GfteaDio!aUG_6o_VjPNuaS8HtZgYUS61J7SQrYdKV_-mpyMEkGutGnBN9WATMv9lIk5MflS0BofTiViRryNVUD4_9A$). Closes 3^rd^ Feb. Talks are 20 minutes long \\'pharma stream\\' and will be delivered in person in Atlanta on September 17 or 18 **Volunteers..**\n\n    -   PHUSE -- SDEs / Conferences..... Volunteers..\n\n        -   **PHUSE US connect:** [PHUSE US Connect 2025 \\| CDISC](https://www.cdisc.org/events/education/external-events/2025/03/phuse-us-connect-2025)  16^th^-19^th^ March.. Lyn to send content to Mike????\n\n    -   ISBC Feb 14^th^, Yannick will submit abstract\n\n    -   PharmaSUg conference **Volunteers..**\n\n    -   R medicine Volunteers. (Michael kane will be going). Vitual (Chi?)\n\n    -   R in Pharma Volunteers.\n\n    -   PSI Conference -- we have 2 talks.\nImproving social media frequency\nBlogs to summarise What are the latest repo updates, how do we showcase this on the website? Or by blogs (but how do people get made aware of them)!!!.\nACTION: Lyn to speak Harshil. Focused Role just to write Monthly blogs. – Bring in extra person to help if needed.\nImproving Technical back end\nWhen lyn tested new posit workbench method. Can do demo & give access to frequent contributors who struggle with package control using renv / rendering.\n\nChristina & Michael Walsh will update us at a later meeting. (Eg. PRs with dummy website views)\nStrategy for how to make Comparison pages more stable with respect to R version changes\nPossibility to include checks which run the code & check for change\n\nKey Topics to update MMRM (Stephen Waugh), CMH (lyn), Sample size (Agnieszka & Andisheh & Molly), re-organize logistic regression (Lyn/Chi), reference based multiple imputation (Yannick), Miriam (Generalized MMRM)**\nHighlights of key content that has been updated & Summary of findings.\nCoin package: Martin PPD to edit Wilcoxon signed rank Lyn let agnieska know. Stephen McCawille – propensity scores restriction on SAS so used R: to talk to christina."
  },
  {
    "objectID": "minutes/meetings/2023-02-13.html",
    "href": "minutes/meetings/2023-02-13.html",
    "title": "White Paper and Demo of connecting Rstudio with Github repo",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n13_feb_2023\n\n\n\n\nAiming Yang\nYes\n\n\nBen Arancibia\nYes\n\n\nBrian Varney\nYes\n\n\nChristina Fillmore\nYes\n\n\nChelsea Dickens\nNo\n\n\nChi Zhang\nNo\n\n\nClara Beck\nNo\n\n\nAditee Dani\nNo\n\n\nDoug Kelkoff\nNo\n\n\nDhvani Patel\nNo\n\n\nFilip Kabaj\nNo\n\n\nHarshal Khanolkar\nYes\n\n\nIris Wu\nNo\n\n\nJayashree Vedanayagam\nYes\n\n\nJoe Rickert\nNo\n\n\nKyle Lee\nNo\n\n\nLeon Shi\nYes\n\n\nLily Hsieh\nYes\n\n\nLyn Taylor\nYes\n\n\nMartin Brown\nYes\n\n\nMia Qi\nYes\n\n\nMichael Kane\nYes\n\n\nMichael Rimler\nYes\n\n\nMike Stackhouse\nNo\n\n\nMin-Hua Jen\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nMona Mehraj\nNo\n\n\nPaula Rowley\nNo\n\n\nSoma Sekhar Sriadibhatla\nNo\n\n\nVandana Yadav\nNo\n\n\nVidya Gopal\nNo\n\n\nVikash Jain\nNo\n\n\nWilmar Igl\nNo\n\n\nOrla Doyle\nNo\n\n\n\n\n\n\n\n\n\n\nMeeting minutes\nMin-Hua went through outstanding comments on the white paper.\nChristina did a demo of how to set up R studio to link through via git project to the CAMIS github repo. See “13Feb2023_Contributing to the CAMIS project_Setting up communication between github and R studio” for more information\n\n\nNext meeting: 13th March 2023: 4:30 UTC, 11:30 EST."
  },
  {
    "objectID": "minutes/meetings/2024-12-09.html",
    "href": "minutes/meetings/2024-12-09.html",
    "title": "CAMIS End of Year Thank you",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n09_Dec_24\n\n\n\n\nChristina Fillmore\nYes\n\n\nLyn Taylor\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBrian Varney\nYes\n\n\nChi Zhang\nNo\n\n\nOrla Doyle\nNo\n\n\nHarshal Khanolkar\nYes\n\n\nLily Hseih\nNo\n\n\nFilip Kabaj\nNo\n\n\nMartin Brown\nNo\n\n\nMin-Hua Jen\nNo\n\n\nSarah Rathwell\nNo\n\n\nKasa Andras\nNo\n\n\nAditee Dani\nNo\n\n\nKeaven Anderson\nNo\n\n\nBenjamin Arancibia\nYes\n\n\nWilmar Igl\nNo\n\n\nVikash Jain\nNo\n\n\nMia Qi\nNo\n\n\nLeon Shi\nNo\n\n\nVandaya Yadav\nNo\n\n\nStephen McCawille\nYes\n\n\nVikrant Vijay\nNo\n\n\nVidya Gopal\nNo\n\n\nDhvani Patel\nNo\n\n\nKyle Lee\nNo\n\n\nChelsea Dickens\nNo\n\n\nDavid Bosak\nNo\n\n\nMichael Kane\nYes\n\n\nLukas Brausch\nNo\n\n\nMichael Walshe\nYes\n\n\nSeemani Abhilipsa\nNo\n\n\nAiming Yang\nNo\n\n\nCuifeng Yin\nNo\n\n\nTodd Coffey\nNo\n\n\nJayashree Vedanayagam\nYes\n\n\nAshwath Gadapa\nNo\n\n\nMiriam Amor\nYes\n\n\nAnwesha Roy\nYes\n\n\nSamrit Pramanik\nYes\n\n\nAgnieszka Tomczyk\nNo\n\n\nPrem Kant Shekhar\nNo\n\n\nSunil\nNo\n\n\nKate Booth\nYes\n\n\nPeilin Zhou\nYes\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\n\n2024 resulted in 160 pull requests and 64 pages of new content\nCAMIS 2024 Awards\n\nLongest Serving Active members (from CSRMLW to CAMIS!): Brian Varney, Min-Hua & Mia Qi\nMost Pull Requests Reviewed: Orla Doyle\nMost Contributions (especially for python content): Seemani Abhilipsa & Lukas Brausch\nSection Closer (for general linear model section): David Bosak\nExpanding Project Remit: Yuli Sidi & Nan Xiao (EAST), and Michael Walshe (Survey stats)\nBest Written (SAS and R cumulative incidence functions): Lillian Yau\nMost Shocking Finding (epibasix package undocumented CI method): Molly Mcdiarmid\nRookie of the Year (From first PR to completing Wilcoxon signed rank section, presenting at PHUSE EU & winning Best Presentation award in the Analytics and Statistics Stream: Agnieszka Tomczyk\n\n\n2025 Objectives\nWorking group re: Improving Technical back end (CICD, tech team)\nVolunteers needed - So far Christina & Michael Walshe\nTo explore: - Posit workbench to improve rendering\n\nWhen PRs come in, be able to render view before pulling in\nStrategy for how to make Comparison pages more stable with respect to R version changes\nPossibility to include checks which run the code & check for change\n\nExpand our influence (particular through representation in USA)\nKey Content\n\nMMRM – Stephen Waugh\nSample size - Agnieszka & Andisheh & Molly\nTobit regression - Yannick\nCIs for Props & Logistic regression & RTSM- Lyn\n\nReview conference attendance at January 2025 meeting.\nAll to let us know any feedback or suggestions for 2025."
  },
  {
    "objectID": "minutes/meetings/2023-07-10.html",
    "href": "minutes/meetings/2023-07-10.html",
    "title": "Plan for Advertising CAMIS progress",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n10_july_2023\n\n\n\n\nAiming Yang\nNo\n\n\nBen Arancibia\nNo\n\n\nBrian Varney\nYes\n\n\nChristina Fillmore\nYes\n\n\nChelsea Dickens\nNo\n\n\nChi Zhang\nNo\n\n\nClara Beck\nNo\n\n\nAditee Dani\nNo\n\n\nDoug Kelkoff\nNo\n\n\nDhvani Patel\nNo\n\n\nFilip Kabaj\nNo\n\n\nHarshal Khanolkar\nYes\n\n\nIris Wu\nYes\n\n\nJayashree Vedanayagam\nYes\n\n\nJoe Rickert\nNo\n\n\nKyle Lee\nYes\n\n\nLeon Shi\nNo\n\n\nLily Hsieh\nYes\n\n\nLyn Taylor\nYes\n\n\nMartin Brown\nYes\n\n\nMia Qi\nYes\n\n\nMichael Kane\nNo\n\n\nMichael Rimler\nNo\n\n\nMike Stackhouse\nNo\n\n\nMin-Hua Jen\nNo\n\n\nMolly MacDiarmid\nYes\n\n\nMona Mehraj\nNo\n\n\nPaula Rowley\nNo\n\n\nSoma Sekhar Sriadibhatla\nYes\n\n\nVandana Yadav\nYes\n\n\nVidya Gopal\nNo\n\n\nVikash Jain\nYes\n\n\nWilmar Igl\nNo\n\n\nOrla Doyle\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda\n\nWelcome new members - Vandana Yadav (Novo Nordisk) and Iris Wu (incyte)\nCAMIS Advertisement Plan - Harshal\n\nWhite paper\nMolly poster prize\nConference plan\n\nWebsite\n\nMMRM/ Other\n\nCAMIS-ONCO / Prep for PHUSE CSS- Soma Sekhar\nAOB\n\nNext meeting 14th Aug. Lyn on vacation, do you want to go ahead or move back 1 week?\n\n\n\n\nMeeting minutes\nCAMIS Advertisement Plan\n\nBlog re: White paper - All to share link with colleagues and like on social media,\nBlog re: Molly poster prize - ACTION: Molly to write\nLinkedIn -\n\nShould we have our own account (CAMIS linkedIN account) or post through the other organizations. Could post through our own personal accounts & have them repost?\nACTION : Harshal to post from own personal account and we will assesss reach if we all like it and ask the organizations to repost it.\n\nAny other social media sites needed to be used? Twitter was popular but not so now so stick with LinkedIn.\nSpread awareness though individual departments working groups\nPHUSE SDE connect - talk / presentation / posters or interactive workshops at connect SDEs.\nPHUSE/ FDA CSS 2024 - Working groups interactive breakout sessions. create a DVOST break out sessions - see CSS Working Groups (phuse-events.org)\n\nMaybe take inspiration from this years event to see what format they take\nACTION Soma to report back after conference and we can plan for next year\n\nSocial media post on CAMIS engagement at conferences\nUtilise #CAMIS on social media.\nPharmaverse - Could we get a link from Pharmaverse\n\nACTION: Christina to see if we can get a link?\n\n\n\nConference plan. The conference plan on the website was reviewed and updated\n\nPHUSE FDA quarterly meeting. CAMIS invited to present. Plan to go through White paper concepts & website. Request a replacement to represent FDA on our group, since Kyle Lee no longer at FDA. Promote use of site to them. Likely to be in attendance someone from the Division of analytics and informatics in CEDER.\nPHUSE CSS: Somar producing poster. Also doing a talk on validation of oncology endpoints and why it’s important to introduce hybrid programming languanges. Will be representatives present from regulatory authorities\n\n\nWebsite progress: Christina\n\nMMRM (Ben Arancibia happy to contribute)\nOthers - Not much new content in last month. Please if anyone time please add content !\nShould we prioritize any areas, or in getting Python/Julia content. Currently we will just see what content people have, rather than priorizing however re-assess based on growth to see if we need to focus more on a single area and get more volunteers on key areas.\nFAQ Doc - still in progress\n\nCAMIS- ONCO: Soma Sekhar\n\nStarted work on poster due July 28th.\nAfter presentation could convert to a white paper. ACTION: send out a draft plan for white paper, & lyn to add to agenda for discussion next meeting. Planning to evaluate endpoints for oncology. Table of endpoints required for approval.\n\nAOB\nNext meeting 14th Aug. Lyn on vacation, will move back 1 week."
  },
  {
    "objectID": "minutes/meetings/2023-03-13.html",
    "href": "minutes/meetings/2023-03-13.html",
    "title": "White Paper, Website, ONCO, Volunteers, Conferences",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n13_mar_2023\n\n\n\n\nAiming Yang\nYes\n\n\nBen Arancibia\nYes\n\n\nBrian Varney\nYes\n\n\nChristina Fillmore\nYes\n\n\nChelsea Dickens\nNo\n\n\nChi Zhang\nNo\n\n\nClara Beck\nNo\n\n\nAditee Dani\nYes\n\n\nDoug Kelkoff\nNo\n\n\nDhvani Patel\nNo\n\n\nFilip Kabaj\nNo\n\n\nHarshal Khanolkar\nYes\n\n\nIris Wu\nNo\n\n\nJayashree Vedanayagam\nYes\n\n\nJoe Rickert\nNo\n\n\nKyle Lee\nYes\n\n\nLeon Shi\nYes\n\n\nLily Hsieh\nYes\n\n\nLyn Taylor\nYes\n\n\nMartin Brown\nYes\n\n\nMia Qi\nNo\n\n\nMichael Kane\nNo\n\n\nMichael Rimler\nYes\n\n\nMike Stackhouse\nNo\n\n\nMin-Hua Jen\nNo\n\n\nMolly MacDiarmid\nYes\n\n\nMona Mehraj\nNo\n\n\nPaula Rowley\nNo\n\n\nSoma Sekhar Sriadibhatla\nYes\n\n\nVandana Yadav\nNo\n\n\nVidya Gopal\nNo\n\n\nVikash Jain\nYes\n\n\nWilmar Igl\nNo\n\n\nOrla Doyle\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda\n\nWhite paper - Lyn\nWebsite progress - Christina\nCAMIS-ONCO - Soma Sekhar\nVolunteers Roles\nConference Reps\nAOB/ PHUSE feedback\n\n\n\nMeeting minutes\nWhite Paper Update: Lyn Min-Hua is sending the white paper to the PHUSE group lead for review soon just a bit more tidying to do following comments.\nWebsite progress: Christina\nThe home page now has the list of stats methods we are looking to collect data on.\nACTION :Christina to put actions for each stats method which we need help to complete into github. We will assign those already selected to the people below. This will enable people that want to help to be able to see which are available for people to select.\nCAMIS- ONCO: Soma Sekhar\n\nplan to launch later this week.\npossibly white paper/ conference presentation.\n\nReview of volunteer roles\n\nGeneral Co-ordination -Lyn\nWebsite Co-ordination / Home page table - Christina\nCAMIS-ONCO - Soma Sekhar\nCopying CSRMLW material to CAMIS\n\nCMH: Aiming Yang\nLinear Models: Brian Varney (ACTION: Set up call with Dani, Lyn, Vikash, christina, + anyone else whose interested in helping to please volunteer)\nMMRM: Ben Arancibia\nSurvival: Min-Hua Jen, Mia Qi\n\n\nACTION: Christina to also add “actions” for people to pick up the following duties.\n\nCo-ordinator for conference material - share standard slides/ content /abstracts\nVolunteer to design a CAMIS Logo\nSocial media rep - to co-ordinate posts (linkedIn/Twitter)\nConference reps/ attendees needed\n\nWe will also add a page which lists the conferences so we can collate and coordinate whose going with the hope of advertising the project more widely once we have content on the website. Include a column for timelines/ abstract deadlines.\n\n\n\n\n\n\n\n\n\n\n\nConference\nLocation\nDate\nMain Contact\nVolunteers to attend\nDetails\n\n\n\n\nPHUSE US Connect\nOrlando, Florida\n5-8 March 2023\nSoma Sekhar\n\nPresentation\n\n\nDISS (Duke industry statistics symposium)\nVirtual\n29-31st March 2023\nLyn Taylor\nMolly MacDiarmid\nPoster\n\n\nPSDM(Pharmaceutical statistics and data management)\nNetherlands\n19 Apr 2023\n\n\n\n\n\nIASCT (ConSPIC - conference for statistics and programming in clinical research)\nBengaluru, India\n4-6 May 2023\nHarshal Khanolkar\nHarshal Khanolkar\n\n\n\nPSI 2023 Conference\nHammersmith London West, England\n11-14 June 2023\nMartin Brown\nChristina Fillmore\nLyn Taylor\nMolly Macdiarmid\nMartin Brown\nOral & poster submission completed\n\n\nDIA 2023 Global Annual Meeting\nBoston MA, USA\n25-29 June 2023\n\n\n\n\n\nJoint statistical meeting (JSM)\nToronto, Ontario, Canada\n5-10 Aug 2023\n\n\n\n\n\nISCB Conference\nMilan-Italy\n27-31 Aug 2023\n\n\n\n\n\nRSS conference\nHarrogate, England\n4-7 sept 2023\n\n\n\n\n\nASA Bio pharmaceutical Section Regulatory-industry Statistics Workshop\nRockville, Maryland, USA\n27-29 Sept 2023\n\n\n\n\n\nEASD 2023 - European Association for study of diabetes\nHamberg Germany\n02-06 Oct 2023\n\n\n\n\n\nPHUSE EU Connect 2023\nICC Birmingham, England\n5-8 November 2023\nChristina Fillmore?\n\n\n\n\nR in Pharma /\nPOSIT conf.\nVirtual/ In person\nNov?\nChristina Fillmore?"
  },
  {
    "objectID": "minutes/meetings/2025-04-14.html",
    "href": "minutes/meetings/2025-04-14.html",
    "title": "Blogs, New content, Conferences",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n14_Apr_25\n\n\n\n\nLyn Taylor\nYes\n\n\nChristina Fillmore\nYes\n\n\nChi Zhang\nNo\n\n\nMolly MacDiarmid\nYes\n\n\nBenjamin Arancibia\nNo\n\n\nMichael Kane\nYes\n\n\nMartin Brown\nNo\n\n\nStephen McCawille\nYes\n\n\nMiriam Amor\nYes\n\n\nPeilin Zhou\nNo\n\n\nSamrit Pramanik\nYes\n\n\nBrian Varney\nYes\n\n\nVikrant Vijay\nNo\n\n\nYannick Vandendijck\nYes\n\n\nVikash Jain\nNo\n\n\nMichael Walshe\nYes\n\n\nAnwesha Roy\nNo\n\n\nMin-Hua Jen\nNo\n\n\nJaskaran Saini\nYes\n\n\nMariusz Zieba\nYes\n\n\nChelsea Dickens\nYes\n\n\nTejas Pandit\nNo\n\n\nAshwath Gadapa\nNo\n\n\nSarah Brosens\nNo\n\n\nKirsten Findlay\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\n\nWelcome new members !\n\nMariusz Zięba (AZ)\nNOTE: for any questions/ discussion best to add into github issues or discussion tab.\nWe dont routinely look at teams so may miss your questions if loaded there.\nAlternatively email: Email: Lyn.taylor@parexel.com or Christina.e.fillmore@gsk.com\nACTION: Lyn to check SAS PR from Jaskaran in Teams. Also go onto PHUSE TEAMS channel and add comment to ask people to contact us over github or email as we dont check teams.\n\nBlog Update\n\nYannick’s Tobit regression blog was sent to PSI enews, and is on the CAMIS blog page.\nACTION: Vikash to work on Blog for PHUSE US.\nFormat for blogs\n\nPSI want short blog & cross reference to our repo for longer version.\nPHUSE want longer blogs.\nACTION: May be worth discussing with PHUSE the blogs, our plan to have monthly short blog pointing to recently content that has been added, but they requested the below?!\n\nAdd a summary describing CAMIS\nPerhaps expand on when Tobit regression (for example) would be used\nProvide an example of use, input, output, explanation of results\nAnd to increase the length of this and make it more in the style of a blog (usual blogs limit is 1000 words)\n\n\n\nContent updates in the last month ! Thank you All !\n\nIntroduction to Machine learning - Andrey\nACTION : Christina to play with where it fits best & update TOC.\nTobit Regression Yannick - updated to 1 sided p-values\nSample size general summary and cochran-armitage trend test.\nCMH (to include risk differences) & RMST (to include more methods) - Lyn\nSoon - Propensity score matching will be loaded to repo today !\n\nRepo Tech\n\nRepo now only re-builds when changes - Reduction in time from &gt;30 min now &lt;6 mins\nPR Previews - coming soon :) Thank you Michael Walshe!!\n\nConferences\n\nYannick was accepted for Poster at ISBC46 24-28th Aug\nFedor Logvin (PXL), is applying for PHUSE EU Connect 16-19 Nov.\n\nYannick & Michael & Miriam (GLMM) may also submit & go\n\nR/Medicine - Final call for abstracts is 18th April\nACTION: If anyone wants to present let Lyn know by Wednesday this week, if no volunteers Christina and/or Lyn would go. Let Michael Kane know if we need 1-2 days extra to submit.\nSchedule announcment 9th May, Pre-recorded video submission due 2nd June & Conference is 12th-13th June (via TC)\nR/Pharma Nov 3-7th info TBC. call for abstracts not yet open.\nR in HTA workshop - conference. Stephen attending in June.\nhttps://r-hta.org/events/workshop/2025/\nJaskaran is presenting in PHUSE CSS: Synthetic data.\nPSI event in Cambridge England re: moving to R: 3rd July. Yannick attending & can mention CAMIS."
  },
  {
    "objectID": "minutes/meetings/2023-05-15.html",
    "href": "minutes/meetings/2023-05-15.html",
    "title": "White Paper, Website, Launch Plan",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n15_may_2023\n\n\n\n\nAiming Yang\nYes\n\n\nBen Arancibia\nYes\n\n\nBrian Varney\nNo\n\n\nChristina Fillmore\nYes\n\n\nChelsea Dickens\nNo\n\n\nChi Zhang\nNo\n\n\nClara Beck\nNo\n\n\nAditee Dani\nYes\n\n\nDoug Kelkoff\nNo\n\n\nDhvani Patel\nNo\n\n\nFilip Kabaj\nNo\n\n\nHarshal Khanolkar\nNo\n\n\nIris Wu\nNo\n\n\nJayashree Vedanayagam\nYes\n\n\nJoe Rickert\nNo\n\n\nKyle Lee\nNo\n\n\nLeon Shi\nYes\n\n\nLily Hsieh\nNo\n\n\nLyn Taylor\nYes\n\n\nMartin Brown\nYes\n\n\nMia Qi\nYes\n\n\nMichael Kane\nNo\n\n\nMichael Rimler\nNo\n\n\nMike Stackhouse\nNo\n\n\nMin-Hua Jen\nNo\n\n\nMolly MacDiarmid\nYes\n\n\nMona Mehraj\nNo\n\n\nPaula Rowley\nNo\n\n\nSoma Sekhar Sriadibhatla\nYes\n\n\nVandana Yadav\nNo\n\n\nVidya Gopal\nNo\n\n\nVikash Jain\nYes\n\n\nWilmar Igl\nYes\n\n\nOrla Doyle\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda\n\nWhite paper - Lyn/Min-Hua\nWebsite progress - Christina\nUpdate on Launch - Lyn\nCAMIS-ONCO - Soma Sekhar\nVolunteer Open Roles\nConference Attendance\nAOB\n\n\n\nMeeting minutes\nWhite Paper Update: Min-Hua Paula at PHUSE will distribute for public review. Over the next days we’ll get a link to the official review. ACTION :Christina will put the white paper onto the website as draft open for public review\nWebsite progress: Christina Website content progressing well. Ben Arancibia - progressing MMRMs + other areas.\nSurvival - With Christina to fix importing. ANCOVA - Aditee in progress - change to CSV not SAV (SPSS file). Update to call it linear regression, Lyn to help find ANCOVA (testing treatments) Independant Two-Sample t-test in SAS - Vikash got a few changes then will load ok.\nLyn: To create a FAQ doc for the website. Make sure it references available material elsewhere so it doesn’t become out of date quickly.\nNOTE: When you do a pull request, check your action to see if the checks pass/fail & reach out to Lyn/CHristina if you have problems. Remember to do snapshot::renv, so that any packages you install were snapshot to the central repo. Else it will fail when you do the pull request as the repo wont have the packages in it that your code needs.\nLaunch Update\n\nBlog video now available here\nBlog text to use with various lengths also available here\nConference slides & abstract available here\n\nRather than a standard set, plan is to have abstracts & slides/posters put into this folder (inc. name & date of conference) then people can use the contact that they have preference to use.\nHarshal has loaded IASCT slides to same location.\n\nContacts for Societies\n\nPSI /EFSPI (Martin) - Content sent.\nR Consortium / PHUSE / RSS (Lyn) - Content sent.\nIASCT (Harshal) - Conference went well and lots of interest from IASCT.\nASA (Leon) - TBC who are ASA to reach out to? If Ben has any contacts that Leon could use please let him know.\nSAS - we may reach out to SAS directly through PHUSE. TBC if they would be Ok with us including their data, copyright. Hopefully they’d give approval as not or project & advertising what you can do in SAS. ACTION: to find contact who may be interested in update/review of SAS. Does PHUSE have a contact already that we can use. Lyn to ask Paula. Aiming/ Martin to let Lyn know if she has a contact. ACTION : Lyn/Christina to Add a disclaimer that we are volunteers adding open source content, but if you see anything that infringes copyright please let us know and we’ll remove it immediately.\n\n\nCAMIS- ONCO: Soma Sekhar\n\nValidation of endpoints (primary/secondary oncology endpoints). Propose to do poster at PHUSE CSS. Once Mia’s survival section is loaded. Sema Sekhar to review. Then highlight what’s missing - what else you want to add. Max combo. BICR vs RECIST? In future we can discuss how these fit with current CAMIS structure. Focus on the Stats method ideally. ACTION :Christina to email Semar Sekhar once Survival is live on Website.\n\nConferences Let’s review\nVikesh- plan for CSS. Abstract deadline 12th June, 30th june registration opens.\nPosters only - only invited people can be speakers. Somar Sekhar, Aditee Dani would be happy to do posters. Suggest all 3 meet to discuss contribution to poster or doing separate ones but not duplicating the same content.\nAsk PHUSE CSS working group (Data visualization and open source technology) DVOST - if we can have a presentation next year at the CSS.\nJSM - ASA conference. Leon attending. Abstract due Feb 2024 - so try have a rep there next year.\nPHUSE Single day event (SDE- Toronto Mississauga), PHUSE EU got a poster abstract: Jayashree Vendanayagam PHUSE Single day event (New york - regeneron hosting Oct 16, check check if Aiming can do any poster/presentation/advert)\nAZ R pharm conference 7th June. LYn & Martin presenting."
  },
  {
    "objectID": "minutes/meetings/2024-01-08.html",
    "href": "minutes/meetings/2024-01-08.html",
    "title": "CAMIS-ONCO, Conferences, Academic & regulatory input plans",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n08_Jan_24\n\n\n\n\nChristina Fillmore\nYes\n\n\nLyn Taylor\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBrian Varney\nYes\n\n\nChi Zhang\nYes\n\n\nOrla Doyle\nYes\n\n\nHarshal Khanolkar\nYes\n\n\nLily Hseih\nYes\n\n\nFilip Kabaj\nYes\n\n\nMartin Brown\nYes\n\n\nMin-Hua Jen\nYes\n\n\nSarah Rathwell\nYes\n\n\nKasa Andras\nYes\n\n\nAditee Dani\nYes\n\n\nKeaven Anderson\nYes\n\n\nBenjamin Arancibia\nNo\n\n\nWilmar Igl\nNo\n\n\nVikash Jain\nNo\n\n\nMia Qi\nNo\n\n\nLeon Shi\nNo\n\n\nVandaya Yadav\nNo\n\n\nStephen McCawille\nNo\n\n\nVikrant Vijay\nNo\n\n\nVidya Gopal\nNo\n\n\nDhvani Patel\nNo\n\n\nKyle Lee\nNo\n\n\nChelsea Dickens\nNo\n\n\nDavid Bosak\nNo\n\n\nMichael Kane\nNo\n\n\nLukas Brausch\nNo\n\n\nMichael Walshe\nNo\n\n\nSeemani Abhilipsa\nNo\n\n\nAiming Yang\nNo\n\n\nCuifeng Yin\nNo\n\n\nTodd Coffey\nNo\n\n\nJayashree Vedanayagam\nNo\n\n\nAshwath Gadapa\nNo\n\n\nMiriam Amor\nNo\n\n\nAnwesha Roy\nNo\n\n\nSamrit Pramanik\nNo\n\n\nAgnieszka Tomczyk\nNo\n\n\nPrem Kant Shekhar\nNo\n\n\nSunil\nNo\n\n\nKate Booth\nNo\n\n\nPeilin Zhou\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\n\nCAMIS- ONCO: Update on progress & next steps to include:\nRegular meetings Cheat sheet for PHUSE 2024 PHUSE CSS planning (workshop in June). Python volunteers & code creation. White paper.\nACTION: Lyn to follow up with Soma/Vikesh to assess status of CAMIS-ONCO. Also set up meeting with team to discuss python content going into website\nOther Conference planning\nLyn will update the conference tab on the repo.\nPHUSE US Connect (Soma/ Vikesh) and Brian are attending.\nUseR is now open for abstract submission (deadline mid-march). Any volunteers to submit /attend. Salzburg (Europe) 8-11 July. Chi will be going, and volunteers to submit an abstract for us.\nPharmaSUG - Abstracts due 15th January. Conference is: May 19th-22nd Baltimore. Volunteers required to submit abstract if possible.\nContent updates\nAnyone with any questions about what they are working on or how to assign themselves?\n\nMMRM - Volunteer please to look at Proc Mixed vs Proc GLIMMIX and use this to expand the SAS/mmrm.qmd file.\nKeaven Anderson (Merck) - will start to look at SAS vs R for sample size / group sequential design / power. They use EAST, gsDesign, but others use rpact. Does anyone have experience of this (& using SAS for sample size)? Lyn & Martin & Keaven will meet to discuss on Friday.\nChristina: will add sales pitch to Website - Why CAMIS !? + re-arrangment of some of the content.\n\nObjective to get more regulatory input\nWork with PSI AIMS as they plan a EMA regulatory panel discussion on R Any other ideas?\nFDA/ Other regulators input/discussion.\nGit training plan for 2024 PSI conference abstract rejected. Creation of a short training session (like the R/pharma workshop) or 6 week 2 hr/ week course. ACTION: Lyn/Christina/Martin to follow up with PSI re: delivery of training. Restart GIT training meetings (Christina/Alex/ Irene)\nInteraction with more Academics & Universities\nPlease can you present/advertise to your universities contacts. Anyone got contacts they can utilize? Ideas for spreading the word? Lyn doing Presentation at University of Sheffield on 28th Feb for RSS local group.\nAcademia Projects ALL: to think about possible dissertation projects. Plan to list available projects in repo & write descriptions of what the project would entail such that universities students can use them at dissertation projects Prof Richard Stevens (Oxford) is open to projects if we have any. Also Novonordisk : working with Alberg Denmark university to have a proposal for project.\nRaising awareness within companies to flag issues to CAMIS\nALL: brainstorm how we can spread awareness within our organization & wider community\nEFSPI - PSI strategy day / heads meeting\nASA OpenStatsware - Orla Doyle: Focus is more on package development. If a gap comes up we could make them aware package is needed. Can also look to sassy r package to see if that replicates SAS (if it’s right to do so) David Bosak. Lyn meeting with David next later this week.\n\nPlan for next Blogs:\n\n\nadd blog tab to repo, then when we post we can link through.\nIdeas for next blogs? - perhaps pick a topic we have content already for & post blog on it.\n\n\nFunding requirements NOTE: We can apply for a grant for any funding if anyone sees an opportunity to progress our work quicker through this method. NOTE: if any university project or individuals need funding to do this CAMIS work (creation of content), then we do have an option to apply to the R Consortium for funding.\nAOB\n\nLinear Regression SAS & R, text are now live on website. Results match, but would be good to add a COMP file which just says what we checked & what matched… for example incase something comes up in future that does not match."
  },
  {
    "objectID": "minutes/meetings/2024-03-11.html",
    "href": "minutes/meetings/2024-03-11.html",
    "title": "How to select packages, Content & Conferences",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n11_Mar_24\n\n\n\n\nChristina Fillmore\nYes\n\n\nLyn Taylor\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nBrian Varney\nYes\n\n\nChi Zhang\nNo\n\n\nOrla Doyle\nNo\n\n\nHarshal Khanolkar\nNo\n\n\nLily Hseih\nYes\n\n\nFilip Kabaj\nNo\n\n\nMartin Brown\nYes\n\n\nMin-Hua Jen\nNo\n\n\nSarah Rathwell\nNo\n\n\nKasa Andras\nYes\n\n\nAditee Dani\nNo\n\n\nKeaven Anderson\nYes\n\n\nBenjamin Arancibia\nYes\n\n\nWilmar Igl\nNo\n\n\nVikash Jain\nYes\n\n\nMia Qi\nNo\n\n\nLeon Shi\nYes\n\n\nVandaya Yadav\nNo\n\n\nStephen McCawille\nYes\n\n\nVikrant Vijay\nNo\n\n\nVidya Gopal\nNo\n\n\nDhvani Patel\nYes\n\n\nKyle Lee\nNo\n\n\nChelsea Dickens\nYes\n\n\nDavid Bosak\nYes\n\n\nMichael Kane\nYes\n\n\nLukas Brausch\nYes\n\n\nMichael Walshe\nYes\n\n\nSeemani Abhilipsa\nNo\n\n\nAiming Yang\nNo\n\n\nCuifeng Yin\nNo\n\n\nTodd Coffey\nNo\n\n\nJayashree Vedanayagam\nNo\n\n\nAshwath Gadapa\nNo\n\n\nMiriam Amor\nNo\n\n\nAnwesha Roy\nNo\n\n\nSamrit Pramanik\nNo\n\n\nAgnieszka Tomczyk\nNo\n\n\nPrem Kant Shekhar\nNo\n\n\nSunil\nNo\n\n\nKate Booth\nNo\n\n\nPeilin Zhou\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\n\nThank you to all those who submitted content this month, especially Chi, David and Filip who all helped to complete new sections. The top section is now almost complete and the first python content will be loaded in the next few weeks which is a great milestone for the project. Watch out for the new column appearing in the repository Table of contents!\nPlease remember even if you dont want to contribute to a section on your own, you can still review current content and propose improvements.\nConference planning. Reminder that if you are attending a conference to represent CAMIS to add the detail here. We need to ensure we continue to advertise the project to encourage people to use the repo and add content. So far in 2024, only 3 conferences being attended, so if you are interested in attending a conference just reach out to Lyn & Christina who can help you with an abstract if needed.\n\nVikash fed back about the PHUSE US Connect conference. CAMIS was mentioned by Michael Rimler in the keynote speech and Soma/Vikash presented a poster so we received great publicity. Brian also attended meeting Soma & Vikash face to face. Thank you to all of you. The abstract for PHUSE FDA CSS has been written by Soma and submitted so all on track.\nReminder to complete CAMIS membership form\nhttps://docs.google.com/forms/d/e/1FAIpQLSdDX79P5ByStVS_3n4tK1mAWidazIiF6DMEtDMK8KqmJywjqA/viewform?vc=0&c=0&w=1&flr=0&usp=mail_form_link\nNOTE:  We will only collect: team members name, email address, organization, software used, interested in oncology, key interests and affiliations to stats organizations.  The email address is solely for the CAMIS leadership team, to make sure you are included in CAMIS emails.\nWe ask on the form: “Are you happy for your Name and company and interests to be visible on the CAMIS website. Note that email addresses will not be visible”. \nIf you do not give permission then your name will not appear on the CAMIS repo as a CAMIS team member. If you do give permission, your name and company and interests will appear but your email addresses will be hidden from public view. At any time you can ask to be removed from the website team list by emailing me.\nSelection of packages: As we continue to grow the number of packages stored in the repository is growing. We realized that this may lead to conflicts and issues for the repo running. We also dont really want packages installed that are no longer used, known to have issues. Therefore if you are writing up an analysis and there are two packages doing similar things, we would like to request that you select the one that is the most commonly used and best quality (i.e. lowest risk). Risk can be assessed using the {riskmetric} package and {riskassessment} application, using the default scoring, but packages risk should also be considered in context of the individual components such as being actively maintained, bug fixes, code coverage, with references, with a github repo or website, by a trusted author and with results being correct vs stats method.\nIt can be very useful to test multiple packages if they are able to do slightly different analysis (i.e. with different options), in these cases it’s useful to include a Table at the top of the comparison summary qmd, to show which package does which analysis, see Comparison of 1 sample t-test as an example.\nPackages that are inferior to others, should not be loaded to the repo, but instead you can add a textual summary of your findings. For example, “Package X also gives the same results” or “Package X can be used but doesn’t have options to do X and Y” or “We do not recommend Package X as during testing, the results are not in line with the statistical methodology”.\nNOTE that we agreed not to have a library of packages “approved” for CAMIS, RENV stores the lock file of the packages in our repo and we do not want to be seen to giving recommendations for/against packages, other than factual evidence based on the analysis they produce.\nIt was noted that when you load the RENV.lock file, it may give a “error downloading” bioconductor warning, this can be ignored, and should not cause issue if you aren’t using these packages. In the future, these packages will be removed as dependancies from mmrm and the issue will resolve.\nAOB\n\nWe had a discussion surrounding communication methods currently used on the project. RE: using teams vs emails, feedback was mixed, Argument for Teams was that it keeps all discussion in one place, and doesn’t fill you in box, but arguments against were that as you often have to log out of your company teams, to log into the PHUSE one, messages are often missed / ignored.\nWe agreed to perhaps send 2 emails a month, the agenda, but also any other important updates that occurr during the month & minutes. This will be supported by also posting on social media. Although small sample, we assessed how many people observed the recent post RE: Soma’s poster (only Lyn & Christina of those on the call saw the post), however when asked re: Other PHUSE posts 7 were getting them. Leadership team to discuss and see if we need to post using PHUSE admin?"
  },
  {
    "objectID": "minutes/meetings/2023-04-17.html",
    "href": "minutes/meetings/2023-04-17.html",
    "title": "White Paper, Website, Launch Plan",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n17_apr_2023\n\n\n\n\nAiming Yang\nYes\n\n\nBen Arancibia\nNo\n\n\nBrian Varney\nYes\n\n\nChristina Fillmore\nYes\n\n\nChelsea Dickens\nNo\n\n\nChi Zhang\nNo\n\n\nClara Beck\nNo\n\n\nAditee Dani\nYes\n\n\nDoug Kelkoff\nYes\n\n\nDhvani Patel\nNo\n\n\nFilip Kabaj\nNo\n\n\nHarshal Khanolkar\nYes\n\n\nIris Wu\nNo\n\n\nJayashree Vedanayagam\nYes\n\n\nJoe Rickert\nYes\n\n\nKyle Lee\nYes\n\n\nLeon Shi\nNo\n\n\nLily Hsieh\nYes\n\n\nLyn Taylor\nYes\n\n\nMartin Brown\nYes\n\n\nMia Qi\nYes\n\n\nMichael Kane\nNo\n\n\nMichael Rimler\nYes\n\n\nMike Stackhouse\nNo\n\n\nMin-Hua Jen\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nMona Mehraj\nNo\n\n\nPaula Rowley\nNo\n\n\nSoma Sekhar Sriadibhatla\nNo\n\n\nVandana Yadav\nNo\n\n\nVidya Gopal\nNo\n\n\nVikash Jain\nNo\n\n\nWilmar Igl\nNo\n\n\nOrla Doyle\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda\n\nWhite paper - Lyn/Min-Hua\nLogo - All - voting!\nWebsite progress - Christina\nLaunch Plan - Lyn\nCAMIS-ONCO - Soma Sekhar\nVolunteer Open Roles\nConference Attendance\nAOB\n\n\n\nMeeting minutes\nWhite Paper Update: Min-Hua PHUSE are doing technical review so hopefully will come back shortly with any comments. I reminded them last week. Has been reviewed by leads team, now with steering committee ( Final review team), so hopefully not much longer.\nLOGO: Lyn - By a small majority the preferred option was the calculator without the P&lt;0.05 in it. This will now be redrawn & finalized. ACTION: Lyn will update website when image available. Will save under CAMIS/images so you can use for any posters/ presentations.\nWebsite progress: Christina **All - review of progress & answer any questions\nSurvival - Mia has made great progress on survival, Christina and Lyn to help fix branch issue & then will get it pushed to the live site.\nACTION : Lyn to Create a video of creating a branch / doing updates. push/pull - github pull request. Create a FAQ doc for the website.\nLaunch Plan\n\nAlign launch of website with release of white paper. Blog writing & “Video” launch - Lyn to write & distribute for review\nOnce content created reach out to the following to help advertise\n\nPSI /EFSPI (Martin),\nR Consortium / PHUSE / RSS (Lyn)\nIASCT (Harshal)\nASA (Min-hua may have contact or See if Ben has a contact- ACTION christina to check with ben then get back to Min-hua. Lily Hsieh to ask Leon as he’s part of ASA. Aiming can also reach out to a contact to see she has a contact )\nOthers : TBC\n\n\nCAMIS- ONCO: Soma Sekhar\nPlans are in progress\nReview of volunteer open roles Still looking for volunteers to do: - Co-ordinator for conference material - share standard slides/ content /abstracts /posters - Social media rep - to co-ordinate posts (linkedIn/Twitter) - Volunteers to represent CAMIS at various conferences\nConferences All to let Lyn know or update the conferences qmd if you want to attend and represent/advertise camis"
  },
  {
    "objectID": "minutes/meetings/2023-06-19.html",
    "href": "minutes/meetings/2023-06-19.html",
    "title": "White Paper Finalization, Advertising CAMIS",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n19_june_2023\n\n\n\n\nAiming Yang\nYes\n\n\nBen Arancibia\nNo\n\n\nBrian Varney\nYes\n\n\nChristina Fillmore\nYes\n\n\nChelsea Dickens\nNo\n\n\nChi Zhang\nNo\n\n\nClara Beck\nNo\n\n\nAditee Dani\nNo\n\n\nDoug Kelkoff\nNo\n\n\nDhvani Patel\nNo\n\n\nFilip Kabaj\nNo\n\n\nHarshal Khanolkar\nYes\n\n\nIris Wu\nNo\n\n\nJayashree Vedanayagam\nNo\n\n\nJoe Rickert\nNo\n\n\nKyle Lee\nNo\n\n\nLeon Shi\nNo\n\n\nLily Hsieh\nNo\n\n\nLyn Taylor\nYes\n\n\nMartin Brown\nYes\n\n\nMia Qi\nNo\n\n\nMichael Kane\nYes\n\n\nMichael Rimler\nNo\n\n\nMike Stackhouse\nNo\n\n\nMin-Hua Jen\nNo\n\n\nMolly MacDiarmid\nYes\n\n\nMona Mehraj\nNo\n\n\nPaula Rowley\nNo\n\n\nSoma Sekhar Sriadibhatla\nNo\n\n\nVandana Yadav\nNo\n\n\nVidya Gopal\nNo\n\n\nVikash Jain\nYes\n\n\nWilmar Igl\nYes\n\n\nOrla Doyle\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda\n\nTeam announcements - Lyn\nWhite paper - Lyn\nWebsite progress - Christina\nConferences feedback (PSI/IASCT)- Lyn/Christina/Martin/Molly/Aiming/Harshal\nConference planning - All\nCAMIS-ONCO - Soma Sekhar\nAOB\n\n\n\nMeeting minutes\nTeam Announcements\nMin-Hua Jen, Gave birth to twins -everyone is doing well !\nWelcome to: Iris Wu (Incyte)\nHarshal volunteered to be our Social Media Rep / co-ordinate our social media posts.\nRole consists of:\n\nHelps to come up for ideas for blogs/posts. Examples could include, if someone writes content on MRMM, you ask them to write a short description on what they’ve done including link to their work on the website, or for example, once the white paper is final, one of us will write a blog post to advertise it. Molly’s poster prize at PSI conference etc !\nChases people up who said they’d write a blog to ensure we are marketing our work in a timely manner.\nEnsures that when you receive content (blog/posts), that it’s sent to all the key contacts for organizations/Societies (See end of minutes for list)\n\nSocial media post list of upcoming posts\n1) Write a short message for Molly winning Poster prize. Just something in third person like “Congrats to Molly for winning a PSI Conference 2023 Poster Prize. If you want to see the poster it’s here.. (Molly to write, Lyn review, then send to Harshil/Christine to review - then Harshil to forward to contacts for advertising).\n2) Once White paper released, PHUSE will advertize but we should write something to share with our wider contacts\nWhite Paper Update No comments from Public review. Paper is here We checked for any last comments from the group. ACTION: Lyn to send confirmation that we are good to proceed to PHUSE tomorrow if no further comments.\nWebsite progress: Christina\nSubstantial content been added in the last month.\nOnce key area we’d like to progress on though is MMRM. ACTION: Christina to ask Kevin Kunzmann if he can write up something.\nLyn - To create a FAQ doc for the website. Make sure it references available material elsewhere so it doesn’t become out of date quickly.\nPSI AIMS will create github training which we can utilize to onboard statisticians.\nConference feedback:\nPSI Conference: Lyn/Christina/Martin/Molly/Aiming. Molly’s conference poster won a Poster Prize ! Need to blog/advertise the award.\nIASCT: Harshil. Spoken to board members, currently board going through election so will restart discussion after that.\nConference planning\nVikash- plan for CSS. Abstract has been submitted by Soma Sekhar (Co-author Vikash & Adittee), 30th june registration opens.\nACTION: Lyn: Ask PHUSE CSS working group (Data visualization and open source technology) DVOST - if we can have a presentation next year at the CSS.\nJSM - ASA conference. Leon. Abstract due Feb 2024 - so try have a rep there next year.\nPHUSE Single day event (SDE- Toronto Mississauga),\nSCT - society of clinical trials - Michael kane? (ACTION : Lyn to update conf website)\nSESUG - South Eastern SAS user group: Brian Varney (ACTION : Lyn to update conf website)\nPHUSE EU got a poster abstract: Jayashree Vendanayagam\nPHUSE Single day event (New york - regeneron hosting Oct 16, Aiming emailed host to see if she can do a poster/presentation/advert - Lyn to add to conf page)\nR in Pharma - Brian or Christina to possibly submit something. Nov virtual. POSIT CONF - September in chicago. (Lyn update website - Christina wont be at POSIT, split into 2 )\nPhuse EU connect : the CAMIS abstract was selected as back up talk only. However there are some companies who have company talks - which take priority so limited independent speakers to accept talks from. TBC if anyone on the list of speakers - could include a slide to advertise us at PHUSE EU!\nLessons learnt for conferences:\n1) Put PHUSE CAMIS on abstract (part of PHUSE DVOST).\n2) submit abstract for Poster & Talk - then you have the back up of a poster if talk is rejected.\nCAMIS- ONCO: Soma Sekhar\n\nNo update this month, carry to next month. Validation of endpoints (primary/secondary oncology endpoints). Propose to do poster at PHUSE CSS. Once Mia’s survival section is loaded. Sema Sekhar to review. Then highlight what’s missing - what else you want to add. Max combo. BICR vs RECIST? In future we can discuss how these fit with current CAMIS structure. Focus on the Stats method ideally. ACTION :Christina to email Semar Sekhar once Survival is live on Website.\n\nPrevious meeting notes/ Key Information\n\nContacts for Organizations/ Societies\n\nPSI /EFSPI (Martin)\nR Consortium / PHUSE / RSS (Lyn)\nIASCT (Harshal)\nASA (Leon) - TBC who are ASA to reach out to? If Ben has any contacts that Leon could use please let him know.\nSAS - Contact TBC.\n\nRoles\n\nLyn Taylor - Lead\nChristina Fillmore - Website/ co-lead\nSoma Sekhar Sriadibhatla- CAMIS ONCO\nHarshal Khanolkar - Social media rep\nLinear models team - Brian Varney, Vikash Jain,\nMMRM - Ben Arancibia / Kevin Kunzmann"
  },
  {
    "objectID": "minutes/meetings/2023-01-23.html",
    "href": "minutes/meetings/2023-01-23.html",
    "title": "New Website Discussion",
    "section": "",
    "text": "attendees\n23_Jan_2023\n\n\n\n\nAiming Yang\nYes\n\n\nBen Arancibia\nYes\n\n\nBrian Varney\nYes\n\n\nChristina Fillmore\nYes\n\n\nChelsea Dickens\nNo\n\n\nChi Zhang\nNo\n\n\nClara Beck\nNo\n\n\nAditee Dani\nNo\n\n\nDoug Kelkoff\nNo\n\n\nDhvani Patel\nNo\n\n\nFilip Kabaj\nNo\n\n\nHarshal Khanolkar\nNo\n\n\nIris Wu\nNo\n\n\nJayashree Vedanayagam\nYes\n\n\nJoe Rickert\nYes\n\n\nKyle Lee\nYes\n\n\nLeon Shi\nYes\n\n\nLily Hsieh\nYes\n\n\nLyn Taylor\nYes\n\n\nMartin Brown\nYes\n\n\nMia Qi\nYes\n\n\nMichael Kane\nNo\n\n\nMichael Rimler\nYes\n\n\nMike Stackhouse\nNo\n\n\nMin-Hua Jen\nYes\n\n\nMolly MacDiarmid\nYes\n\n\nMona Mehraj\nNo\n\n\nPaula Rowley\nNo\n\n\nSoma Sekhar Sriadibhatla\nYes\n\n\nVandana Yadav\nNo\n\n\nVidya Gopal\nNo\n\n\nVikash Jain\nNo\n\n\nWilmar Igl\nNo\n\n\nOrla Doyle\nNo"
  },
  {
    "objectID": "minutes/meetings/2023-01-23.html#christina-provided-a-summary-of-work-to-date-on-the-website",
    "href": "minutes/meetings/2023-01-23.html#christina-provided-a-summary-of-work-to-date-on-the-website",
    "title": "New Website Discussion",
    "section": "Christina provided a summary of work to date on the website",
    "text": "Christina provided a summary of work to date on the website\nRepo now live: \\[https://psiaims.github.io/CAMIS/\\]\nPrimary mode of navigation will be the table of contents..\nComprehensive Search function is available to supplement the use of the TOC.\nThe website is build from 3 folders in github:\nR SAS Comp\nThese folders, map to the columns of the table, I.e. everything about R is in Quarto files under R.\nComp folder: for the Comparison – name sure you name the two software you are using r-sas - so we can use this when dynamically selecting.\nIn future we can add Python / Julia directories.\nThe idea would be for people to use the: \\[CAMIS/templates/R_template.qmd\\] - A template of how to write documentation for the R part of the site. They’d Edit template & save it back into the R folder naming it clearly for what it is. Template should also contain name packages being used at start of each method comparison. It’d be difficult to be exhaustive with all the survival analysis packages i.e. accelerated failure time packages, etc.., but as long as stated hopefully can grow over time.\nThe Data-info folder – contains description of all data being used for the comparisons. Going forward if different data used, the information about the data would be put into this folder. This allows the data description to sit outside of the comparison folders & where possible same data be used across comparisons.\n\nQuestions & Discussion\nJoe & Michael raised that the About tab which has information about the project is out of date, so should be updated. We also have no detail on the driving mechanism… I.e. what we would like from collaborators. Add “How to collaborate” button.\nItems to be discussed further which may need to be included in the site:\n\nupdate Methods: needs to make it more robust to future uploads - i.e. topics within linear models? (Sub categories) focus on methods, but how sort the methods for inclusion of all in future\nRating the software discrepancies. I..e How severe the difference is?\nNeed to create a template for comparisons. Discuss if we would have a purpose/highlight of comparison/ summary/conclusions at the top first. Also if we put List of R packages this comparison uses (use Tags?) - Need to consider if package superseeded/ multiple packages whether they go in 1 document or multiple.\nHow to expand to sort by: therapeutic area relevance (would be good to link from methods to Oncology somehow\nWhat if a different package.., does same analysis… have to make it clear which package is being used & include multiple packages. It was agreed that as long as we are clear on what we have compared then Its ok to not be all inclusive. That can be added by other collaborators later. It was noted by Kyle that for survival (I.e. accelerated failure time packages), it may be hard to include all. The recommendation is to start with 1 and can expand further as it grows. We may have to re-think website design as it grows to accommodate. Hence why we want everything written in smaller parts to can easily manipulate going forward."
  },
  {
    "objectID": "minutes/meetings/2023-01-23.html#min-hua-provided-an-update-on-the-white-paper",
    "href": "minutes/meetings/2023-01-23.html#min-hua-provided-an-update-on-the-white-paper",
    "title": "New Website Discussion",
    "section": "Min-Hua provided an update on the white paper:",
    "text": "Min-Hua provided an update on the white paper:\nIn its final stages of review by team, and will now be sent for wider review."
  },
  {
    "objectID": "minutes/meetings/2025-02-10.html",
    "href": "minutes/meetings/2025-02-10.html",
    "title": "General meeting updates",
    "section": "",
    "text": "Attendees\n\n\n\n\n\n\n\n\n\n\n\nattendees\n10_Feb_25\n\n\n\n\nLyn Taylor\nYes\n\n\nChristina Fillmore\nNo\n\n\nChi Zhang\nNo\n\n\nMolly MacDiarmid\nYes\n\n\nBenjamin Arancibia\nNo\n\n\nMichael Kane\nYes\n\n\nMartin Brown\nNo\n\n\nStephen McCawille\nYes\n\n\nMiriam Amor\nYes\n\n\nPeilin Zhou\nNo\n\n\nSamrit Pramanik\nNo\n\n\nBrian Varney\nYes\n\n\nVikrant Vijay\nNo\n\n\nYannick Vandendijck\nYes\n\n\nVikash Jain\nYes\n\n\nMichael Walshe\nYes\n\n\nAnwesha Roy\nNo\n\n\nMin-Hua Jen\nNo\n\n\nJaskaran Saini\nNo\n\n\nMariusz Zieba\nNo\n\n\nChelsea Dickens\nNo\n\n\nTejas Pandit\nNo\n\n\nAshwath Gadapa\nNo\n\n\nSarah Brosens\nNo\n\n\nKirsten Findlay\nNo\n\n\n\n\n\n\n\n\n\n\nAgenda & Minutes\n\nVolunteers needed for\n\nCI for props section (See r page).\n\nany R packages that can do CI for matched 2 proportions using wilson or normal approximation methods.\nany R packages that can do CI for unmatched 2 proportions using newcombe (or wilson method)\n(Stephen M suggested: https://search.r-project.org/CRAN/refmans/DescTools/html/BinomDiffCI.html and https://cran.r-project.org/web/packages/presize/presize.pdf\nACTION: Lyn to investigate & write up.\n\nNOTE: logistic regression will be updated soon to include Multiple treatment contrasts.\n\n\nConference planning See latest Conference Tab on website (lyn updated today but needs PR approving)\n\n-   posit::conf(2025) deadline 3rd Feb in person atlanta\n\n-   PHUSE US connect 16th-19th march. lyn to send content to Hamming Tu (Vikash attending) Lyn to CC vikash let Hamming know you are going. Vikash & Hamming to discuss any presenting plan for CAMIS\n\n-   ISBC 14th Feb submission deadline. Yannick submitting abstract\n\n-   Any others? Please add to the page\n\nCommunication team update (Vikash & Molly)\n\nBlog ideas\n\nlatest repo updates (CI for Props)\nKey interesting findings\nConferences\nMolly will maintain conferences tab going forward\n\n\nContent updates\nAnyone with any questions about what they are working on or how to assign themselves?\n\nMMRM (stephen waugh)\nCMH (Lyn)\nSample size (agnieska)\nReference based MI (Yannick)\nGeneralized (binomial & multi-nom?) MMRM (Miriam)\nWilcoxon signed rank coin package - Martin\nPropensity scores restriction on SAS vs R (Stephen McCawille & Christina)\n\n\nObjective to get more regulatory input - ongoing\nWork with PSI AIMS as they plan a EMA regulatory panel discussion on R Any other ideas?\nFDA/ Other regulators input/discussion.\nThink about white paper.. on robustness of results and finding local minima in convergence that are actually issues?….\nUniversity contacts - ongoing\n\nChristina has a new student looking for CAMIS project\nMichael Kane : R medicine\nYannick may have a intern in summer 8-10 weeks CAMIS research\nStephen W doing MSc dissertation project on MMRM\n\nTechnical back end improvements - ongoing\nCAMIS- 3 x workshops - ongoing\n\nIntroduction to CAMIS project / how to contribute - Christina.\nKey findings of CAMIS project - Lyn\nHow do you do comparisons in software\n\n\nACTION :Lyn to ask Orla if she can update renv for Yannicks PR. (And also explain how to do it so others can do it in future)."
  },
  {
    "objectID": "Comp/r-sas_survival.html",
    "href": "Comp/r-sas_survival.html",
    "title": "R vs SAS - Kaplan Meier and Cox-proportion hazards modelling",
    "section": "",
    "text": "The following table shows the options available in SAS and R for Kaplan Meier and Cox Proportional Hazards modelling, the capabilities of each language, and whether or not the results from each language match.\n\n\n\n\n\n\n\n\n\n\nAnalysis\nSupported in R using {survival}\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nKaplan Meier with confidence intervals using log-log method\nYes (using the option conf.type = “log-log”)\nYes (Default)\nMostly\n1) Survival estimates can disagree when last event is censored and survival estimate does not cross the percentile being estimated.\n2) Survival estimates at time X can disagree when the time X is after the last observed censored time\n\n\nKaplan Meier with confidence intervals using log method\nYes (Default)\nYes (using the option conftype=log)\nMostly\nAs above.\n\n\nCox Proportional Hazards Model using breslow method for ties\nYes (using the option ties=“breslow”)\nYes (Default)\nYes\n\n\n\nCox Proportional Hazards Model using efron method for ties\nYes (Default)\nYes (using the option ties=efron)\nYes\n\n\n\nCox Proportional Hazards Model using exact partial likelihood method for ties\nYes (using the option ties=“exact”)\nYes (using the option ties=“discrete”)\nYes\nThe option ties=“exact” in SAS uses the exact marginal likelihood which is not available in R\n\n\n\nResults from the examples shown for R here and SAS here were compared below.\nComparing the non-stratified model results side-by-side, the CIs for the quartile estimates and landmark estimates are different between R and SAS. HR and CI also have slight differences.\n\n\n\n\n\n\n\n\n\n\n\nThe default methods for handling ties in a Cox regression model are different which can lead to a different result for the Hazard ratio and associated confidence interval.\nR uses “efron” by default. SAS uses “breslow” by default. Both R and SAS are able to change these default options. By making the changes to the code below, we can force R to use “breslow” to match SAS, or SAS to use “efron” to match R. When the software use the same methods, then we obtain an identical HR and CI.\n\nR: change method for ties to use “breslow”\n\n\nfit.cox &lt;- survival::coxph(\n  survival::Surv(LENFOLY, FSTAT) ~ AFB,\n  ties = \"breslow\",\n  data = dat\n)\n\n\nSAS: change method for ties to use “efron”\n\n\nproc phreg data=dat;\n    class afb;\n    model lenfol*fstat(0) = afb/rl ties = efron;\nrun;\n\nIf there are no tied event times, then the methods are equivalent.\nThe Breslow approximation is the easiest to program and hence it historically became the first option coded for almost all software. It then ended up as the default option when other options were added in order to maintain “backwards compatibility”. The Efron option is more accurate if there are a large number of ties, and it was therefore selected as the default option in R. In practice the number of ties is usually small, in which case all the methods are statistically indistinguishable.\nFrom the arguments of coxph in R, there are three possible choices for handling tied event times ‘ties=breslow’, ‘ties=efron’, or ‘ties=exact’. This last option is an exact partial likelihood approach, and corresponds to the “discrete” method in SAS. See here for more detail. (For {survival} versions prior to 3.2-14, the options are ‘ties=breslow’, ‘ties=efron’, or ‘ties=logit’.)\n\n\n\nThe default methods for calculation of the confidence interval of a KM estimator are different in the two languages (for example, for calculation of the CI associated with the Median Survival estimate, the 25th percentile and the 75th percentile).\nR uses “log” by default, and SAS uses “log-log” by default. As shown below, using ‘conf.type’ option, R can be forced to use the “log-log” method to match SAS. Alternatively, using the ‘conftype=’ option, SAS can be forced to use the “log” method to match R.\n\nR: change to “log-log”\n\n\nfit.km &lt;- survival::survfit(\n  survival::Surv(LENFOLY, FSTAT) ~ AFB,\n  conf.type = \"log-log\",\n  data = dat\n)\n\n\nSAS: change to “log”\n\n\nproc lifetest data=dat conftype=log;\n    time lenfoly*fstat(0);\n    strata afb;\nrun;\n\n“log-log” prevents the problem of having confidence intervals of &gt;1 or &lt;0, which might happen if using “log” transformation. However, both R and SAS will clip the interval at [0, 1] and report a bound &gt;1 as 1 and &lt;0 as 0.\nFrom a reference: The appeal of the log-log interval is clear, but the log-scale interval has the advantage of variance stabilization. As a result, simulation studies have generally found it to have better (closer to nominal) coverage; for this reason, it is the default in the survival package.\nNow if we change the confidence interval type in SAS to “log” and tie handling to “efron”, the results will be identical to the results in R.\n\n\n\n\n\n\n\n\n\nBelow is the side-by-side comparison for stratified analysis with default methods in SAS matched to R’s, the results are also identical.\n\n\n\n\n\n\n\n\n\n\n\n\nAnother source of discrepancy between R and SAS in Cox models can arise from the default convergence criteria used by the two software packages.\nIn R, the survival::coxph() function has a default convergence criterion for the relative change in log partial likelihood set at 1e-9. On the other hand, SAS’s PHREG procedure uses a default convergence criterion for the relative gradient convergence set at 1e-8. This discrepancy in the convergence criteria can lead to slight differences in the hazard ratios (HR) obtained from the two software packages.\nTo achieve comparable results, it is possible to adjust the convergence criteria in SAS to match the more stringent criteria used by R. This can be done by specifying the fconv option in the model statement within PHREG to change the criteria to relative function convergence with a value of 1e-9.\n\nR: default convergence criterion\n\n\nfit.cox &lt;- survival::coxph(survival::Surv(LENFOLY, FSTAT) ~ AFB, data = dat)\n\n\nSAS: adjust convergence criterion\n\n\nproc phreg data=dat;\n    class afb;\n    model lenfol*fstat(0) = afb / rl fconv = 1e-9;\nrun;\n\nBy making this adjustment, the hazard ratios obtained from SAS will align more closely with those from R or even achieve bitwise reproducibility.\nThe convergence criterion details are described in their documentation:\n\nSAS PHREG documentation.\nR survival::coxph() documentation.\nR survival::coxph.control() ancillary arguments documentation."
  },
  {
    "objectID": "Comp/r-sas_survival.html#reason-1-cox-regression-handling-of-tied-survival-times",
    "href": "Comp/r-sas_survival.html#reason-1-cox-regression-handling-of-tied-survival-times",
    "title": "R vs SAS - Kaplan Meier and Cox-proportion hazards modelling",
    "section": "",
    "text": "The default methods for handling ties in a Cox regression model are different which can lead to a different result for the Hazard ratio and associated confidence interval.\nR uses “efron” by default. SAS uses “breslow” by default. Both R and SAS are able to change these default options. By making the changes to the code below, we can force R to use “breslow” to match SAS, or SAS to use “efron” to match R. When the software use the same methods, then we obtain an identical HR and CI.\n\nR: change method for ties to use “breslow”\n\n\nfit.cox &lt;- survival::coxph(\n  survival::Surv(LENFOLY, FSTAT) ~ AFB,\n  ties = \"breslow\",\n  data = dat\n)\n\n\nSAS: change method for ties to use “efron”\n\n\nproc phreg data=dat;\n    class afb;\n    model lenfol*fstat(0) = afb/rl ties = efron;\nrun;\n\nIf there are no tied event times, then the methods are equivalent.\nThe Breslow approximation is the easiest to program and hence it historically became the first option coded for almost all software. It then ended up as the default option when other options were added in order to maintain “backwards compatibility”. The Efron option is more accurate if there are a large number of ties, and it was therefore selected as the default option in R. In practice the number of ties is usually small, in which case all the methods are statistically indistinguishable.\nFrom the arguments of coxph in R, there are three possible choices for handling tied event times ‘ties=breslow’, ‘ties=efron’, or ‘ties=exact’. This last option is an exact partial likelihood approach, and corresponds to the “discrete” method in SAS. See here for more detail. (For {survival} versions prior to 3.2-14, the options are ‘ties=breslow’, ‘ties=efron’, or ‘ties=logit’.)"
  },
  {
    "objectID": "Comp/r-sas_survival.html#reason-2-kaplan-meier-median-survival-confidence-intervals",
    "href": "Comp/r-sas_survival.html#reason-2-kaplan-meier-median-survival-confidence-intervals",
    "title": "R vs SAS - Kaplan Meier and Cox-proportion hazards modelling",
    "section": "",
    "text": "The default methods for calculation of the confidence interval of a KM estimator are different in the two languages (for example, for calculation of the CI associated with the Median Survival estimate, the 25th percentile and the 75th percentile).\nR uses “log” by default, and SAS uses “log-log” by default. As shown below, using ‘conf.type’ option, R can be forced to use the “log-log” method to match SAS. Alternatively, using the ‘conftype=’ option, SAS can be forced to use the “log” method to match R.\n\nR: change to “log-log”\n\n\nfit.km &lt;- survival::survfit(\n  survival::Surv(LENFOLY, FSTAT) ~ AFB,\n  conf.type = \"log-log\",\n  data = dat\n)\n\n\nSAS: change to “log”\n\n\nproc lifetest data=dat conftype=log;\n    time lenfoly*fstat(0);\n    strata afb;\nrun;\n\n“log-log” prevents the problem of having confidence intervals of &gt;1 or &lt;0, which might happen if using “log” transformation. However, both R and SAS will clip the interval at [0, 1] and report a bound &gt;1 as 1 and &lt;0 as 0.\nFrom a reference: The appeal of the log-log interval is clear, but the log-scale interval has the advantage of variance stabilization. As a result, simulation studies have generally found it to have better (closer to nominal) coverage; for this reason, it is the default in the survival package.\nNow if we change the confidence interval type in SAS to “log” and tie handling to “efron”, the results will be identical to the results in R.\n\n\n\n\n\n\n\n\n\nBelow is the side-by-side comparison for stratified analysis with default methods in SAS matched to R’s, the results are also identical."
  },
  {
    "objectID": "Comp/r-sas_survival.html#reason-3-convergence-criteria-in-cox-proportional-hazards-model",
    "href": "Comp/r-sas_survival.html#reason-3-convergence-criteria-in-cox-proportional-hazards-model",
    "title": "R vs SAS - Kaplan Meier and Cox-proportion hazards modelling",
    "section": "",
    "text": "Another source of discrepancy between R and SAS in Cox models can arise from the default convergence criteria used by the two software packages.\nIn R, the survival::coxph() function has a default convergence criterion for the relative change in log partial likelihood set at 1e-9. On the other hand, SAS’s PHREG procedure uses a default convergence criterion for the relative gradient convergence set at 1e-8. This discrepancy in the convergence criteria can lead to slight differences in the hazard ratios (HR) obtained from the two software packages.\nTo achieve comparable results, it is possible to adjust the convergence criteria in SAS to match the more stringent criteria used by R. This can be done by specifying the fconv option in the model statement within PHREG to change the criteria to relative function convergence with a value of 1e-9.\n\nR: default convergence criterion\n\n\nfit.cox &lt;- survival::coxph(survival::Surv(LENFOLY, FSTAT) ~ AFB, data = dat)\n\n\nSAS: adjust convergence criterion\n\n\nproc phreg data=dat;\n    class afb;\n    model lenfol*fstat(0) = afb / rl fconv = 1e-9;\nrun;\n\nBy making this adjustment, the hazard ratios obtained from SAS will align more closely with those from R or even achieve bitwise reproducibility.\nThe convergence criterion details are described in their documentation:\n\nSAS PHREG documentation.\nR survival::coxph() documentation.\nR survival::coxph.control() ancillary arguments documentation."
  },
  {
    "objectID": "Comp/r-sas_survival.html#differences-observed-in-the-km-estimators",
    "href": "Comp/r-sas_survival.html#differences-observed-in-the-km-estimators",
    "title": "R vs SAS - Kaplan Meier and Cox-proportion hazards modelling",
    "section": "Differences Observed in the KM Estimators",
    "text": "Differences Observed in the KM Estimators\nSuppose we are interested to know the 25%, 50% and 75% quartile estimates, and the day 80, 100, and 120 estimates.\nBelow is the R code:\n\nfit.km &lt;- survival::survfit(\n  survival::Surv(time, status) ~ 1,\n  conf.type = \"log-log\",\n  data = test\n)\n\n## quantile estimates\nquantile(fit.km, probs = c(0.25, 0.5, 0.75))\n\n## landmark estimates at 80, 100, 120-day\nsummary(fit.km, times = c(80, 100, 120), extend = T)\n\nBelow is the SAS code:\n\nproc lifetest data=dat outsurv=_SurvEst timelist= 80 100 120 reduceout stderr; \n    time lenfoly*fstat(0);\nrun;\n\nBelow is the side-by-side comparison:"
  },
  {
    "objectID": "Comp/r-sas_survival.html#reasons",
    "href": "Comp/r-sas_survival.html#reasons",
    "title": "R vs SAS - Kaplan Meier and Cox-proportion hazards modelling",
    "section": "Reasons",
    "text": "Reasons\nThe reasons for the differences are because:\nReason 1: Survival estimate does not cross the 50% percentile.\nThe kth quantile for a survival curve S(t) is the location at which a horizontal line at height p= 1-k intersects the plot of S(t) as shown in the KM curve below. Since S(t) is a step function, it is possible for the curve to have a horizontal segment at exactly 1-k, in which case the midpoint of the horizontal segment is returned.\nFor example, using the data above, the survival probability is exactly 0.5 at time=87 and remains at 0.5 until the last censored observation at 118.\n\n\n\n\n\n\n\n\n\nWhen using R, the median is the smallest time which survival estimate is &lt;= 0.5 –&gt; (87+118) / 2 = 102.5. However, SAS searches the smallest time which survival estimate is &lt; 0.5, which does not exist in this dataset, so it gives “NE” (Not evaluable).\n\npl &lt;- survminer::ggsurvplot(fit.km, conf.int = TRUE, ggtheme = theme_light())\n\npl$plot + geom_hline(yintercept = 0.5, color = \"black\", linetype = \"solid\")\n\nsummary(fit.km)\n\nReason 2: Last event censored and prior to the required landmark estimate.\nFor the 120-day event-free estimate, SAS considers that 120 days is beyond the maximum observed day in the data (which was a censored event at time =118). Therefore, SAS considers this as Unknown and returns a result of “NE” (Not-evaluable). However, R uses the rate at last observed censored date to estimate the 120-day event free rate. As the event-free estimate at time of the last censored event at 118 was 0.5 (0.184, 0.753), R makes the assumption that this is the best estimate for the event-free rate at Time =120.\nIf we change the last observation in the dataset to be an event (instead of censored), R and SAS will both give 0 for the event-free survival estimate, because it is for sure that all subjects did not survive beyond 120 days.\n\ntest &lt;- tibble(\n  time = c(54, 75, 77, 84, 87, 92, 103, 105, 112, 118),\n  status = c(1, 1, 1, 1, 1, 0, 0, 0, 0, 1)\n)\n\ntest\n\n# A tibble: 10 × 2\n    time status\n   &lt;dbl&gt;  &lt;dbl&gt;\n 1    54      1\n 2    75      1\n 3    77      1\n 4    84      1\n 5    87      1\n 6    92      0\n 7   103      0\n 8   105      0\n 9   112      0\n10   118      1"
  },
  {
    "objectID": "Comp/r-sas_manova.html",
    "href": "Comp/r-sas_manova.html",
    "title": "Multivariate Analysis of Variance in R vs SAS",
    "section": "",
    "text": "MANOVA: Testing for group mean vectors are the same vs at least one is different\nWhen applying the following hypothesis, SAS and R match identically see R and SAS.\n\nH0: Group mean vectors are the same for all groups or they don’t differ significantly.\nH1: At least one of the group mean vectors is different from the rest.\n\nHowever, if interest was in comparing 1 level of a parameter vs the others, this was only achieved using SAS. Contrast statements in SAS were easy to implement as shown here SAS however R did not replicate these results and to date a solution has not been found.\nNOTE: if you feel you can help with the above discrepancy please contribute to the CAMIS repo by following the instructions on the contributions page."
  },
  {
    "objectID": "Comp/r-sas_mmrm.html",
    "href": "Comp/r-sas_mmrm.html",
    "title": "R vs SAS MMRM",
    "section": "",
    "text": "In this vignette we briefly compare the mmrm::mmrm, SAS’s PROC GLIMMIX, nlme::gls, lme4::lmer, and glmmTMB::glmmTMB functions for fitting mixed models for repeated measures (MMRMs). A primary difference in these implementations lies in the covariance structures that are supported “out of the box”. In particular, PROC GLIMMIX and mmrm are the only procedures which provide support for many of the most common MMRM covariance structures. Most covariance structures can be implemented in gls, though users are required to define them manually. lmer and glmmTMB are more limited. We find that mmmrm converges more quickly than other R implementations while also producing estimates that are virtually identical to PROC GLIMMIX’s.\nNOTE: that factor parameterization in the model, and the default order that SAS and R choose reference levels for factors are different. Hence, the first thing to ensure when trying to replicate MMRMs in SAS and R is that you have these options aligned. See parameterization in SAS for more detail on SAS parameterization. This can be matched in R using the default contr.treatment option. It is reccommended to specify the level of any factors you want to use as the reference in both SAS and R.\nIn SAS this is done on the class row: ‘class armcd(ref=“ARM A”)’ In R, this is done using relevel(ARMCD,ref=\"ARM A\") in addition to adding the base option to the contrast() statement when selecting the contr.treatment parameterization. contrasts(ARMCD) &lt;- contr.treatment(levels(ARMCD), base=which(levels(ARMCD)==\"ARM A\"))"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#fev-data",
    "href": "Comp/r-sas_mmrm.html#fev-data",
    "title": "R vs SAS MMRM",
    "section": "FEV Data",
    "text": "FEV Data\nThe FEV dataset contains measurements of FEV1 (forced expired volume in one second), a measure of how quickly the lungs can be emptied. Low levels of FEV1 may indicate chronic obstructive pulmonary disease (COPD). It is summarized below.\n                                      Stratified by ARMCD\n                               Overall       PBO           TRT\n  n                              800           420           380\n  USUBJID (%)\n     PT[1-200]                   200           105 (52.5)     95 (47.5)\n  AVISIT\n     VIS1                        200           105            95\n     VIS2                        200           105            95\n     VIS3                        200           105            95\n     VIS4                        200           105            95\n  RACE (%)\n     Asian                       280 (35.0)    152 (36.2)    128 (33.7)\n     Black or African American   300 (37.5)    184 (43.8)    116 (30.5)\n     White                       220 (27.5)     84 (20.0)    136 (35.8)\n  SEX = Female (%)               424 (53.0)    220 (52.4)    204 (53.7)\n  FEV1_BL (mean (SD))          40.19 (9.12)  40.46 (8.84)  39.90 (9.42)\n  FEV1 (mean (SD))             42.30 (9.32)  40.24 (8.67)  44.45 (9.51)\n  WEIGHT (mean (SD))            0.52 (0.23)   0.52 (0.23)   0.51 (0.23)\n  VISITN (mean (SD))            2.50 (1.12)   2.50 (1.12)   2.50 (1.12)\n  VISITN2 (mean (SD))          -0.02 (1.03)   0.01 (1.07)  -0.04 (0.98)"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#bcva-data",
    "href": "Comp/r-sas_mmrm.html#bcva-data",
    "title": "R vs SAS MMRM",
    "section": "BCVA Data",
    "text": "BCVA Data\nThe BCVA dataset contains data from a randomized longitudinal ophthalmology trial evaluating the change in baseline corrected visual acuity (BCVA) over the course of 10 visits. BCVA corresponds to the number of letters read from a visual acuity chart. A summary of the data is given below:\n                                      Stratified by ARMCD\n                               Overall         CTL            TRT\n  n                             8605          4123           4482\n  USUBJID (%)\n     PT[1-1000]                 1000           494 (49.4)     506 (50.6)\n  AVISIT\n     VIS1                        983           482            501\n     VIS2                        980           481            499\n     VIS3                        960           471            489\n     VIS4                        946           458            488\n     VIS5                        925           454            471\n     VIS6                        868           410            458\n     VIS7                        816           388            428\n     VIS8                        791           371            420\n     VIS9                        719           327            392\n     VIS10                       617           281            336\n  RACE (%)\n     Asian                       297 (29.7)    151 (30.6)     146 (28.9)\n     Black or African American   317 (31.7)    149 (30.1)     168 (33.2)\n     White                       386 (38.6)    194 (39.3)     192 (37.9)\n  BCVA_BL (mean (SD))          75.12 (9.93)  74.90 (9.76)   75.40 (10.1)\n  BCVA_CHG (mean (SD))\n     VIS1                       5.59 (1.31)   5.32 (1.23)    5.86 (1.33)\n     VIS10                      9.18 (2.91)   7.49 (2.58)   10.60 (2.36)"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#ante-dependence-heterogeneous",
    "href": "Comp/r-sas_mmrm.html#ante-dependence-heterogeneous",
    "title": "R vs SAS MMRM",
    "section": "Ante-dependence (heterogeneous)",
    "text": "Ante-dependence (heterogeneous)\n\nPROC GLIMMIX\n\nPROC GLIMMIX DATA = fev_data;\n    CLASS AVISIT(ref = 'VIS1') ARMCD(ref = 'PBO') USUBJID;\n    MODEL FEV1 = AVISIT|ARMCD / ddfm=satterthwaite solution chisq;\n    RANDOM AVISIT / subject=USUBJID type=ANTE(1);\nRUN;\n\n\n\nmmrm\n\nmmrm::mmrm(\n  formula = FEV1 ~ ARMCD * AVISIT + adh(VISITN | USUBJID),\n  data = fev_data\n)"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#ante-dependence-homogeneous",
    "href": "Comp/r-sas_mmrm.html#ante-dependence-homogeneous",
    "title": "R vs SAS MMRM",
    "section": "Ante-dependence (homogeneous)",
    "text": "Ante-dependence (homogeneous)\n\nmmrm\n\nmmrm::mmrm(\n  formula = FEV1 ~ ARMCD * AVISIT + ad(VISITN | USUBJID),\n  data = fev_data\n)"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#auto-regressive-heterogeneous",
    "href": "Comp/r-sas_mmrm.html#auto-regressive-heterogeneous",
    "title": "R vs SAS MMRM",
    "section": "Auto-regressive (heterogeneous)",
    "text": "Auto-regressive (heterogeneous)\n\nPROC GLIMMIX\n\nPROC GLIMMIX DATA = fev_data;\n    CLASS AVISIT(ref = 'VIS1') ARMCD(ref = 'PBO') USUBJID;\n    MODEL FEV1 = AVISIT|ARMCD / ddfm=satterthwaite solution chisq;\n    RANDOM AVISIT / subject=USUBJID type=ARH(1);\nRUN;\n\n\n\nmmrm\n\nmmrm::mmrm(\n  formula = FEV1 ~ ARMCD * AVISIT + ar1h(VISITN | USUBJID),\n  data = fev_data\n)\n\n\n\ngls\n\nnlme::gls(\n  formula = FEV1 ~ ARMCD * AVISIT,\n  data = fev_data,\n  correlation = nlme::corCAR1(form = ~ AVISIT | USUBJID),\n  weights = nlme::varIdent(form = ~ 1 | AVISIT),\n  na.action = na.omit\n)"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#auto-regressive-homogeneous",
    "href": "Comp/r-sas_mmrm.html#auto-regressive-homogeneous",
    "title": "R vs SAS MMRM",
    "section": "Auto-regressive (homogeneous)",
    "text": "Auto-regressive (homogeneous)\n\nPROC GLIMMIX\n\nPROC GLIMMIX DATA = fev_data;\n    CLASS AVISIT(ref = 'VIS1') ARMCD(ref = 'PBO') USUBJID;\n    MODEL FEV1 =  ARMCD|AVISIT / ddfm=satterthwaite solution chisq;\n    RANDOM AVISIT / subject=USUBJID type=AR(1);\nRUN;\n\n\n\nmmrm\n\nmmrm::mmrm(\n  formula = FEV1 ~ ARMCD * AVISIT + ar1(VISITN | USUBJID),\n  data = fev_data\n)\n\n\n\ngls\n\nnlme::gls(\n  formula = FEV1 ~ ARMCD * AVISIT,\n  data = fev_data,\n  correlation = nlme::corCAR1(form = ~ AVISIT | USUBJID),\n  na.action = na.omit\n)\n\n\n\nglmmTMB\n\nglmmTMB::glmmTMB(\n  FEV1 ~ ARMCD * AVISIT + ar1(0 + AVISIT | USUBJID),\n  dispformula = ~0,\n  data = fev_data\n)"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#compound-symmetry-heterogeneous",
    "href": "Comp/r-sas_mmrm.html#compound-symmetry-heterogeneous",
    "title": "R vs SAS MMRM",
    "section": "Compound symmetry (heterogeneous)",
    "text": "Compound symmetry (heterogeneous)\n\nPROC GLIMMIX\n\nPROC GLIMMIX DATA = fev_data;\n    CLASS AVISIT(ref = 'VIS1') ARMCD(ref = 'PBO') USUBJID;\n    MODEL FEV1 = AVISIT|ARMCD / ddfm=satterthwaite solution chisq;\n    RANDOM AVISIT / subject=USUBJID type=CSH;\nRUN;\n\n\n\nmmrm\n\nmmrm::mmrm(\n  formula = FEV1 ~ ARMCD * AVISIT + csh(VISITN | USUBJID),\n  data = fev_data\n)\n\n\n\ngls\n\nnlme::gls(\n  formula = FEV1 ~ ARMCD * AVISIT,\n  data = fev_data,\n  correlation = nlme::corCompSymm(form = ~ AVISIT | USUBJID),\n  weights = nlme::varIdent(form = ~ 1 | AVISIT),\n  na.action = na.omit\n)\n\n\n\nglmmTMB\n\nglmmTMB::glmmTMB(\n  FEV1 ~ ARMCD * AVISIT + cs(0 + AVISIT | USUBJID),\n  dispformula = ~0,\n  data = fev_data\n)"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#compound-symmetry-homogeneous",
    "href": "Comp/r-sas_mmrm.html#compound-symmetry-homogeneous",
    "title": "R vs SAS MMRM",
    "section": "Compound symmetry (homogeneous)",
    "text": "Compound symmetry (homogeneous)\n\nPROC GLIMMIX\n\nPROC GLIMMIX DATA = fev_data;\n    CLASS AVISIT(ref = 'VIS1') ARMCD(ref = 'PBO') USUBJID;\n    MODEL FEV1 = AVISIT|ARMCD / ddfm=satterthwaite solution chisq;\n    RANDOM AVISIT / subject=USUBJID type=CS;\nRUN;\n\n\n\nmmrm\n\nmmrm::mmrm(\n  formula = FEV1 ~ ARMCD * AVISIT + cs(VISITN | USUBJID),\n  data = fev_data\n)\n\n\n\ngls\n\nnlme::gls(\n  formula = FEV1 ~ ARMCD * AVISIT,\n  data = fev_data,\n  correlation = nlme::corCompSymm(form = ~ AVISIT | USUBJID),\n  na.action = na.omit\n)"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#spatial-exponential",
    "href": "Comp/r-sas_mmrm.html#spatial-exponential",
    "title": "R vs SAS MMRM",
    "section": "Spatial exponential",
    "text": "Spatial exponential\n\nPROC GLIMMIX\n\nPROC GLIMMIX DATA = fev_data;\n    CLASS AVISIT(ref = 'VIS1') ARMCD(ref = 'PBO') USUBJID;\n    MODEL FEV1 = AVISIT|ARMCD / ddfm=satterthwaite solution chisq;\n    RANDOM / subject=USUBJID type=sp(exp)(visitn) rcorr;\nRUN;\n\n\n\nmmrm\n\nmmrm::mmrm(\n  formula = FEV1 ~ ARMCD * AVISIT + sp_exp(VISITN | USUBJID),\n  data = fev_data\n)\n\n\n\ngls\n\nnlme::gls(\n  formula = FEV1 ~ ARMCD * AVISIT,\n  data = fev_data,\n  correlation = corExp(form = ~ AVISIT | USUBJID),\n  weights = varIdent(form = ~ 1 | AVISIT),\n  na.action = na.omit\n)\n\n\n\nglmmTMB\n\n# NOTE: requires use of coordinates\nglmmTMB::glmmTMB(\n  FEV1 ~ ARMCD * AVISIT + exp(0 + AVISIT | USUBJID),\n  dispformula = ~0,\n  data = fev_data\n)"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#toeplitz-heterogeneous",
    "href": "Comp/r-sas_mmrm.html#toeplitz-heterogeneous",
    "title": "R vs SAS MMRM",
    "section": "Toeplitz (heterogeneous)",
    "text": "Toeplitz (heterogeneous)\n\nPROC GLIMMIX\n\nPROC GLIMMIX DATA = fev_data;\n    CLASS AVISIT(ref = 'VIS1') ARMCD(ref = 'PBO') USUBJID;\n    MODEL FEV1 = AVISIT|ARMCD / ddfm=satterthwaite solution chisq;\n    RANDOM AVISIT / subject=USUBJID type=TOEPH;\nRUN;\n\n\n\nmmrm\n\nmmrm::mmrm(\n  formula = FEV1 ~ ARMCD * AVISIT + toeph(AVISIT | USUBJID),\n  data = fev_data\n)\n\n\n\nglmmTMB\n\nglmmTMB::glmmTMB(\n  FEV1 ~ ARMCD * AVISIT + toep(0 + AVISIT | USUBJID),\n  dispformula = ~0,\n  data = fev_data\n)"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#toeplitz-homogeneous",
    "href": "Comp/r-sas_mmrm.html#toeplitz-homogeneous",
    "title": "R vs SAS MMRM",
    "section": "Toeplitz (homogeneous)",
    "text": "Toeplitz (homogeneous)\n\nPROC GLIMMIX\n\nPROC GLIMMIX DATA = fev_data;\n    CLASS AVISIT(ref = 'VIS1') ARMCD(ref = 'PBO') USUBJID;\n    MODEL FEV1 = AVISIT|ARMCD / ddfm=satterthwaite solution chisq;\n    RANDOM AVISIT / subject=USUBJID type=TOEP;\nRUN;\n\n\n\nmmrm\n\nmmrm::mmrm(\n  formula = FEV1 ~ ARMCD * AVISIT + toep(AVISIT | USUBJID),\n  data = fev_data\n)"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#unstructured",
    "href": "Comp/r-sas_mmrm.html#unstructured",
    "title": "R vs SAS MMRM",
    "section": "Unstructured",
    "text": "Unstructured\n\nPROC GLIMMIX\n\nPROC GLIMMIX DATA = fev_data;\n    CLASS AVISIT(ref = 'VIS1') ARMCD(ref = 'PBO') USUBJID;\n    MODEL FEV1 = ARMCD|AVISIT / ddfm=satterthwaite solution chisq;\n    RANDOM AVISIT / subject=USUBJID type=un;\nRUN;\n\n\n\nmmrm\n\nmmrm::mmrm(\n  formula = FEV1 ~ ARMCD * AVISIT + us(AVISIT | USUBJID),\n  data = fev_data\n)\n\n\n\ngls\n\nnlme::gls(\n  formula = FEV1 ~ ARMCD * AVISIT,\n  data = fev_data,\n  correlation = nlme::corSymm(form = ~ AVISIT | USUBJID),\n  weights = nlme::varIdent(form = ~ 1 | AVISIT),\n  na.action = na.omit\n)\n\n\n\nlmer\n\nlme4::lmer(\n  FEV1 ~ ARMCD * AVISIT + (0 + AVISIT | USUBJID),\n  data = fev_data,\n  control = lme4::lmerControl(check.nobs.vs.nRE = \"ignore\"),\n  na.action = na.omit\n)\n\n\n\nglmmTMB\n\nglmmTMB::glmmTMB(\n  FEV1 ~ ARMCD * AVISIT + us(0 + AVISIT | USUBJID),\n  dispformula = ~0,\n  data = fev_data\n)"
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#convergence-times",
    "href": "Comp/r-sas_mmrm.html#convergence-times",
    "title": "R vs SAS MMRM",
    "section": "Convergence Times",
    "text": "Convergence Times\n\nFEV Data\nThe mmrm, PROC GLIMMIX, gls, lmer, and glmmTMB functions are applied to the FEV dataset 10 times. The convergence times are recorded for each replicate and are reported in the table below.\n\n\n\nComparison of convergence times: milliseconds\n\n\nImplementation\nMedian\nFirst Quartile\nThird Quartile\n\n\n\n\nmmrm\n56.15\n55.76\n56.30\n\n\nPROC GLIMMIX\n100.00\n100.00\n100.00\n\n\nlmer\n247.02\n245.25\n257.46\n\n\ngls\n687.63\n683.50\n692.45\n\n\nglmmTMB\n715.90\n708.70\n721.57\n\n\n\n\n\nIt is clear from these results that mmrm converges significantly faster than other R functions. Though not demonstrated here, this is generally true regardless of the sample size and covariance structure used. mmrm is faster than PROC GLIMMIX.\n\n\nBCVA Data\nThe MMRM implementations are now applied to the BCVA dataset 10 times. The convergence times are presented below.\n\n\n\nComparison of convergence times: seconds\n\n\nImplementation\nMedian\nFirst Quartile\nThird Quartile\n\n\n\n\nmmrm\n3.36\n3.32\n3.46\n\n\nglmmTMB\n18.65\n18.14\n18.87\n\n\nPROC GLIMMIX\n36.25\n36.17\n36.29\n\n\ngls\n164.36\n158.61\n165.93\n\n\nlmer\n165.26\n157.46\n166.42\n\n\n\n\n\nWe again find that mmrm produces the fastest convergence times on average."
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#marginal-treatment-effect-estimates-comparison",
    "href": "Comp/r-sas_mmrm.html#marginal-treatment-effect-estimates-comparison",
    "title": "R vs SAS MMRM",
    "section": "Marginal Treatment Effect Estimates Comparison",
    "text": "Marginal Treatment Effect Estimates Comparison\nWe next estimate the marginal mean treatment effects for each visit in the FEV and BCVA datasets using the MMRM fitting procedures. All R implementations’ estimates are reported relative to PROC GLIMMIX’s estimates. Convergence status is also reported.\n\nFEV Data\n\n\n\n\n\n\n\n\n\nThe R procedures’ estimates are very similar to those output by PROC GLIMMIX, though mmrm and gls generate the estimates that are closest to those produced when using SAS. All methods converge using their default optimization arguments.\n\n\nBCVA Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmmrm, gls and lmer produce estimates that are virtually identical to PROC GLIMMIX’s, while glmmTMB does not. This is likely explained by glmmTMB’s failure to converge. Note too that lmer fails to converge."
  },
  {
    "objectID": "Comp/r-sas_mmrm.html#impact-of-missing-data-on-convergence-rates",
    "href": "Comp/r-sas_mmrm.html#impact-of-missing-data-on-convergence-rates",
    "title": "R vs SAS MMRM",
    "section": "Impact of Missing Data on Convergence Rates",
    "text": "Impact of Missing Data on Convergence Rates\nThe results of the previous benchmark suggest that the amount of patients missing from later time points affect certain implementations’ capacity to converge. We investigate this further by simulating data using a data-generating process similar to that of the BCVA datasets, though with various rates of patient dropout.\nTen datasets of 200 patients are generated each of the following levels of missingness: none, mild, moderate, and high. In all scenarios, observations are missing at random. The number patients observed at each visit is obtained for one replicated dataset at each level of missingness is presented in the table below.\n\n\n\nNumber of patients per visit\n\n\n\nnone\nmild\nmoderate\nhigh\n\n\n\n\nVIS01\n200\n196.7\n197.6\n188.1\n\n\nVIS02\n200\n195.4\n194.4\n182.4\n\n\nVIS03\n200\n195.1\n190.7\n175.2\n\n\nVIS04\n200\n194.1\n188.4\n162.8\n\n\nVIS05\n200\n191.6\n182.5\n142.7\n\n\nVIS06\n200\n188.2\n177.3\n125.4\n\n\nVIS07\n200\n184.6\n168.0\n105.9\n\n\nVIS08\n200\n178.5\n155.4\n82.6\n\n\nVIS09\n200\n175.3\n139.9\n58.1\n\n\nVIS10\n200\n164.1\n124.0\n39.5\n\n\n\n\n\nThe convergence rates of all implementations for stratified by missingness level is presented in the plot below.\n\n\n\n\n\n\n\n\n\nmmrm, gls, and PROC GLIMMIX are resilient to missingness, only exhibiting some convergence problems in the scenarios with the most missingness. These implementations converged in all the other scenarios’ replicates. glmmTMB, on the other hand, has convergence issues in the no-, mild-, and high-missingness datasets, with the worst convergence rate occurring in the datasets with the most dropout. Finally, lmer is unreliable in all scenarios, suggesting that it’s convergence issues stem from something other than the missing observations.\nNote that the default optimization schemes are used for each method; these schemes can be modified to potentially improve convergence rates.\nA more comprehensive simulation study using data-generating processes similar to the one used here is outlined in the simulations/missing-data-benchmarks subdirectory. In addition to assessing the effect of missing data on software convergence rates, we also evaluate these methods’ fit times and empirical bias, variance, 95% coverage rates, type I error rates and type II error rates. mmrm is found to be the most most robust software for fitting MMRMs in scenarios where a large proportion of patients are missing from the last time points. Additionally, mmrm has the fastest average fit times regardless of the amount of missingness. All implementations considered produce similar empirical biases, variances, 95% coverage rates, type I error rates and type II error rates."
  },
  {
    "objectID": "Comp/r-sas_ttest_Paired.html",
    "href": "Comp/r-sas_ttest_Paired.html",
    "title": "R vs SAS Paired T-Test",
    "section": "",
    "text": "The following table shows the types of Paired t-test analysis, the capabilities of each language, and whether or not the results from each language match.\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nPaired t-test, normal data\nYes\nYes\nYes\nIn Base R, use paired = TRUE on t.test() function\n\n\nPaired t-test, lognormal data\nMaybe\nYes\nNA\nMay be supported by envstats package\n\n\n\n\n\n\n\nHere is a table of comparison values between t.test(), proc_ttest(), and SAS PROC TTEST:\n\n\n\n\n\n\n\n\n\n\n\nStatistic\nt.test()\nproc_ttest()\nPROC TTEST\nMatch\nNotes\n\n\n\n\nDegrees of Freedom\n11\n11\n11\nYes\n\n\n\nt value\n-1.089648\n-1.089648\n-1.089648\nYes\n\n\n\np value\n0.2992\n0.2992\n0.2992\nYes\n\n\n\n\n\n\n\nSince there is currently no known support for lognormal t-test in R, this comparison is not applicable."
  },
  {
    "objectID": "Comp/r-sas_ttest_Paired.html#comparison-results",
    "href": "Comp/r-sas_ttest_Paired.html#comparison-results",
    "title": "R vs SAS Paired T-Test",
    "section": "",
    "text": "Here is a table of comparison values between t.test(), proc_ttest(), and SAS PROC TTEST:\n\n\n\n\n\n\n\n\n\n\n\nStatistic\nt.test()\nproc_ttest()\nPROC TTEST\nMatch\nNotes\n\n\n\n\nDegrees of Freedom\n11\n11\n11\nYes\n\n\n\nt value\n-1.089648\n-1.089648\n-1.089648\nYes\n\n\n\np value\n0.2992\n0.2992\n0.2992\nYes\n\n\n\n\n\n\n\nSince there is currently no known support for lognormal t-test in R, this comparison is not applicable."
  },
  {
    "objectID": "Comp/r-sas_anova.html",
    "href": "Comp/r-sas_anova.html",
    "title": "R vs SAS Linear Models",
    "section": "",
    "text": "This section compares the implementation of analysis of variance (ANOVA) in R and SAS. ANOVA compares the mean of two or more groups to determine if at least one group is significantly different from the others.\nR and SAS give the same result for the linear model. But, there some differences with calculating sums of squares. If you are looking for type I sum of square that is available in base R stats package using the anova() function. Type II and Type III sum of squares are available in the car and the rstatix packages. rstatix uses the car package to calculate the sum of square, but can be considered easier to use as it handles the contrast for type III automatically.\n\n\n\nThe following table provides an overview of the support and results comparability between R and SAS for the new analysis point.\n\n\n\n\n\n\n\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nANOVA\nYes ✅\nYes ✅\nMostly yes\nR can’t calculate type IV Sum of Squares\n\n\n\n\n\n\n\n\n\n\nIn order to get the ANOVA model fit and sum of squares you can use the anova function in the stats package.\n\nlibrary(emmeans)\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\ndrug_trial &lt;- read.csv(\"../data/drug_trial.csv\")\n\nlm_model &lt;- lm(formula = post ~ pre + drug, data = drug_trial)\nlm_model |&gt;\n  anova()\n\nAnalysis of Variance Table\n\nResponse: post\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \npre        1 802.94  802.94 50.0393 1.639e-07 ***\ndrug       2  68.55   34.28  2.1361    0.1384    \nResiduals 26 417.20   16.05                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIt is recommended to use the emmeans package to get the contrasts between R.\n\nlm_model |&gt;\n  emmeans(\"drug\") |&gt;\n  contrast(\n    method = list(\n      \"C vs A\" = c(-1, 1, 0),\n      \"E vs CA\" = c(-1, -1, 2)\n    )\n  )\n\n contrast estimate   SE df t.ratio p.value\n C vs A      0.109 1.80 26   0.061  0.9521\n E vs CA     6.783 3.28 26   2.067  0.0488\n\n\nIn SAS, all contrasts must be manually defined, but the syntax is largely similar in both.\n\nproc glm data=work.mycsv;\n   class drug;\n   model post = pre drug / solution;\n   estimate 'C vs A'  drug -1  1 0;\n   estimate 'E vs CA' drug -1 -1 2;\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProvided below is a detailed comparison of the results obtained from both SAS and R.\n\n\n\n\n\n\n\n\n\n\n\nStatistic\nR Result\nSAS Result\nMatch\n\n\n\n\nSum of Square (Type I)\n802.94\n68.55\n802.94\n68.55\nYes\n\n\nDegrees of Freedom\n1\n2\n1\n2\nYes\n\n\nMean Square\n802.94\n34.28\n802.94\n34.28\nYes\n\n\nF Value\n50.04\n2.14\n50.04\n2.14\nYes\n\n\np-value\n&lt;0.0001\n0.1384\n&lt;0.0001\n0.1384\nYes\n\n\n\n\n\n\n\n\n\nStatistic\nR Result\nSAS Result\nMatch\n\n\n\n\ncontrast estimate C vs A\n0.109\n0.109\nYes\n\n\nSE\n1.80\n1.80\nYes\n\n\nt-ratio\n0.06\n0.06\nYes\n\n\np-value\n0.9521\n0.9521\nYes\n\n\ncontrast estimate E vs CA\n6.783\n6.783\nYes\n\n\nSE\n3.28\n3.28\nYes\n\n\nt-ratio\n2.07\n2.07\nYes\n\n\np-value\n0.0488\n0.0488\nYes\n\n\n\nNote, however, that there are some cases where the scale of the parameter estimates between SAS and R is off, though the test statistics and p-values are identical. In these cases, we can adjust the SAS code to include a divisor. As far as we can tell, this difference only occurs when using the predefined Base R contrast methods like contr.helmert.\n\nproc glm data=work.mycsv;\n   class drug;\n   model post = pre drug / solution;\n   estimate 'C vs A'  drug -1  1 0 / divisor = 2;\n   estimate 'E vs CA' drug -1 -1 2 / divisor = 6;\nrun;\n\n\n\n\n\n\n\nThere were no major differences between the R emmeans package and the SAS PROC GLM step in conducting ANOVA on the clinical trial data. Both are robust software tools that generate mostly same results. Scaling for parameter coefficients need to be handled with care however as contrast estimates between R and S differed by a sign.\n\n\n\nProvide references and additional reading materials for both R and SAS documentation related to the analysis.\nR Documentation:\n\nlm function: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm\nemmeans package: https://cran.r-project.org/web/packages/emmeans/\n\nSAS Documentation:\n\nPROC GLM: https://documentation.sas.com/doc/en/statug/15.2/statug_glm_syntax01.htm"
  },
  {
    "objectID": "Comp/r-sas_anova.html#introduction",
    "href": "Comp/r-sas_anova.html#introduction",
    "title": "R vs SAS Linear Models",
    "section": "",
    "text": "This section compares the implementation of analysis of variance (ANOVA) in R and SAS. ANOVA compares the mean of two or more groups to determine if at least one group is significantly different from the others.\nR and SAS give the same result for the linear model. But, there some differences with calculating sums of squares. If you are looking for type I sum of square that is available in base R stats package using the anova() function. Type II and Type III sum of squares are available in the car and the rstatix packages. rstatix uses the car package to calculate the sum of square, but can be considered easier to use as it handles the contrast for type III automatically."
  },
  {
    "objectID": "Comp/r-sas_anova.html#general-comparison-table",
    "href": "Comp/r-sas_anova.html#general-comparison-table",
    "title": "R vs SAS Linear Models",
    "section": "",
    "text": "The following table provides an overview of the support and results comparability between R and SAS for the new analysis point.\n\n\n\n\n\n\n\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nANOVA\nYes ✅\nYes ✅\nMostly yes\nR can’t calculate type IV Sum of Squares\n\n\n\n\n\n\n\n\n\n\nIn order to get the ANOVA model fit and sum of squares you can use the anova function in the stats package.\n\nlibrary(emmeans)\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\ndrug_trial &lt;- read.csv(\"../data/drug_trial.csv\")\n\nlm_model &lt;- lm(formula = post ~ pre + drug, data = drug_trial)\nlm_model |&gt;\n  anova()\n\nAnalysis of Variance Table\n\nResponse: post\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \npre        1 802.94  802.94 50.0393 1.639e-07 ***\ndrug       2  68.55   34.28  2.1361    0.1384    \nResiduals 26 417.20   16.05                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIt is recommended to use the emmeans package to get the contrasts between R.\n\nlm_model |&gt;\n  emmeans(\"drug\") |&gt;\n  contrast(\n    method = list(\n      \"C vs A\" = c(-1, 1, 0),\n      \"E vs CA\" = c(-1, -1, 2)\n    )\n  )\n\n contrast estimate   SE df t.ratio p.value\n C vs A      0.109 1.80 26   0.061  0.9521\n E vs CA     6.783 3.28 26   2.067  0.0488\n\n\nIn SAS, all contrasts must be manually defined, but the syntax is largely similar in both.\n\nproc glm data=work.mycsv;\n   class drug;\n   model post = pre drug / solution;\n   estimate 'C vs A'  drug -1  1 0;\n   estimate 'E vs CA' drug -1 -1 2;\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProvided below is a detailed comparison of the results obtained from both SAS and R.\n\n\n\n\n\n\n\n\n\n\n\nStatistic\nR Result\nSAS Result\nMatch\n\n\n\n\nSum of Square (Type I)\n802.94\n68.55\n802.94\n68.55\nYes\n\n\nDegrees of Freedom\n1\n2\n1\n2\nYes\n\n\nMean Square\n802.94\n34.28\n802.94\n34.28\nYes\n\n\nF Value\n50.04\n2.14\n50.04\n2.14\nYes\n\n\np-value\n&lt;0.0001\n0.1384\n&lt;0.0001\n0.1384\nYes\n\n\n\n\n\n\n\n\n\nStatistic\nR Result\nSAS Result\nMatch\n\n\n\n\ncontrast estimate C vs A\n0.109\n0.109\nYes\n\n\nSE\n1.80\n1.80\nYes\n\n\nt-ratio\n0.06\n0.06\nYes\n\n\np-value\n0.9521\n0.9521\nYes\n\n\ncontrast estimate E vs CA\n6.783\n6.783\nYes\n\n\nSE\n3.28\n3.28\nYes\n\n\nt-ratio\n2.07\n2.07\nYes\n\n\np-value\n0.0488\n0.0488\nYes\n\n\n\nNote, however, that there are some cases where the scale of the parameter estimates between SAS and R is off, though the test statistics and p-values are identical. In these cases, we can adjust the SAS code to include a divisor. As far as we can tell, this difference only occurs when using the predefined Base R contrast methods like contr.helmert.\n\nproc glm data=work.mycsv;\n   class drug;\n   model post = pre drug / solution;\n   estimate 'C vs A'  drug -1  1 0 / divisor = 2;\n   estimate 'E vs CA' drug -1 -1 2 / divisor = 6;\nrun;"
  },
  {
    "objectID": "Comp/r-sas_anova.html#summary-and-recommendation",
    "href": "Comp/r-sas_anova.html#summary-and-recommendation",
    "title": "R vs SAS Linear Models",
    "section": "",
    "text": "There were no major differences between the R emmeans package and the SAS PROC GLM step in conducting ANOVA on the clinical trial data. Both are robust software tools that generate mostly same results. Scaling for parameter coefficients need to be handled with care however as contrast estimates between R and S differed by a sign."
  },
  {
    "objectID": "Comp/r-sas_anova.html#additional-references",
    "href": "Comp/r-sas_anova.html#additional-references",
    "title": "R vs SAS Linear Models",
    "section": "",
    "text": "Provide references and additional reading materials for both R and SAS documentation related to the analysis.\nR Documentation:\n\nlm function: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm\nemmeans package: https://cran.r-project.org/web/packages/emmeans/\n\nSAS Documentation:\n\nPROC GLM: https://documentation.sas.com/doc/en/statug/15.2/statug_glm_syntax01.htm"
  },
  {
    "objectID": "Comp/r-sas_cmh.html",
    "href": "Comp/r-sas_cmh.html",
    "title": "R vs SAS CMH",
    "section": "",
    "text": "The CMH procedure tests for conditional independence in partial contingency tables for a 2 x 2 x K design. However, it can be generalized to tables of X x Y x K dimensions.\n\nknitr::include_graphics('../images/cmh/img.png')\n\n\n\n\n\n\n\n\n\n\nFor the remainder of this document, we adopt the following naming convention when referring to variables of a contingency table:\n\nX = exposure (Often the treatment variable)\nY = response (the variable of interest)\nK = control (often a potential confounder you want to control for)\n\n\n\n\nThe scale of the exposure (X) and response (Y) variables dictate which test statistic is computed for the contingency table. Each test statistic is evaluated on different degrees of freedom (df):\n\nGeneral association statistic (X and Y both nominal) results in (X-1) * (Y-1) dfs\nRow mean scores statistic (X is nominal and Y is ordinal) results in X-1 dfs\nNonzero correlation statistic (X and Y both ordinal) results in 1 df"
  },
  {
    "objectID": "Comp/r-sas_cmh.html#naming-convention",
    "href": "Comp/r-sas_cmh.html#naming-convention",
    "title": "R vs SAS CMH",
    "section": "",
    "text": "For the remainder of this document, we adopt the following naming convention when referring to variables of a contingency table:\n\nX = exposure (Often the treatment variable)\nY = response (the variable of interest)\nK = control (often a potential confounder you want to control for)"
  },
  {
    "objectID": "Comp/r-sas_cmh.html#scale",
    "href": "Comp/r-sas_cmh.html#scale",
    "title": "R vs SAS CMH",
    "section": "",
    "text": "The scale of the exposure (X) and response (Y) variables dictate which test statistic is computed for the contingency table. Each test statistic is evaluated on different degrees of freedom (df):\n\nGeneral association statistic (X and Y both nominal) results in (X-1) * (Y-1) dfs\nRow mean scores statistic (X is nominal and Y is ordinal) results in X-1 dfs\nNonzero correlation statistic (X and Y both ordinal) results in 1 df"
  },
  {
    "objectID": "Comp/r-sas_cmh.html#data",
    "href": "Comp/r-sas_cmh.html#data",
    "title": "R vs SAS CMH",
    "section": "Data",
    "text": "Data\nTo begin investigating the differences in the SAS and R implementations of the CMH test, we decided to use the CDISC Pilot data set, which is publicly available on the PHUSE Test Data Factory repository. We applied very basic filtering conditions upfront (see below) and this data set served as the basis of the examples to follow.\n\ndata &lt;- read.csv(\"../data/adcibc.csv\")\nhead(data)\n\n  X      STUDYID SITEID SITEGR1     USUBJID     TRTSDT     TRTEDT\n1 1 CDISCPILOT01    701     701 01-701-1015 2014-01-02 2014-07-02\n2 2 CDISCPILOT01    701     701 01-701-1023 2012-08-05 2012-09-01\n3 3 CDISCPILOT01    701     701 01-701-1028 2013-07-19 2014-01-14\n4 4 CDISCPILOT01    701     701 01-701-1033 2014-03-18 2014-03-31\n5 5 CDISCPILOT01    701     701 01-701-1034 2014-07-01 2014-12-30\n6 6 CDISCPILOT01    701     701 01-701-1047 2013-02-12 2013-03-09\n                  TRTP TRTPN AGE AGEGR1 AGEGR1N  RACE RACEN SEX ITTFL EFFFL\n1              Placebo     0  63    &lt;65       1 WHITE     1   F     Y     Y\n2              Placebo     0  64    &lt;65       1 WHITE     1   M     Y     Y\n3 Xanomeline High Dose    81  71  65-80       2 WHITE     1   M     Y     Y\n4  Xanomeline Low Dose    54  74  65-80       2 WHITE     1   M     Y     Y\n5 Xanomeline High Dose    81  77  65-80       2 WHITE     1   F     Y     Y\n6              Placebo     0  85    &gt;80       3 WHITE     1   F     Y     Y\n  COMP24FL AVISIT AVISITN             VISIT VISITNUM ADY        ADT  PARAMCD\n1        Y Week 8       8            WEEK 8        8  63 2014-03-05 CIBICVAL\n2        N Week 8       8            WEEK 4        5  29 2012-09-02 CIBICVAL\n3        Y Week 8       8            WEEK 8        8  54 2013-09-10 CIBICVAL\n4        N Week 8       8            WEEK 4        5  28 2014-04-14 CIBICVAL\n5        Y Week 8       8            WEEK 8        8  57 2014-08-26 CIBICVAL\n6        N Week 8       8 AMBUL ECG REMOVAL        6  46 2013-03-29 CIBICVAL\n        PARAM PARAMN AVAL ANL01FL DTYPE AWRANGE AWTARGET AWTDIFF AWLO AWHI  AWU\n1 CIBIC Score      1    4       Y    NA    2-84       56       7    2   84 DAYS\n2 CIBIC Score      1    3       Y    NA    2-84       56      27    2   84 DAYS\n3 CIBIC Score      1    4       Y    NA    2-84       56       2    2   84 DAYS\n4 CIBIC Score      1    4       Y    NA    2-84       56      28    2   84 DAYS\n5 CIBIC Score      1    4       Y    NA    2-84       56       1    2   84 DAYS\n6 CIBIC Score      1    4       Y    NA    2-84       56      10    2   84 DAYS\n  QSSEQ\n1  6001\n2  6001\n3  6001\n4  6001\n5  6001\n6  6001"
  },
  {
    "objectID": "Comp/r-sas_cmh.html#schemes",
    "href": "Comp/r-sas_cmh.html#schemes",
    "title": "R vs SAS CMH",
    "section": "Schemes",
    "text": "Schemes\nIn order to follow a systematic approach to testing, and to cover variations in the CMH test, we considered the traditional 2 x 2 x K design as well as scenarios where the generalized CMH test is employed (e.g. 5 x 3 x 3).\nWe present 5 archetype test scenarios that illustrate diverging results, possibly related to sparse data and possibly considered edge cases.\n\n\n\n\n\n\n\n\n\n\nNumber\nSchema (XxYxK)\nVariables\nRelevant Test\nDescription\n\n\n\n\n1\n2x2x2\nX = TRTP, Y = SEX, K = AGEGR1\nGeneral Association\nTRTP and AGEGR1 were limited to two categories (removing the low dose and &gt;80 year group), overall the the groups were rather balanced\n\n\n2\n3x2x3\nX = TRTP, Y = SEX, K = AGEGR1\nGeneral Association\nTRTP and AGEGR1 each have 3 levels, SEX has 2 levels, overall the the groups were rather balanced\n\n\n3\n2x2x3\nX = TRTP, Y = SEX, K = RACE\nGeneral Association\nGives back NaN in R because RACE is very imbalanced\n\n\n6\n2x5x2\nX = TRTP, Y = AVAL, K = SEX\nRow Means\nCompare Row Means results for R and SAS because Y is ordinal\n\n\n9\n3x5x17\nX = TRTP, Y = AVAL, K = SITEID\nRow Means\nSITEID has many strata and provokes sparse groups, AVAL is ordinal, therefore row means statistic applies here, R threw an error\n\n\n10\n5x3x3\nX = AVAL, Y = AGEGR1, K = TRTP\nCorrelation\nX and Y are ordinal variables and therefore the correlation statistics has to be taken here"
  },
  {
    "objectID": "Comp/r-sas_cmh.html#cmh-statistics",
    "href": "Comp/r-sas_cmh.html#cmh-statistics",
    "title": "R vs SAS CMH",
    "section": "CMH Statistics",
    "text": "CMH Statistics\n\nsas_results &lt;- tribble(\n  ~Scenario, ~Test, ~Chisq, ~Df, ~Prob,\n  1L ,\"Correlation\",         0.2166, 1, 0.617,\n  1L ,\"Row Means\",           0.2166, 1, 0.617,\n  1L ,\"General Association\", 0.2166, 1, 0.617,\n  2L ,\"Correlation\",         0.0009, 1, 0.9765,\n  2L ,\"Row Means\",           2.4820, 1, 0.2891,\n  2L ,\"General Association\", 2.4820, 1, 0.2891,\n  6L ,\"Correlation\",         1.1472, 1, 0.2841,\n  6L ,\"Row Means\",           1.1472, 1, 0.2841,\n  6L ,\"General Association\", 2.5672, 4, 0.6326,\n  10L ,\"Correlation\",        2.738160852, 1, 0.09797747,\n  10L ,\"Row Means\",          4.407010917,4, 0.35371641,\n  10L ,\"General Association\",5.730538193, 8, 0.67738613, \n  3L ,\"Correlation\",         0.002787130, 1, 0.95789662,\n  3L ,\"Row Means\",           2.386069847, 2, 0.30329938, \n  3L ,\"General Association\", 2.386069847, 2, 0.30329938,\n  9L ,\"Correlation\",         0.085443119, 1, 0.77005225,\n  9L ,\"Row Means\",           2.476313667, 2, 0.28991809,\n  9L ,\"General Association\", 7.033878442, 8, 0.53298189\n) |&gt;\n  mutate(lang = \"SAS\")\n\n\nlibrary(vcdExtra)\n\nLoading required package: vcd\n\n\nLoading required package: grid\n\n\nLoading required package: gnm\n\n\n\nAttaching package: 'vcdExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n\ndata2 &lt;- data |&gt;\n  filter(TRTPN != \"54\" & AGEGR1 != \"&gt;80\")\n\ns1 &lt;- vcdExtra::CMHtest(\n  Freq ~ TRTP + SEX | AGEGR1,\n  data = data2,\n  overall = TRUE\n)$ALL$table\n\ns2 &lt;- vcdExtra::CMHtest(\n  Freq ~ TRTP + SEX | AGEGR1,\n  data = data,\n  overall = TRUE\n)$ALL$table\n\ns3 &lt;- vcdExtra::CMHtest(\n  Freq ~ TRTP + SEX | RACE,\n  data = data,\n  overall = TRUE\n)$ALL$table\n\ns6 &lt;- vcdExtra::CMHtest(\n  Freq ~ TRTP + AVAL | SEX,\n  data = data,\n  overall = TRUE\n)$ALL$table\n\n# Unable to run\n# For large sparse table (many strata) CMHTest will occasionally throw an error in solve.default(AVA) because of singularity\n# s9 &lt;- CMHtest(Freq ~ TRTP + AVAL | SITEID, data = data, overall = TRUE)$ALL$table\ns10 &lt;- vcdExtra::CMHtest(\n  Freq ~ AVAL + AGEGR1 | TRTP,\n  data = data,\n  overall = TRUE\n)$ALL$table\n\nr_results &lt;- list(s1, s2, s3, s6, s10) |&gt;\n  map(function(x) {\n    as_tibble(x) |&gt;\n      mutate(across(everything(), unlist), Test = rownames(x))\n  }) |&gt;\n  reduce(bind_rows) |&gt;\n  mutate(\n    Scenario = rep(c(1, 2, 3, 6, 10), each = 4),\n    Test = case_when(\n      Test == \"cor\" ~ \"Correlation\",\n      Test == \"rmeans\" ~ \"Row Means\",\n      Test == \"general\" ~ \"General Association\"\n    ),\n    lang = \"R\"\n  ) |&gt;\n  filter(!is.na(Test))\n\nscenarios this is a test\nAs it can be seen, there are two schemata where R does not provide any results:\n\nlibrary(gt)\n\nbind_rows(sas_results, r_results) |&gt;\n  arrange(Scenario) |&gt;\n  pivot_wider(names_from = lang, values_from = c(\"Chisq\", \"Df\", \"Prob\")) |&gt;\n  gt(\n    groupname_col = \"Scenario\"\n  ) |&gt;\n  tab_spanner(\n    label = \"Chi-Square\",\n    columns = starts_with(\"Chisq\")\n  ) |&gt;\n  tab_spanner(\n    label = \"df\",\n    columns = starts_with(\"Df\")\n  ) |&gt;\n  tab_spanner(\n    label = \"p-value\",\n    columns = starts_with(\"Prob\")\n  ) |&gt;\n  cols_label(\n    Chisq_SAS = \"SAS\",\n    Chisq_R = \"R\",\n    Df_SAS = \"SAS\",\n    Df_R = \"R\",\n    Prob_SAS = \"SAS\",\n    Prob_R = \"R\"\n  ) |&gt;\n  tab_options(row_group.as_column = TRUE) |&gt;\n  tab_footnote(\n    footnote = md(\n      \"**Reason for NaN in schema 3**: Stratum k = AMERICAN INDIAN OR ALASKA NATIVE can not be compared because there are only values for one treatment and one gender.\"\n    ),\n    cells_row_groups(groups = \"3\"),\n    placement = \"right\"\n  ) |&gt;\n  tab_footnote(\n    footnote = md(\n      \"**Reason for Error 4:**\nFor large sparse table (many strata) CMHTest will occasionally throw an error in solve.default(AVA) because of singularity\"\n    ),\n    cells_row_groups(groups = \"9\"),\n    placement = \"right\"\n  ) |&gt;\n  opt_footnote_marks(marks = \"standard\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTest\n\nChi-Square\n\n\ndf\n\n\np-value\n\n\n\nSAS\nR\nSAS\nR\nSAS\nR\n\n\n\n\n1\nCorrelation\n0.21660000\n0.2165549886\n1\n1\n0.61700000\n0.6416775\n\n\nRow Means\n0.21660000\n0.2165549886\n1\n1\n0.61700000\n0.6416775\n\n\nGeneral Association\n0.21660000\n0.2165549886\n1\n1\n0.61700000\n0.6416775\n\n\n2\nCorrelation\n0.00090000\n0.0008689711\n1\n1\n0.97650000\n0.9764831\n\n\nRow Means\n2.48200000\n2.4820278527\n1\n2\n0.28910000\n0.2890910\n\n\nGeneral Association\n2.48200000\n2.4820278527\n1\n2\n0.28910000\n0.2890910\n\n\n3*\nCorrelation\n0.00278713\nNaN\n1\n1\n0.95789662\nNaN\n\n\nRow Means\n2.38606985\nNaN\n2\n2\n0.30329938\nNaN\n\n\nGeneral Association\n2.38606985\nNaN\n2\n2\n0.30329938\nNaN\n\n\n6\nCorrelation\n1.14720000\n0.1115439738\n1\n1\n0.28410000\n0.7383931\n\n\nRow Means\n1.14720000\n2.6632420358\n1\n2\n0.28410000\n0.2640489\n\n\nGeneral Association\n2.56720000\n6.5238474681\n4\n8\n0.63260000\n0.5887637\n\n\n9†\nCorrelation\n0.08544312\nNA\n1\nNA\n0.77005225\nNA\n\n\nRow Means\n2.47631367\nNA\n2\nNA\n0.28991809\nNA\n\n\nGeneral Association\n7.03387844\nNA\n8\nNA\n0.53298189\nNA\n\n\n10\nCorrelation\n2.73816085\n0.8715295423\n1\n1\n0.09797747\n0.3505322\n\n\nRow Means\n4.40701092\n3.0445270087\n4\n4\n0.35371641\n0.5504018\n\n\nGeneral Association\n5.73053819\n5.7305381934\n8\n8\n0.67738613\n0.6773861\n\n\n\n* Reason for NaN in schema 3: Stratum k = AMERICAN INDIAN OR ALASKA NATIVE can not be compared because there are only values for one treatment and one gender.\n\n\n† Reason for Error 4: For large sparse table (many strata) CMHTest will occasionally throw an error in solve.default(AVA) because of singularity"
  },
  {
    "objectID": "Comp/r-sas_survival_csh.html",
    "href": "Comp/r-sas_survival_csh.html",
    "title": "R vs SAS - Estimating and Testing Cause-Specific Hazard",
    "section": "",
    "text": "The following table shows the options available in R and SAS for estimating and testing cause-specific hazard in a competing risk analysis, especially the capabilities and whether the results match.\n\n\n\n\n\n\n\n\n\nAnalysis\nSupported in R package survival\nSupported in SAS PROC PHREG\nResults Match\n\n\n\n\nCause-specific hazard ratio estimates\nYes: with coxph()\nYes\nYes\n\n\nStratified cause-specific hazard ratio estimates\nYes: with the stratification variable x specified as strata(factor(x)) on the right-hand side of the input formula\nYes: with strata statement\nYes\n\n\nVariance estimates for the parameter estimates with robust sandwich estimator\nYes: default (robust = TRUE)\nYes: with covsandwich or covs option in proc phreg statement\nYes\n\n\nConfidence intervals for hazard ratio estimates\nYes: Wald’s method by default\nYes: Wald’s method by default\nYes\n\n\nEstimating cause specific hazard for multiple events\nYes\nYes\nDepends (see note below)\n\n\n\nAdditional details for using survival in R are given here and for SAS PROC PHREG here .\n\n\nR and SAS have different approach when it comes to estimating the hazard ratios for multiple events. Results for the hazard ratio estimates are the same between the two; what is different is the global hypothesis:\n\nThe global hypothesis per coxph() in this case is “There is no difference in the hazards of experiencing any of the events.”\nIn PROC PHREG, one syntax allows the hazard ratio estimates to be generated for all events. However, there is no corresponding global hypothesis as in coxph() in R. In SAS, there are only individual global hypotheses, one for each event. In addition, currently, when this syntax is used in SAS, stratified analysis cannot be implemented.\n\n\n\n\n\nMost of the functionality of survival::coxph() and proc phreg also apply to estimating cause-specific hazards in competing risks settings.\nDue to the different internal numerical estimation methods of R and SAS, results only match up to the 4th decimal places. However, overall consistency can be established between the two for estimating and testing cause-specific hazard ratio using Cox’s PH model.\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package  * version date (UTC) lib source\n survival   3.7-0   2024-06-05 [1] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n─ External software ──────────────────────────────────────────────────────────\n setting value\n SAS     9.04.01M7P080520\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "Comp/r-sas_survival_csh.html#summary",
    "href": "Comp/r-sas_survival_csh.html#summary",
    "title": "R vs SAS - Estimating and Testing Cause-Specific Hazard",
    "section": "",
    "text": "Most of the functionality of survival::coxph() and proc phreg also apply to estimating cause-specific hazards in competing risks settings.\nDue to the different internal numerical estimation methods of R and SAS, results only match up to the 4th decimal places. However, overall consistency can be established between the two for estimating and testing cause-specific hazard ratio using Cox’s PH model.\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-08-29\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package  * version date (UTC) lib source\n survival   3.7-0   2024-06-05 [1] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n─ External software ──────────────────────────────────────────────────────────\n setting value\n SAS     9.04.01M7P080520\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "Comp/r-sas_logistic-regr.html",
    "href": "Comp/r-sas_logistic-regr.html",
    "title": "R vs SAS: Logistic Regression",
    "section": "",
    "text": "Comparison of results between SAS vs R for different applications of logistic regression; where possible we try to ensure the same statistical method or algorithm is specified. However, there are some underlying differences between the algorithms in SAS vs R that cannot be (at least not easily) “tweaked”. The document also provides some remarks on what parameters to look out for and what could have caused the numerical differences.\n\n\n\n\n\n\n\n\n\n\n\nNoteMethodologies\n\n\n\n\n\n\nLogistic regression\nFirth’s bias-reduced logistic regression\ng-computation / standardization with covariate adjustment\n\n\n\n\n\n\n\n\n\n\n\nNoteTechnical implementations\n\n\n\n\n\n\nSAS: PROC LOGISTIC (with and without firth option) and %margins macro\n\nR: stats::glm, logistf::logistf and beeca::get_marginal_effect\n\n\n\n\n\n\n\n\n\nBelow are summary of findings from a numerical comparison using example data, where possible we specify the same algorithm in R and SAS.\n\n\n\n\n\n\nNoteLogistic regression\n\n\n\n\n\nMaximum Likelihood Estimates and p-values for the Model Parameters have an exact match (at 0.001 level) using glm in R vs PROC LOGISTIC procedure (without Firth option) in SAS.\nWhen using GLM parameterization (see SAS page for explanation of SAS parameterization types), the parameters estimates (and 95% CIs) can be exponentiated to provide odds ratios and 95% CIs for odds ratios.\nAs default for categorical variables, R uses the first category as reference see R page, and SAS uses the last category as reference group. Check your design matrix in SAS, and contr. options in R to ensure interpretation of estimates from the model is correct, then results align.\nAn exact match (at 0.001 level) is obtained for the Odds ratios and CIs when the same method and same parameterization is used, however SAS Proc Logistic can only calculate Wald CI’s. Profile likelihood CIs are not available.\nR using glm() function, can use the confint() function to calculate CI’s using the profile likelihood method or the confint.default() function to calculate CIs using the Wald method.\n\n\n\n\n\n\n\n\n\nNoteFirth logistic regression\n\n\n\n\n\nExact match cannot be obtained for all estimates using logistf vs PROC LOGISTIC procedure (with Firth option). More specifically:\n- Coefficient estimate and 95% CI matched at 0.001 level;\n- Standard error are not the same (e.g., 0.02023 for age in R vs 0.02065 in SAS);\n- p-value is not the same (0.6288 in R for age vs 0.6348 in SAS);\n\n\n\n\n\n\n\n\n\n\nNoteg-computation with covariate adjustment\n\n\n\n\n\nExact match (at 0.001 level) can be obtained using get_marginal_effect in R vs %margins macro in SAS.\n\n\n\nIn the following sections, the parameterisation of logistic regression implementation (with an without Firth option) will be compared followed by numerical comparison using example data."
  },
  {
    "objectID": "Comp/r-sas_logistic-regr.html#goal",
    "href": "Comp/r-sas_logistic-regr.html#goal",
    "title": "R vs SAS: Logistic Regression",
    "section": "",
    "text": "Comparison of results between SAS vs R for different applications of logistic regression; where possible we try to ensure the same statistical method or algorithm is specified. However, there are some underlying differences between the algorithms in SAS vs R that cannot be (at least not easily) “tweaked”. The document also provides some remarks on what parameters to look out for and what could have caused the numerical differences."
  },
  {
    "objectID": "Comp/r-sas_logistic-regr.html#scope",
    "href": "Comp/r-sas_logistic-regr.html#scope",
    "title": "R vs SAS: Logistic Regression",
    "section": "",
    "text": "NoteMethodologies\n\n\n\n\n\n\nLogistic regression\nFirth’s bias-reduced logistic regression\ng-computation / standardization with covariate adjustment\n\n\n\n\n\n\n\n\n\n\n\nNoteTechnical implementations\n\n\n\n\n\n\nSAS: PROC LOGISTIC (with and without firth option) and %margins macro\n\nR: stats::glm, logistf::logistf and beeca::get_marginal_effect"
  },
  {
    "objectID": "Comp/r-sas_logistic-regr.html#findings",
    "href": "Comp/r-sas_logistic-regr.html#findings",
    "title": "R vs SAS: Logistic Regression",
    "section": "",
    "text": "Below are summary of findings from a numerical comparison using example data, where possible we specify the same algorithm in R and SAS.\n\n\n\n\n\n\nNoteLogistic regression\n\n\n\n\n\nMaximum Likelihood Estimates and p-values for the Model Parameters have an exact match (at 0.001 level) using glm in R vs PROC LOGISTIC procedure (without Firth option) in SAS.\nWhen using GLM parameterization (see SAS page for explanation of SAS parameterization types), the parameters estimates (and 95% CIs) can be exponentiated to provide odds ratios and 95% CIs for odds ratios.\nAs default for categorical variables, R uses the first category as reference see R page, and SAS uses the last category as reference group. Check your design matrix in SAS, and contr. options in R to ensure interpretation of estimates from the model is correct, then results align.\nAn exact match (at 0.001 level) is obtained for the Odds ratios and CIs when the same method and same parameterization is used, however SAS Proc Logistic can only calculate Wald CI’s. Profile likelihood CIs are not available.\nR using glm() function, can use the confint() function to calculate CI’s using the profile likelihood method or the confint.default() function to calculate CIs using the Wald method.\n\n\n\n\n\n\n\n\n\nNoteFirth logistic regression\n\n\n\n\n\nExact match cannot be obtained for all estimates using logistf vs PROC LOGISTIC procedure (with Firth option). More specifically:\n- Coefficient estimate and 95% CI matched at 0.001 level;\n- Standard error are not the same (e.g., 0.02023 for age in R vs 0.02065 in SAS);\n- p-value is not the same (0.6288 in R for age vs 0.6348 in SAS);\n\n\n\n\n\n\n\n\n\n\nNoteg-computation with covariate adjustment\n\n\n\n\n\nExact match (at 0.001 level) can be obtained using get_marginal_effect in R vs %margins macro in SAS.\n\n\n\nIn the following sections, the parameterisation of logistic regression implementation (with an without Firth option) will be compared followed by numerical comparison using example data."
  },
  {
    "objectID": "Comp/r-sas_logistic-regr.html#r-packages",
    "href": "Comp/r-sas_logistic-regr.html#r-packages",
    "title": "R vs SAS: Logistic Regression",
    "section": "R packages",
    "text": "R packages\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(survival) # for example data\nlibrary(logistf) # for firth regression\nlibrary(beeca) # for covariate adjustment"
  },
  {
    "objectID": "Comp/r-sas_logistic-regr.html#data",
    "href": "Comp/r-sas_logistic-regr.html#data",
    "title": "R vs SAS: Logistic Regression",
    "section": "Data",
    "text": "Data\n\nLogistic regressions\nWe use the lung dataset provided with {survival} R package. Initial data preparation involves generating a new binary outcome based on the weight change.\n\n# the lung dataset is available in ./data/lung_cancer.csv\nlung2 &lt;- survival::lung |&gt;\n  mutate(\n    wt_grp = factor(wt.loss &gt; 0, labels = c(\"weight loss\", \"weight gain\"))\n  )\nglimpse(lung2)\n\nRows: 228\nColumns: 11\n$ inst      &lt;dbl&gt; 3, 3, 3, 5, 1, 12, 7, 11, 1, 7, 6, 16, 11, 21, 12, 1, 22, 16…\n$ time      &lt;dbl&gt; 306, 455, 1010, 210, 883, 1022, 310, 361, 218, 166, 170, 654…\n$ status    &lt;dbl&gt; 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ age       &lt;dbl&gt; 74, 68, 56, 57, 60, 74, 68, 71, 53, 61, 57, 68, 68, 60, 57, …\n$ sex       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, …\n$ ph.ecog   &lt;dbl&gt; 1, 0, 0, 1, 0, 1, 2, 2, 1, 2, 1, 2, 1, NA, 1, 1, 1, 2, 2, 1,…\n$ ph.karno  &lt;dbl&gt; 90, 90, 90, 90, 100, 50, 70, 60, 70, 70, 80, 70, 90, 60, 80,…\n$ pat.karno &lt;dbl&gt; 100, 90, 90, 60, 90, 80, 60, 80, 80, 70, 80, 70, 90, 70, 70,…\n$ meal.cal  &lt;dbl&gt; 1175, 1225, NA, 1150, NA, 513, 384, 538, 825, 271, 1025, NA,…\n$ wt.loss   &lt;dbl&gt; NA, 15, 15, 11, 0, 0, 10, 1, 16, 34, 27, 23, 5, 32, 60, 15, …\n$ wt_grp    &lt;fct&gt; NA, weight gain, weight gain, weight gain, weight loss, weig…\n\n\n\n\ng-computation\nWe use the trial01 dataset provided with {beeca} R package. Initial data preparation involves setting the treatment indicator as a categorical variable and removing any incomplete cases.\n\ndata(\"trial01\")\n\ntrial01$trtp &lt;- factor(trial01$trtp) ## set treatment to a factor\n\ntrial01 &lt;- trial01 |&gt;\n  filter(!is.na(aval)) ## remove missing data i.e complete cases analysis\n\n# save the dataset to be imported in SAS\n# write.csv(trial01, file = \"data/trial01.csv\", na = \".\")"
  },
  {
    "objectID": "Comp/r-sas_logistic-regr.html#parameterisation-comparison",
    "href": "Comp/r-sas_logistic-regr.html#parameterisation-comparison",
    "title": "R vs SAS: Logistic Regression",
    "section": "Parameterisation Comparison",
    "text": "Parameterisation Comparison\nThe following set of tables compare how to configure particular parameters / attributes of the methodologies.\n\n\n\nTable 1: Standard Logistic Regression in SAS vs R\n\n\n\n\n\n\n\n\n\n\n\n\nAttribute\nSAS  PROC LOGISTIC\nR stats::glm\nDescription\nNote\n\n\n\n\nLikelihood optimization algorithm\nDefault\nDefault\nFisher’s scoring method (i.e., iteratively reweighted least squares (IRLS))\nFor logistic regression, parameter estimates and covariance matrices estimated should be the same for both Fisher’s and Newton-Raphson algorithm for maximum likelihood.\n\n\nConvergence criteria\nDefault\nNA\nSpecifies relative gradient convergence criterion (GCONV=1E–8)\nInPROC LOGISTIC there are three other convergence criteria which can be specified. However, there is no exact criterion that matches the criteria in stats::glm.\n\n\nConvergence criteria\nNA\nDefault\nSpecifies relative difference between deviance &lt; 1E–8.\n\n\n\nConfidence interval (CI) estimation method\nDefault\nconfint.default()\nWald CI\nIn stats::glm in R, function confint.default() gives the Wald confidence limits; whereas function confint() gives the profile-likelihood limits.\n\n\nHypothesis tests for regression coefficients\nDefault\nDefault\nWald tests, which are based on estimates for the regression coefficients and its corresponding standard error."
  },
  {
    "objectID": "Comp/r-sas_logistic-regr.html#sec-num-comp",
    "href": "Comp/r-sas_logistic-regr.html#sec-num-comp",
    "title": "R vs SAS: Logistic Regression",
    "section": "Numerical Comparison",
    "text": "Numerical Comparison\nEvery effort is made to ensure that the R code employs estimation methods/ optimization algorithms/ other components that closely match (as much as possible) those used in the SAS code.\n\nglm in R\nNote, the default fitting method in glm is consistent with the default fitting method in PROC LOGISTIC procedure.\n\nDefault fitting method in glm is iteratively reweighted least squares, and the documentation can be found here.\nDefault fitting method for PROC LOGISTIC procedure is Fisher’s scoring method, which is reported as part of the SAS default output, and it is equivalent to “Iteratively reweighted least squares” method as reported in this documentation.\n\n\nm1 &lt;- stats::glm(\n  wt_grp ~ age + sex + ph.ecog + meal.cal,\n  data = lung2,\n  family = binomial(link = \"logit\")\n)\n\n# model coefficients summary\nsummary(m1)$coefficients\n\n                 Estimate   Std. Error    z value   Pr(&gt;|z|)\n(Intercept)  3.2631672833 1.6488206996  1.9790917 0.04780569\nage         -0.0101717451 0.0208107243 -0.4887742 0.62500157\nsex         -0.8717357187 0.3714041991 -2.3471348 0.01891841\nph.ecog      0.4179665342 0.2588653214  1.6146100 0.10639518\nmeal.cal    -0.0008869427 0.0004467405 -1.9853642 0.04710397\n\n\nNote, function confint.default gives the Wald confidence limits, which is the default option in SAS PROC LOGISTIC procedure; whereas confint gives the profile-likelihood limits. Conditional odds ratio is calculated by taking the exponential of the model parameters.\n\ncbind(est = coef(m1), confint.default(m1))\n\n                      est        2.5 %        97.5 %\n(Intercept)  3.2631672833  0.031538095  6.494796e+00\nage         -0.0101717451 -0.050960015  3.061653e-02\nsex         -0.8717357187 -1.599674572 -1.437969e-01\nph.ecog      0.4179665342 -0.089400173  9.253332e-01\nmeal.cal    -0.0008869427 -0.001762538 -1.134731e-05\n\n\n\n\nPROC LOGISTIC in SAS (without firth option)\n\nPROC LOGISTIC DATA=LUNG2; # import lung\n    MODEL WT_GRP(EVENT=\"weight_gain\") = AGE SEX PH_ECOG MEAL_CAL;\n    ods output ESTIMATEs=estimates;\nrun;\n\nBelow is screenshot of output tables summarizing coefficient estimates and confidence intervals\n\n\n\n\n\n\n\n\n\n\n\n\nComment on model selection\nAs indicated in Logistic regression in R and Logistic regression in SAS, the chi-Sq test statistics and p-values are different when performing model selections in R vs. SAS. The reason for this discrepancy is that the chi-Sq statistics from anova() in R is based on deviance test using residual deviance while the chi-Sq statistics from PROC LOGISTIC w/ SELECTION option in SAS is based on Wald test using z-values squared.\n\n\n\n\n\n\nNoteConclusion for logistic regression\n\n\n\n\n\nExact match (at 0.001 level) can be obtained using glm in R vs PROC LOGISTIC procedure (without Firth option) in SAS, for coefficient estimates, 95% CI, and for p-value."
  },
  {
    "objectID": "Comp/r-sas_logistic-regr.html#parameterisation-comparison-1",
    "href": "Comp/r-sas_logistic-regr.html#parameterisation-comparison-1",
    "title": "R vs SAS: Logistic Regression",
    "section": "Parameterisation Comparison",
    "text": "Parameterisation Comparison\n\n\n\nTable 2: Firth’s Bias-Reduced Logistic Regression in SAS vs R\n\n\n\n\n\n\n\n\n\n\n\n\nAttribute\nSAS  PROC LOGISTIC w/ Firth option\nR logistf::logistf\nDescription\nNote\n\n\n\n\nLikelihood optimization algorithm\nDefault\ncontrol =logistf.control (fit =“IRLS”)\nFisher’s scoring method (i.e., iteratively reweighted least squares (IRLS))\n\n\n\nLikelihood optimization algorithm\nTECHNIQUE = NEWTON\nDefault\nNewton-Raphson algorithm\n\n\n\nConvergence criteria\nDefault\nNA\nSpecifies relative gradient convergence criterion (GCONV=1E–8).\nInPROC LOGISTIC there are three other convergence criteria which can be specified. If more than one convergence criterion is specified, the optimization is terminated as soon as one of the criteria is satisfied.\n\n\nConvergence criteria\nNA\nDefault\nSpecifies three criteria that need to be met: the change in log likelihood is less than lconv (default is 1E-5), the maximum absolute element of the score vector is less than gconv (default is 1E-5), and the maximum absolute change in beta is less than xconv (default is 1E-5).\nThe gconv criteria in logistif is different from GCONV in SAS. The lconv criteria is also not exactly the same as the ABSFCONV or FCONV in PROC LOGISTIC in SAS, although the criteria use log likelihood. However, the xconv in R and XCONV in SAS seems to be consistent.\n\n\nConvergence criteria\nXCONV = 1E–8\ncontrol = logistf.control( xconv = 1E–8, lconv = 1, gconv = 1)\nSpecifies the maximum absolute change in beta &lt; 1E–8.\nIn logistf, three convergence criteria are checked at the same time. So here we use a large convergence criteria value for lconv and gconv to mimic the scenario where only xconv is checked.\n\n\nConfidence interval (CI) estimation method\nDefault\npl= FALSE\nWald CI\nFor logistf: “Note that from version 1.24.1 on, the variance-covariance matrix is based on the second derivative of the likelihood of the augmented data rather than the original data, which proved to be a better approximation if the user chooses to set a higher value for the penalty strength.” This could cause differences in standard error estimates in R vs SAS for Firth logistic regression, and consequently results in differences in the corresponding Wald CI estimates and hypothesis tests results (e.g., p-values).\n\n\nConfidence interval (CI) estimation method\nCLPARM = PL  CLODDS = PL\nDefault\nProfile likelihood-based CI\nFor Firth’s bias-reduced logistic regression, it makes more sense to use penalized likelihood-based CI so it is consistent with the parameter estimation method which uses penalized maximum likelihood.\n\n\nHypothesis tests for regression coefficients\nDefault\npl= FALSE\nWald tests, which are based on estimates for the regression coefficients and its corresponding standard error.\n\n\n\nHypothesis tests for regression coefficients\nNA\nDefault\n“Likelihood ratio tests”, which are based on profile penalized log likelihood.\nIn SAS, when the model statement option CLPARM = PL is specified, the CI will be calculated based on profile likelihood. However, the hypothesis testing method is still a Wald method. This could cause results mismatch in the p-value."
  },
  {
    "objectID": "Comp/r-sas_logistic-regr.html#numerical-comparison",
    "href": "Comp/r-sas_logistic-regr.html#numerical-comparison",
    "title": "R vs SAS: Logistic Regression",
    "section": "Numerical Comparison",
    "text": "Numerical Comparison\nNote that while Firth logistic regression is not required for our example dataset nonetheless we use it for demonstration purposes only.\n\nlogistf in R\n\nBy default, the convergence criteria in logistf specifies that three criteria need to be met at the same time, i.e., the change in log likelihood is less than lconv (default is 1E-5), the maximum absolute element of the score vector is less than gconv (default is 1E-5), and the maximum absolute change in beta is less than xconv (default is 1E-5). In SAS, the default convergence criteria in PROC LOGISTIC specifies relative gradient convergence criterion (GCONV=1E–8); while SAS also support three other convergence criteria but when there are more than one convergence criterion specified, the optimization is terminated as soon as one of the criteria is satisfied. By looking at the R pacakge/SAS documentation, the gconv criteria in logistif function is different from the GCONV in SAS. The lconv criteria is also not exactly the same as the ABSFCONV or FCONV in PROC LOGISTIC in SAS, although the criteria use log likelihood. However, similar convergence criteria might be obtained by using the maximum absolute change in parameter estimates (i.e., xconv in R and SAS). Therefore, for comparison with the SAS output, in logistf function, we use a large convergence criteria value for lconv and gconv to mimic the scenario where only xconv is checked, i.e., specify logistf.control(xconv = 0.00000001, gconv = 1, lconv = 1) for the control argument.\nBy default, logistf function in R computes the confidence interval estimates and hypothesis tests (including p-value) for each parameter based on profile likelihood, which is also reported in the output below. However, Wald method (confidence interval and tests) can be specified by specifying the control argument with pl = FALSE.\n\n\nfirth_mod &lt;- logistf(\n  wt_grp ~ age + sex + ph.ecog + meal.cal,\n  data = lung2,\n  control = logistf.control(\n    fit = \"IRLS\",\n    xconv = 0.00000001,\n    gconv = 1,\n    lconv = 1\n  )\n)\nsummary(firth_mod)$coefficients\n\nlogistf(formula = wt_grp ~ age + sex + ph.ecog + meal.cal, data = lung2, \n    control = logistf.control(fit = \"IRLS\", xconv = 1e-08, gconv = 1, \n        lconv = 1))\n\nModel fitted by Penalized ML\nCoefficients:\n                     coef     se(coef)   lower 0.95    upper 0.95     Chisq\n(Intercept)  3.1532937589 1.6031659729  0.051844703  6.410119e+00 3.9726447\nage         -0.0098111679 0.0202315630 -0.050518148  2.974343e-02 0.2337368\nsex         -0.8455619163 0.3632129422 -1.571158740 -1.356810e-01 5.4536777\nph.ecog      0.4018229715 0.2520090355 -0.090278518  9.093255e-01 2.5553004\nmeal.cal    -0.0008495327 0.0004288525 -0.001722033 -7.098976e-06 3.9058205\n                     p method\n(Intercept) 0.04624509      2\nage         0.62876680      2\nsex         0.01952718      2\nph.ecog     0.10992492      2\nmeal.cal    0.04811912      2\n\nMethod: 1-Wald, 2-Profile penalized log-likelihood, 3-None\n\nLikelihood ratio test=10.54964 on 4 df, p=0.03212009, n=170\nWald test = 33.85701 on 4 df, p = 7.972359e-07\n\n\n  (Intercept)           age           sex       ph.ecog      meal.cal \n 3.1532937589 -0.0098111679 -0.8455619163  0.4018229715 -0.0008495327 \n\n## Code below would give Wald CI and tests results by adding `pl = FALSE`\n# logistf(..., pl = FALSE)\n\nNote, function confint gives the profile-likelihood limits. Given the parameters from Firth’s bias-reduced logistic regression is estimated using penalized maximum likelihood, confint function is used. Conditional odds ratio is calculated by taking the exponential of the model parameters.\n\ncbind(est = coef(firth_mod), confint(firth_mod))\n\n                      est    Lower 95%     Upper 95%\n(Intercept)  3.1532937589  0.051844703  6.410119e+00\nage         -0.0098111679 -0.050518148  2.974343e-02\nsex         -0.8455619163 -1.571158740 -1.356810e-01\nph.ecog      0.4018229715 -0.090278518  9.093255e-01\nmeal.cal    -0.0008495327 -0.001722033 -7.098976e-06\n\n\n\n\nPROC LOGISTIC in SAS (with firth option)\n\nNote, by default, SAS computes confidence interval based on Wald tests. Given the parameters from Firth’s method is estimated using penalized maximum likelihood, below specifies CLODDS = PL CLPARM=PL (based on profile likelihood), which is consistent with the maximization method and the R code above. However, the default hypothesis test for the regression coefficients is still a Wald test, and the Chi-square statistics is calculated based on coefficient estimate and its corresponding standard error.\nXCONV specifies relative parameter convergence criterion, which should correspond to the xconv in logistf function in R. We specify XCONV = 0.00000001 so it should be consistent with the R code above.\n\n\nPROC LOGISTIC DATA=LUNG2;\n    MODEL WT_GRP(EVENT=\"weight gain\") = AGE SEX PH_ECOG MEAL_CAL / firth \n  clodds=PL clparm=PL xconv = 0.00000001;\n    ods output ESTIMATEs=estimates;\nrun;\n\nBelow is screenshot of output tables summarizing coefficient estimates and it’s 95% CI\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteConclusion for Firth logistic regression\n\n\n\n\n\nExact match cannot be obtained for all estimates using logistf vs PROC LOGISTIC procedure with Firth option. More specifically:\n- Coefficient estimate and its 95% CI matched at 0.001 level;\n- Standard error are not the same (e.g., 0.02023 for age in R vs 0.02065 in SAS);\n- p-value is not the same (0.6288 in R for age vs 0.6348 in SAS);"
  },
  {
    "objectID": "Comp/r-sas_logistic-regr.html#numerical-comparison-1",
    "href": "Comp/r-sas_logistic-regr.html#numerical-comparison-1",
    "title": "R vs SAS: Logistic Regression",
    "section": "Numerical Comparison",
    "text": "Numerical Comparison\n\nget_marginal_effect in R\nWe fit a logistic regression model with covariate adjustment to estimate the marginal treatment effect using the delta method for variance estimation: as outlined in Ge et al (2011).\n\n## fit the model including model based variance estimation with delta method\nfit1 &lt;- stats::glm(aval ~ trtp + bl_cov, family = \"binomial\", data = trial01) |&gt;\n  beeca::get_marginal_effect(\n    trt = \"trtp\",\n    method = \"Ge\",\n    contrast = \"diff\",\n    reference = \"0\",\n    type = \"model-based\"\n  )\n\n\"Marginal treatment effect\"\n\n[1] \"Marginal treatment effect\"\n\nfit1$marginal_est\n\nmarginal_est \n -0.06836399 \nattr(,\"reference\")\n[1] \"0\"\nattr(,\"contrast\")\n[1] \"diff: 1-0\"\n\n\"Standard error\"\n\n[1] \"Standard error\"\n\nfit1$marginal_se\n\nmarginal_se \n 0.06071641 \nattr(,\"reference\")\n[1] \"0\"\nattr(,\"contrast\")\n[1] \"diff: 1-0\"\nattr(,\"type\")\n[1] \"Ge - model-based\"\n\n\n\n\n%Margins macro in SAS\nWe now use the SAS %Margins macro to perform the Ge et al. (2011) method on trial01 to estimate the marginal risk difference and it’s standard error.\n\n%Margins(data      = myWork.trial01,\n          class     = trtp,\n          classgref = first, /*Set reference to first level*/\n          response  = avaln,\n          roptions  = event='1', /*Ensure event is set to 1 = Yes */\n          dist      = binomial,  \n          model     = trtp bl_cov,\n          margins   = trtp, \n          options   = cl diff reverse, /*Specify risk difference contrast and \n                                      direction of treatment effect is correct*/\n         link      = logit);  /*Specify logit link function */\n    \n** Store output data sets ; \ndata myWork.margins_trt_estimates;\n    set work._MARGINS;\nrun;\n\ndata myWork.margins_trt_diffs;\n    set work._DIFFSPM;\nrun;\n\n\n\n\n\n\n\n\n%LR macro in SAS (Ge et al, 2011)\n\n%LR(data = myWork.trial01, /* input data set */\n    var1 = bl_cov, /* continuous covariates in the logistic regression */\n    var2 = trtp, /* categorical covariates in the logistic regression */\n    p1 = 1, /* number of continuous covariates in the logistic regression */\n    p2 = 1, /* number of categorical covariates in the logistic regression */\n    resp = avaln, /* binary response variable in the logistic regression */\n    ntrt = 1); /* position of the treatment variable in the categorical covariates */\n    \ndata myWork.ge_macro_trt_diffs;\n  set work.geout;\nrun;\n\n\n\n\n\n\n\n\n\n\n\n\nNoteConclusion for g-computation with covariate adjustment\n\n\n\n\n\nExact match at the 0.001 level."
  },
  {
    "objectID": "Comp/r-sas_jonckheere.html",
    "href": "Comp/r-sas_jonckheere.html",
    "title": "R vs SAS on the Jonckheere-Terpstra test",
    "section": "",
    "text": "Analysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nJonckheere-Terpstra test using normal approximation\nYes\nYes\nPartial match\nThe test statistics was 184.5 from both languages.\nRegarding the p-value, R yields 0.002655, and SAS 0.002649\n\n\nJonckheere-Terpstra test using Monte Carlo approximation for an exact test\nYes\nYes\nPartially matching\nThe resampling number is 10000.\nThe test statistics was 184.5 from both languages.\nRegarding the p-value, R yields 0.0023, and SAS 0.0016"
  },
  {
    "objectID": "Comp/r-sas_jonckheere.html#comparison",
    "href": "Comp/r-sas_jonckheere.html#comparison",
    "title": "R vs SAS on the Jonckheere-Terpstra test",
    "section": "",
    "text": "Analysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nJonckheere-Terpstra test using normal approximation\nYes\nYes\nPartial match\nThe test statistics was 184.5 from both languages.\nRegarding the p-value, R yields 0.002655, and SAS 0.002649\n\n\nJonckheere-Terpstra test using Monte Carlo approximation for an exact test\nYes\nYes\nPartially matching\nThe resampling number is 10000.\nThe test statistics was 184.5 from both languages.\nRegarding the p-value, R yields 0.0023, and SAS 0.0016"
  },
  {
    "objectID": "Comp/r-sas_jonckheere.html#conclusion",
    "href": "Comp/r-sas_jonckheere.html#conclusion",
    "title": "R vs SAS on the Jonckheere-Terpstra test",
    "section": "Conclusion",
    "text": "Conclusion\n\nResults from normal approximation\nFor the test using normal approximation, the results look slightly different. The reason for this gap may be either of the following.\n\nContinuity correction\nHandling of ties in calculating the variance of the test statistics\nNumerical integration for normal distribution\n\nRegarding continuity correction, the SAS manual mentions that PROC FREQ does not apply it. The DescTools manual does not mention anything about this point.\nRegarding variance of the test statistics, it depends only on the “cell counts” in the context of cross tabulation analysis. From the viewpoint of rank tests, it depends on the frequencies of each tie values. However, since the same test statistics value was given by both R and SAS, it is less likely that a gap exists in calculation variance between languages.\nBased on consideration above, the gap looks acceptable. However, it should kept in mind that R and SAS may take different approaches in continuity correction.\n\n\nResults from Monte Carlo approximation of an exact test\nFor the test using simulation, the results also look slightly different.\nAs mentioned above, R and SAS may take different approaches in continuity correction and calculation of variance for the test statistics. In addition, simulation-based results generally differ between different environments.\nThe \\(95 \\%\\) CI for the approximate p-value given by SAS was \\([0.0008, 0.0024]\\). Since the p-value from R, 0.0023, locates within the CI, this result looks comparable.\n\n\nOverall conclusion\nOverall, the gap between R and SAS is accaptable regarding the Jonckheere-Terpstra test. However, users should know that R and SAS may take different approaches for the following aspects:\n\nContinuity correction\nHandling of ties in calculating the variance of the test statistics"
  },
  {
    "objectID": "Comp/r-sas_ci_for_prop.html",
    "href": "Comp/r-sas_ci_for_prop.html",
    "title": "R vs SAS Confidence Intervals for Proportions",
    "section": "",
    "text": "The methods to use for calculating a confidence interval (CI) for a proportion depend on the type of proportion you have.\n\n1 sample proportion (1 proportion calculated from 1 group of subjects)\n2 sample proportions and you want a CI for the difference in the 2 proportions.\n\nIf the 2 samples come from 2 independent samples (different subjects in each of the 2 groups)\nIf the 2 samples are matched (i.e. the same subject has 2 results, one on each group [paired data]).\n\n\nThe method selected is also dependent on whether your proportion is close to 0 or 1 (or near to the 0.5 midpoint), and your sample size.\nFor more technical derivation and reasons why you would use one method above another see the corresponding SAS page.\nThe tables below provide an overview of findings from R & SAS, for calculation of CIs, for a Single Sample Proportion and for calculation of a difference between 2 matched pair proportions or 2 independent sample proportions."
  },
  {
    "objectID": "Comp/r-sas_ci_for_prop.html#introduction",
    "href": "Comp/r-sas_ci_for_prop.html#introduction",
    "title": "R vs SAS Confidence Intervals for Proportions",
    "section": "",
    "text": "The methods to use for calculating a confidence interval (CI) for a proportion depend on the type of proportion you have.\n\n1 sample proportion (1 proportion calculated from 1 group of subjects)\n2 sample proportions and you want a CI for the difference in the 2 proportions.\n\nIf the 2 samples come from 2 independent samples (different subjects in each of the 2 groups)\nIf the 2 samples are matched (i.e. the same subject has 2 results, one on each group [paired data]).\n\n\nThe method selected is also dependent on whether your proportion is close to 0 or 1 (or near to the 0.5 midpoint), and your sample size.\nFor more technical derivation and reasons why you would use one method above another see the corresponding SAS page.\nThe tables below provide an overview of findings from R & SAS, for calculation of CIs, for a Single Sample Proportion and for calculation of a difference between 2 matched pair proportions or 2 independent sample proportions."
  },
  {
    "objectID": "Comp/r-sas_ci_for_prop.html#general-comparison-table-for-single-sample-proportions",
    "href": "Comp/r-sas_ci_for_prop.html#general-comparison-table-for-single-sample-proportions",
    "title": "R vs SAS Confidence Intervals for Proportions",
    "section": "General Comparison Table For Single Sample Proportions",
    "text": "General Comparison Table For Single Sample Proportions\nSee the corresponding SAS page and R page for results showing a single set of data which has been run through both SAS and R.\n\n\n\n\n\n\n\n\n\nAnalysis of One Sample Proportion\nSupported in R\nSupported in SAS\nResults Match\n\n\n\n\nClopper-Pearson Exact\nYes {cardx}\nYes (default)\nYes\n\n\nNormal approximation (Wald Method)\nYes {cardx}\nYes (default)\nYes\n\n\nNormal approximation (Wald Method) with continuity correction\nYes {cardx}\nYes\nYes\n\n\nWilson (Score, Altman, Newcombe) method\nYes {cardx}\nYes\nYes\n\n\nWilson (Score, Altman, Newcombe) method with continuity correction\nYes {cardx}\nYes\nYes\n\n\nAgresti Coull\nYes {cardx}\nYes\nYes\n\n\nJeffreys Bayesian HPD\nYes {cardx}\nYes\nYes\n\n\nmidp\nYes {PropCIs}\nYes\nresults match to the 3rd decimal place\n\n\nBlaker\nYes {PropCIs}\nYes\nresults match to the 5th decimal place\n\n\nWilson Stratified score\nYes {cardx}\nNo\nNA"
  },
  {
    "objectID": "Comp/r-sas_ci_for_prop.html#general-comparison-table-for-two-matched-samples-proportions",
    "href": "Comp/r-sas_ci_for_prop.html#general-comparison-table-for-two-matched-samples-proportions",
    "title": "R vs SAS Confidence Intervals for Proportions",
    "section": "General Comparison Table For Two Matched Samples Proportions",
    "text": "General Comparison Table For Two Matched Samples Proportions\n\n\n\nAnalysis of Two Matched Sample Proportions\nSupported in R\nSupported in SAS\nNotes\n\n\n\n\nExact method\nYes {ExactCIdiff}\nNo\n\n\n\nNormal approximation (Wald Method)\nNo\nNo (proc freq does CIs for the risk difference, not the difference between two proportions)\nUsing the equations provided in the SAS page, You could do this programatically in either package\n\n\nWilson (Score method or the Altman, Newcombe method)\nNo\nNo (proc freq does CIs for the risk difference, not the difference between two proportions)\nUsing the equations provided in the SAS page, You could do this programatically in either package\n\n\n\nCalculating the Normal approximation and Wilson methods by hand and comparing it to the Exact method gave similar results for the 1 example demonstrated indicating as long as the proportion of responders is not close to 0 or 1, then the faster computation of the approximation methods may be easier to implement than the exact method and produce similar results. Hence {ExactCIdiff} is not recommended for most scenarios.\n\n\n\nMethod Name\nCalculated Using matched pair example from R & SAS pages\nLower 95% CI\nUpper 95% CI\n\n\n\n\nExact\nR\n-0.00339\n0.38065\n\n\nNormal\nby hand using equation from SAS page\n0.00911\n0.38289\n\n\nWilson\nby hand using equation from SAS page\n0.00032\n0.36739"
  },
  {
    "objectID": "Comp/r-sas_ci_for_prop.html#general-comparison-table-for-two-independent-samples-proportions",
    "href": "Comp/r-sas_ci_for_prop.html#general-comparison-table-for-two-independent-samples-proportions",
    "title": "R vs SAS Confidence Intervals for Proportions",
    "section": "General Comparison Table For Two Independent Samples Proportions",
    "text": "General Comparison Table For Two Independent Samples Proportions\n\n\n\n\n\n\n\n\n\nAnalysis of Two Independant Sample Proportions\nSupported in R\nSupported in SAS\nResults Match\n\n\n\n\nNormal approximation (Wald Method)\nYes {DescTools}\nBinomDiffCI(..,method=c(\"wald\"))\nYes {cardx} ard_stats_prop_test function uses stats::prop.test\nYes (default)\nYes and results match by hand calculation\nWarning The documentation for stats::prop.test which is used in {cardx} says it’s using newcombe method. However, the results match the Normal Approximation (wald) method. Hence it is reccomended to use {DescTools} instead of {cardx}\n\n\nNormal approximation (Wald Method) with continuity correction\nYes {DescTools}\nBinomDiffCI(..,method=c(\"waldcc\"))\nYes {cardx} as per above but with correct=TRUE\nYes\nYes\nWarning that documentation for stats::prop.test says it’s using newcombe method. However, the results match the Normal Approximation (wald) method.\n\n\nWilson (Score, Altman, Newcombe) method\nYes {DescTools}\nBinomDiffCI(..,method=c(\"score\"))\nYes\nYes and results match by hand calculation\n\n\nWilson (Score, Altman, Newcombe) method with continuity correction\nYes {DescTools}\nBinomDiffCI(..,method=c(\"scorecc\"))\nYes\nYes\n\n\nAgresti-Caffo\nYes {DescTools}\nBinomDiffCI(..,method=c(\"ac\"))\nYes\nYes\n\n\nHauck-Anderson\nYes {DescTools}\nBinomDiffCI(..,method=c(\"ha\"))\nYes\nYes\n\n\nMiettinen-Nurminen\nYes {DescTools}\nBinomDiffCI(..,method=c(\"mn\"))\nYes\nYes"
  },
  {
    "objectID": "Comp/r-sas_ci_for_prop.html#prerequisites-r-packages",
    "href": "Comp/r-sas_ci_for_prop.html#prerequisites-r-packages",
    "title": "R vs SAS Confidence Intervals for Proportions",
    "section": "Prerequisites: R Packages",
    "text": "Prerequisites: R Packages\nSee the R page for more detail.\n\n# Example R packages required\nlibrary(cardx)"
  },
  {
    "objectID": "Comp/r-sas_rounding.html",
    "href": "Comp/r-sas_rounding.html",
    "title": "R v SAS rounding",
    "section": "",
    "text": "Rounding; R and SAS\nOn comparing the documentation of rounding rules for both languages, it will be noted that the default rounding rule (implemented in the respective language’s round() function) are different. Numerical differences arise in the knife-edge case where the number being rounded is equidistant between the two possible results. The round() function in SAS will round the number ‘away from zero’, meaning that 12.5 rounds to the integer 13. The round() function in Base R will round the number ‘to even’, meaning that 12.5 rounds to the integer 12. SAS does provide the rounde() function which rounds to even and the cards package in R contains a function round5() that rounds away from zero. In this use case, SAS produces a correct result from its round() function, based on its documentation, as does R. Both are right based on what they say they do, but they produce different results (Rimler, M.S. et al.).\nAs described in R - Rounding and SAS - Rounding, round() in SAS and cards::round5() in R are incorrect in rare different cases. It may need to be considered when comparing results between SAS and R.\nReferences\nRimler M.S., Rickert J., Jen M-H., Stackhouse M. Understanding differences in statistical methodology implementations across programming languages (2022, Fall). ASA Biopharmaceutical Report Issue 3, Volume 29.  Retrieved from https://higherlogicdownload.s3.amazonaws.com/AMSTAT/fa4dd52c-8429-41d0-abdf-0011047bfa19/UploadedImages/BIOP%20Report/BioPharm_fall2022FINAL.pdf"
  },
  {
    "objectID": "Comp/r-sas_ttest_1Sample.html",
    "href": "Comp/r-sas_ttest_1Sample.html",
    "title": "R vs SAS One Sample T-Test",
    "section": "",
    "text": "The following table shows the types of One Sample t-test analysis, the capabilities of each language, and whether or not the results from each language match.\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nOne sample t-test, normal data\nYes\nYes\nYes\nIn Base R, use mu parameter on t.test() function to set null hypothesis value\n\n\nOne sample t-test, lognormal data\nMaybe\nYes\nNA\nMay be supported by envstats package\n\n\n\n\n\n\n\nHere is a table of comparison values between t.test(), proc_ttest(), and SAS PROC TTEST:\n\n\n\n\n\n\n\n\n\n\n\nStatistic\nt.test()\nproc_ttest()\nPROC TTEST\nMatch\nNotes\n\n\n\n\nDegrees of Freedom\n29\n29\n29\nYes\n\n\n\nt value\n2.364306\n2.364306\n2.364306\nYes\n\n\n\np value\n0.0249741\n0.0249741\n0.0249741\nYes\n\n\n\n\n\n\n\nSince there is currently no known support for lognormal t-test in R, this comparison is not applicable."
  },
  {
    "objectID": "Comp/r-sas_ttest_1Sample.html#comparison-results",
    "href": "Comp/r-sas_ttest_1Sample.html#comparison-results",
    "title": "R vs SAS One Sample T-Test",
    "section": "",
    "text": "Here is a table of comparison values between t.test(), proc_ttest(), and SAS PROC TTEST:\n\n\n\n\n\n\n\n\n\n\n\nStatistic\nt.test()\nproc_ttest()\nPROC TTEST\nMatch\nNotes\n\n\n\n\nDegrees of Freedom\n29\n29\n29\nYes\n\n\n\nt value\n2.364306\n2.364306\n2.364306\nYes\n\n\n\np value\n0.0249741\n0.0249741\n0.0249741\nYes\n\n\n\n\n\n\n\nSince there is currently no known support for lognormal t-test in R, this comparison is not applicable."
  },
  {
    "objectID": "Comp/r-sas_summary_skew_kurt.html",
    "href": "Comp/r-sas_summary_skew_kurt.html",
    "title": "R vs SAS Skewness/Kurtosis",
    "section": "",
    "text": "The following table shows the types of Skewness, the capabilities of each language, and whether or not the results from each language match.\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nSkewness, Type 1\nYes\nYes\nYes\nIn e1071, use type = 1.In SAS use vardef = N.\n\n\nSkewness, Type 2\nYes\nYes\nYes\nIn e1071, use type = 2.In SAS use vardef = DF.procs and sasLM use defaults.\n\n\nSkewness, Type 3\nYes\nNo\nNA\nIn e1071, use type = 3.Not supported in SAS.\n\n\n\nNote that the SAS default is Type 2."
  },
  {
    "objectID": "Comp/r-sas_summary_skew_kurt.html#comparison-results",
    "href": "Comp/r-sas_summary_skew_kurt.html#comparison-results",
    "title": "R vs SAS Skewness/Kurtosis",
    "section": "Comparison Results",
    "text": "Comparison Results\n\nSkewness\nHere is a table of Skewness comparison values between the four R packages examined and SAS:\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistic\ne1071\nmoments\nprocs\nsasLM\nSAS\nMatch\nNotes\n\n\n\n\nSkewness, Type 1\n0.9054442\n0.9054442\nNA\nNA\n0.9054442\nYes\n\n\n\nSkewness, Type 2\n1.009318\nNA\n1.009318\n1.009318\n1.0093179\nYes\n\n\n\nSkewness, Type 3\n0.8164261\nNA\nNA\nNA\nNA\nNA\nType 3 not supported in SAS\n\n\n\n\n\nKurtosis\nHere is a table of Kurtosis comparison values between the four R packages examined and SAS:\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistic\ne1071\nmoments\nprocs\nsasLM\nSAS\nMatch\nNotes\n\n\n\n\nKurtosis, Type 1\n-0.5833411\nNA\nNA\nNA\n-0.5833411\nYes\n\n\n\nKurtosis, Type 2\n-0.2991564\nNA\n-0.2991564\n-0.2991564\n-0.2991564\nYes\n\n\n\nKurtosis, Type 3\n-0.8948216\nNA\nNA\nNA\nNA\nNA\nType 3 not supported in SAS\n\n\nKurtosis, Pearson’s\nNA\n2.416659\nNA\nNA\nNA\nNA\nPearson’s not supported in SAS"
  },
  {
    "objectID": "Comp/r-sas_rbmi_continuous_joint.html",
    "href": "Comp/r-sas_rbmi_continuous_joint.html",
    "title": "R vs SAS Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "",
    "text": "The following table shows the types of reference-based multiple imputation (rbmi), the capabilities of each language, and whether or not the results from each language match. The following holds for data that are assumed to be normally distributed. In this comparison, we used the rbmi package in R and the so-called Five macros in SAS.\nThe following assumptions are made in both languages:\n\nEqual unstructured covariance matrix across treatment groups\nSame covariates formula for the imputation and analysis model\nSimilar number of MCMC tuning parameters (burn-in, thinning) was used in the MCMC\nThe one intermittent missingness was imputed under MAR assumption\n\n\n\n\nAnalysis\nSupported in R\nSupported in SAS\nResults Match\nNotes\n\n\n\n\nrbmi - MI MAR\nYes\nYes\nYes\nResults will be (slightly) different given the randomness in multiple imputations\n\n\nrbmi - MI MNAR Copy Reference\nYes\nYes\nYes\nResults will be (slightly) different given the randomness in multiple imputations\n\n\nrbmi - MI MNAR Jump to Reference\nYes\nYes\nYes\nResults will be (slightly) different given the randomness in multiple imputations\n\n\nrbmi - MI MNAR Copy Increments in Reference\nYes\nYes\nYes\nResults will be (slightly) different given the randomness in multiple imputations\n\n\n\n\n\nThe following figure compares the contrast estimate (and associated 95% confidence interval) for the explored dataset per number of multiple imputations M (ie, 500, 2000 and 5000). Note that the complete case analysis is presented across M for completeness. For the contrast estimate the range of the difference between R and SAS results are [-0.29 to 2.21]%, [0.0 to 0.75]% and [-0.25 to 0.19]% for respectively M=500, 2000, 5000.\n\n\n\n\n\n\n\n\n\nCC = Complete Case; MAR = Missing at Random; MNAR = Missing not at Random, CIR = Copy Increments in Reference; CR = Copy Reference; JR = Jump to Reference"
  },
  {
    "objectID": "Comp/r-sas_rbmi_continuous_joint.html#comparison-results",
    "href": "Comp/r-sas_rbmi_continuous_joint.html#comparison-results",
    "title": "R vs SAS Reference-Based Multiple Imputation (joint modelling): Continuous Data",
    "section": "",
    "text": "The following figure compares the contrast estimate (and associated 95% confidence interval) for the explored dataset per number of multiple imputations M (ie, 500, 2000 and 5000). Note that the complete case analysis is presented across M for completeness. For the contrast estimate the range of the difference between R and SAS results are [-0.29 to 2.21]%, [0.0 to 0.75]% and [-0.25 to 0.19]% for respectively M=500, 2000, 5000.\n\n\n\n\n\n\n\n\n\nCC = Complete Case; MAR = Missing at Random; MNAR = Missing not at Random, CIR = Copy Increments in Reference; CR = Copy Reference; JR = Jump to Reference"
  },
  {
    "objectID": "Comp/r-sas_psmatch.html",
    "href": "Comp/r-sas_psmatch.html",
    "title": "Propensity Score Matching",
    "section": "",
    "text": "Propensity score (PS) matching is a statistical technique widely employed in Real World Evidence (RWE) studies to address confounding bias and facilitate the estimation of causal treatment effects. By estimating the probability of treatment assignment based on observed covariates, PS matching aims to create comparable treatment and control groups. While both SAS and R provide methods to do PS matching, the syntax and available options differ considerably, potentially leading to variations in analytical outcomes. The PS matching process generally involves several key stages: first, the estimation of propensity scores using a regression model; second, the specification of a region of common support to ensure overlap between treatment and control groups; and third, the matching of treated and control subjects based on their calculated propensity scores."
  },
  {
    "objectID": "Comp/r-sas_psmatch.html#options",
    "href": "Comp/r-sas_psmatch.html#options",
    "title": "Propensity Score Matching",
    "section": "Options",
    "text": "Options\n\n\n\n\n\n\n\n\nOption\nPROC PSMATCH\nmatchit\n\n\n\n\nDistance\nPS, LPS; only for matching: mahalanobis, euclidean\nPS, euclidean, scaled_euclidean, mahalanobis, robust_mahalanobis\n\n\nPS methods\nlogistic regression\nglm, gam, gbm, lasso, ridge, elasticnet with different links, partitioning tree, RF, single-hidden-layer neural network, covariate balancing propensity score (CBPS) algorithm, Bayesian additive regression trees (BART)\n\n\nRegion\nAlways used; allobs, treated or cs (common support), with allowed extension\nnone, treated, control, both (common support)\n\n\nCaliper\nApplies only to the distance metric, such that distance&lt;=caliper\nCan be applied to both covariates and distance metric. If a positive value is supplied, it functions as in SAS; If a negative value is supplied, it imposes the condition distance &gt; abs(caliper).\n\n\nPS std.dev formula when caliper applied as multiplier\nsqrt((sd(PStrt)2+sd(Pcontrol)2)/2)\nsd(PSall)\n\n\nMatching methods\ngreedy (greedy nn), full, optimal, replace, varratio\nnearest (greedy nn), full, optimal, quick, genetic, cem, exact, cardinality, subclass\n\n\nMethod=optimal options\nOnly K should be supplied\nIn addition to k (number of matches), the tol option can also be specified, and its value can significantly impact the matching results.\n\n\nMethod=full options\nn max controls, n max treated, mean n treated, n controls, pct controls\nn min controls, n max controls, mean n controls, fraction to omit, tol, solver\n\n\nMahalanobis distance\nPS are always calculated to determine the region; only numeric covariates are allowed in MAHVARS option\nmahvars accepts any var type; region calculation is ommited when distance=mahalanobis, but can be performed when distance=glm and mahvars is supplied with a formula\n\n\nCovariance matrix for mahalanobis distance\nComputed from trt obs and control obs\nIs pooled within-group, computed from trt mean-centered covariates of the full sample\n\n\nReplace\nCould be specified only as method=replace; in the output, match IDs are shared among all subjects within a matched set.\nCould be specified as an argument (e.g. replace=TRUE). In the output, each treated subject receives up to K matched controls\n\n\nEstimands\nATT, ATE\nATT, ATE, ATC\n\n\nReestimate\nNot available\nCould be specified as an argument (e.g. reestimate=TRUE)\n\n\nExact, anti-exact\nOnly exact matching is available and can only be performed on variables listed in the CLASS statement.\nBoth exact and anti-exact matching are available, with no restrictions on the variable types.\n\n\nNormalization\nNot available\nCould be specified as an argument (e.g. normalize=TRUE)"
  },
  {
    "objectID": "Comp/r-sas_psmatch.html#output",
    "href": "Comp/r-sas_psmatch.html#output",
    "title": "Propensity Score Matching",
    "section": "Output",
    "text": "Output\nThe way SAS and R show the results of matching is different. The output from SAS matching is presented as a dataset where each treated subject (or all subjects) is given a row, and a match ID column containing a unique pair (or group) identifier is included:\n\n\n\n\nTRTP\n_MatchID\n\n\n\n\n1\ntrt\n1\n\n\n2\ntrt\n2\n\n\n3\ncontrol\n1\n\n\n4\ncontrol\n2\n\n\n\nIn contrast, the matchit() function in R returns a matrix, where each treated unit’s identifier is associated with the identifiers of its k matched control units:\n\n\n\n\n[,1]\n\n\n\n\n1\n“3”\n\n\n2\n“4”\n\n\n\n\nStatistics\nIn SAS, descriptive statistics for assessing balance are primarily generated through the ASSESS statement within PROC PSMATCH. Conversely, in R, balance diagnostics could be obtained by applying the summary() function to the output object returned by the matchit(). The following table summarizes the balance statistics available in SAS and R:\n\n\n\nStat\nAll\nRegion\nMatched\n\n\n\n\nN\nSAS & R\nSAS\nSAS & R\n\n\nPS mean\nSAS & R\nSAS\nSAS & R\n\n\nPS std\nSAS\nSAS\nSAS\n\n\nPS min\nSAS\nSAS\nSAS\n\n\nPS max\nSAS\nSAS\nSAS\n\n\nVars mean\nSAS & R\nSAS\nSAS & R\n\n\nVars std\nSAS\nSAS\nSAS\n\n\nVars min\nSAS\nSAS\nSAS\n\n\nVars max\nSAS\nSAS\nSAS\n\n\nPS mean diff\nSAS\nSAS\nSAS\n\n\nPS SMD\nSAS & R\nSAS\nSAS & R\n\n\nPS perc. red.\nSAS\nSAS\nSAS\n\n\nPS var ratio\nSAS & R\nSAS\nSAS & R\n\n\nVars mean diff\nSAS\nSAS\nSAS\n\n\nVars SMD\nSAS & R\nSAS\nSAS & R\n\n\nVars perc. red.\nSAS\nSAS\nSAS\n\n\nVars var ratio\nSAS & R\nSAS\nSAS & R\n\n\nPS eCDF min\nR\n-\nR\n\n\nPS eCDF max\nR\n-\nR\n\n\nVars eCDF min\nR\n-\nR\n\n\nVars eCDF max\nR\n-\nR\n\n\nPS std pair distance\nR\n-\nR\n\n\nVars std pair distance\nR\n-\nR\n\n\n\n\n\nFigures\n\n\n\n\n\n\n\n\nPlot type\nR\nSAS\n\n\n\n\nLove plot\n\nplot(): -\ncobalt: many different settings.\n\nDisplayed for: all/region/matched/weighted matched, trt/control.\nIncludes PS, all numeric and binary variables.\n\n\nGeneral distribution plots\n\nplot(): Displayed for: all/matched. Includes all variables; numeric - distribution plots, character and factor - histograms.\ncobalt : Highly customizable plots.\n\nDisplayed for: all/region/matched/weighted matched, trt/control.\nIncludes PS and all variables.\nFor PS and numeric - boxplots, character - barplots.\n\n\neCDF plots\nplot():\nDisplayed for: all/matched.\nIncludes all variables.\nDisplayed for: all/region/matched/weighted matched, trt/control.\nIncludes PS and all numeric variables.\n\n\neQQ plots\nplot():\nDisplayed for: all/matched.\nIncludes all variables.\n-\n\n\nCloud plots\nplot():\nDisplayed for: all/matched, trt/control.\nIncludes PS.\nPresented as 4 separate clouds.\nDisplayed for: all/region/matched/weighted matched, trt/control.\nIncludes PS and all numeric variables.\nPresented as 2 separate clouds per variable.\n\n\nPS histogram\n\nplot(): Displayed for: all/matched, trt/control. Includes PS.\ncobalt: Highly customizable plots.\n\n-"
  },
  {
    "objectID": "Comp/r-sas_psmatch.html#greedy-nearest-neighbor-1-to-1-matching-with-common-support-region",
    "href": "Comp/r-sas_psmatch.html#greedy-nearest-neighbor-1-to-1-matching-with-common-support-region",
    "title": "Propensity Score Matching",
    "section": "Greedy Nearest Neighbor 1 to 1 matching with common support region",
    "text": "Greedy Nearest Neighbor 1 to 1 matching with common support region\n\nSAS\n\nproc psmatch data=data region=cs(extend=0);\n    class trtp sex bmi_cat;\n    psmodel trtp(Treated=\"trt\")= sex weight age bmi_cat;\n    match distance=PS \n        method=greedy(k=1 order=descending) \n        caliper(MULT=ONE)=0.25;\n    output out(obs=match)=ps_res matchid=_MatchID ps=_PScore;\nrun;\n\n\n\nR\n\nlibrary(MatchIt)\n\nps_res &lt;- MatchIt::matchit(\n  trtp ~ sex + weight + age + bmi_cat,\n  data = data,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  discard = \"both\",\n  m.order = \"largest\",\n  replace = FALSE,\n  caliper = 0.25,\n  std.caliper = FALSE,\n  ratio = 1,\n  normalize = FALSE\n)\n\nThe following arguments, when altered in the previous example, can still produce matching results comparable between SAS and R:\n\nregion (discard)\ncaliper value\norder\nk (ratio)\nexact"
  },
  {
    "objectID": "Comp/r-sas_psweight.html",
    "href": "Comp/r-sas_psweight.html",
    "title": "Propensity Score Weighting",
    "section": "",
    "text": "Propensity score (PS) weighting is a statistical technique widely employed in Real World Evidence (RWE) studies to address confounding bias and facilitate the estimation of causal treatment effects. By using the estimated probability of treatment assignment to create weights, PS weighting aims to balance the observed covariates across treatment groups. While both SAS and R provide methods to do PS weighting, the syntax and available options differ considerably. The PS weighting process generally involves several key stages: first, the estimation of propensity scores using a regression model; second, the calculation of weights for each subject based on their propensity score; and third, the use of these weights in the analysis of choice."
  },
  {
    "objectID": "Comp/r-sas_psweight.html#options",
    "href": "Comp/r-sas_psweight.html#options",
    "title": "Propensity Score Weighting",
    "section": "Options",
    "text": "Options\n\n\n\n\n\n\n\n\nOption\nPROC PSMATCH\nweightit\n\n\n\n\nPS methods\nlogistic regression\nglm, gbm, covariate balancing propensity score (CBPS) algorithm, non-parametric CBPS, entropy balancing, inverse probability tilting, optimization-based weighting, PS weighting using SuperLearner, bayesian additive regression trees (BART), energy balancing\n\n\nEstimands\nATT, ATE\nATT, ATE, ATC, for some methods ATO, ATM, ATOS\n\n\nRegion\nAlways used; allobs, treated or cs (common support), with allowed extension\nNot available\n\n\nStabilize weights\nAvailable as logical, only for ATE\nAvailable as logical or formula when used with continuous treatments or when estimand is ATE\n\n\nMoments\nNot available\nSome methods allows to set the greatest power of each covariate to be balanced\n\n\nInteractions\nNot available\nSome methods allows to set the first-order interactions of the covariates to be balanced"
  },
  {
    "objectID": "Comp/r-sas_psweight.html#output",
    "href": "Comp/r-sas_psweight.html#output",
    "title": "Propensity Score Weighting",
    "section": "Output",
    "text": "Output\nThe way SAS and R output the weights is similar - they are given as a column (SAS) / vector in the output list (R) with a computed weight for each observation. However, seems to be due to the different rounding rules, the PS weights may differ on the last digit.\n\nStatistics\nIn SAS, descriptive statistics for assessing balance are primarily generated through the ASSESS statement within PROC PSMATCH. Conversely, in R, descriptive statistics for weights could be obtained by applying the summary() function to the output object returned by the weightit(). The balance assessment after weighting could be performed using the cobalt package. The following table summarizes the statistics available in SAS and R:\n\n\n\nStat or info\nSAS\nR\n\n\n\n\nN\n+\n+\n\n\nWeights range\n-\n+\n\n\nExtreme weights\n+\n+\n\n\nESS\n-\n+\n\n\nCoefficient of Variation\n-\n+\n\n\nMean absolute deviation\n-\n+\n\n\nNegative Entropy\n-\n+\n\n\nNumber of zero weights\n-\n+\n\n\nWeighted covariates stats\n+\n-*\n\n\n\n*available from cobalt package\n\n\nFigures\n\n\n\n\n\n\n\n\nPlot type\nR\nSAS\n\n\n\n\nLove plot\n\nplot(): -\ncobalt: many different settings.\n\nDisplayed for: all/region/matched/weighted matched, trt/control.\nIncludes PS, all numeric and binary variables.\n\n\nGeneral distribution plots\n\nplot(): -\ncobalt : Highly customizable plots.\n\nDisplayed for: all/region/weighted, trt/control.\nIncludes PS and all variables.\nFor PS and numeric - boxplots, character - barplots.\n\n\neCDF plots\nplot(): -\nDisplayed for: all/region/weighted, trt/control.\nIncludes PS and all numeric variables.\n\n\nCloud plots\nplot(): -\nDisplayed for: all/region, trt/control.\nIncludes PS, weights and all numeric variables.\nPresented as 2 separate clouds per variable.\n\n\nPS weights histogram\n\nplot(): Displayed for: trt/control. Includes PS weigths.\ncobalt: Highly customizable plots.\n\n-"
  },
  {
    "objectID": "Comp/r-sas_psweight.html#average-treatment-effect-in-treated-att",
    "href": "Comp/r-sas_psweight.html#average-treatment-effect-in-treated-att",
    "title": "Propensity Score Weighting",
    "section": "Average Treatment Effect in Treated (ATT)",
    "text": "Average Treatment Effect in Treated (ATT)\n\nSAS\nproc psmatch data=data;\n    class trtp sex bmi_cat;\n    psmodel trtp(Treated=\"trt\")= sex weight age bmi_cat;\n    psweight weight=ATTWGT;\n    output out(obs=all)=ps_res ps=_PScore weight=_PSweight;\nrun;\n\n\nR\nps_res &lt;- weightit(trtp ~ sex + weight + age + bmi_cat,\n                    data=data_gen,\n                    method=\"glm\",\n                    estimand=\"ATT\",\n                    focal=\"trt\")"
  },
  {
    "objectID": "Comp/r-sas_psweight.html#average-treatment-effect-ate",
    "href": "Comp/r-sas_psweight.html#average-treatment-effect-ate",
    "title": "Propensity Score Weighting",
    "section": "Average Treatment Effect (ATE)",
    "text": "Average Treatment Effect (ATE)\n\nSAS\nproc psmatch data=data;\n    class trtp sex bmi_cat;\n    psmodel trtp(Treated=\"trt\")= sex weight age bmi_cat;\n    psweight weight=ATEWGT;\n    output out(obs=all)=ps_res ps=_PScore weight=_PSweight;\nrun;\n\n\nR\nps_res &lt;- weightit(trtp ~ sex + weight + age + bmi_cat,\n                    data=data_gen,\n                    method=\"glm\",\n                    estimand=\"ATE\")"
  },
  {
    "objectID": "Comp/r-sas_psweight.html#average-treatment-effect-ate-stabilized-weights",
    "href": "Comp/r-sas_psweight.html#average-treatment-effect-ate-stabilized-weights",
    "title": "Propensity Score Weighting",
    "section": "Average Treatment Effect (ATE), stabilized weights",
    "text": "Average Treatment Effect (ATE), stabilized weights\n\nSAS\nproc psmatch data=data;\n    class trtp sex bmi_cat;\n    psmodel trtp(Treated=\"trt\")= sex weight age bmi_cat;\n    psweight weight=ATEWGT(stabilize=YES);\n    output out(obs=all)=ps_res ps=_PScore weight=_PSweight;\nrun;\n\n\nR\nps_res &lt;- weightit(trtp ~ sex + weight + age + bmi_cat,\n                    data=data_gen,\n                    method=\"glm\",\n                    estimand=\"ATE\",\n                    stabilize=TRUE)"
  },
  {
    "objectID": "Comp/r-sas-wilcoxon-ranksum_hl.html",
    "href": "Comp/r-sas-wilcoxon-ranksum_hl.html",
    "title": "R vs SAS Wilcoxon Rank-Sum Test",
    "section": "",
    "text": "This page compares the Wilcoxon rank-sum test, Hodges-Lehmann estimator, and estimation of the Mann-Whitney parameter in R and SAS.\n\n\nFor this example we are using a dataset of birth weights for smoking and non-smoking mothers (Data source: Table 30.4, Kirkwood BR. and Sterne JAC. Essentials of medical statistics. Second Edition. ISBN 978-0-86542-871-3). This dataset is both small (so an exact test is recommended) and has ties in it.\n\nbw_ns &lt;- c(3.99, 3.89, 3.6, 3.73, 3.31, \n            3.7, 4.08, 3.61, 3.83, 3.41, \n            4.13, 3.36, 3.54, 3.51, 2.71)\nbw_s &lt;- c(3.18, 2.74, 2.9, 3.27, 3.65, \n           3.42, 3.23, 2.86, 3.6, 3.65, \n           3.69, 3.53, 2.38, 2.34)\n\nsmk_data &lt;- data.frame(\n  value = c(bw_ns, bw_s), \n  smoke = as.factor(rep(c(\"non\", \"smoke\"), c(length(bw_ns), length(bw_s))))\n) \n# Relevel the factors to make it smoker - non-smokers \nsmk_data$smoke &lt;- forcats::fct_relevel(smk_data$smoke, \"smoke\")\nhead(smk_data)\n\n  value smoke\n1  3.99   non\n2  3.89   non\n3  3.60   non\n4  3.73   non\n5  3.31   non\n6  3.70   non\n\n\nTo view the code implementations, see the SAS and R pages, respectively."
  },
  {
    "objectID": "Comp/r-sas-wilcoxon-ranksum_hl.html#introduction",
    "href": "Comp/r-sas-wilcoxon-ranksum_hl.html#introduction",
    "title": "R vs SAS Wilcoxon Rank-Sum Test",
    "section": "",
    "text": "This page compares the Wilcoxon rank-sum test, Hodges-Lehmann estimator, and estimation of the Mann-Whitney parameter in R and SAS.\n\n\nFor this example we are using a dataset of birth weights for smoking and non-smoking mothers (Data source: Table 30.4, Kirkwood BR. and Sterne JAC. Essentials of medical statistics. Second Edition. ISBN 978-0-86542-871-3). This dataset is both small (so an exact test is recommended) and has ties in it.\n\nbw_ns &lt;- c(3.99, 3.89, 3.6, 3.73, 3.31, \n            3.7, 4.08, 3.61, 3.83, 3.41, \n            4.13, 3.36, 3.54, 3.51, 2.71)\nbw_s &lt;- c(3.18, 2.74, 2.9, 3.27, 3.65, \n           3.42, 3.23, 2.86, 3.6, 3.65, \n           3.69, 3.53, 2.38, 2.34)\n\nsmk_data &lt;- data.frame(\n  value = c(bw_ns, bw_s), \n  smoke = as.factor(rep(c(\"non\", \"smoke\"), c(length(bw_ns), length(bw_s))))\n) \n# Relevel the factors to make it smoker - non-smokers \nsmk_data$smoke &lt;- forcats::fct_relevel(smk_data$smoke, \"smoke\")\nhead(smk_data)\n\n  value smoke\n1  3.99   non\n2  3.89   non\n3  3.60   non\n4  3.73   non\n5  3.31   non\n6  3.70   non\n\n\nTo view the code implementations, see the SAS and R pages, respectively."
  },
  {
    "objectID": "Comp/r-sas-wilcoxon-ranksum_hl.html#comparison",
    "href": "Comp/r-sas-wilcoxon-ranksum_hl.html#comparison",
    "title": "R vs SAS Wilcoxon Rank-Sum Test",
    "section": "Comparison",
    "text": "Comparison\n\nSoftware Capabilities\nThe following table provides an overview of the supported analyses between R and SAS. A specific comparison of the results and whether they match are provided below.\n\n\n\n\n\n\n\n\n\n\n\nAnalysis\nSupported in R {stats}\nSupported in R {coin}\nSupported in R {asht}\nSupported in SAS\nNotes\n\n\n\n\nWilcoxon Rank-Sum – Normal approximation with continuity correction\nYes\nNo\nYes\nYes\nIn {coin}, one can add correct=TRUE, but note that no error is given and the results of a normal approximation approach without continuity correction are provided.\n\n\nWilcoxon Rank-Sum – Normal approximation without continuity correction\nYes\nYes\nYes\nYes\n\n\n\nWilcoxon Rank-Sum – Exact\nPartly\nYes\nPartly\nYes\nIn {stats}, one can only do the exact method when no ties are present.; In {asht}, exact test is possible but the run time is long for larger sample size.\n\n\nWilcoxon Rank-Sum – Approximative (Monte Carlo simulation)\nNo\nYes\nYes\nNo\n\n\n\nHodges-Lehmann estimator – Asymptotic\nYes\nNo\nNo\nYes\n\n\n\nHodges-Lehmann estimator – Exact\nPartly\nYes\nNo\nYes\nIn {stats}, one can only do the exact method when no ties are present.\n\n\nHodges-Lehmann estimator – Approximative (Monte Carlo simulation)\nNo\nYes\nNo\nNo\n\n\n\nMann-Whitney parameter\nNo\nNo\nYes\nNo\nIn {asht}, confidence intervals can be obtained using asymptotic approximation, Monte Carlo simulations, or exact methods (for small sample size)\n\n\n\n\n\nWilcoxon Rank Sum test\nIn the below table the p-values of the Wilcoxon Rank Sum Test with different options are compared.\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis\nR {stats}\nR {coin}\nR {asht}\nSAS\nMatch\nNotes\n\n\n\n\nWilcoxon Rank-Sum – Normal approximation with continuity correction\n0.0100\n/\n0.0100\n0.0100\nYes\nNot possible with {coin}\n\n\nWilcoxon Rank-Sum – Normal approximation without continuity correction\n0.0094\n0.0094\n0.0094\n0.0094\nYes\n\n\n\nWilcoxon Rank-Sum – Exact\n/\n0.0082\n/\n0.0082\nYes\nNot possible with {stats} since there are ties.; In {asht} run-time very long.\n\n\nWilcoxon Rank-Sum – Approximative (Monte Carlo simulation)\n/\n0.0083\n0.0083\n/\nYes\nWith 100,000 simulations\n\n\n\n\n\nHodges-Lehmann estimator\nIn the below table the Hodges-Lehmann estimate and 95% confidence intervals are compared.\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis\nR {stats}\nR {coin}\nR {asht}\nSAS\nMatch\nNotes\n\n\n\n\nHodges-Lehmann estimator – Asymptotic\n-0.426 (-0.770 to -0.090)\n-0.426 (-0.760 to -0.100)\n/\n-0.425 (-0.770 to -0.090)\nNo\nIn {coin}, the CI is the exact CI. The CIs match between {stats} and SAS.\n\n\nHodges-Lehmann estimator – Exact\n/\n-0.425 (-0.760 to -0.100)\n/\n-0.425 (-0.760 to -0.100)\nYes\nNot possible with {stats} since there are ties; In {asht} run-time very long.\n\n\nHodges-Lehmann estimator – Approximative (Monte Carlo simulation)\n/\n-0.425 (-0.760 to -0.100)\n/\n/\n/\nWith 500,000 simulations\n\n\n\n\n\nMann-Whitney Parameter\nThe estimation of the Mann-Whitney parameter is only possible in R asht package."
  },
  {
    "objectID": "Comp/r-sas-wilcoxon-ranksum_hl.html#special-considerations-for-one-sided-p-values",
    "href": "Comp/r-sas-wilcoxon-ranksum_hl.html#special-considerations-for-one-sided-p-values",
    "title": "R vs SAS Wilcoxon Rank-Sum Test",
    "section": "Special considerations for one-sided p-values",
    "text": "Special considerations for one-sided p-values\nIt is important to note that in SAS you can get an unexpected one-sided p-value. In the SAS documentation for PROC NPAR1WAY it is stated that:\n“PROC NPAR1WAY computes one-sided and two-sided asymptotic p-values for each two-sample linear rank test. When the test statistic z is greater than its null hypothesis expected value of 0, PROC NPAR1WAY computes the right-sided p-value, which is the probability of a larger value of the statistic occurring under the null hypothesis. When the test statistic is less than or equal to 0, PROC NPAR1WAY computes the left-sided p-value, which is the probability of a smaller value of the statistic occurring under the null hypothesis” (similar for the exact p-value).\nThus SAS reports the one-sided p-value in the direction of the test statistic. This can cause an unexpected one-sided p-value, if your data provides a test statistic in the other direction of the pre-specified one-sided hypothesis.\nConsider the following data example to showcase this:\n\ndat_used &lt;- data.frame(\n  ID = c(\"001\", \"002\", \"003\", \"004\", \"005\", \"006\", \"007\", \"008\", \"009\", \"010\",\n         \"011\", \"012\", \"013\", \"014\", \"015\", \"016\", \"017\", \"018\", \"019\", \"020\",\n         \"021\", \"022\", \"023\", \"024\", \"025\", \"026\", \"027\", \"028\", \"029\", \"030\"),\n  ARM = c(\"Placebo\", \"Placebo\", \"Placebo\", \"Placebo\", \"Placebo\", \"Placebo\", \"Placebo\", \"Placebo\", \"Placebo\", \"Placebo\",\n          \"Low\", \"Low\", \"Low\", \"Low\", \"Low\", \"Low\", \"Low\", \"Low\", \"Low\", \"Low\",\n          \"High\", \"High\", \"High\", \"High\", \"High\", \"High\", \"High\", \"High\", \"High\", \"High\"),\n  Y = c(8.5, 8.9, 8.2, 8.1, 7.1, 7.4, 6.0, 6.5, 7.0, 7.0,\n        6.5, 9.4, 8.9, 8.8, 9.6, 8.3, 8.9, 7.0, 9.1, 6.9,\n        8.0, 7.3, 7.1, 6.2, 4.7, 4.7, 4.2, 4.1, 3.4, 3.9)\n)\ndat_used\n\n    ID     ARM   Y\n1  001 Placebo 8.5\n2  002 Placebo 8.9\n3  003 Placebo 8.2\n4  004 Placebo 8.1\n5  005 Placebo 7.1\n6  006 Placebo 7.4\n7  007 Placebo 6.0\n8  008 Placebo 6.5\n9  009 Placebo 7.0\n10 010 Placebo 7.0\n11 011     Low 6.5\n12 012     Low 9.4\n13 013     Low 8.9\n14 014     Low 8.8\n15 015     Low 9.6\n16 016     Low 8.3\n17 017     Low 8.9\n18 018     Low 7.0\n19 019     Low 9.1\n20 020     Low 6.9\n21 021    High 8.0\n22 022    High 7.3\n23 023    High 7.1\n24 024    High 6.2\n25 025    High 4.7\n26 026    High 4.7\n27 027    High 4.2\n28 028    High 4.1\n29 029    High 3.4\n30 030    High 3.9\n\n\nSuppose we would have the following two hypothesis, where for both Low Dose and High Dose we expect smaller values (Y) than Placebo:\n\n\\(H_{0}\\): No difference between Placebo and Low Dose, vs \\(H_{1}\\): Placebo has higher values (Y) than Low Dose\n\\(H_{0}\\): No difference between Placebo and High Dose, vs \\(H_{1}\\): Placebo has higher values (Y) than High Dose\n\n\nAsymptotic results without continuity correction\nPlacebo and High Dose group\nLet us the {coin} package in R to compare the Placebo and High Dose group:\n\n# Note: greater implies that H1 is Y1 - Y2 = Placebo - High &gt; 0\ncoin::wilcox_test(\n  Y ~ factor(ARM, levels = c(\"Placebo\", \"High\")),\n  distribution = \"asymptotic\",\n  alternative = \"greater\",\n  data = dat_used %&gt;% dplyr::filter(ARM %in% c(\"Placebo\", \"High\")))\n\n\n    Asymptotic Wilcoxon-Mann-Whitney Test\n\ndata:  Y by\n     factor(ARM, levels = c(\"Placebo\", \"High\")) (Placebo, High)\nZ = 2.5352, p-value = 0.005619\nalternative hypothesis: true mu is greater than 0\n\n\nIn SAS, the following results is obtained. As can be seen in both R and SAS the one-sided p-value is 0.0056.\n\n\n\n\n\n\n\n\n\nPlacebo and Low Dose group\nLet us the {coin} package in R to compare the Placebo and Low Dose group:\n\n# Note: greater implies that H1 is Y1 - Y2 = Placebo - High &gt; 0\ncoin::wilcox_test(\n  Y ~ factor(ARM, levels = c(\"Placebo\", \"Low\")),\n  distribution = \"asymptotic\",\n  alternative = \"greater\",\n  data = dat_used %&gt;% dplyr::filter(ARM %in% c(\"Placebo\", \"Low\")))\n\n\n    Asymptotic Wilcoxon-Mann-Whitney Test\n\ndata:  Y by\n     factor(ARM, levels = c(\"Placebo\", \"Low\")) (Placebo, Low)\nZ = -1.7066, p-value = 0.9561\nalternative hypothesis: true mu is greater than 0\n\n\nIn SAS, the following results is obtained. The one-sided p-values clearly do not match ({coin} p-value = 0.9561; SAS p-value = 0.0439). As mentioned above, SAS reports the p-value in the direction of the test statistic. This can cause an unexpected one-sided p-value, if your data provides a test statistic in the other directiont than the pre-specified one-sided hypothesis. Do note that \\(1 - 0.9561 = 0.0439\\).\n\n\n\n\n\n\n\n\n\n\n\nExact results\nPlacebo and High Dose group\nLet us the {coin} package in R to compare the Placebo and High Dose group:\n\n# Note: greater implies that H1 is Y1 - Y2 = Placebo - High &gt; 0\ncoin::wilcox_test(\n  Y ~ factor(ARM, levels = c(\"Placebo\", \"High\")),\n  distribution = \"exact\",\n  alternative = \"greater\",\n  data = dat_used %&gt;% dplyr::filter(ARM %in% c(\"Placebo\", \"High\")))\n\n\n    Exact Wilcoxon-Mann-Whitney Test\n\ndata:  Y by\n     factor(ARM, levels = c(\"Placebo\", \"High\")) (Placebo, High)\nZ = 2.5352, p-value = 0.004682\nalternative hypothesis: true mu is greater than 0\n\n\nIn SAS (see above), the same one-sided p-value of 0.0047 is obtained.\nPlacebo and Low Dose group\nLet us the {coin} package in R to compare the Placebo and Low Dose group:\n\n# Note: greater implies that H1 is Y1 - Y2 = Placebo - High &gt; 0\ncoin::wilcox_test(\n  Y ~ factor(ARM, levels = c(\"Placebo\", \"Low\")),\n  distribution = \"exact\",\n  alternative = \"greater\",\n  data = dat_used %&gt;% dplyr::filter(ARM %in% c(\"Placebo\", \"Low\")))\n\n\n    Exact Wilcoxon-Mann-Whitney Test\n\ndata:  Y by\n     factor(ARM, levels = c(\"Placebo\", \"Low\")) (Placebo, Low)\nZ = -1.7066, p-value = 0.9574\nalternative hypothesis: true mu is greater than 0\n\n\nPlease see above for the SAS result. The one-sided p-values clearly do not match ({coin} p-value = 0.9574; SAS p-value = 0.0455)."
  },
  {
    "objectID": "Comp/r-sas-wilcoxon-ranksum_hl.html#summary-and-recommendation",
    "href": "Comp/r-sas-wilcoxon-ranksum_hl.html#summary-and-recommendation",
    "title": "R vs SAS Wilcoxon Rank-Sum Test",
    "section": "Summary and Recommendation",
    "text": "Summary and Recommendation\nWilcoxon Rank Sum test and the associated Hodges-Lehmann CI are able to be consistently computed in both SAS and R. The user needs to be aware of some small differences:\n\nIn SAS the exact wilcoxon hl statement is needed to get both the exact p-value and CI.\nIn {stats} exact values are only possible when there are no ties and the exact parameter is set to true (exact = TRUE). This will give the exact p-value and CI.\nIn {coin} it is not possible to do a normal approximation with continuity correction.\nFor the asymptotic Hodges-Lehmann estimator, {stats} and {coin} use an algorithm to define the estimate, whereas SAS provides the traditional Hodges-Lehmann estimator.\n\nIf you have a study where you would like to use R for the exact Wilcoxon Rank Sum test and there is the risk of ties, {coin} would be recommended."
  },
  {
    "objectID": "Comp/r-sas-wilcoxon-ranksum_hl.html#ties",
    "href": "Comp/r-sas-wilcoxon-ranksum_hl.html#ties",
    "title": "R vs SAS Wilcoxon Rank-Sum Test",
    "section": "Ties",
    "text": "Ties\nIn all presented R packages and SAS, when there are tied values, the average score method (mid-ranks) is used. This is done by first sorting the observations in ascending order and assigning ranks as if there were no ties. The procedure averages the scores for tied observations and assigns this average score to each of the tied observations. Thus, all tied data values have the same score value."
  },
  {
    "objectID": "Comp/r-sas-wilcoxon-ranksum_hl.html#additional-references",
    "href": "Comp/r-sas-wilcoxon-ranksum_hl.html#additional-references",
    "title": "R vs SAS Wilcoxon Rank-Sum Test",
    "section": "Additional References",
    "text": "Additional References\nProvided are references and additional reading materials for both R and SAS documentation related to the analysis.\nR Documentation:\n\nwilcox.test function: https://rdrr.io/r/stats/wilcox.test.html\nwilcox_test function: https://rdrr.io/cran/coin/man/LocationTests.html\n\nSAS Documentation:\n\nPROC npar1way: https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_npar1way_gettingstarted.htm\n\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sequoia 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2025-10-13\n pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package * version date (UTC) lib source\n P coin    * 1.4-3   2023-09-27 [?] CRAN (R 4.4.0)\n\n [1] /Users/christinafillmore/Documents/GitHub/CAMIS/renv/library/macos/R-4.4/aarch64-apple-darwin20\n [2] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n P ── Loaded and on-disk path mismatch.\n\n─ External software ──────────────────────────────────────────────────────────\n setting value\n SAS     9.04.01M7P080520\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "templates/single_language_template.html",
    "href": "templates/single_language_template.html",
    "title": "(Language): (Method Name)",
    "section": "",
    "text": "This first section should provide a brief background on the methodology with links to associated journal articles, or relevant sources. This should give the reader a high level overview of the method and its implementation. This will be helpful in setting the stage for the examples and discussion that follow."
  },
  {
    "objectID": "templates/single_language_template.html#example-code-using-package-name",
    "href": "templates/single_language_template.html#example-code-using-package-name",
    "title": "(Language): (Method Name)",
    "section": "Example Code using < package name >",
    "text": "Example Code using &lt; package name &gt;\nNow you can start adding specific examples of how to use these packages or methods to conduct the analysis. It is helpful to include some notes and comments throughout.\nFor R packages, it is helpful to prepend package names to functions so new readers can understand where specific functions originate, especially with new packages.\n\n# For R packages\nlme4::lmer()\n\nsurvival::Surv()"
  },
  {
    "objectID": "templates/single_language_template.html#comparison-of-packages",
    "href": "templates/single_language_template.html#comparison-of-packages",
    "title": "(Language): (Method Name)",
    "section": "Comparison of Packages",
    "text": "Comparison of Packages\nIf you are comparing more than one package of a single language, consider adding in a table to illustrate some of the differences/similarities between the packages/methods."
  },
  {
    "objectID": "templates/single_language_template.html#conclusion",
    "href": "templates/single_language_template.html#conclusion",
    "title": "(Language): (Method Name)",
    "section": "Conclusion",
    "text": "Conclusion\nFinally, add a conclusion section to the page. This may take on different forms but should broadly summarize the findings in the comparison of languages, packages, or approaches. In summarizing, be sure to include the advantages/limitations of the packages and approaches so the reader can understand the capabilities of the approaches to the statstical methodology.\nThere may be instances where you recommend specific languages, packages, or functions. Be sure to provide your rationale for these recommendations."
  },
  {
    "objectID": "templates/single_language_template.html#references",
    "href": "templates/single_language_template.html#references",
    "title": "(Language): (Method Name)",
    "section": "References",
    "text": "References\nBe sure to include any references or sources used for the analysis here. These could be external links to pages or in-text citations. This will all help the reader find material needed for further evaluation.\nAlso, include this Session Info section. Manually add the packages used in your analysis in a vector, like shown below. This captures the environment used, which is important for reproducibility.\n\n\n\n\n\n\nNoteSession Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       Ubuntu 24.04.3 LTS\n system   x86_64, linux-gnu\n ui       X11\n language (EN)\n collate  C.UTF-8\n ctype    C.UTF-8\n tz       UTC\n date     2025-10-17\n pandoc   3.6.3 @ /opt/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package  * version date (UTC) lib source\n janitor    2.2.0   2023-02-02 [1] RSPM (R 4.4.0)\n readr      2.1.5   2024-01-10 [1] RSPM (R 4.4.0)\n survival   3.7-0   2024-06-05 [2] CRAN (R 4.4.2)\n\n [1] /home/runner/work/CAMIS/CAMIS/renv/library/linux-ubuntu-noble/R-4.4/x86_64-pc-linux-gnu\n [2] /opt/R/4.4.2/lib/R/library\n\n─ Python configuration ───────────────────────────────────────────────────────\n python:         /home/runner/work/CAMIS/CAMIS/renv/python/virtualenvs/renv-python-3.12/bin/python\n libpython:      /usr/lib/python3.12/config-3.12-x86_64-linux-gnu/libpython3.12.so\n pythonhome:     /home/runner/work/CAMIS/CAMIS/renv/python/virtualenvs/renv-python-3.12:/home/runner/work/CAMIS/CAMIS/renv/python/virtualenvs/renv-python-3.12\n version:        3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0]\n numpy:          /home/runner/work/CAMIS/CAMIS/renv/python/virtualenvs/renv-python-3.12/lib/python3.12/site-packages/numpy\n numpy_version:  2.0.1\n \n NOTE: Python version was forced by RETICULATE_PYTHON\n\n──────────────────────────────────────────────────────────────────────────────"
  }
]